üîù Retour au [Sommaire](/SOMMAIRE.md)

# 4.2.4 Cas d'usage : Top N, moyenne mobile, cumuls

> **Niveau** : Avanc√©
> **Dur√©e estim√©e** : 3-4 heures
> **Pr√©requis** : Ma√Ætrise compl√®te des sections 4.2, 4.2.1, 4.2.2 et 4.2.3

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Impl√©menter des requ√™tes Top N performantes et flexibles
- Calculer diff√©rents types de moyennes mobiles (SMA, WMA, EMA)
- Cr√©er des cumuls et agr√©gations progressives
- Appliquer des patterns r√©utilisables pour des besoins analytiques courants
- Combiner plusieurs window functions pour des analyses complexes
- Optimiser les requ√™tes analytiques en production

---

## Introduction

Cette section pr√©sente des **patterns r√©utilisables** pour r√©soudre des probl√®mes analytiques courants en production. Chaque cas d'usage est accompagn√© d'exemples concrets, de variations et de conseils d'optimisation.

üí° **Philosophie** : Ces patterns sont des points de d√©part √† adapter selon vos besoins sp√©cifiques. La ma√Ætrise des window functions r√©side dans la capacit√© √† combiner et personnaliser ces techniques.

---

## 1. Top N : S√©lectionner les meilleurs √©l√©ments

### Pattern de base : Top N simple

```sql
-- Top 5 des produits les plus vendus
WITH produits_classes AS (
    SELECT
        produit_id,
        nom,
        quantite_vendue,
        ROW_NUMBER() OVER (ORDER BY quantite_vendue DESC) AS rang
    FROM produits
)
SELECT
    rang,
    produit_id,
    nom,
    quantite_vendue
FROM produits_classes
WHERE rang <= 5
ORDER BY rang;
```

### Variation 1 : Top N par cat√©gorie

```sql
-- Top 3 des produits les plus chers par cat√©gorie
WITH produits_par_categorie AS (
    SELECT
        categorie,
        produit_id,
        nom,
        prix,
        ROW_NUMBER() OVER (
            PARTITION BY categorie
            ORDER BY prix DESC
        ) AS rang_categorie
    FROM produits
)
SELECT
    categorie,
    rang_categorie,
    nom,
    prix
FROM produits_par_categorie
WHERE rang_categorie <= 3
ORDER BY categorie, rang_categorie;
```

**R√©sultat :**
```
| categorie    | rang_categorie | nom         | prix   |
|--------------|----------------|-------------|--------|
| Ordinateurs  | 1              | MacBook Pro | 2499   |
| Ordinateurs  | 2              | Dell XPS    | 1899   |
| Ordinateurs  | 3              | Lenovo X1   | 1599   |
| Smartphones  | 1              | iPhone 15   | 999    |
| Smartphones  | 2              | Galaxy S24  | 899    |
| Smartphones  | 3              | Pixel 8     | 699    |
```

### Variation 2 : Top N avec ex-aequo (RANK vs ROW_NUMBER)

```sql
-- Top 5 incluant les ex-aequo en 5√®me position
WITH classement_ventes AS (
    SELECT
        vendeur,
        total_ventes,
        RANK() OVER (ORDER BY total_ventes DESC) AS rang
    FROM (
        SELECT
            vendeur,
            SUM(montant) AS total_ventes
        FROM ventes
        WHERE YEAR(date_vente) = 2024
        GROUP BY vendeur
    ) ventes_2024
)
SELECT
    rang,
    vendeur,
    total_ventes,
    ROUND(total_ventes / SUM(total_ventes) OVER () * 100, 2) AS pct_total
FROM classement_ventes
WHERE rang <= 5
ORDER BY rang, vendeur;
```

üí° **Choix RANK vs ROW_NUMBER** :
- **ROW_NUMBER()** : Exactement N r√©sultats, m√™me avec ex-aequo
- **RANK()** : Peut retourner plus de N r√©sultats si ex-aequo en position N
- **DENSE_RANK()** : Garantit N valeurs distinctes (mais possiblement plus de N lignes)

### Variation 3 : Top N avec contexte enrichi

```sql
-- Top 10 des produits avec statistiques comparatives
WITH produits_enrichis AS (
    SELECT
        produit_id,
        nom,
        categorie,
        quantite_vendue,
        prix,
        ROW_NUMBER() OVER (ORDER BY quantite_vendue DESC) AS rang_global,
        ROW_NUMBER() OVER (PARTITION BY categorie ORDER BY quantite_vendue DESC) AS rang_categorie,
        -- Statistiques globales
        AVG(quantite_vendue) OVER () AS ventes_moyenne_globale,
        MAX(quantite_vendue) OVER () AS ventes_max_globale,
        -- Statistiques par cat√©gorie
        AVG(quantite_vendue) OVER (PARTITION BY categorie) AS ventes_moyenne_categorie,
        -- Percentile
        PERCENT_RANK() OVER (ORDER BY quantite_vendue) AS percentile
    FROM produits
)
SELECT
    rang_global,
    nom,
    categorie,
    quantite_vendue,
    prix,
    ROUND(quantite_vendue / ventes_moyenne_globale, 2) AS ratio_vs_moyenne,
    ROUND(quantite_vendue / ventes_max_globale * 100, 2) AS pct_du_max,
    ROUND(percentile * 100, 2) AS percentile_pct,
    rang_categorie
FROM produits_enrichis
WHERE rang_global <= 10
ORDER BY rang_global;
```

### Variation 4 : Bottom N et Top N combin√©s

```sql
-- Top 5 et Bottom 5 des performances de vendeurs
WITH classement AS (
    SELECT
        vendeur,
        total_ventes,
        ROW_NUMBER() OVER (ORDER BY total_ventes DESC) AS rang_desc,
        ROW_NUMBER() OVER (ORDER BY total_ventes ASC) AS rang_asc,
        COUNT(*) OVER () AS total_vendeurs
    FROM (
        SELECT vendeur, SUM(montant) AS total_ventes
        FROM ventes
        WHERE date_vente >= CURRENT_DATE - INTERVAL 1 YEAR
        GROUP BY vendeur
    ) v
)
SELECT
    CASE
        WHEN rang_desc <= 5 THEN CONCAT('üèÜ Top ', rang_desc)
        WHEN rang_asc <= 5 THEN CONCAT('‚ö†Ô∏è Bottom ', rang_asc)
    END AS position,
    vendeur,
    total_ventes,
    ROUND(total_ventes / (SUM(total_ventes) OVER () / COUNT(*) OVER ()) * 100, 2) AS index_performance
FROM classement
WHERE rang_desc <= 5 OR rang_asc <= 5
ORDER BY total_ventes DESC;
```

### Variation 5 : Top N avec filtres dynamiques

```sql
-- Top produits par cat√©gorie, seulement si la cat√©gorie a assez de produits
WITH stats_categories AS (
    SELECT
        categorie,
        COUNT(*) AS nb_produits,
        AVG(prix) AS prix_moyen
    FROM produits
    GROUP BY categorie
),
top_par_categorie AS (
    SELECT
        p.categorie,
        p.produit_id,
        p.nom,
        p.prix,
        p.quantite_vendue,
        s.nb_produits,
        s.prix_moyen,
        ROW_NUMBER() OVER (
            PARTITION BY p.categorie
            ORDER BY p.quantite_vendue DESC
        ) AS rang
    FROM produits p
    JOIN stats_categories s ON p.categorie = s.categorie
    WHERE s.nb_produits >= 5  -- Cat√©gorie avec au moins 5 produits
)
SELECT
    categorie,
    rang,
    nom,
    prix,
    quantite_vendue,
    nb_produits AS total_produits_categorie,
    ROUND(prix / prix_moyen * 100, 2) AS index_prix
FROM top_par_categorie
WHERE rang <= 3
ORDER BY categorie, rang;
```

---

## 2. Moyennes mobiles : Lisser les tendances

### Pattern 1 : Moyenne mobile simple (SMA)

```sql
-- SMA sur 7, 30 et 90 jours
SELECT
    date_vente,
    montant,
    -- SMA 7 jours
    ROUND(
        AVG(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ),
        2
    ) AS sma_7j,
    -- SMA 30 jours
    ROUND(
        AVG(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ),
        2
    ) AS sma_30j,
    -- SMA 90 jours
    ROUND(
        AVG(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 89 PRECEDING AND CURRENT ROW
        ),
        2
    ) AS sma_90j,
    -- Nombre de jours dans le calcul (pour les premi√®res lignes)
    COUNT(*) OVER (
        ORDER BY date_vente
        ROWS BETWEEN 89 PRECEDING AND CURRENT ROW
    ) AS nb_jours_sma_90j
FROM ventes_quotidiennes
ORDER BY date_vente DESC
LIMIT 30;
```

**Utilisation** : Identifier les tendances en lissant les variations quotidiennes.

### Pattern 2 : Moyenne mobile pond√©r√©e (WMA)

```sql
-- WMA o√π les jours r√©cents ont plus de poids
-- Poids : 7, 6, 5, 4, 3, 2, 1 (total = 28)
WITH ventes_avec_position AS (
    SELECT
        date_vente,
        montant,
        ROW_NUMBER() OVER (ORDER BY date_vente DESC) AS position_inverse
    FROM ventes_quotidiennes
)
SELECT
    date_vente,
    montant,
    ROUND(
        (
            -- Jour actuel : poids 7
            SUM(CASE WHEN position_inverse = 1 THEN montant * 7 ELSE 0 END) OVER w +
            -- J-1 : poids 6
            SUM(CASE WHEN position_inverse = 2 THEN montant * 6 ELSE 0 END) OVER w +
            -- J-2 : poids 5
            SUM(CASE WHEN position_inverse = 3 THEN montant * 5 ELSE 0 END) OVER w +
            -- J-3 : poids 4
            SUM(CASE WHEN position_inverse = 4 THEN montant * 4 ELSE 0 END) OVER w +
            -- J-4 : poids 3
            SUM(CASE WHEN position_inverse = 5 THEN montant * 3 ELSE 0 END) OVER w +
            -- J-5 : poids 2
            SUM(CASE WHEN position_inverse = 6 THEN montant * 2 ELSE 0 END) OVER w +
            -- J-6 : poids 1
            SUM(CASE WHEN position_inverse = 7 THEN montant * 1 ELSE 0 END) OVER w
        ) / 28,
        2
    ) AS wma_7j
FROM ventes_avec_position
WINDOW w AS (
    ORDER BY date_vente
    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
)
ORDER BY date_vente DESC
LIMIT 30;
```

üí° **Alternative plus simple** : Utiliser une formule g√©n√©rique avec ROW_NUMBER.

### Pattern 3 : Croisement de moyennes mobiles (Golden Cross / Death Cross)

```sql
-- Signal d'achat/vente bas√© sur le croisement SMA 50j et SMA 200j
WITH moyennes AS (
    SELECT
        date_cotation,
        cours_cloture,
        AVG(cours_cloture) OVER (
            ORDER BY date_cotation
            ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
        ) AS sma_50j,
        AVG(cours_cloture) OVER (
            ORDER BY date_cotation
            ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
        ) AS sma_200j,
        LAG(AVG(cours_cloture) OVER (
            ORDER BY date_cotation
            ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
        ), 1) OVER (ORDER BY date_cotation) AS sma_50j_hier,
        LAG(AVG(cours_cloture) OVER (
            ORDER BY date_cotation
            ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
        ), 1) OVER (ORDER BY date_cotation) AS sma_200j_hier
    FROM cours_bourse
    WHERE symbole = 'AAPL'
)
SELECT
    date_cotation,
    cours_cloture,
    ROUND(sma_50j, 2) AS sma_50j,
    ROUND(sma_200j, 2) AS sma_200j,
    CASE
        -- Golden Cross : SMA 50j croise SMA 200j √† la hausse
        WHEN sma_50j > sma_200j AND sma_50j_hier <= sma_200j_hier
            THEN 'üü¢ GOLDEN CROSS (Signal achat)'
        -- Death Cross : SMA 50j croise SMA 200j √† la baisse
        WHEN sma_50j < sma_200j AND sma_50j_hier >= sma_200j_hier
            THEN 'üî¥ DEATH CROSS (Signal vente)'
        -- Tendance haussi√®re
        WHEN sma_50j > sma_200j
            THEN 'üìà Tendance haussi√®re'
        -- Tendance baissi√®re
        WHEN sma_50j < sma_200j
            THEN 'üìâ Tendance baissi√®re'
        ELSE '‚û°Ô∏è Neutre'
    END AS signal
FROM moyennes
WHERE sma_200j IS NOT NULL  -- Assure 200 jours d'historique
ORDER BY date_cotation DESC
LIMIT 60;
```

### Pattern 4 : Moyenne mobile avec d√©tection d'anomalies

```sql
-- Identifier les pics qui d√©passent significativement la moyenne mobile
WITH moyennes_et_ecarts AS (
    SELECT
        date_vente,
        montant,
        AVG(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ) AS sma_30j,
        STDDEV(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ) AS stddev_30j,
        COUNT(*) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ) AS nb_jours
    FROM ventes_quotidiennes
)
SELECT
    date_vente,
    montant,
    ROUND(sma_30j, 2) AS sma_30j,
    ROUND(stddev_30j, 2) AS stddev_30j,
    -- √âcart en nombre d'√©carts-types
    ROUND((montant - sma_30j) / NULLIF(stddev_30j, 0), 2) AS z_score,
    -- Classification
    CASE
        WHEN nb_jours < 30 THEN '‚è≥ P√©riode de rodage'
        WHEN (montant - sma_30j) / NULLIF(stddev_30j, 0) > 2
            THEN 'üî¥ Anomalie positive (> +2œÉ)'
        WHEN (montant - sma_30j) / NULLIF(stddev_30j, 0) < -2
            THEN 'üîµ Anomalie n√©gative (< -2œÉ)'
        WHEN ABS((montant - sma_30j) / NULLIF(stddev_30j, 0)) > 1
            THEN 'üü° Variation notable (> 1œÉ)'
        ELSE 'üü¢ Normal'
    END AS statut
FROM moyennes_et_ecarts
WHERE nb_jours = 30  -- Filtre les jours avec fen√™tre compl√®te
ORDER BY date_vente DESC;
```

### Pattern 5 : Comparaison multiple p√©riodes

```sql
-- Comparer les ventes actuelles avec moyennes de diff√©rentes p√©riodes
SELECT
    date_vente,
    montant,
    -- Moyennes mobiles
    ROUND(AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW), 2) AS sma_7j,
    ROUND(AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS sma_30j,
    -- Comparaisons
    ROUND(
        (montant - AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)) /
        AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) * 100,
        2
    ) AS ecart_sma_7j_pct,
    ROUND(
        (montant - AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW)) /
        AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) * 100,
        2
    ) AS ecart_sma_30j_pct,
    -- Tendance
    CASE
        WHEN AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) >
             AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW)
            THEN 'üìà Court terme > Long terme'
        ELSE 'üìâ Court terme < Long terme'
    END AS tendance
FROM ventes_quotidiennes
ORDER BY date_vente DESC
LIMIT 30;
```

---

## 3. Cumuls : Agr√©gations progressives

### Pattern 1 : Cumul simple (Running Total)

```sql
-- Total cumul√© des ventes par jour
SELECT
    date_vente,
    montant,
    SUM(montant) OVER (ORDER BY date_vente) AS cumul_total,
    -- Pourcentage du total final
    ROUND(
        SUM(montant) OVER (ORDER BY date_vente) /
        SUM(montant) OVER () * 100,
        2
    ) AS pct_cumul
FROM ventes_quotidiennes
ORDER BY date_vente;
```

### Pattern 2 : Cumul par groupe

```sql
-- Cumul des ventes par vendeur et par mois
SELECT
    vendeur,
    DATE_FORMAT(date_vente, '%Y-%m') AS mois,
    date_vente,
    montant,
    -- Cumul dans le mois
    SUM(montant) OVER (
        PARTITION BY vendeur, DATE_FORMAT(date_vente, '%Y-%m')
        ORDER BY date_vente
    ) AS cumul_mois,
    -- Cumul global du vendeur
    SUM(montant) OVER (
        PARTITION BY vendeur
        ORDER BY date_vente
    ) AS cumul_vendeur,
    -- Objectif mensuel
    10000 AS objectif_mois,
    -- Progression vers objectif
    ROUND(
        SUM(montant) OVER (
            PARTITION BY vendeur, DATE_FORMAT(date_vente, '%Y-%m')
            ORDER BY date_vente
        ) / 10000 * 100,
        2
    ) AS progression_objectif_pct
FROM ventes
ORDER BY vendeur, date_vente;
```

### Pattern 3 : Cumul avec reset p√©riodique

```sql
-- Cumul qui red√©marre √† chaque d√©but de mois
SELECT
    date_vente,
    DATE_FORMAT(date_vente, '%Y-%m') AS mois,
    montant,
    -- Cumul mensuel (reset chaque mois)
    SUM(montant) OVER (
        PARTITION BY DATE_FORMAT(date_vente, '%Y-%m')
        ORDER BY date_vente
    ) AS cumul_mois,
    -- Jour du mois
    DAY(date_vente) AS jour_mois,
    -- Projection fin de mois (lin√©aire)
    ROUND(
        SUM(montant) OVER (
            PARTITION BY DATE_FORMAT(date_vente, '%Y-%m')
            ORDER BY date_vente
        ) / DAY(date_vente) * DAY(LAST_DAY(date_vente)),
        2
    ) AS projection_fin_mois
FROM ventes_quotidiennes
ORDER BY date_vente DESC
LIMIT 100;
```

### Pattern 4 : Cumul avec plusieurs dimensions

```sql
-- Cumuls crois√©s : par produit, cat√©gorie et global
SELECT
    date_vente,
    categorie,
    produit_id,
    montant,
    -- Cumul pour ce produit
    SUM(montant) OVER (
        PARTITION BY produit_id
        ORDER BY date_vente
    ) AS cumul_produit,
    -- Cumul pour la cat√©gorie
    SUM(montant) OVER (
        PARTITION BY categorie
        ORDER BY date_vente
    ) AS cumul_categorie,
    -- Cumul global
    SUM(montant) OVER (ORDER BY date_vente) AS cumul_global,
    -- Part du produit dans sa cat√©gorie
    ROUND(
        SUM(montant) OVER (PARTITION BY produit_id ORDER BY date_vente) /
        SUM(montant) OVER (PARTITION BY categorie ORDER BY date_vente) * 100,
        2
    ) AS pct_produit_dans_categorie
FROM ventes
ORDER BY date_vente DESC, categorie, produit_id
LIMIT 50;
```

### Pattern 5 : Cumul avec comparaison ann√©e pr√©c√©dente

```sql
-- Cumul YTD (Year-to-Date) avec comparaison N-1
WITH ventes_ytd AS (
    SELECT
        YEAR(date_vente) AS annee,
        DAYOFYEAR(date_vente) AS jour_annee,
        date_vente,
        montant,
        SUM(montant) OVER (
            PARTITION BY YEAR(date_vente)
            ORDER BY DAYOFYEAR(date_vente)
        ) AS cumul_ytd
    FROM ventes_quotidiennes
    WHERE YEAR(date_vente) IN (2023, 2024)
)
SELECT
    v2024.date_vente,
    v2024.jour_annee,
    v2024.montant AS montant_2024,
    v2024.cumul_ytd AS cumul_ytd_2024,
    v2023.cumul_ytd AS cumul_ytd_2023,
    -- Variation absolue
    v2024.cumul_ytd - v2023.cumul_ytd AS variation_ytd,
    -- Variation en %
    ROUND(
        (v2024.cumul_ytd - v2023.cumul_ytd) / v2023.cumul_ytd * 100,
        2
    ) AS variation_ytd_pct
FROM ventes_ytd v2024
LEFT JOIN ventes_ytd v2023
    ON v2024.jour_annee = v2023.jour_annee
    AND v2024.annee = 2024
    AND v2023.annee = 2023
WHERE v2024.annee = 2024
ORDER BY v2024.date_vente DESC
LIMIT 30;
```

---

## 4. Patterns combin√©s : Analyses complexes

### Pattern 1 : Dashboard de vente complet

```sql
-- Vue d'ensemble des ventes avec multiples m√©triques
WITH metriques_quotidiennes AS (
    SELECT
        date_vente,
        SUM(montant) AS ventes_jour,
        COUNT(DISTINCT commande_id) AS nb_commandes,
        COUNT(DISTINCT client_id) AS nb_clients,
        AVG(montant) AS panier_moyen
    FROM ventes
    GROUP BY date_vente
)
SELECT
    date_vente,
    ventes_jour,
    nb_commandes,
    nb_clients,
    ROUND(panier_moyen, 2) AS panier_moyen,

    -- Cumuls
    SUM(ventes_jour) OVER (ORDER BY date_vente) AS cumul_ytd,
    SUM(nb_commandes) OVER (ORDER BY date_vente) AS cumul_commandes,

    -- Moyennes mobiles
    ROUND(AVG(ventes_jour) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW), 2) AS sma_7j,
    ROUND(AVG(ventes_jour) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS sma_30j,

    -- Comparaisons
    LAG(ventes_jour, 1) OVER (ORDER BY date_vente) AS ventes_hier,
    LAG(ventes_jour, 7) OVER (ORDER BY date_vente) AS ventes_j_moins_7,

    -- Variations
    ROUND(
        (ventes_jour - LAG(ventes_jour, 1) OVER (ORDER BY date_vente)) /
        LAG(ventes_jour, 1) OVER (ORDER BY date_vente) * 100,
        2
    ) AS variation_j_j_pct,
    ROUND(
        (ventes_jour - LAG(ventes_jour, 7) OVER (ORDER BY date_vente)) /
        LAG(ventes_jour, 7) OVER (ORDER BY date_vente) * 100,
        2
    ) AS variation_hebdo_pct,

    -- Rangs
    RANK() OVER (ORDER BY ventes_jour DESC) AS rang_jour
FROM metriques_quotidiennes
ORDER BY date_vente DESC
LIMIT 30;
```

### Pattern 2 : Analyse de cohorte client

```sql
-- R√©tention client par cohorte mensuelle d'inscription
WITH cohortes AS (
    SELECT
        client_id,
        DATE_FORMAT(MIN(date_inscription), '%Y-%m') AS cohorte_mois,
        MIN(date_inscription) AS date_inscription
    FROM clients
    GROUP BY client_id
),
activite AS (
    SELECT
        c.client_id,
        c.cohorte_mois,
        DATE_FORMAT(v.date_vente, '%Y-%m') AS mois_activite,
        TIMESTAMPDIFF(MONTH, c.date_inscription, v.date_vente) AS mois_depuis_inscription,
        SUM(v.montant) AS montant_mois
    FROM cohortes c
    JOIN ventes v ON c.client_id = v.client_id
    GROUP BY c.client_id, c.cohorte_mois, DATE_FORMAT(v.date_vente, '%Y-%m')
)
SELECT
    cohorte_mois,
    mois_depuis_inscription,
    COUNT(DISTINCT client_id) AS nb_clients_actifs,
    -- Taille de la cohorte (M0)
    FIRST_VALUE(COUNT(DISTINCT client_id)) OVER (
        PARTITION BY cohorte_mois
        ORDER BY mois_depuis_inscription
    ) AS taille_cohorte,
    -- Taux de r√©tention
    ROUND(
        COUNT(DISTINCT client_id) * 100.0 /
        FIRST_VALUE(COUNT(DISTINCT client_id)) OVER (
            PARTITION BY cohorte_mois
            ORDER BY mois_depuis_inscription
        ),
        2
    ) AS taux_retention_pct,
    -- Revenue moyen par client actif
    ROUND(SUM(montant_mois) / COUNT(DISTINCT client_id), 2) AS arpu,
    -- Revenue cumul√© de la cohorte
    SUM(SUM(montant_mois)) OVER (
        PARTITION BY cohorte_mois
        ORDER BY mois_depuis_inscription
    ) AS revenue_cumule_cohorte
FROM activite
WHERE cohorte_mois >= '2023-01'
GROUP BY cohorte_mois, mois_depuis_inscription
ORDER BY cohorte_mois, mois_depuis_inscription;
```

### Pattern 3 : Analyse RFM (Recency, Frequency, Monetary)

```sql
-- Segmentation client avec scores RFM
WITH rfm_raw AS (
    SELECT
        client_id,
        MAX(date_vente) AS derniere_vente,
        DATEDIFF(CURRENT_DATE, MAX(date_vente)) AS recency_jours,
        COUNT(DISTINCT commande_id) AS frequency,
        SUM(montant) AS monetary
    FROM ventes
    WHERE date_vente >= CURRENT_DATE - INTERVAL 2 YEAR
    GROUP BY client_id
),
rfm_scores AS (
    SELECT
        client_id,
        recency_jours,
        frequency,
        monetary,
        -- Scores quintiles (1 = meilleur, 5 = moins bon)
        NTILE(5) OVER (ORDER BY recency_jours ASC) AS score_recency,
        NTILE(5) OVER (ORDER BY frequency DESC) AS score_frequency,
        NTILE(5) OVER (ORDER BY monetary DESC) AS score_monetary
    FROM rfm_raw
)
SELECT
    client_id,
    recency_jours,
    frequency,
    monetary,
    score_recency,
    score_frequency,
    score_monetary,
    CONCAT(score_recency, score_frequency, score_monetary) AS rfm_score,
    -- Segmentation
    CASE
        WHEN score_recency <= 2 AND score_frequency <= 2 AND score_monetary <= 2
            THEN 'üëë Champions'
        WHEN score_recency <= 2 AND score_frequency <= 3
            THEN 'üíé Clients fid√®les'
        WHEN score_recency <= 3 AND score_frequency = 1 AND score_monetary <= 3
            THEN 'üåü Clients potentiels'
        WHEN score_recency <= 3
            THEN '‚úÖ Clients r√©guliers'
        WHEN score_recency = 4
            THEN '‚ö†Ô∏è √Ä risque'
        WHEN score_recency = 5 AND frequency <= 2
            THEN 'üí§ Hibernants'
        ELSE 'üî¥ Perdus'
    END AS segment,
    -- Rang dans le segment
    ROW_NUMBER() OVER (
        PARTITION BY
            CASE
                WHEN score_recency <= 2 AND score_frequency <= 2 AND score_monetary <= 2 THEN 'Champions'
                WHEN score_recency <= 2 AND score_frequency <= 3 THEN 'Fideles'
                ELSE 'Autres'
            END
        ORDER BY monetary DESC
    ) AS rang_segment
FROM rfm_scores
ORDER BY monetary DESC;
```

### Pattern 4 : Analyse ABC avec courbe de Pareto

```sql
-- Classification ABC des produits (principe 80/20)
WITH ventes_produits AS (
    SELECT
        produit_id,
        nom,
        SUM(quantite * prix_unitaire) AS ca_total
    FROM ventes
    WHERE date_vente >= CURRENT_DATE - INTERVAL 1 YEAR
    GROUP BY produit_id, nom
),
produits_classes AS (
    SELECT
        produit_id,
        nom,
        ca_total,
        -- Cumul du CA
        SUM(ca_total) OVER (ORDER BY ca_total DESC) AS ca_cumul,
        -- CA total
        SUM(ca_total) OVER () AS ca_global,
        -- Pourcentage cumul√©
        ROUND(
            SUM(ca_total) OVER (ORDER BY ca_total DESC) /
            SUM(ca_total) OVER () * 100,
            2
        ) AS pct_cumul,
        -- Rang
        ROW_NUMBER() OVER (ORDER BY ca_total DESC) AS rang,
        -- Nombre total de produits
        COUNT(*) OVER () AS nb_produits_total
    FROM ventes_produits
)
SELECT
    rang,
    produit_id,
    nom,
    ca_total,
    ca_cumul,
    pct_cumul,
    -- Classification ABC
    CASE
        WHEN pct_cumul <= 80 THEN 'A - Produits strat√©giques (80% du CA)'
        WHEN pct_cumul <= 95 THEN 'B - Produits importants (15% du CA)'
        ELSE 'C - Produits standards (5% du CA)'
    END AS categorie_abc,
    -- Part du CA
    ROUND(ca_total / ca_global * 100, 2) AS pct_ca,
    -- Part du nombre de produits
    ROUND(rang / nb_produits_total * 100, 2) AS pct_produits
FROM produits_classes
ORDER BY rang;
```

### Pattern 5 : Pr√©vision bas√©e sur les tendances

```sql
-- Pr√©vision simple bas√©e sur la moyenne mobile et la tendance
WITH historique AS (
    SELECT
        date_vente,
        montant,
        -- Moyenne mobile 30 jours
        AVG(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ) AS sma_30j,
        -- Tendance (pente sur 30 jours)
        (AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) -
         LAG(AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 30)
         OVER (ORDER BY date_vente)) / 30 AS tendance_30j,
        -- Volatilit√©
        STDDEV(montant) OVER (
            ORDER BY date_vente
            ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
        ) AS volatilite_30j
    FROM ventes_quotidiennes
    WHERE date_vente >= CURRENT_DATE - INTERVAL 6 MONTH
)
SELECT
    date_vente,
    montant,
    ROUND(sma_30j, 2) AS sma_30j,
    ROUND(tendance_30j, 2) AS tendance_quotidienne,
    ROUND(volatilite_30j, 2) AS volatilite,
    -- Pr√©vision J+1 (SMA + tendance)
    ROUND(sma_30j + tendance_30j, 2) AS prevision_j1,
    -- Intervalle de confiance (¬±1.96 œÉ pour 95%)
    ROUND(sma_30j + tendance_30j - (1.96 * volatilite_30j), 2) AS borne_inf_95,
    ROUND(sma_30j + tendance_30j + (1.96 * volatilite_30j), 2) AS borne_sup_95,
    -- √âcart r√©el vs pr√©vision (backtest)
    CASE
        WHEN LAG(sma_30j + tendance_30j, 1) OVER (ORDER BY date_vente) IS NOT NULL
        THEN ROUND(
            ABS(montant - LAG(sma_30j + tendance_30j, 1) OVER (ORDER BY date_vente)) /
            montant * 100,
            2
        )
    END AS erreur_prevision_pct
FROM historique
ORDER BY date_vente DESC
LIMIT 30;
```

---

## 5. Optimisation des requ√™tes analytiques

### Conseil 1 : Utiliser des tables mat√©rialis√©es pour les agr√©gations fr√©quentes

```sql
-- Cr√©er une vue mat√©rialis√©e (simul√©e avec table + trigger)
CREATE TABLE ventes_quotidiennes_agg (
    date_vente DATE PRIMARY KEY,
    ventes_jour DECIMAL(12,2),
    nb_commandes INT,
    nb_clients INT,
    panier_moyen DECIMAL(10,2),
    derniere_maj TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Peupler initialement
INSERT INTO ventes_quotidiennes_agg
SELECT
    date_vente,
    SUM(montant),
    COUNT(DISTINCT commande_id),
    COUNT(DISTINCT client_id),
    AVG(montant),
    CURRENT_TIMESTAMP
FROM ventes
GROUP BY date_vente;

-- Index pour les requ√™tes de window functions
CREATE INDEX idx_date ON ventes_quotidiennes_agg(date_vente);

-- Utiliser la table agr√©g√©e
SELECT
    date_vente,
    ventes_jour,
    SUM(ventes_jour) OVER (ORDER BY date_vente) AS cumul,
    AVG(ventes_jour) OVER (
        ORDER BY date_vente
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    ) AS sma_30j
FROM ventes_quotidiennes_agg
ORDER BY date_vente DESC
LIMIT 30;
```

### Conseil 2 : Limiter le scope avec WHERE

```sql
-- ‚ùå LENT : Applique window functions sur toutes les donn√©es
SELECT
    date_vente,
    montant,
    AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS sma_30j
FROM ventes  -- Potentiellement millions de lignes
ORDER BY date_vente DESC
LIMIT 100;

-- ‚úÖ RAPIDE : Filtre d'abord
SELECT
    date_vente,
    montant,
    AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS sma_30j
FROM ventes
WHERE date_vente >= CURRENT_DATE - INTERVAL 1 YEAR  -- R√©duit drastiquement le dataset
ORDER BY date_vente DESC
LIMIT 100;
```

### Conseil 3 : R√©utiliser les fen√™tres avec WINDOW

```sql
-- ‚ùå R√âP√âTITIF : M√™me fen√™tre d√©finie plusieurs fois
SELECT
    date_vente,
    montant,
    AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS sma_30j,
    MIN(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS min_30j,
    MAX(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS max_30j,
    STDDEV(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS std_30j
FROM ventes_quotidiennes;

-- ‚úÖ OPTIMIS√â : Fen√™tre nomm√©e r√©utilis√©e
SELECT
    date_vente,
    montant,
    AVG(montant) OVER w AS sma_30j,
    MIN(montant) OVER w AS min_30j,
    MAX(montant) OVER w AS max_30j,
    STDDEV(montant) OVER w AS std_30j
FROM ventes_quotidiennes
WINDOW w AS (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW);
```

### Conseil 4 : Pr√©-calculer dans des CTE

```sql
-- ‚úÖ Calculer une fois, r√©utiliser plusieurs fois
WITH moyennes_mobiles AS (
    SELECT
        date_vente,
        montant,
        AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS sma_7j,
        AVG(montant) OVER (ORDER BY date_vente ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) AS sma_30j
    FROM ventes_quotidiennes
    WHERE date_vente >= CURRENT_DATE - INTERVAL 1 YEAR
)
SELECT
    date_vente,
    montant,
    sma_7j,
    sma_30j,
    montant - sma_7j AS ecart_sma_7j,
    montant - sma_30j AS ecart_sma_30j,
    CASE
        WHEN sma_7j > sma_30j THEN 'üìà Tendance haussi√®re'
        WHEN sma_7j < sma_30j THEN 'üìâ Tendance baissi√®re'
        ELSE '‚û°Ô∏è Neutre'
    END AS tendance
FROM moyennes_mobiles
ORDER BY date_vente DESC
LIMIT 100;
```

---

## ‚úÖ Points cl√©s √† retenir

- **Top N** : Utiliser ROW_NUMBER() pour r√©sultats exacts, RANK() pour inclure ex-aequo
- **Moyennes mobiles** : ROWS pour fen√™tres fixes, SMA pour tendances g√©n√©rales, WMA pour pond√©ration
- **Cumuls** : PARTITION BY pour reset p√©riodique, combinaison avec FIRST_VALUE/LAST_VALUE pour ratios
- **Optimisation** : Filtrer avec WHERE avant window functions, utiliser WINDOW pour r√©utilisation
- **CTE** : Pr√©-calculer les m√©triques complexes pour r√©utilisation et lisibilit√©
- **Indexation** : Index sur colonnes PARTITION BY et ORDER BY am√©liore significativement les performances
- **Tables agr√©g√©es** : Pr√©-calculer les agr√©gations quotidiennes/mensuelles pour analyses fr√©quentes
- **Patterns combin√©s** : Window functions brillent quand plusieurs m√©triques sont combin√©es
- **ROWS vs RANGE** : ROWS est g√©n√©ralement plus rapide et pr√©visible
- **Taille de fen√™tre** : Adapter selon le contexte (7j, 30j, 90j sont des standards)
- **Validation** : Toujours v√©rifier les calculs sur les premi√®res/derni√®res lignes des partitions
- **Documentation** : Commenter les calculs complexes pour faciliter la maintenance

---

## üîó Ressources et r√©f√©rences

- [üìñ Documentation officielle MariaDB - Window Functions](https://mariadb.com/kb/en/window-functions/)
- [üìñ Window Functions Overview](https://mariadb.com/kb/en/window-functions-overview/)
- [üìñ Performance Considerations](https://mariadb.com/kb/en/window-functions-performance/)

**Lectures compl√©mentaires :**
- [Modern SQL - Practical Examples](https://modern-sql.com/use-case)
- [SQL Window Functions Explained](https://www.sqltutorial.org/sql-window-functions/)

**Outils d'analyse :**
- [Percona Toolkit](https://www.percona.com/software/database-tools/percona-toolkit)
- [MySQLTuner](https://github.com/major/MySQLTuner-perl)

---

## ‚û°Ô∏è Section suivante

**[4.3 Requ√™tes pivot√©es et transformations](/04-concepts-avances-sql/03-requetes-pivotees.md)** : Transformer les donn√©es entre formats ligne/colonne, cr√©er des tableaux crois√©s dynamiques et restructurer les r√©sultats pour l'analyse.

---

**Note pratique** : Les patterns pr√©sent√©s ici sont des points de d√©part √©prouv√©s en production. N'h√©sitez pas √† les adapter et les combiner selon vos besoins sp√©cifiques. La cl√© du succ√®s avec les window functions est de commencer simple, tester rigoureusement, puis progressivement ajouter de la complexit√©. Documentez vos requ√™tes complexes pour faciliter la maintenance ! üéØ

‚è≠Ô∏è [Requ√™tes pivot√©es et transformations](/04-concepts-avances-sql/03-requetes-pivotees.md)
