üîù Retour au [Sommaire](/SOMMAIRE.md)

# 4.7.1 Stockage et type de donn√©es JSON

> **Niveau** : Avanc√©
> **Dur√©e estim√©e** : 2 heures
> **Pr√©requis** : Section 4.7 (JSON dans MariaDB), connaissance des types de donn√©es MariaDB

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre la diff√©rence entre le type JSON de MariaDB et MySQL
- Ma√Ætriser le comportement de validation automatique du type JSON
- Choisir entre JSON, LONGTEXT et TEXT selon les besoins
- Optimiser le stockage de documents JSON volumineux
- √âvaluer l'impact m√©moire et disque du stockage JSON
- Anticiper les implications de performance du format texte

---

## Introduction

Le type **JSON** dans MariaDB est fondamentalement diff√©rent de celui de MySQL 5.7+. Comprendre cette diff√©rence est crucial pour optimiser les performances et √©viter les pi√®ges. Cette section explore en profondeur les m√©canismes de stockage, la validation et les implications techniques.

---

## Type JSON : Un alias avec validation

### D√©finition technique

Dans MariaDB, le type `JSON` est un **alias** pour `LONGTEXT` avec une **contrainte de validation automatique** :

```sql
-- Ces trois d√©clarations sont √©quivalentes en termes de stockage
CREATE TABLE t1 (data JSON);
CREATE TABLE t2 (data LONGTEXT CHECK (JSON_VALID(data)));
CREATE TABLE t3 (data LONGTEXT);  -- Sans validation

-- V√©rification du type r√©el
DESC t1;
-- Field | Type     | Null | Key | Default | Extra
-- data  | longtext | YES  |     | NULL    |
```

üí° **Observation** : Le type affich√© est `longtext`, pas un type distinct `json`.

### √âquivalence interne

```sql
-- Ces deux approches sont identiques
CREATE TABLE produits_v1 (
    id INT PRIMARY KEY,
    details JSON
);

CREATE TABLE produits_v2 (
    id INT PRIMARY KEY,
    details LONGTEXT,
    CONSTRAINT check_json CHECK (JSON_VALID(details))
);

-- Structure interne identique
SHOW CREATE TABLE produits_v1\G
-- details longtext DEFAULT NULL

SHOW CREATE TABLE produits_v2\G
-- details longtext DEFAULT NULL
-- CONSTRAINT check_json CHECK (json_valid(details))
```

### Diff√©rence avec MySQL

| Aspect | MariaDB | MySQL 5.7+ |
|--------|---------|-----------|
| **Type de stockage** | Texte (UTF-8) | Binaire optimis√© |
| **Structure interne** | LONGTEXT avec validation | Format binaire propri√©taire |
| **Parsing** | √Ä chaque lecture | Une fois (d√©j√† pars√©) |
| **Taille sur disque** | Texte complet | Binaire compress√© |
| **Validation** | JSON_VALID() | Validation + structure interne |
| **Performance lecture** | Plus lent (parsing) | Plus rapide (binaire) |
| **Portabilit√©** | Standard JSON | Format MySQL |

```sql
-- MySQL 5.7+ : Type binaire distinct
CREATE TABLE mysql_json (data JSON);
-- Stock√© dans un format binaire optimis√©, non lisible directement

-- MariaDB : Texte lisible
CREATE TABLE mariadb_json (data JSON);
INSERT INTO mariadb_json VALUES ('{"test": 123}');
SELECT HEX(data) FROM mariadb_json;
-- 7B2274657374223A203132337D (repr√©sentation hexad√©cimale du texte)
```

---

## Validation automatique

### M√©canisme de validation

Lorsqu'une colonne est d√©clar√©e comme `JSON`, MariaDB applique automatiquement `JSON_VALID()` :

```sql
CREATE TABLE test_validation (
    id INT PRIMARY KEY AUTO_INCREMENT,
    data JSON
);

-- ‚úÖ JSON valide : accept√©
INSERT INTO test_validation (data) VALUES
    ('{"nom": "Alice"}'),
    ('["a", "b", "c"]'),
    ('123'),
    ('"cha√Æne simple"'),
    ('true'),
    ('null');

-- ‚ùå JSON invalide : rejet√©
INSERT INTO test_validation (data) VALUES ('{invalide}');
-- ERROR 4038 (HY000): Syntax error in JSON text in argument 1 to function 'json_valid' at position 2

INSERT INTO test_validation (data) VALUES ('{"non_ferme": ');
-- ERROR 4038 (HY000): Syntax error in JSON text

INSERT INTO test_validation (data) VALUES ('undefined');
-- ERROR 4038 (HY000): Syntax error in JSON text
```

### Validation √† l'insertion vs √† la modification

```sql
-- Validation lors de INSERT
INSERT INTO test_validation (data) VALUES ('{"x": 1}');  -- ‚úÖ

-- Validation lors de UPDATE
UPDATE test_validation SET data = '{"y": 2}' WHERE id = 1;  -- ‚úÖ
UPDATE test_validation SET data = '{bad}' WHERE id = 1;     -- ‚ùå Erreur

-- Validation lors de REPLACE
REPLACE INTO test_validation (id, data) VALUES (1, '{"z": 3}');  -- ‚úÖ

-- Validation lors de INSERT ... ON DUPLICATE KEY UPDATE
INSERT INTO test_validation (id, data) VALUES (1, '{"a": 1}')
ON DUPLICATE KEY UPDATE data = '{"b": 2}';  -- ‚úÖ
```

### Contournement de la validation

‚ö†Ô∏è **Attention** : La validation peut √™tre contourn√©e si le type est modifi√© :

```sql
-- Cr√©er une table JSON
CREATE TABLE test (data JSON);

-- Modifier le type en LONGTEXT (retire la validation)
ALTER TABLE test MODIFY data LONGTEXT;

-- Maintenant, JSON invalide est accept√© !
INSERT INTO test (data) VALUES ('{invalid json}');  -- ‚úÖ Accept√© !

-- V√©rification manuelle n√©cessaire
SELECT data, JSON_VALID(data) AS est_valide FROM test;
-- data          | est_valide
-- {invalid json}| 0
```

üí° **Recommandation** : Toujours utiliser le type `JSON` explicitement et √©viter les modifications de type.

---

## Choix du type : JSON vs LONGTEXT vs TEXT

### Hi√©rarchie des types texte

```sql
-- Types texte par taille maximale
-- TINYTEXT   : 255 bytes
-- TEXT       : 65,535 bytes (64 KB)
-- MEDIUMTEXT : 16,777,215 bytes (16 MB)
-- LONGTEXT   : 4,294,967,295 bytes (4 GB)

-- JSON est un alias de LONGTEXT
CREATE TABLE comparaison (
    petit TINYTEXT,      -- Max 255 bytes
    moyen TEXT,          -- Max 64 KB
    grand MEDIUMTEXT,    -- Max 16 MB
    tres_grand LONGTEXT, -- Max 4 GB
    json_data JSON       -- Alias LONGTEXT (Max 4 GB)
);
```

### Quand utiliser chaque type ?

```sql
-- 1. JSON : Documents avec validation
CREATE TABLE config (
    module VARCHAR(50) PRIMARY KEY,
    settings JSON  -- Garantit JSON valide
);

-- 2. TEXT : Petits documents (<64KB), pas de validation n√©cessaire
CREATE TABLE logs_compacts (
    id INT PRIMARY KEY AUTO_INCREMENT,
    timestamp DATETIME,
    message TEXT,  -- Plus √©conome que LONGTEXT si <64KB
    metadata TEXT  -- Peut contenir JSON non valid√©
);

-- 3. LONGTEXT : Grands documents, flexibilit√©
CREATE TABLE documents (
    id INT PRIMARY KEY AUTO_INCREMENT,
    content LONGTEXT,  -- Peut √™tre JSON, XML, HTML, etc.
    type ENUM('json', 'xml', 'html', 'text')
);

-- 4. MEDIUMTEXT : Compromis entre TEXT et LONGTEXT
CREATE TABLE articles (
    id INT PRIMARY KEY AUTO_INCREMENT,
    contenu MEDIUMTEXT,  -- Max 16MB, suffisant pour la plupart des articles
    metadata JSON        -- Informations structur√©es
);
```

### Matrice de d√©cision

| Crit√®re | TINYTEXT | TEXT | MEDIUMTEXT | LONGTEXT | JSON |
|---------|----------|------|------------|----------|------|
| **Taille max** | 255 B | 64 KB | 16 MB | 4 GB | 4 GB |
| **Validation JSON** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| **Overhead stockage** | 1 byte | 2 bytes | 3 bytes | 4 bytes | 4 bytes |
| **Cas d'usage** | Tr√®s petits textes | Descriptions, notes | Articles, documents | Gros contenus | Documents JSON |
| **Performance** | ‚ö° Rapide | ‚ö° Rapide | üü° Moyen | üü† Lent si gros | üü† Lent + parsing |

### Exemples comparatifs

```sql
-- Mesurer la taille des donn√©es
CREATE TABLE test_taille (
    id INT PRIMARY KEY AUTO_INCREMENT,
    data_text TEXT,
    data_json JSON
);

-- Insertion de donn√©es identiques
INSERT INTO test_taille (data_text, data_json) VALUES
    ('{"nom": "Alice", "age": 30}', '{"nom": "Alice", "age": 30}'),
    ('{"nom": "Bob", "age": 25}', '{"nom": "Bob", "age": 25}');

-- V√©rifier la taille r√©elle sur disque
SELECT
    id,
    LENGTH(data_text) AS taille_text_bytes,
    LENGTH(data_json) AS taille_json_bytes,
    data_text = data_json AS identiques
FROM test_taille;
-- id | taille_text_bytes | taille_json_bytes | identiques
-- 1  | 28                | 28                | 1
-- 2  | 26                | 26                | 1

-- Conclusion : M√™me taille de stockage (alias LONGTEXT)
```

---

## Stockage physique et overhead

### Structure du stockage LONGTEXT

```
+----------------+------------------+
| Length prefix  | Data             |
| (4 bytes)      | (variable)       |
+----------------+------------------+
```

**Composants** :
1. **Pr√©fixe de longueur** : 4 bytes stockant la longueur du contenu
2. **Donn√©es** : Contenu texte UTF-8
3. **Stockage externe** : Si >256 bytes, stock√© hors ligne (off-page)

### Overhead par type

```sql
-- Calculer l'overhead r√©el
CREATE TABLE overhead_test (
    id INT PRIMARY KEY AUTO_INCREMENT,
    data_tiny TINYTEXT,   -- +1 byte overhead
    data_text TEXT,       -- +2 bytes overhead
    data_medium MEDIUMTEXT, -- +3 bytes overhead
    data_long LONGTEXT,   -- +4 bytes overhead
    data_json JSON        -- +4 bytes overhead (alias LONGTEXT)
);

-- Ins√©rer la m√™me cha√Æne dans tous les champs
INSERT INTO overhead_test (data_tiny, data_text, data_medium, data_long, data_json)
VALUES ('test', 'test', 'test', 'test', '"test"');

-- Analyser la taille sur disque (approximative)
SELECT
    LENGTH(data_tiny) AS len_tiny,      -- 4
    LENGTH(data_text) AS len_text,      -- 4
    LENGTH(data_medium) AS len_medium,  -- 4
    LENGTH(data_long) AS len_long,      -- 4
    LENGTH(data_json) AS len_json       -- 6 (inclut les guillemets JSON)
FROM overhead_test;
```

### Stockage off-page (overflow pages)

Quand un champ LONGTEXT/JSON d√©passe un certain seuil, InnoDB le stocke dans des **overflow pages** :

```sql
-- Configuration InnoDB pour overflow
SHOW VARIABLES LIKE 'innodb_page_size';
-- 16384 (16 KB par d√©faut)

-- Seuil pour off-page storage
-- Si la ligne totale > ~8KB, les colonnes TEXT/BLOB/JSON sont d√©plac√©es

-- Exemple : Document JSON volumineux
CREATE TABLE documents_volumineux (
    id INT PRIMARY KEY AUTO_INCREMENT,
    titre VARCHAR(200),
    contenu JSON  -- Stock√© off-page si >8KB
);

-- Ins√©rer un document de 50KB
INSERT INTO documents_volumineux (titre, contenu) VALUES
    ('Grand document', REPEAT('{"data": "x"}', 5000));

-- Impact :
-- - Donn√©es principales dans la page InnoDB
-- - Pointeur (20 bytes) vers overflow pages
-- - Contenu r√©el dans overflow pages s√©par√©es
```

### Implications performances

```sql
-- ‚ùå LENT : Lecture de grandes colonnes JSON (off-page)
SELECT * FROM documents_volumineux;
-- N√©cessite de suivre les pointeurs vers overflow pages

-- ‚úÖ RAPIDE : Lecture s√©lective sans JSON
SELECT id, titre FROM documents_volumineux;
-- Pas besoin d'acc√©der aux overflow pages

-- üü° MOYEN : Extraction de petites valeurs JSON
SELECT id, JSON_EXTRACT(contenu, '$.titre') AS titre_doc
FROM documents_volumineux;
-- Doit lire l'overflow page, mais extraction cibl√©e
```

---

## Comparaison performance : MariaDB vs MySQL

### Test de parsing

```sql
-- MariaDB : Parsing √† chaque acc√®s
SELECT JSON_EXTRACT(data, '$.nom') FROM utilisateurs;
-- 1. Lit LONGTEXT depuis disque
-- 2. Parse le JSON texte
-- 3. Extrait la valeur
-- Temps : O(n) o√π n = taille du JSON

-- MySQL 5.7+ : Format binaire pr√©-pars√©
SELECT JSON_EXTRACT(data, '$.nom') FROM utilisateurs;
-- 1. Lit format binaire depuis disque
-- 2. Navigation directe (offset pr√©-calcul√©)
-- 3. Retourne la valeur
-- Temps : O(1) pour acc√®s direct
```

### Benchmark indicatif

```sql
-- Sc√©nario : Table 100k lignes, JSON moyen ~1KB
-- Requ√™te : Extraction d'une valeur simple

-- MariaDB 10.11+
SELECT AVG(CAST(JSON_EXTRACT(data, '$.prix') AS DECIMAL(10,2)))
FROM produits;
-- Temps : ~800ms (parsing de 100k documents)

-- MySQL 8.0
SELECT AVG(CAST(data->>'$.prix' AS DECIMAL(10,2)))
FROM produits;
-- Temps : ~250ms (acc√®s binaire direct)

-- Ratio : MariaDB ~3x plus lent sur extraction JSON
```

üí° **Note** : Cet √©cart se r√©duit si vous utilisez des colonnes virtuelles index√©es dans MariaDB.

### Optimisation MariaDB : Colonnes virtuelles

```sql
-- ‚úÖ Solution MariaDB : Pr√©-extraire et indexer
CREATE TABLE produits_optimises (
    id INT PRIMARY KEY AUTO_INCREMENT,
    nom VARCHAR(100),
    data JSON,
    -- Colonnes virtuelles extraites
    prix DECIMAL(10,2) AS (CAST(JSON_EXTRACT(data, '$.prix') AS DECIMAL(10,2))) STORED,
    categorie VARCHAR(50) AS (JSON_UNQUOTE(JSON_EXTRACT(data, '$.categorie'))) VIRTUAL,
    -- Index sur colonnes virtuelles
    INDEX(prix),
    INDEX(categorie)
);

-- Requ√™te optimis√©e (utilise l'index sur prix)
SELECT AVG(prix) FROM produits_optimises;
-- Temps : ~50ms (pas de parsing JSON, lecture d'index)

-- Comp√©titif avec MySQL !
```

---

## Validation avanc√©e et contraintes

### Validation basique avec CHECK

```sql
-- Validation JSON + contraintes m√©tier
CREATE TABLE commandes (
    id INT PRIMARY KEY AUTO_INCREMENT,
    data JSON,

    -- Contraintes multiples
    CONSTRAINT check_json_valid CHECK (JSON_VALID(data)),
    CONSTRAINT check_required_fields CHECK (
        JSON_CONTAINS_PATH(data, 'all', '$.client_id', '$.montant')
    ),
    CONSTRAINT check_montant_positif CHECK (
        CAST(JSON_EXTRACT(data, '$.montant') AS DECIMAL(10,2)) > 0
    )
);

-- ‚úÖ Valide
INSERT INTO commandes (data) VALUES
    ('{"client_id": 123, "montant": 99.99, "statut": "en_attente"}');

-- ‚ùå Invalide : montant manquant
INSERT INTO commandes (data) VALUES
    ('{"client_id": 123, "statut": "en_attente"}');
-- ERROR 4025 (23000): CONSTRAINT `check_required_fields` failed

-- ‚ùå Invalide : montant n√©gatif
INSERT INTO commandes (data) VALUES
    ('{"client_id": 123, "montant": -10}');
-- ERROR 4025 (23000): CONSTRAINT `check_montant_positif` failed
```

### Validation avec fonctions personnalis√©es

```sql
-- Fonction de validation personnalis√©e
DELIMITER //
CREATE FUNCTION validate_user_json(json_data JSON)
RETURNS BOOLEAN
DETERMINISTIC
BEGIN
    -- V√©rifier structure et valeurs
    IF NOT JSON_VALID(json_data) THEN
        RETURN FALSE;
    END IF;

    -- V√©rifier champs requis
    IF NOT JSON_CONTAINS_PATH(json_data, 'all', '$.nom', '$.email') THEN
        RETURN FALSE;
    END IF;

    -- V√©rifier format email
    IF JSON_UNQUOTE(JSON_EXTRACT(json_data, '$.email')) NOT REGEXP '^[^@]+@[^@]+\.[^@]+$' THEN
        RETURN FALSE;
    END IF;

    RETURN TRUE;
END//
DELIMITER ;

-- Utiliser dans une contrainte
CREATE TABLE utilisateurs_valides (
    id INT PRIMARY KEY AUTO_INCREMENT,
    profile JSON,
    CONSTRAINT check_profile CHECK (validate_user_json(profile))
);

-- ‚úÖ Valide
INSERT INTO utilisateurs_valides (profile) VALUES
    ('{"nom": "Alice", "email": "alice@example.com", "age": 30}');

-- ‚ùå Invalide : email incorrect
INSERT INTO utilisateurs_valides (profile) VALUES
    ('{"nom": "Bob", "email": "pas-un-email"}');
-- ERROR 4025 (23000): CONSTRAINT `check_profile` failed
```

---

## Limites et consid√©rations

### Limite de taille : 4 GB th√©orique

```sql
-- LONGTEXT/JSON : Max 4,294,967,295 bytes (4 GB)
-- Mais limitations pratiques :

-- 1. max_allowed_packet (d√©faut 64 MB)
SHOW VARIABLES LIKE 'max_allowed_packet';
-- 67108864 (64 MB)

-- Insertion d'un document >64MB √©choue
INSERT INTO test (data) VALUES (REPEAT('{"x":1}', 10000000));
-- ERROR 1301 (HY000): Result of repeat() was larger than max_allowed_packet

-- 2. InnoDB row size (~64KB pratique)
-- Documents >8KB stock√©s off-page (overflow)
-- Impact sur performance de lecture

-- 3. M√©moire disponible
-- Parsing JSON consomme RAM proportionnelle √† la taille
```

### Fragmentation avec documents volumineux

```sql
-- Documents JSON qui grossissent causent fragmentation
CREATE TABLE logs (
    id INT PRIMARY KEY AUTO_INCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    events JSON  -- Commence petit, grossit avec le temps
);

-- Insertion initiale : petit document
INSERT INTO logs (events) VALUES ('[]');

-- Ajouts successifs : document grandit
UPDATE logs SET events = JSON_ARRAY_APPEND(events, '$', JSON_OBJECT('event', 'login', 'time', NOW()))
WHERE id = 1;
-- R√©p√©t√© 1000 fois...

-- Probl√®me : Chaque UPDATE peut n√©cessiter d√©placement si page pleine
-- R√©sultat : Fragmentation de la table

-- Solution : Limiter la croissance ou archiver p√©riodiquement
```

### Performance avec JSON tr√®s imbriqu√©

```sql
-- ‚ùå LENT : Imbrication profonde
SELECT JSON_EXTRACT(data, '$.level1.level2.level3.level4.level5.value')
FROM deep_nested;
-- MariaDB doit parser tout le document pour atteindre level5

-- ‚úÖ RAPIDE : Structure plate
SELECT JSON_EXTRACT(data, '$.value')
FROM flat_structure;
-- Acc√®s direct au champ

-- Recommandation : Limiter l'imbrication √† 3-4 niveaux maximum
```

### NULL vs JSON null

```sql
-- Diff√©rence importante entre NULL SQL et "null" JSON
CREATE TABLE test_null (
    id INT PRIMARY KEY,
    data JSON
);

-- NULL SQL : Absence de valeur
INSERT INTO test_null VALUES (1, NULL);
SELECT data FROM test_null WHERE id = 1;
-- NULL (aucune valeur)

-- "null" JSON : Valeur JSON null
INSERT INTO test_null VALUES (2, 'null');
SELECT data FROM test_null WHERE id = 2;
-- null (valeur JSON)

-- Comparaisons
SELECT
    data IS NULL AS is_sql_null,
    JSON_TYPE(data) AS json_type
FROM test_null;
-- id=1 : is_sql_null=1, json_type=NULL
-- id=2 : is_sql_null=0, json_type=NULL (type JSON)

-- Filtrage
SELECT * FROM test_null WHERE data IS NULL;        -- Retourne id=1
SELECT * FROM test_null WHERE data = 'null';       -- Retourne id=2
SELECT * FROM test_null WHERE JSON_TYPE(data) = 'NULL';  -- Retourne id=2
```

---

## Optimisations de stockage

### 1. Compression des documents JSON

```sql
-- MariaDB supporte la compression de page InnoDB
-- Active pour LONGTEXT/JSON automatiquement

-- Configuration de compression
CREATE TABLE documents_compresses (
    id INT PRIMARY KEY AUTO_INCREMENT,
    contenu JSON
) ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;

-- Gain de compression d√©pend du contenu
-- JSON r√©p√©titif : compression ~50-70%
-- JSON al√©atoire : compression ~10-20%

-- V√©rifier la compression
SELECT
    TABLE_NAME,
    ROW_FORMAT,
    CREATE_OPTIONS
FROM INFORMATION_SCHEMA.TABLES
WHERE TABLE_NAME = 'documents_compresses';
```

### 2. Partitionnement avec colonnes virtuelles

```sql
-- Partitionner sur une valeur extraite du JSON
CREATE TABLE ventes_partitionees (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    data JSON,
    -- Colonne virtuelle pour partitionnement
    annee INT AS (YEAR(JSON_UNQUOTE(JSON_EXTRACT(data, '$.date')))) STORED
)
PARTITION BY RANGE (annee) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION pfuture VALUES LESS THAN MAXVALUE
);

-- Requ√™tes sur partition sp√©cifique = plus rapides
SELECT * FROM ventes_partitionees
WHERE annee = 2024;
-- Scanne uniquement la partition p2024
```

### 3. Normalisation s√©lective

```sql
-- Pattern hybride : JSON + colonnes normalis√©es
CREATE TABLE produits_hybrides (
    id INT PRIMARY KEY AUTO_INCREMENT,

    -- Colonnes normalis√©es : donn√©es critiques
    nom VARCHAR(100) NOT NULL,
    prix DECIMAL(10,2) NOT NULL,
    categorie VARCHAR(50) NOT NULL,
    stock INT NOT NULL DEFAULT 0,

    -- JSON : attributs variables
    details JSON,

    -- Index sur colonnes normalis√©es
    INDEX(categorie, prix),
    INDEX(stock)
);

-- Avantages :
-- ‚úÖ Recherches rapides sur prix, categorie, stock
-- ‚úÖ Agr√©gations performantes (SUM, AVG)
-- ‚úÖ Flexibilit√© pour attributs sp√©cifiques dans details
```

---

## Migration et conversion

### Conversion TEXT ‚Üí JSON

```sql
-- Donn√©es existantes en TEXT, migration vers JSON
CREATE TABLE legacy_data (
    id INT PRIMARY KEY,
    config_text TEXT  -- Contient JSON mais non valid√©
);

-- V√©rifier la validit√© avant migration
SELECT
    id,
    JSON_VALID(config_text) AS est_valide,
    config_text
FROM legacy_data
WHERE JSON_VALID(config_text) = 0;
-- Identifier les donn√©es invalides √† corriger

-- Migration s√©curis√©e
ALTER TABLE legacy_data
ADD COLUMN config_json JSON;

UPDATE legacy_data
SET config_json = config_text
WHERE JSON_VALID(config_text) = 1;
-- Seules les donn√©es valides sont migr√©es

-- V√©rifier et corriger les invalides manuellement
-- Puis supprimer l'ancienne colonne
-- ALTER TABLE legacy_data DROP COLUMN config_text;
```

### Conversion JSON ‚Üí Colonnes normalis√©es

```sql
-- D√©normaliser JSON vers colonnes si n√©cessaire
CREATE TABLE produits_denormalises (
    id INT PRIMARY KEY,
    data JSON,
    -- Colonnes extraites
    prix DECIMAL(10,2),
    stock INT,
    marque VARCHAR(50)
);

-- Peupler les colonnes normalis√©es
UPDATE produits_denormalises
SET
    prix = CAST(JSON_EXTRACT(data, '$.prix') AS DECIMAL(10,2)),
    stock = CAST(JSON_EXTRACT(data, '$.stock') AS UNSIGNED),
    marque = JSON_UNQUOTE(JSON_EXTRACT(data, '$.marque'));

-- Cr√©er des index
CREATE INDEX idx_prix ON produits_denormalises(prix);
CREATE INDEX idx_marque ON produits_denormalises(marque);

-- Maintenir la synchronisation avec trigger
DELIMITER //
CREATE TRIGGER sync_json_to_columns
BEFORE UPDATE ON produits_denormalises
FOR EACH ROW
BEGIN
    IF NEW.data != OLD.data OR (NEW.data IS NOT NULL AND OLD.data IS NULL) THEN
        SET NEW.prix = CAST(JSON_EXTRACT(NEW.data, '$.prix') AS DECIMAL(10,2));
        SET NEW.stock = CAST(JSON_EXTRACT(NEW.data, '$.stock') AS UNSIGNED);
        SET NEW.marque = JSON_UNQUOTE(JSON_EXTRACT(NEW.data, '$.marque'));
    END IF;
END//
DELIMITER ;
```

---

## ‚úÖ Points cl√©s √† retenir

- **Type JSON** = alias de LONGTEXT avec validation automatique `JSON_VALID()`
- **Stockage** = format texte UTF-8, pas de format binaire comme MySQL
- **Validation** = automatique √† l'insertion/modification, emp√™che JSON invalide
- **Taille max** = 4 GB th√©orique, limit√© par `max_allowed_packet` (d√©faut 64 MB) en pratique
- **Overhead** = 4 bytes de pr√©fixe + donn√©es texte + parsing √† chaque lecture
- **Off-page storage** = documents >8KB stock√©s dans overflow pages (impact performance)
- **Performance** = Plus lent que MySQL pour extraction JSON (format texte vs binaire)
- **Optimisation** = Colonnes virtuelles index√©es pour valeurs JSON fr√©quemment recherch√©es
- **NULL vs "null"** = Diff√©rence entre NULL SQL (absence) et "null" JSON (valeur)
- **Compression** = Activable avec ROW_FORMAT=COMPRESSED pour √©conomiser espace
- **Best practice** = Mod√®le hybride (colonnes critiques + JSON pour flexibilit√©)
- **Validation avanc√©e** = Contraintes CHECK avec JSON_CONTAINS_PATH, fonctions personnalis√©es

---

## üîó Ressources et r√©f√©rences

- [üìñ Documentation MariaDB - JSON Data Type](https://mariadb.com/kb/en/json-data-type/)
- [üìñ JSON_VALID()](https://mariadb.com/kb/en/json_valid/)
- [üìñ InnoDB Row Formats](https://mariadb.com/kb/en/innodb-row-formats/)
- [üìñ InnoDB Compression](https://mariadb.com/kb/en/innodb-compressed-row-format/)
- [üìñ Generated Columns](https://mariadb.com/kb/en/generated-columns/)

**Comparaisons** :
- [MySQL JSON Type Documentation](https://dev.mysql.com/doc/refman/8.0/en/json.html)
- [PostgreSQL JSONB vs JSON](https://www.postgresql.org/docs/current/datatype-json.html)

---

## ‚û°Ô∏è Section suivante

**[4.7.2 Fonctions JSON (JSON_EXTRACT, JSON_SET, JSON_ARRAY, etc.)](/04-concepts-avances-sql/07.2-fonctions-json.md)** : Explorer les 40+ fonctions JSON disponibles dans MariaDB pour cr√©er, extraire, modifier et analyser des documents JSON.

---

**Note technique** : Le choix de MariaDB de stocker JSON comme texte (vs format binaire MySQL) est un compromis d√©lib√©r√© privil√©giant la compatibilit√© et la simplicit√© au d√©triment de la performance pure. L'utilisation judicieuse de colonnes virtuelles permet de combler l'√©cart de performance pour la plupart des cas d'usage r√©els. Comprenez les implications techniques pour optimiser vos sch√©mas ! üéØ

‚è≠Ô∏è [Fonctions JSON (JSON_EXTRACT, JSON_SET, JSON_ARRAY, etc.)](/04-concepts-avances-sql/07.2-fonctions-json.md)
