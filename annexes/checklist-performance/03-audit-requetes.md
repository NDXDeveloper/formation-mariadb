üîù Retour au [Sommaire](/SOMMAIRE.md)

# E.3 Audit de Requ√™tes

> **Type** : Checklist d'audit queries SQL  
> **Focus** : Slow queries, N+1, optimisations, anti-patterns  
> **Dur√©e** : 2-4 heures  
> **Pr√©requis** : Slow query log activ√©, Performance Schema ON

---

## üéØ Objectifs de cet audit

V√©rifier que les **requ√™tes SQL** sont optimales pour :
- ‚úÖ Toutes les queries < seuil latence (1s OLTP, 10s OLAP)
- ‚úÖ Aucun anti-pattern (N+1, SELECT *, sub-queries inefficaces)
- ‚úÖ Utilisation efficace des index et plans d'ex√©cution
- ‚úÖ Pas de temporary tables sur disque
- ‚úÖ Code applicatif optimis√© (ORM, batching)

**R√©sultat attendu :** Top 10-20 queries √† optimiser avec impact chiffr√© et solutions concr√®tes.

---

## üìã Checklist compl√®te (18 points)

### Cat√©gorie 1 : Identification Slow Queries

#### ‚úÖ 1.1 Top Slow Queries par temps total

**üîç Diagnostic**

```sql
-- Top 20 queries par temps total (Performance Schema)
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query_preview,
    COUNT_STAR AS executions,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec,
    ROUND(MAX_TIMER_WAIT / 1000000000000, 3) AS max_sec,
    ROUND(SUM_TIMER_WAIT / 1000000000000, 2) AS total_sec,
    ROUND(SUM_LOCK_TIME / 1000000000000, 2) AS total_lock_sec,
    SUM_ROWS_EXAMINED AS rows_examined,
    SUM_ROWS_SENT AS rows_sent,
    ROUND(SUM_ROWS_EXAMINED / SUM_ROWS_SENT, 0) AS rows_examined_per_sent
FROM performance_schema.events_statements_summary_by_digest
WHERE SCHEMA_NAME NOT IN ('mysql', 'performance_schema', 'information_schema')
  AND DIGEST_TEXT NOT LIKE '%performance_schema%'
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;
```

**Analyse slow query log :**

```bash
# Avec pt-query-digest (Percona Toolkit)
pt-query-digest /var/log/mysql/slow-query.log \
  --limit 20 \
  --order-by Query_time:sum

# Top queries par temps total, fr√©quence, variance
```

**‚ö†Ô∏è Seuils critiques**

| M√©trique | üü¢ OLTP | üü° OLTP | üî¥ OLTP | üü¢ OLAP |
|----------|---------|---------|---------|---------|
| **Latence P95** | < 50ms | 50-100ms | > 100ms | < 5s |
| **Latence moyenne** | < 10ms | 10-50ms | > 50ms | < 2s |
| **Rows examined/sent** | 1-10√ó | 10-100√ó | > 100√ó | Variable |

**üîß Actions correctives**

1. **Prioriser par impact** :
   ```
   Impact = executions √ó avg_latency
   
   Query A : 1000 exec/sec √ó 100ms = 100s/sec
   Query B : 10 exec/sec √ó 5s = 50s/sec
   
   ‚Üí Optimiser A en priorit√© (impact 2√ó plus grand)
   ```

2. **Cat√©goriser slow queries** :
   ```
   Cat√©gorie 1 : Missing index ‚Üí Cr√©er index (E.2)
   Cat√©gorie 2 : Query mal √©crite ‚Üí Refactoring SQL
   Cat√©gorie 3 : Volum√©trie ‚Üí Partitionnement, archivage
   Cat√©gorie 4 : Lock contention ‚Üí Optimistic locking
   ```

3. **Template analyse** :
   ```sql
   -- Pour chaque slow query :
   
   -- 1. EXPLAIN
   EXPLAIN FORMAT=JSON SELECT ...;
   
   -- 2. Identifier goulot
   -- - Full table scan ?
   -- - Filesort ?
   -- - Temporary table ?
   
   -- 3. Actions
   -- - Ajouter index
   -- - Rewrite query
   -- - Partitionner table
   ```

**üìä Validation**

```sql
-- Comparer avant/apr√®s optimisation
SELECT 
    DIGEST_TEXT,
    COUNT_STAR AS exec_before,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec_before
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%target_query%';

-- Apr√®s optimisation, reset stats
TRUNCATE TABLE performance_schema.events_statements_summary_by_digest;

-- Attendre 24h, re-mesurer
-- avg_sec_after devrait √™tre << avg_sec_before
```

---

#### ‚úÖ 1.2 Queries avec full table scans

**üîç Diagnostic**

```sql
-- Queries sans index (SUM_NO_INDEX_USED > 0)
SELECT 
    LEFT(DIGEST_TEXT, 120) AS query,
    COUNT_STAR AS executions,
    SUM_NO_INDEX_USED AS full_scans,
    SUM_NO_GOOD_INDEX_USED AS suboptimal_index,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec,
    ROUND(SUM_TIMER_WAIT / 1000000000000, 2) AS total_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_NO_INDEX_USED > 0
   OR SUM_NO_GOOD_INDEX_USED > 0
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;
```

**EXPLAIN queries suspectes :**

```sql
-- Exemple query probl√©matique
EXPLAIN SELECT * FROM orders WHERE status = 'pending';

-- ‚ùå Signaux alerte :
-- type: ALL (full table scan)
-- rows: 1000000 (examine 1M lignes)
-- Extra: Using where (filtre apr√®s scan)
```

**‚ö†Ô∏è Seuils critiques**

| Type scan | OLTP | OLAP | Action |
|-----------|------|------|--------|
| **Index scan** | ‚úÖ OK | ‚úÖ OK | - |
| **Range scan** | ‚úÖ OK | ‚úÖ OK | - |
| **Full table scan (< 1K rows)** | ‚úÖ OK | ‚úÖ OK | - |
| **Full table scan (> 10K rows)** | üî¥ Probl√®me | üü° Acceptable | Index |
| **Full table scan (> 1M rows)** | üî¥ Critique | üü° Normal | Index/Partition |

**üîß Actions correctives**

1. **Ajouter index manquant** :
   ```sql
   -- Query lente : WHERE status = 'pending'
   EXPLAIN SELECT * FROM orders WHERE status = 'pending';
   -- type: ALL ‚ùå
   
   -- Cr√©er index
   CREATE INDEX idx_orders_status ON orders(status);
   
   -- V√©rifier
   EXPLAIN SELECT * FROM orders WHERE status = 'pending';
   -- type: ref ‚úÖ
   -- rows: 1000 (au lieu de 1M)
   ```

2. **Index composite pour WHERE multiples** :
   ```sql
   -- WHERE status = X AND created_at > Y
   CREATE INDEX idx_status_created ON orders(status, created_at);
   
   -- Index utilis√© compl√®tement
   ```

3. **Cas OLAP : Full scan acceptable** :
   ```sql
   -- Analytics : Agr√©gation table enti√®re
   SELECT DATE(created_at), COUNT(*)
   FROM orders
   WHERE created_at >= '2024-01-01'
   GROUP BY DATE(created_at);
   
   -- Full scan normal si > 10% table scann√©e
   -- Pas d'optimisation n√©cessaire
   ```

**üìä Validation**

```sql
-- Avant/apr√®s : Rows examined
EXPLAIN SELECT * FROM orders WHERE status = 'pending';

-- Avant index :
-- rows: 1000000

-- Apr√®s index :
-- rows: 1000 (1000√ó r√©duction)
```

---

#### ‚úÖ 1.3 Queries avec filesort/temporary tables

**üîç Diagnostic**

```sql
-- Queries cr√©ant temp tables ou filesort
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query,
    COUNT_STAR AS executions,
    SUM_SORT_MERGE_PASSES AS filesort_on_disk,
    SUM_SORT_ROWS AS rows_sorted,
    SUM_CREATED_TMP_TABLES AS tmp_tables,
    SUM_CREATED_TMP_DISK_TABLES AS tmp_tables_on_disk,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_SORT_MERGE_PASSES > 0
   OR SUM_CREATED_TMP_DISK_TABLES > 0
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;
```

**EXPLAIN pour identifier :**

```sql
EXPLAIN SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;
-- Extra: Using filesort ‚ùå

EXPLAIN SELECT customer_id, COUNT(*)
FROM orders
GROUP BY customer_id;
-- Extra: Using temporary ‚ùå
```

**‚ö†Ô∏è Seuils critiques**

| Op√©ration | üü¢ Optimal | üü° Acceptable | üî¥ Critique |
|-----------|-----------|---------------|-------------|
| **Filesort** | Index utilis√© | M√©moire (RAM) | Sur disque |
| **Temp table** | Pas de temp | M√©moire | Sur disque |
| **Sort merge passes** | 0 | < 10/sec | > 100/sec |

**üîß Actions correctives**

1. **√âliminer filesort avec index** :
   ```sql
   -- Query : ORDER BY created_at DESC
   CREATE INDEX idx_orders_created_desc ON orders(created_at DESC);
   
   EXPLAIN SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;
   -- Extra: Backward index scan ‚úÖ (pas de filesort)
   ```

2. **Temp table ‚Üí Index covering** :
   ```sql
   -- Query lente avec temp table
   SELECT customer_id, status, COUNT(*)
   FROM orders
   WHERE created_at > '2024-01-01'
   GROUP BY customer_id, status;
   
   -- Index covering √©limine temp table
   CREATE INDEX idx_created_customer_status 
   ON orders(created_at, customer_id, status);
   
   -- Extra: Using index ‚úÖ
   ```

3. **Augmenter buffers si impossible √©viter** :
   ```sql
   -- Si filesort/temp in√©vitable, augmenter buffers
   SET SESSION sort_buffer_size = 16777216;  -- 16MB
   SET SESSION tmp_table_size = 134217728;   -- 128MB
   
   -- Ou global (my.cnf)
   -- sort_buffer_size = 16M
   -- tmp_table_size = 128M
   ```

**üìä Validation**

```sql
-- V√©rifier √©limination dans EXPLAIN
EXPLAIN SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;

-- Avant :
-- Extra: Using filesort

-- Apr√®s index :
-- Extra: Backward index scan (pas de filesort ‚úÖ)
```

---

### Cat√©gorie 2 : N+1 Queries Problem

#### ‚úÖ 2.1 D√©tection pattern N+1

**üîç Diagnostic**

Le probl√®me N+1 est **invisible dans Performance Schema** (queries individuelles rapides). Requiert analyse code application.

**Sympt√¥mes :**
```python
# ‚ùå Code application avec N+1
users = db.query("SELECT * FROM users LIMIT 100")  # 1 query
for user in users:
    posts = db.query(f"SELECT * FROM posts WHERE user_id = {user.id}")  # N queries
    # 100 queries suppl√©mentaires !

# Total : 101 queries (1 + 100)
```

**D√©tection via monitoring :**

```sql
-- Spike queries identiques r√©p√©t√©es
-- Pattern suspect dans Performance Schema
SELECT 
    DIGEST_TEXT,
    COUNT_STAR AS executions,
    COUNT_STAR / (SELECT MAX(variable_value) FROM information_schema.global_status WHERE variable_name = 'Uptime') AS queries_per_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%WHERE user_id%'
ORDER BY COUNT_STAR DESC;

-- Si COUNT_STAR tr√®s √©lev√© pour query simple ‚Üí suspect N+1
```

**Outils code :**
- **Django** : django-debug-toolbar (affiche queries)
- **Rails** : Bullet gem (d√©tecte N+1)
- **Node.js** : Dataloader (batching)
- **Laravel** : Debugbar, Telescope

**‚ö†Ô∏è Seuils critiques**

| Sc√©nario | Queries | Impact | Action |
|----------|---------|--------|--------|
| **Liste 10 items** | 11 queries (1+10) | üü° Acceptable | Optimiser si fr√©quent |
| **Liste 100 items** | 101 queries | üî¥ Probl√®me | JOIN ou batching |
| **Liste 1000+ items** | 1001+ queries | üî¥ Critique | Refactoring urgent |

**üîß Actions correctives**

1. **Solution 1 : JOIN** :
   ```sql
   -- ‚ùå N+1 (2 queries)
   SELECT * FROM users WHERE id = 1;
   SELECT * FROM posts WHERE user_id = 1;
   
   -- ‚úÖ JOIN (1 query)
   SELECT 
       u.id, u.name,
       p.id AS post_id, p.title
   FROM users u
   LEFT JOIN posts p ON u.id = p.user_id
   WHERE u.id = 1;
   ```

2. **Solution 2 : Eager Loading (ORM)** :
   ```python
   # ‚ùå Lazy loading (N+1)
   users = User.objects.all()
   for user in users:
       posts = user.posts.all()  # Query par user
   
   # ‚úÖ Eager loading
   users = User.objects.prefetch_related('posts').all()
   # 2 queries optimis√©es :
   # 1. SELECT * FROM users
   # 2. SELECT * FROM posts WHERE user_id IN (1,2,3,...)
   ```

3. **Solution 3 : IN clause batching** :
   ```python
   # ‚ùå N queries
   for user_id in user_ids:
       posts = db.query(f"SELECT * FROM posts WHERE user_id = {user_id}")
   
   # ‚úÖ 1 query avec IN
   posts = db.query(f"SELECT * FROM posts WHERE user_id IN ({','.join(map(str, user_ids))})")
   # Group by user_id en application
   ```

**üìä Validation**

```python
# Avant optimisation
import time
start = time.time()
# Code N+1
duration_n_plus_1 = time.time() - start
# Exemple : 2.5 secondes (101 queries)

# Apr√®s optimisation (JOIN ou eager loading)
start = time.time()
# Code optimis√©
duration_optimized = time.time() - start
# Exemple : 0.05 secondes (1-2 queries)

# Gain : 50√ó plus rapide
```

---

#### ‚úÖ 2.2 Batching et bulk operations

**üîç Diagnostic**

```python
# ‚ùå Anti-pattern : INSERT en boucle
for record in records:  # 1000 records
    db.execute("INSERT INTO logs (message) VALUES (?)", record)
    # 1000 INSERTs individuels = lent
```

**Mesurer impact :**

```sql
-- Compter INSERTs individuels vs bulk
SHOW GLOBAL STATUS LIKE 'Com_insert';
-- Si Com_insert tr√®s √©lev√© : suspect batching manquant
```

**‚ö†Ô∏è Seuils critiques**

| Op√©ration | Individuel | Batch | Gain |
|-----------|------------|-------|------|
| **100 INSERTs** | 1s | 50ms | 20√ó |
| **1000 INSERTs** | 10s | 200ms | 50√ó |
| **10000 INSERTs** | 100s | 2s | 50√ó |

**üîß Actions correctives**

1. **Bulk INSERT** :
   ```sql
   -- ‚ùå 1000 queries
   INSERT INTO logs (message) VALUES ('log1');
   INSERT INTO logs (message) VALUES ('log2');
   -- ...
   
   -- ‚úÖ 1 query
   INSERT INTO logs (message) VALUES
   ('log1'),
   ('log2'),
   ('log3'),
   -- ... 1000 rows
   ('log1000');
   
   -- Ou LOAD DATA INFILE (encore plus rapide)
   LOAD DATA LOCAL INFILE '/tmp/logs.csv'
   INTO TABLE logs
   FIELDS TERMINATED BY ','
   LINES TERMINATED BY '\n';
   ```

2. **Bulk UPDATE** :
   ```sql
   -- ‚ùå 100 UPDATEs individuels
   UPDATE products SET price = 10 WHERE id = 1;
   UPDATE products SET price = 20 WHERE id = 2;
   -- ...
   
   -- ‚úÖ CASE statement (1 query)
   UPDATE products
   SET price = CASE id
       WHEN 1 THEN 10
       WHEN 2 THEN 20
       WHEN 3 THEN 30
       -- ...
       ELSE price
   END
   WHERE id IN (1, 2, 3, ...);
   ```

3. **Transaction batching** :
   ```sql
   -- ‚ùå Auto-commit chaque INSERT (overhead)
   INSERT INTO logs VALUES (...);  -- Commit
   INSERT INTO logs VALUES (...);  -- Commit
   
   -- ‚úÖ Transaction unique
   START TRANSACTION;
   INSERT INTO logs VALUES (...);
   INSERT INTO logs VALUES (...);
   -- ... 1000 INSERTs
   COMMIT;  -- 1 seul commit
   ```

**üìä Validation**

```bash
# Benchmark INSERT
time python insert_individual.py
# 10.5 secondes

time python insert_bulk.py
# 0.2 secondes (50√ó plus rapide)
```

---

### Cat√©gorie 3 : Query Anti-Patterns

#### ‚úÖ 3.1 SELECT * (√©viter)

**üîç Diagnostic**

```sql
-- Rechercher SELECT * dans queries
SELECT 
    LEFT(DIGEST_TEXT, 150) AS query
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%SELECT %*%FROM%'
  AND DIGEST_TEXT NOT LIKE '%COUNT%'
LIMIT 20;
```

**Probl√®mes SELECT * :**

```sql
-- ‚ùå SELECT *
SELECT * FROM users WHERE id = 1;
-- Probl√®mes :
-- 1. Transfert donn√©es inutiles (bio TEXT 10KB, avatar BLOB 500KB)
-- 2. Pas de covering index possible
-- 3. Fragile (schema change casse code)
```

**‚ö†Ô∏è Seuils critiques**

| Table | SELECT * | SELECT colonnes | Gain |
|-------|----------|-----------------|------|
| **10 colonnes, 50KB row** | 50KB | 200 bytes | 250√ó |
| **Table avec BLOB** | 1MB+ | 100 bytes | 10000√ó |

**üîß Actions correctives**

1. **S√©lection explicite colonnes** :
   ```sql
   -- ‚ùå Mauvais
   SELECT * FROM users WHERE id = 1;
   -- Retourne : id, email, name, bio(10KB), avatar(500KB), ...
   
   -- ‚úÖ Bon
   SELECT id, email, name FROM users WHERE id = 1;
   -- Retourne : 3 colonnes, < 1KB
   ```

2. **Covering index possible** :
   ```sql
   -- Avec SELECT *
   SELECT * FROM orders WHERE customer_id = 123;
   -- Index : idx_customer_id ne peut pas √™tre covering
   -- Table lookup requis
   
   -- Avec s√©lection explicite
   SELECT id, total_amount FROM orders WHERE customer_id = 123;
   -- Index covering : idx_customer_id_amount (customer_id, id, total_amount)
   -- Pas de table lookup ‚úÖ
   ```

3. **ORM : Specify fields** :
   ```python
   # ‚ùå Django ORM : SELECT *
   users = User.objects.all()
   
   # ‚úÖ Specify fields
   users = User.objects.values('id', 'email', 'name')
   # Ou
   users = User.objects.only('id', 'email', 'name')
   ```

**üìä Validation**

```sql
-- Mesurer taille r√©sultat
SELECT 
    LENGTH(CONCAT_WS(',', *)) AS row_size_bytes
FROM users
WHERE id = 1;
-- Avec SELECT * : 512000 bytes (500KB)

SELECT 
    LENGTH(CONCAT_WS(',', id, email, name)) AS row_size_bytes
FROM users
WHERE id = 1;
-- Avec colonnes sp√©cifiques : 150 bytes (3000√ó moins)
```

---

#### ‚úÖ 3.2 Fonctions sur colonnes index√©es (√©viter)

**üîç Diagnostic**

```sql
-- Queries avec fonctions sur colonnes WHERE
-- Rendent index inutilisable

-- ‚ùå Fonction sur colonne index√©e
SELECT * FROM orders WHERE YEAR(created_at) = 2024;
-- Index idx_created_at NON utilis√© (fonction emp√™che)

EXPLAIN SELECT * FROM orders WHERE YEAR(created_at) = 2024;
-- type: ALL (full scan malgr√© index)
```

**Anti-patterns courants :**

```sql
-- ‚ùå DATE/TIME functions
WHERE YEAR(created_at) = 2024
WHERE DATE(created_at) = '2024-01-01'
WHERE DATE_FORMAT(created_at, '%Y-%m') = '2024-01'

-- ‚ùå String functions
WHERE LOWER(email) = 'test@example.com'
WHERE SUBSTRING(name, 1, 3) = 'Bob'

-- ‚ùå Math functions
WHERE price * 1.2 > 100
WHERE ABS(balance) < 1000
```

**‚ö†Ô∏è Seuils critiques**

| Pattern | Index utilis√© ? | Performance |
|---------|-----------------|-------------|
| `WHERE col = value` | ‚úÖ Oui | ‚ö° Rapide |
| `WHERE func(col) = value` | ‚ùå Non | üêå Lent (full scan) |
| `WHERE col LIKE 'prefix%'` | ‚úÖ Oui | ‚ö° Rapide |
| `WHERE col LIKE '%suffix'` | ‚ùå Non | üêå Lent |

**üîß Actions correctives**

1. **R√©√©crire sans fonction** :
   ```sql
   -- ‚ùå Fonction sur colonne
   WHERE YEAR(created_at) = 2024
   
   -- ‚úÖ Range (index utilisable)
   WHERE created_at >= '2024-01-01' 
     AND created_at < '2025-01-01'
   
   -- Index idx_created_at utilis√© ‚úÖ
   ```

2. **Colonne g√©n√©r√©e pour fonction** :
   ```sql
   -- Si fonction fr√©quente, cr√©er colonne g√©n√©r√©e
   ALTER TABLE orders 
   ADD COLUMN created_year INT GENERATED ALWAYS AS (YEAR(created_at)) STORED;
   
   CREATE INDEX idx_created_year ON orders(created_year);
   
   -- Query rapide
   SELECT * FROM orders WHERE created_year = 2024;
   -- Index utilis√© ‚úÖ
   ```

3. **Normalisation pour LOWER()** :
   ```sql
   -- ‚ùå Case-insensitive search
   WHERE LOWER(email) = 'test@example.com'
   
   -- ‚úÖ Stocker lowercase d√®s l'insertion
   CREATE TRIGGER before_insert_user
   BEFORE INSERT ON users
   FOR EACH ROW
   SET NEW.email = LOWER(NEW.email);
   
   -- Query simple
   WHERE email = 'test@example.com'
   -- Index utilis√© ‚úÖ
   ```

**üìä Validation**

```sql
-- Comparer plans d'ex√©cution
EXPLAIN SELECT * FROM orders WHERE YEAR(created_at) = 2024;
-- type: ALL, rows: 1000000 ‚ùå

EXPLAIN SELECT * FROM orders 
WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';
-- type: range, rows: 50000, key: idx_created_at ‚úÖ
```

---

#### ‚úÖ 3.3 OR conditions (optimisation)

**üîç Diagnostic**

```sql
-- OR peut emp√™cher utilisation optimale index
SELECT * FROM users 
WHERE email = 'test@example.com' 
   OR username = 'testuser';

EXPLAIN ...;
-- type: index_merge (parfois) ou ALL (pire cas)
```

**‚ö†Ô∏è Seuils critiques**

| Pattern | Index usage | Performance |
|---------|-------------|-------------|
| `WHERE a = X OR b = Y` (index sur a, b) | Index merge | üü° Moyen |
| `WHERE a = X OR a = Y` | Index scan | ‚úÖ Bon |
| `WHERE a = X OR unindexed = Y` | Full scan | üî¥ Mauvais |

**üîß Actions correctives**

1. **UNION ALL pour OR** :
   ```sql
   -- ‚ùå OR avec index merge
   SELECT * FROM users 
   WHERE email = 'test@example.com' 
      OR username = 'testuser';
   
   -- ‚úÖ UNION ALL (2 index scans s√©par√©s)
   SELECT * FROM users WHERE email = 'test@example.com'
   UNION ALL
   SELECT * FROM users WHERE username = 'testuser';
   
   -- Parfois 2-3√ó plus rapide
   ```

2. **IN pour OR sur m√™me colonne** :
   ```sql
   -- ‚ùå Multiple OR
   WHERE status = 'pending' 
      OR status = 'processing' 
      OR status = 'shipped'
   
   -- ‚úÖ IN clause
   WHERE status IN ('pending', 'processing', 'shipped')
   -- Index utilis√© efficacement
   ```

3. **Index composite pour OR fr√©quent** :
   ```sql
   -- Si query fr√©quente : WHERE a = X OR b = Y
   CREATE INDEX idx_a_b ON table(a, b);
   
   -- Ou mieux : index s√©par√©s + index merge
   CREATE INDEX idx_a ON table(a);
   CREATE INDEX idx_b ON table(b);
   -- Optimizer utilise index_merge
   ```

**üìä Validation**

```sql
-- Comparer OR vs UNION ALL
EXPLAIN SELECT * FROM users WHERE email = 'a' OR username = 'b';
-- type: index_merge, rows: 200

EXPLAIN (
    SELECT * FROM users WHERE email = 'a'
    UNION ALL
    SELECT * FROM users WHERE username = 'b'
);
-- Deux index scans s√©par√©s, rows: 1 + 1
```

---

### Cat√©gorie 4 : Sub-queries et JOINs

#### ‚úÖ 4.1 Sub-queries corr√©l√©es (√©viter)

**üîç Diagnostic**

```sql
-- Sub-query corr√©l√©e (ex√©cut√©e pour CHAQUE ligne)
SELECT 
    o.id,
    o.total,
    (SELECT name FROM customers c WHERE c.id = o.customer_id) AS customer_name
FROM orders o;

-- EXPLAIN : Dependent subquery ‚ùå
```

**Performance impact :**

```
Table orders : 100K lignes
‚Üí Sub-query ex√©cut√©e 100K fois
‚Üí Tr√®s lent (m√™me avec index sur customers)

Vs JOIN :
‚Üí 1 seule op√©ration
‚Üí 100-1000√ó plus rapide
```

**‚ö†Ô∏è Seuils critiques**

| Type sub-query | Performance | Recommandation |
|----------------|-------------|----------------|
| **Non-corr√©l√©e** | ‚úÖ Bon | OK (ex√©cut√©e 1√ó) |
| **Corr√©l√©e simple** | üü° Moyen | Remplacer par JOIN |
| **Corr√©l√©e complexe** | üî¥ Mauvais | Refactoring urgent |

**üîß Actions correctives**

1. **Remplacer par JOIN** :
   ```sql
   -- ‚ùå Sub-query corr√©l√©e
   SELECT 
       o.id,
       (SELECT name FROM customers WHERE id = o.customer_id)
   FROM orders o;
   
   -- ‚úÖ JOIN
   SELECT 
       o.id,
       c.name
   FROM orders o
   JOIN customers c ON o.customer_id = c.id;
   
   -- 100-1000√ó plus rapide
   ```

2. **Sub-query non-corr√©l√©e OK** :
   ```sql
   -- ‚úÖ Non-corr√©l√©e (ex√©cut√©e 1 seule fois)
   SELECT * FROM orders
   WHERE customer_id IN (
       SELECT id FROM customers WHERE country = 'France'
   );
   
   -- √âquivalent JOIN, performance similaire
   SELECT o.* FROM orders o
   JOIN customers c ON o.customer_id = c.id
   WHERE c.country = 'France';
   ```

3. **Derived table vs sub-query** :
   ```sql
   -- Sub-query dans FROM (derived table)
   SELECT *
   FROM (
       SELECT customer_id, SUM(total) AS total_spent
       FROM orders
       GROUP BY customer_id
   ) AS customer_totals
   WHERE total_spent > 1000;
   
   -- Equivalent CTE (plus lisible)
   WITH customer_totals AS (
       SELECT customer_id, SUM(total) AS total_spent
       FROM orders
       GROUP BY customer_id
   )
   SELECT * FROM customer_totals WHERE total_spent > 1000;
   ```

**üìä Validation**

```sql
-- Benchmark sub-query vs JOIN
-- Sub-query corr√©l√©e
SELECT BENCHMARK(100, (
    SELECT (SELECT name FROM customers WHERE id = o.customer_id)
    FROM orders o LIMIT 1000
));
-- 5.2 secondes

-- JOIN
SELECT BENCHMARK(100, (
    SELECT c.name FROM orders o JOIN customers c ON o.customer_id = c.id LIMIT 1000
));
-- 0.3 secondes (17√ó plus rapide)
```

---

#### ‚úÖ 4.2 JOIN efficace (ordre et type)

**üîç Diagnostic**

```sql
-- Analyser ordre JOINs
EXPLAIN FORMAT=JSON
SELECT *
FROM orders o
JOIN customers c ON o.customer_id = c.id
JOIN products p ON o.product_id = p.id
WHERE o.created_at > '2024-01-01';
```

**Ordre JOINs important :**

```
Optimizer choisit ordre JOIN optimal MAIS :
- Statistiques parfois obsol√®tes
- Queries complexes > 6 tables : ordre sub-optimal

R√®gle manuelle :
1. Table avec WHERE restrictif d'abord (r√©duit dataset)
2. Petite table avant grosse table
3. Index disponibles
```

**‚ö†Ô∏è Seuils critiques**

| Type JOIN | Use case | Performance |
|-----------|----------|-------------|
| **INNER JOIN** | Intersection | ‚ö° Rapide |
| **LEFT JOIN (small ‚Üí large)** | Extension | ‚úÖ Bon |
| **LEFT JOIN (large ‚Üí small)** | Extension | üü° Moyen |
| **CROSS JOIN** | Produit cart√©sien | üî¥ √âviter |

**üîß Actions correctives**

1. **Straight_JOIN pour forcer ordre** :
   ```sql
   -- Forcer ordre JOIN si optimizer se trompe
   SELECT STRAIGHT_JOIN
       o.*,
       c.name
   FROM small_table o
   JOIN large_table c ON o.customer_id = c.id
   WHERE o.status = 'active';  -- Tr√®s s√©lectif
   
   -- Force small_table d'abord (r√©duit dataset)
   ```

2. **EXISTS vs IN pour semi-join** :
   ```sql
   -- IN (mat√©rialise sub-query)
   SELECT * FROM customers
   WHERE id IN (SELECT customer_id FROM orders WHERE total > 1000);
   
   -- EXISTS (short-circuit possible)
   SELECT * FROM customers c
   WHERE EXISTS (
       SELECT 1 FROM orders o 
       WHERE o.customer_id = c.id AND o.total > 1000
   );
   
   -- EXISTS souvent plus rapide pour grosses tables
   ```

3. **Index pour JOIN conditions** :
   ```sql
   -- JOIN sur colonnes non index√©es
   SELECT *
   FROM orders o
   JOIN shipments s ON o.order_number = s.order_number;
   
   -- Cr√©er index sur colonnes JOIN
   CREATE INDEX idx_orders_order_number ON orders(order_number);
   CREATE INDEX idx_shipments_order_number ON shipments(order_number);
   
   -- JOIN 10-100√ó plus rapide
   ```

**üìä Validation**

```sql
-- Comparer ordres JOIN
EXPLAIN SELECT ...;
-- Regarder "table" column dans ordre d'ex√©cution
-- Si mauvais ordre : utiliser STRAIGHT_JOIN
```

---

### Cat√©gorie 5 : LIMIT et Pagination

#### ‚úÖ 5.1 LIMIT avec OFFSET √©lev√© (√©viter)

**üîç Diagnostic**

```sql
-- Pagination avec OFFSET √©lev√©
SELECT * FROM orders 
ORDER BY created_at DESC 
LIMIT 20 OFFSET 100000;

-- ‚ùå MySQL/MariaDB lit 100020 lignes puis skip 100000
-- Tr√®s lent pour grandes offsets
```

**Performance degradation :**

```
OFFSET 0     : 10ms
OFFSET 1000  : 50ms
OFFSET 10000 : 500ms
OFFSET 100000: 5000ms (5s) ‚ùå

Relation lin√©aire : offset 10√ó plus grand = 10√ó plus lent
```

**‚ö†Ô∏è Seuils critiques**

| OFFSET | Performance | Action |
|--------|-------------|--------|
| **< 1000** | ‚úÖ OK | Standard pagination |
| **1000-10000** | üü° Moyen | Cursor-based |
| **> 10000** | üî¥ Lent | Cursor obligatoire |

**üîß Actions correctives**

1. **Cursor-based pagination (keyset)** :
   ```sql
   -- ‚ùå OFFSET pagination
   SELECT * FROM orders 
   ORDER BY created_at DESC 
   LIMIT 20 OFFSET 100000;
   -- Lit 100020 lignes
   
   -- ‚úÖ Cursor-based
   -- Page 1
   SELECT * FROM orders 
   ORDER BY created_at DESC 
   LIMIT 20;
   -- Retourne : last_created_at = '2024-01-15 10:00:00'
   
   -- Page 2
   SELECT * FROM orders 
   WHERE created_at < '2024-01-15 10:00:00'
   ORDER BY created_at DESC 
   LIMIT 20;
   -- Lit seulement 20 lignes ‚úÖ
   ```

2. **Index pour cursor pagination** :
   ```sql
   -- Index sur colonne ORDER BY
   CREATE INDEX idx_orders_created_desc ON orders(created_at DESC);
   
   -- Cursor pagination ultra rapide (m√™me OFFSET "√©lev√©")
   ```

3. **Infinite scroll vs numbered pages** :
   ```
   ‚ùå Numbered pages : "Page 5000" (OFFSET 100000)
   ‚úÖ Infinite scroll : "Load more" (cursor-based)
   
   UI adaptation pour meilleure performance
   ```

**üìä Validation**

```sql
-- Benchmark OFFSET vs cursor
-- OFFSET 100000
SELECT BENCHMARK(100, (
    SELECT * FROM orders ORDER BY id LIMIT 20 OFFSET 100000
));
-- 50 secondes

-- Cursor
SELECT BENCHMARK(100, (
    SELECT * FROM orders WHERE id < 123456 ORDER BY id DESC LIMIT 20
));
-- 0.5 secondes (100√ó plus rapide)
```

---

## üìä Script d'audit automatis√©

### audit-queries.sql

```sql
-- ============================================================================
-- SCRIPT D'AUDIT REQU√äTES MARIADB 11.8
-- ============================================================================

SELECT '=' AS '', '=' AS '';
SELECT 'AUDIT REQU√äTES SQL' AS '';
SELECT '=' AS '', '=' AS '';

-- 1. TOP 10 SLOW QUERIES
SELECT '\n1. TOP 10 QUERIES PAR TEMPS TOTAL' AS '';
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query,
    COUNT_STAR AS exec,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec,
    ROUND(SUM_TIMER_WAIT / 1000000000000, 2) AS total_sec,
    ROUND(SUM_ROWS_EXAMINED / SUM_ROWS_SENT, 0) AS rows_ratio
FROM performance_schema.events_statements_summary_by_digest
WHERE SCHEMA_NAME NOT IN ('mysql', 'performance_schema', 'information_schema')
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 10;

-- 2. QUERIES SANS INDEX
SELECT '\n2. QUERIES SANS INDEX (üî¥ CRITIQUE)' AS '';
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query,
    COUNT_STAR AS exec,
    SUM_NO_INDEX_USED AS no_index,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_NO_INDEX_USED > 0
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 10;

-- 3. FILESORT ET TEMP TABLES
SELECT '\n3. FILESORT / TEMP TABLES' AS '';
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query,
    SUM_SORT_MERGE_PASSES AS filesort_disk,
    SUM_CREATED_TMP_DISK_TABLES AS tmp_disk,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 3) AS avg_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_SORT_MERGE_PASSES > 0 OR SUM_CREATED_TMP_DISK_TABLES > 0
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 10;

-- 4. QUERIES AVEC SELECT *
SELECT '\n4. QUERIES AVEC SELECT *' AS '';
SELECT 
    LEFT(DIGEST_TEXT, 100) AS query,
    COUNT_STAR AS exec
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT LIKE '%SELECT%*%FROM%'
  AND DIGEST_TEXT NOT LIKE '%COUNT%'
ORDER BY COUNT_STAR DESC
LIMIT 10;

SELECT '=' AS '', '=' AS '';
SELECT 'FIN AUDIT REQU√äTES' AS '';
```

---

## ‚úÖ Points cl√©s √† retenir

- üéØ **Top 10 queries = 80% impact** : Focus sur queries les plus utilis√©es
- üîç **EXPLAIN syst√©matique** : Analyser AVANT d√©ploiement production
- ‚ùå **N+1 = #1 probl√®me** : JOIN ou eager loading obligatoire
- üì¶ **Bulk operations** : 50√ó plus rapide que loops
- üö´ **SELECT * interdit** : S√©lection colonnes explicite
- ‚öôÔ∏è **Fonctions sur colonnes** : Rendent index inutilisable
- üîÄ **Sub-queries corr√©l√©es** : Remplacer par JOIN
- üìÑ **Cursor pagination** : OFFSET √©lev√© = anti-pattern
- üìä **Performance Schema** : Monitoring continu requis
- üîß **Refactoring > Hardware** : Optimiser code avant scaler

---

## üîó Ressources compl√©mentaires

### Documentation MariaDB
- [Optimization and Tuning](https://mariadb.com/kb/en/optimization-and-tuning/)
- [EXPLAIN](https://mariadb.com/kb/en/explain/)
- [Subquery Optimizations](https://mariadb.com/kb/en/subquery-optimizations/)

### Outils
- [pt-query-digest](https://www.percona.com/doc/percona-toolkit/LATEST/pt-query-digest.html)
- [Performance Schema](https://mariadb.com/kb/en/performance-schema/)

### Autres checklists
- [E.1 - Audit de configuration](./01-audit-configuration.md)
- [E.2 - Audit d'indexation](./02-audit-indexation.md)
- [E.4 - Audit de sch√©ma](./04-audit-schema.md)

---

## ‚û°Ô∏è Section suivante

**[E.4 - Audit de sch√©ma](./04-audit-schema.md)** : Design tables, normalisation, partitionnement

---

**MariaDB** : Version 11.8 LTS

‚è≠Ô∏è [Audit de sch√©ma](/annexes/checklist-performance/04-audit-schema.md)
