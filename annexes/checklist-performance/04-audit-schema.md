üîù Retour au [Sommaire](/SOMMAIRE.md)

# E.4 Audit de Sch√©ma

> **Type** : Checklist d'audit design base de donn√©es  
> **Focus** : Structure tables, types de donn√©es, normalisation, partitionnement  
> **Dur√©e** : 1-3 heures  
> **Pr√©requis** : Acc√®s sch√©ma, connaissance m√©tier

---

## üéØ Objectifs de cet audit

V√©rifier que le **design du sch√©ma** est optimal pour :
- ‚úÖ Types de donn√©es appropri√©s (espace, performance)
- ‚úÖ Normalisation adapt√©e au cas d'usage
- ‚úÖ Cl√©s primaires et contraintes efficaces
- ‚úÖ Partitionnement pour tables volumineuses
- ‚úÖ Strat√©gie d'archivage et r√©tention
- ‚úÖ √âvolutivit√© et maintenance

**R√©sultat attendu :** Plan de refactoring sch√©ma avec migrations prioritaires et impact estim√©.

---

## üìã Checklist compl√®te (16 points)

### Cat√©gorie 1 : Types de Donn√©es

#### ‚úÖ 1.1 Taille des entiers (INT vs BIGINT)

**üîç Diagnostic**

```sql
-- Identifier colonnes INT sous-utilis√©es ou surcharg√©es
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    DATA_TYPE,
    CASE DATA_TYPE
        WHEN 'tinyint' THEN 127
        WHEN 'smallint' THEN 32767
        WHEN 'mediumint' THEN 8388607
        WHEN 'int' THEN 2147483647
        WHEN 'bigint' THEN 9223372036854775807
    END AS max_value,
    (SELECT MAX(COLUMN_NAME) FROM TABLE_NAME) AS current_max,
    ROUND(100.0 * (SELECT MAX(COLUMN_NAME) FROM TABLE_NAME) / 
          CASE DATA_TYPE
              WHEN 'int' THEN 2147483647
              WHEN 'bigint' THEN 9223372036854775807
          END, 2) AS usage_pct
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE IN ('tinyint', 'smallint', 'mediumint', 'int', 'bigint')
  AND COLUMN_NAME LIKE '%id%'
ORDER BY TABLE_NAME, COLUMN_NAME;
```

**Tailles des types entiers :**

| Type | Bytes | Range (UNSIGNED) | Use case |
|------|-------|------------------|----------|
| **TINYINT** | 1 | 0 - 255 | Statuts, flags, √¢ges |
| **SMALLINT** | 2 | 0 - 65,535 | IDs tables petites |
| **MEDIUMINT** | 3 | 0 - 16,777,215 | IDs tables moyennes |
| **INT** | 4 | 0 - 4,294,967,295 | IDs standard (~4B) |
| **BIGINT** | 8 | 0 - 18,446,744,073,709,551,615 | Twitter-scale |

**‚ö†Ô∏è Seuils critiques**

| Situation | Probl√®me | Action |
|-----------|----------|--------|
| **BIGINT avec max < 1M** | Gaspillage 4 bytes/row | Downgrade √† INT |
| **INT proche 2B (80%+)** | Risque overflow | Upgrade √† BIGINT |
| **Status en INT** | Gaspillage 3 bytes | TINYINT ou ENUM |

**üîß Actions correctives**

1. **Downgrade BIGINT inutile** :
   ```sql
   -- Table avec 100K lignes, max ID = 100000
   -- BIGINT gaspille 4 bytes √ó 100K = 400 KB
   
   -- ‚ùå Avant
   CREATE TABLE users (
       id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
       -- Max actuel : 100000 (< 4B)
   );
   
   -- ‚úÖ Apr√®s
   ALTER TABLE users MODIFY id INT UNSIGNED AUTO_INCREMENT;
   -- √âconomie : 4 bytes √ó 100K lignes = 400 KB
   -- Sur table 10M lignes = 40 MB √©conomis√©s
   ```

2. **Upgrade INT proche limite** :
   ```sql
   -- Table approche 2 milliards
   SELECT MAX(id) FROM orders;
   -- 1,850,000,000 (85% du max INT)
   
   -- Upgrade AVANT overflow
   ALTER TABLE orders MODIFY id BIGINT UNSIGNED AUTO_INCREMENT;
   
   -- ‚ö†Ô∏è Migration lourde, planifier maintenance window
   ```

3. **Status/Flags en TINYINT ou ENUM** :
   ```sql
   -- ‚ùå Gaspillage
   status INT  -- 4 bytes pour 3 valeurs
   
   -- ‚úÖ Optimis√©
   status TINYINT UNSIGNED  -- 1 byte (0-255)
   -- Ou
   status ENUM('pending', 'completed', 'cancelled')  -- 1-2 bytes
   ```

**üìä Validation**

```sql
-- V√©rifier espace r√©cup√©r√©
SELECT 
    TABLE_NAME,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS size_mb_before
FROM information_schema.tables
WHERE TABLE_SCHEMA = 'mydb' AND TABLE_NAME = 'users';

-- Apr√®s ALTER TABLE
-- size_mb_after < size_mb_before
```

---

#### ‚úÖ 1.2 VARCHAR size optimal

**üîç Diagnostic**

```sql
-- Analyser longueur r√©elle des VARCHAR
SELECT 
    c.TABLE_NAME,
    c.COLUMN_NAME,
    c.CHARACTER_MAXIMUM_LENGTH AS declared_length,
    ROUND(AVG(LENGTH(t.COLUMN_NAME)), 0) AS avg_actual_length,
    MAX(LENGTH(t.COLUMN_NAME)) AS max_actual_length,
    ROUND(100.0 * MAX(LENGTH(t.COLUMN_NAME)) / c.CHARACTER_MAXIMUM_LENGTH, 2) AS usage_pct
FROM information_schema.columns c
JOIN information_schema.tables tbl 
    ON c.TABLE_SCHEMA = tbl.TABLE_SCHEMA 
    AND c.TABLE_NAME = tbl.TABLE_NAME
-- Remplacer par query dynamique r√©elle sur chaque table
WHERE c.TABLE_SCHEMA = DATABASE()
  AND c.DATA_TYPE = 'varchar'
ORDER BY c.CHARACTER_MAXIMUM_LENGTH DESC;
```

**Impacts taille VARCHAR :**

```
VARCHAR(50)  : Longueur stock√©e + donn√©es (ex: "Bob" = 1 byte length + 3 bytes = 4 bytes)
VARCHAR(255) : Idem (pas de p√©nalit√© si donn√©es courtes)
VARCHAR(500) : Peut forcer tmp tables sur disque si total row > 65KB
VARCHAR(5000): ‚ùå Probl√®me performance (sorting, tmp tables)

R√®gle : D√©clarer taille r√©aliste (max observ√© √ó 1.5)
```

**‚ö†Ô∏è Seuils critiques**

| D√©clar√© | R√©el max | Probl√®me | Action |
|---------|----------|----------|--------|
| VARCHAR(255) | < 50 | Pas grave | OK (threshold index) |
| VARCHAR(1000) | < 100 | Gaspillage metadata | R√©duire √† 255 |
| VARCHAR(5000) | Variable | Tmp tables disque | TEXT + index prefix |

**üîß Actions correctives**

1. **R√©duire VARCHAR surdimensionn√©** :
   ```sql
   -- Colonne d√©clar√©e 1000, utilis√©e max 80
   ALTER TABLE products 
   MODIFY name VARCHAR(100) NOT NULL;
   
   -- ‚ö†Ô∏è V√©rifier AVANT qu'aucune donn√©e > 100
   SELECT MAX(LENGTH(name)) FROM products;
   -- Si > 100 ‚Üí ajuster limite
   ```

2. **VARCHAR(255) = threshold magique** :
   ```sql
   -- InnoDB : VARCHAR <= 255 utilise 1 byte pour length
   -- VARCHAR > 255 utilise 2 bytes pour length
   
   -- Pr√©f√©rer VARCHAR(255) si longueur variable < 255
   email VARCHAR(255)  -- vs VARCHAR(320) (RFC 5321)
   ```

3. **TEXT pour contenu long variable** :
   ```sql
   -- ‚ùå VARCHAR tr√®s long
   description VARCHAR(5000)  -- Probl√®me sort, group by
   
   -- ‚úÖ TEXT avec index prefix
   description TEXT,
   INDEX idx_description_prefix (description(100))
   
   -- TEXT stock√© hors page (row pointer)
   ```

**üìä Validation**

```sql
-- V√©rifier distribution longueurs
SELECT 
    LENGTH(name) AS length,
    COUNT(*) AS count
FROM products
GROUP BY LENGTH(name)
ORDER BY length DESC
LIMIT 10;

-- Si 99% < 100 chars ‚Üí VARCHAR(100) optimal
```

---

#### ‚úÖ 1.3 ENUM vs VARCHAR vs TINYINT

**üîç Diagnostic**

```sql
-- Colonnes candidates pour ENUM
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    DATA_TYPE,
    COUNT(DISTINCT COLUMN_NAME) AS distinct_values
FROM information_schema.columns c
-- Joindre avec donn√©es r√©elles (requ√™te par table)
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE = 'varchar'
-- HAVING distinct_values < 10  -- Candidat ENUM
ORDER BY distinct_values;
```

**Comparaison types pour valeurs fixes :**

| Type | Stockage | Avantages | Inconv√©nients |
|------|----------|-----------|---------------|
| **ENUM** | 1-2 bytes | Compact, lisible SQL | Schema change pour nouvelle valeur |
| **VARCHAR** | Length + data | Flexible | 5-20√ó plus gros |
| **TINYINT + lookup** | 1 byte | Le plus compact | Moins lisible, JOIN requis |

**‚ö†Ô∏è Seuils critiques**

| Valeurs distinctes | Type recommand√© | Raison |
|-------------------|-----------------|--------|
| **2-3 (fixe)** | ENUM | Optimal stockage + lisibilit√© |
| **4-10 (fixe)** | ENUM ou TINYINT | Selon fr√©quence changement |
| **10+ (√©volutif)** | VARCHAR ou lookup table | Flexibilit√© |

**üîß Actions correctives**

1. **VARCHAR ‚Üí ENUM pour valeurs fixes** :
   ```sql
   -- ‚ùå Avant : status VARCHAR(20)
   -- Valeurs : 'pending', 'completed', 'cancelled'
   -- Stockage : 7-9 bytes par row
   
   -- ‚úÖ Apr√®s : status ENUM
   ALTER TABLE orders 
   MODIFY status ENUM('pending', 'processing', 'shipped', 'completed', 'cancelled') 
   NOT NULL DEFAULT 'pending';
   -- Stockage : 1 byte par row (5 valeurs = 1 byte ENUM)
   
   -- √âconomie : Table 10M lignes = 10M √ó 8 bytes = 80 MB
   ```

2. **ENUM avec valeurs fr√©quentes** :
   ```sql
   -- Use case : 99% des valeurs dans 5 cat√©gories
   -- 1% autres
   
   -- ‚úÖ ENUM + 'other' + colonne description
   category ENUM('electronics', 'clothing', 'food', 'books', 'other'),
   category_other VARCHAR(50) NULL  -- Seulement si category = 'other'
   ```

3. **Lookup table pour √©volutivit√©** :
   ```sql
   -- Si nouvelles valeurs fr√©quentes (sans ALTER TABLE)
   CREATE TABLE order_statuses (
       id TINYINT UNSIGNED PRIMARY KEY,
       name VARCHAR(50) NOT NULL UNIQUE
   );
   
   CREATE TABLE orders (
       id BIGINT PRIMARY KEY,
       status_id TINYINT UNSIGNED NOT NULL,
       FOREIGN KEY (status_id) REFERENCES order_statuses(id)
   );
   
   -- Ajout nouvelle valeur = INSERT (pas de schema change)
   ```

**üìä Validation**

```sql
-- Comparer taille table avant/apr√®s
SELECT 
    ROUND(DATA_LENGTH / 1024 / 1024, 2) AS data_mb,
    ROUND(INDEX_LENGTH / 1024 / 1024, 2) AS index_mb
FROM information_schema.tables
WHERE TABLE_SCHEMA = 'mydb' AND TABLE_NAME = 'orders';

-- Apr√®s VARCHAR ‚Üí ENUM : data_mb devrait diminuer
```

---

#### ‚úÖ 1.4 JSON vs colonnes normalis√©es

**üîç Diagnostic**

```sql
-- Tables avec colonnes JSON
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    DATA_TYPE
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE = 'json';

-- Analyser taille JSON
SELECT 
    AVG(LENGTH(json_column)) AS avg_json_size_bytes,
    MAX(LENGTH(json_column)) AS max_json_size_bytes,
    COUNT(DISTINCT JSON_KEYS(json_column)) AS distinct_key_sets
FROM table_with_json;
```

**JSON : Quand utiliser ?**

```
‚úÖ Utiliser JSON :
- Sch√©ma flexible (user preferences, metadata)
- Donn√©es semi-structur√©es (API responses)
- √âvolution fr√©quente du sch√©ma
- Queries rares sur attributs JSON

‚ùå √âviter JSON :
- Queries fr√©quentes sur attributs
- Agr√©gations (SUM, AVG sur attribut JSON)
- Index sur sous-attribut requis
- Donn√©es volumineuses
```

**‚ö†Ô∏è Seuils critiques**

| Use case | JSON | Colonnes normales |
|----------|------|-------------------|
| **User preferences** | ‚úÖ Optimal | ‚ùå Rigide |
| **Product attributes (query fr√©quent)** | ‚ùå Lent | ‚úÖ Optimal |
| **Logs non-structur√©s** | ‚úÖ OK | ‚ùå Complexe |
| **Analytics queries** | ‚ùå Tr√®s lent | ‚úÖ Rapide |

**üîß Actions correctives**

1. **JSON ‚Üí Colonnes pour queries fr√©quentes** :
   ```sql
   -- ‚ùå JSON query√© souvent
   CREATE TABLE products (
       id BIGINT PRIMARY KEY,
       attributes JSON
       -- {"price": 99.99, "stock": 50, "category": "electronics"}
   );
   
   SELECT * FROM products 
   WHERE JSON_EXTRACT(attributes, '$.price') > 50;
   -- Tr√®s lent, pas d'index possible
   
   -- ‚úÖ Colonnes normalis√©es
   ALTER TABLE products 
   ADD COLUMN price DECIMAL(10,2),
   ADD COLUMN stock INT UNSIGNED,
   ADD COLUMN category VARCHAR(50);
   
   CREATE INDEX idx_price ON products(price);
   CREATE INDEX idx_category ON products(category);
   
   -- Queries 100-1000√ó plus rapides
   ```

2. **Colonnes ‚Üí JSON pour flexibilit√©** :
   ```sql
   -- Si sch√©ma change souvent (metadata, preferences)
   -- 50+ colonnes optionnelles ‚Üí JSON
   
   -- Avant : 50 colonnes NULL
   user_pref_1 VARCHAR(50),
   user_pref_2 VARCHAR(50),
   -- ...
   user_pref_50 VARCHAR(50)
   
   -- Apr√®s : 1 colonne JSON
   preferences JSON
   -- {"theme": "dark", "language": "fr", "notifications": true}
   ```

3. **üÜï MariaDB 11.8 : Generated columns + index** :
   ```sql
   -- JSON avec index sur sous-attribut
   CREATE TABLE products (
       id BIGINT PRIMARY KEY,
       attributes JSON,
       
       -- Colonne g√©n√©r√©e pour attribut query√©
       price DECIMAL(10,2) GENERATED ALWAYS AS (JSON_VALUE(attributes, '$.price')) STORED,
       
       INDEX idx_price (price)
   );
   
   -- Query rapide avec index
   SELECT * FROM products WHERE price > 50;
   -- Utilise idx_price ‚úÖ
   ```

**üìä Validation**

```sql
-- Comparer performance
-- JSON query
EXPLAIN SELECT * FROM products 
WHERE JSON_EXTRACT(attributes, '$.category') = 'electronics';
-- type: ALL (full scan)

-- Colonne normale
EXPLAIN SELECT * FROM products WHERE category = 'electronics';
-- type: ref, key: idx_category ‚úÖ
```

---

### Cat√©gorie 2 : Normalisation et Design

#### ‚úÖ 2.1 Niveau de normalisation (3NF vs d√©normalisation)

**üîç Diagnostic**

```sql
-- D√©tecter colonnes dupliqu√©es (candidates d√©normalisation inverse)
SELECT 
    c1.TABLE_NAME AS table1,
    c1.COLUMN_NAME,
    c2.TABLE_NAME AS table2
FROM information_schema.columns c1
JOIN information_schema.columns c2
  ON c1.COLUMN_NAME = c2.COLUMN_NAME
  AND c1.TABLE_NAME < c2.TABLE_NAME
WHERE c1.TABLE_SCHEMA = DATABASE()
  AND c2.TABLE_SCHEMA = DATABASE()
  AND c1.COLUMN_NAME NOT IN ('id', 'created_at', 'updated_at')
ORDER BY c1.COLUMN_NAME;
```

**Niveaux normalisation :**

```
1NF : Valeurs atomiques (pas de listes dans colonnes)
2NF : Pas de d√©pendances partielles
3NF : Pas de d√©pendances transitives

Optimal OLTP : 3NF (pas de redondance)
Optimal OLAP : D√©normalis√© (star schema, agr√©gats pr√©-calcul√©s)
```

**‚ö†Ô∏è Seuils critiques**

| Cas d'usage | Normalisation | Raison |
|-------------|---------------|--------|
| **OLTP transactionnel** | 3NF strict | √âviter anomalies update |
| **OLTP lectures >> writes** | 2NF + d√©norm cibl√©e | Optimiser JOINs fr√©quents |
| **OLAP reporting** | Star schema | √âviter JOINs complexes |
| **Mixed workload** | 3NF + tables summary | Compromis |

**üîß Actions correctives**

1. **Normaliser donn√©es redondantes** :
   ```sql
   -- ‚ùå D√©normalis√© (anomalies update)
   CREATE TABLE orders (
       id BIGINT PRIMARY KEY,
       customer_name VARCHAR(100),
       customer_email VARCHAR(255),
       customer_phone VARCHAR(20)
       -- Si customer change email ‚Üí UPDATE tous orders ‚ùå
   );
   
   -- ‚úÖ Normalis√© 3NF
   CREATE TABLE customers (
       id BIGINT PRIMARY KEY,
       name VARCHAR(100),
       email VARCHAR(255),
       phone VARCHAR(20)
   );
   
   CREATE TABLE orders (
       id BIGINT PRIMARY KEY,
       customer_id BIGINT NOT NULL,
       FOREIGN KEY (customer_id) REFERENCES customers(id)
   );
   ```

2. **D√©normaliser pour performance (OLTP lecture)** :
   ```sql
   -- Si query fr√©quente n√©cessite JOIN
   SELECT o.id, o.total, c.name
   FROM orders o
   JOIN customers c ON o.customer_id = c.id;
   -- Ex√©cut√©e 10000√ó/sec
   
   -- D√©normaliser colonne rarement modifi√©e
   ALTER TABLE orders ADD COLUMN customer_name VARCHAR(100);
   
   -- Maintenir avec trigger
   CREATE TRIGGER update_customer_name
   AFTER UPDATE ON customers
   FOR EACH ROW
   UPDATE orders SET customer_name = NEW.name WHERE customer_id = NEW.id;
   
   -- Query sans JOIN (10√ó plus rapide)
   SELECT id, total, customer_name FROM orders;
   ```

3. **OLAP : Star schema** :
   ```sql
   -- Fact table (centre)
   CREATE TABLE fact_sales (
       sale_id BIGINT PRIMARY KEY,
       date_id INT,           -- FK ‚Üí dim_date
       product_id INT,        -- FK ‚Üí dim_product
       customer_id INT,       -- FK ‚Üí dim_customer
       amount DECIMAL(10,2),
       quantity INT
   );
   
   -- Dimension tables (d√©normalis√©es)
   CREATE TABLE dim_product (
       product_id INT PRIMARY KEY,
       name VARCHAR(100),
       category VARCHAR(50),
       brand VARCHAR(50),
       -- Toutes infos product (pas de JOIN sous-cat√©gories)
   );
   
   -- Query OLAP rapide (1 ou 2 JOINs max)
   ```

**üìä Validation**

```sql
-- Comparer performance avant/apr√®s d√©normalisation
-- Avant (JOIN)
EXPLAIN SELECT o.id, c.name FROM orders o JOIN customers c ON o.customer_id = c.id;
-- rows examined: 1M + 100K

-- Apr√®s (d√©normalis√©)
EXPLAIN SELECT id, customer_name FROM orders;
-- rows examined: 1M (pas de JOIN)
```

---

#### ‚úÖ 2.2 Cl√©s primaires (choix et type)

**üîç Diagnostic**

```sql
-- Tables sans PRIMARY KEY
SELECT 
    t.TABLE_NAME,
    t.ENGINE,
    t.TABLE_ROWS
FROM information_schema.tables t
WHERE t.TABLE_SCHEMA = DATABASE()
  AND t.TABLE_TYPE = 'BASE TABLE'
  AND NOT EXISTS (
      SELECT 1 FROM information_schema.statistics s
      WHERE s.TABLE_SCHEMA = t.TABLE_SCHEMA
        AND s.TABLE_NAME = t.TABLE_NAME
        AND s.INDEX_NAME = 'PRIMARY'
  );

-- PRIMARY KEY composites
SELECT 
    TABLE_NAME,
    GROUP_CONCAT(COLUMN_NAME ORDER BY SEQ_IN_INDEX) AS pk_columns,
    COUNT(*) AS pk_column_count
FROM information_schema.statistics
WHERE TABLE_SCHEMA = DATABASE()
  AND INDEX_NAME = 'PRIMARY'
GROUP BY TABLE_NAME
HAVING pk_column_count > 1;
```

**Types PRIMARY KEY :**

| Type | Avantages | Inconv√©nients | Use case |
|------|-----------|---------------|----------|
| **AUTO_INCREMENT INT** | Simple, s√©quentiel | Pr√©dictible | Standard OLTP |
| **AUTO_INCREMENT BIGINT** | Scalable | +4 bytes | Twitter-scale |
| **UUID/GUID** | Distribu√©, unique globalement | 16 bytes, random I/O | Microservices |
| **Composite** | Logique m√©tier | Index secondaires gros | Many-to-many |

**‚ö†Ô∏è Seuils critiques**

| Probl√®me | Impact | Action |
|----------|--------|--------|
| **Pas de PRIMARY KEY** | üî¥ Critique | Cr√©er imm√©diatement |
| **UUID sur grosse table** | Fragmentation index | INT + UUID unique |
| **PK composite 3+ colonnes** | Index √©normes | Surrogate key |

**üîß Actions correctives**

1. **Ajouter PRIMARY KEY manquant** :
   ```sql
   -- ‚ùå Table sans PK
   CREATE TABLE logs (
       message TEXT,
       created_at TIMESTAMP
   );
   -- InnoDB cr√©e hidden PK (6 bytes) + pas de contrainte unicit√©
   
   -- ‚úÖ Ajouter PK
   ALTER TABLE logs ADD COLUMN id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY FIRST;
   ```

2. **UUID : Compromis performance** :
   ```sql
   -- ‚ùå UUID PRIMARY KEY sur table volumineuse
   CREATE TABLE events (
       id BINARY(16) PRIMARY KEY DEFAULT (UUID_TO_BIN(UUID())),
       -- Random I/O, fragmentation index
   );
   
   -- ‚úÖ INT AUTO_INCREMENT + UUID UNIQUE
   CREATE TABLE events (
       id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,  -- S√©quentiel
       uuid BINARY(16) UNIQUE NOT NULL DEFAULT (UUID_TO_BIN(UUID())),
       INDEX idx_uuid (uuid)
   );
   -- Utiliser id en interne, uuid pour API externe
   ```

3. **Composite PK ‚Üí Surrogate key** :
   ```sql
   -- ‚ùå PK composite lourd
   CREATE TABLE user_roles (
       user_id BIGINT,
       role_id BIGINT,
       organization_id BIGINT,
       PRIMARY KEY (user_id, role_id, organization_id)
   );
   -- Index secondaires incluent les 3 colonnes (24 bytes)
   
   -- ‚úÖ Surrogate key + UNIQUE composite
   CREATE TABLE user_roles (
       id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
       user_id BIGINT,
       role_id BIGINT,
       organization_id BIGINT,
       UNIQUE KEY uk_user_role_org (user_id, role_id, organization_id)
   );
   -- Index secondaires utilisent id (8 bytes)
   ```

**üìä Validation**

```sql
-- V√©rifier taille index apr√®s changement PK
SELECT 
    TABLE_NAME,
    INDEX_NAME,
    ROUND(STAT_VALUE * @@innodb_page_size / 1024 / 1024, 2) AS size_mb
FROM mysql.innodb_index_stats
WHERE DATABASE_NAME = 'mydb'
  AND TABLE_NAME = 'events'
ORDER BY STAT_VALUE DESC;
```

---

### Cat√©gorie 3 : Partitionnement

#### ‚úÖ 3.1 Candidates au partitionnement

**üîç Diagnostic**

```sql
-- Tables volumineuses (> 10M lignes ou > 10GB)
SELECT 
    TABLE_NAME,
    TABLE_ROWS,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 / 1024, 2) AS size_gb,
    ROUND(DATA_LENGTH / TABLE_ROWS, 0) AS avg_row_bytes,
    CREATE_TIME,
    CASE 
        WHEN TABLE_ROWS > 100000000 THEN 'üî¥ CRITIQUE (>100M)'
        WHEN TABLE_ROWS > 10000000 THEN 'üü° Candidat (>10M)'
        ELSE 'üü¢ OK'
    END AS partitioning_status
FROM information_schema.tables
WHERE TABLE_SCHEMA = DATABASE()
  AND TABLE_TYPE = 'BASE TABLE'
ORDER BY TABLE_ROWS DESC;

-- Tables avec pattern temporel (time-series)
SELECT 
    TABLE_NAME,
    COLUMN_NAME
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND (COLUMN_NAME LIKE '%date%' OR COLUMN_NAME LIKE '%created%' OR DATA_TYPE IN ('date', 'datetime', 'timestamp'))
ORDER BY TABLE_NAME;
```

**Candidats partitionnement :**

```
‚úÖ Partitionner si :
1. Table > 10M lignes ou > 10GB
2. Queries filtr√©es par date/range (WHERE created_at > '2024-01-01')
3. Archivage p√©riodique (DROP partition vs DELETE)
4. Donn√©es time-series (logs, events, metrics)

‚ùå Ne PAS partitionner :
- Table < 1M lignes (overhead inutile)
- Queries sans filtre partition key
- Nombreux index (multiplication par nb partitions)
```

**‚ö†Ô∏è Seuils critiques**

| Taille table | Partitionnement | Raison |
|--------------|-----------------|--------|
| **< 1M lignes** | ‚ùå Non | Overhead > b√©n√©fice |
| **1-10M lignes** | üü° Optionnel | Selon use case |
| **> 10M lignes** | ‚úÖ Recommand√© | Maintenance + perf |
| **> 100M lignes** | üî¥ Obligatoire | Management impossible sans |

**üîß Actions correctives**

1. **RANGE partitioning (time-series)** :
   ```sql
   -- Table logs 100M lignes, requ√™tes sur created_at
   
   -- Partitionner par mois
   ALTER TABLE logs PARTITION BY RANGE (YEAR(created_at) * 100 + MONTH(created_at)) (
       PARTITION p202401 VALUES LESS THAN (202402),  -- Jan 2024
       PARTITION p202402 VALUES LESS THAN (202403),  -- Feb 2024
       PARTITION p202403 VALUES LESS THAN (202404),  -- Mar 2024
       -- ...
       PARTITION p202412 VALUES LESS THAN (202501),  -- Dec 2024
       PARTITION p_future VALUES LESS THAN MAXVALUE
   );
   
   -- Query sur 1 mois = scan 1 partition (vs table enti√®re)
   SELECT * FROM logs WHERE created_at >= '2024-03-01' AND created_at < '2024-04-01';
   -- Partition pruning : Scan seulement p202403 ‚úÖ
   ```

2. **Archivage avec DROP PARTITION** :
   ```sql
   -- Supprimer donn√©es > 1 an
   
   -- ‚ùå Sans partition : DELETE (tr√®s lent)
   DELETE FROM logs WHERE created_at < '2023-01-01';
   -- Sur 100M lignes = heures, lock table
   
   -- ‚úÖ Avec partition : DROP (instantan√©)
   ALTER TABLE logs DROP PARTITION p202301, p202302, p202303;
   -- Millisecondes, pas de lock table ‚úÖ
   ```

3. **LIST partitioning (g√©ographie, cat√©gorie)** :
   ```sql
   -- Partitionner par r√©gion
   ALTER TABLE orders PARTITION BY LIST (country_code) (
       PARTITION p_us VALUES IN ('US'),
       PARTITION p_eu VALUES IN ('FR', 'DE', 'UK', 'ES', 'IT'),
       PARTITION p_asia VALUES IN ('JP', 'CN', 'KR', 'IN'),
       PARTITION p_other VALUES IN (DEFAULT)
   );
   
   -- Query filtr√©e par pays = 1 partition
   SELECT * FROM orders WHERE country_code = 'FR';
   -- Scan seulement p_eu
   ```

**üìä Validation**

```sql
-- V√©rifier partition pruning
EXPLAIN PARTITIONS
SELECT * FROM logs WHERE created_at >= '2024-03-01' AND created_at < '2024-04-01';
-- partitions: p202403 (1 seule partition scann√©e ‚úÖ)

-- Statistiques par partition
SELECT 
    PARTITION_NAME,
    TABLE_ROWS,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS size_mb
FROM information_schema.partitions
WHERE TABLE_SCHEMA = 'mydb' AND TABLE_NAME = 'logs'
ORDER BY PARTITION_ORDINAL_POSITION;
```

---

#### ‚úÖ 3.2 Strat√©gie d'archivage

**üîç Diagnostic**

```sql
-- Distribution temporelle des donn√©es
SELECT 
    DATE_FORMAT(created_at, '%Y-%m') AS month,
    COUNT(*) AS row_count,
    ROUND(COUNT(*) * AVG_ROW_LENGTH / 1024 / 1024, 2) AS estimated_mb
FROM large_table
GROUP BY DATE_FORMAT(created_at, '%Y-%m')
ORDER BY month DESC;

-- Donn√©es anciennes jamais acc√©d√©es
SELECT 
    MIN(created_at) AS oldest_record,
    MAX(created_at) AS newest_record,
    DATEDIFF(NOW(), MIN(created_at)) AS days_retention
FROM large_table;
```

**Strat√©gies archivage :**

```
1. Hard delete : DELETE (lent, lock)
2. Soft delete : is_archived = 1 (espace pas lib√©r√©)
3. Archive table : INSERT INTO archive + DELETE FROM main
4. Partition DROP : ALTER TABLE DROP PARTITION (instantan√© ‚úÖ)
5. External storage : Export S3/parquet + DELETE
```

**‚ö†Ô∏è Seuils critiques**

| R√©tention | Strat√©gie | Raison |
|-----------|-----------|--------|
| **< 30 jours** | Partition RANGE journali√®re | Archivage fr√©quent |
| **30-365 jours** | Partition RANGE mensuelle | √âquilibre |
| **1-3 ans** | Archive table | Queries rares |
| **> 3 ans** | Cold storage (S3) | Compliance, co√ªt |

**üîß Actions correctives**

1. **Archive table automatis√©e** :
   ```sql
   -- Table principale (donn√©es chaudes)
   CREATE TABLE orders (
       id BIGINT PRIMARY KEY,
       created_at DATETIME NOT NULL,
       -- ...
   ) PARTITION BY RANGE (YEAR(created_at) * 100 + MONTH(created_at)) (
       -- Partitions r√©centes
   );
   
   -- Table archive (donn√©es froides)
   CREATE TABLE orders_archive LIKE orders;
   
   -- Event Scheduler : Archivage automatique mensuel
   CREATE EVENT archive_old_orders
   ON SCHEDULE EVERY 1 MONTH
   DO
   BEGIN
       -- Calculer partition √† archiver (> 1 an)
       SET @old_partition = CONCAT('p', DATE_FORMAT(DATE_SUB(NOW(), INTERVAL 13 MONTH), '%Y%m'));
       
       -- Copier vers archive
       SET @sql = CONCAT('INSERT INTO orders_archive SELECT * FROM orders PARTITION (', @old_partition, ')');
       PREPARE stmt FROM @sql;
       EXECUTE stmt;
       DEALLOCATE PREPARE stmt;
       
       -- Supprimer partition
       SET @sql = CONCAT('ALTER TABLE orders DROP PARTITION ', @old_partition);
       PREPARE stmt FROM @sql;
       EXECUTE stmt;
       DEALLOCATE PREPARE stmt;
   END;
   ```

2. **Soft delete avec filtre applicatif** :
   ```sql
   -- Colonne archived_at
   ALTER TABLE orders ADD COLUMN archived_at DATETIME NULL;
   CREATE INDEX idx_archived_at ON orders(archived_at);
   
   -- Archiver logiquement (pas de suppression)
   UPDATE orders 
   SET archived_at = NOW() 
   WHERE created_at < DATE_SUB(NOW(), INTERVAL 1 YEAR);
   
   -- Application filtre automatique
   SELECT * FROM orders WHERE archived_at IS NULL;
   
   -- Purge physique p√©riodique (batch)
   DELETE FROM orders WHERE archived_at < DATE_SUB(NOW(), INTERVAL 3 YEAR) LIMIT 10000;
   ```

3. **ColumnStore pour cold data** :
   ```sql
   -- üÜï MariaDB 11.8 : Donn√©es anciennes ‚Üí ColumnStore (compression)
   
   -- Table hot (InnoDB)
   CREATE TABLE metrics_hot (
       id BIGINT AUTO_INCREMENT PRIMARY KEY,
       created_at DATETIME,
       value DOUBLE
   ) ENGINE=InnoDB;
   
   -- Table cold (ColumnStore - compression 10√ó)
   CREATE TABLE metrics_cold (
       id BIGINT,
       created_at DATETIME,
       value DOUBLE
   ) ENGINE=ColumnStore;
   
   -- Migration mensuelle hot ‚Üí cold
   INSERT INTO metrics_cold 
   SELECT * FROM metrics_hot 
   WHERE created_at < DATE_SUB(NOW(), INTERVAL 3 MONTH);
   
   DELETE FROM metrics_hot 
   WHERE created_at < DATE_SUB(NOW(), INTERVAL 3 MONTH);
   ```

**üìä Validation**

```sql
-- V√©rifier espace r√©cup√©r√©
SELECT 
    TABLE_NAME,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 / 1024, 2) AS size_gb
FROM information_schema.tables
WHERE TABLE_SCHEMA = 'mydb'
  AND TABLE_NAME IN ('orders', 'orders_archive');

-- orders devrait diminuer apr√®s archivage
```

---

### Cat√©gorie 4 : Contraintes et Relations

#### ‚úÖ 4.1 Foreign Keys (performance vs int√©grit√©)

**üîç Diagnostic**

```sql
-- Foreign Keys d√©finies
SELECT 
    kcu.TABLE_NAME,
    kcu.COLUMN_NAME,
    kcu.REFERENCED_TABLE_NAME,
    kcu.REFERENCED_COLUMN_NAME,
    rc.UPDATE_RULE,
    rc.DELETE_RULE
FROM information_schema.key_column_usage kcu
JOIN information_schema.referential_constraints rc
  ON kcu.CONSTRAINT_NAME = rc.CONSTRAINT_NAME
  AND kcu.TABLE_SCHEMA = rc.CONSTRAINT_SCHEMA
WHERE kcu.TABLE_SCHEMA = DATABASE()
  AND kcu.REFERENCED_TABLE_NAME IS NOT NULL;

-- Tables sans FK mais devraient en avoir
-- (D√©tection manuelle via nommage : *_id)
SELECT 
    TABLE_NAME,
    COLUMN_NAME
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND COLUMN_NAME LIKE '%\_id'
  AND COLUMN_NAME != 'id'
  AND NOT EXISTS (
      SELECT 1 FROM information_schema.key_column_usage kcu
      WHERE kcu.TABLE_SCHEMA = DATABASE()
        AND kcu.TABLE_NAME = columns.TABLE_NAME
        AND kcu.COLUMN_NAME = columns.COLUMN_NAME
        AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
  );
```

**Foreign Keys : Trade-offs**

| Aspect | Avec FK | Sans FK |
|--------|---------|---------|
| **Int√©grit√©** | ‚úÖ Garantie | ‚ùå Doit v√©rifier en app |
| **Performance INSERT** | üü° -5-10% | ‚úÖ Plus rapide |
| **Performance DELETE** | üü° Cascade check | ‚úÖ Plus rapide |
| **D√©veloppement** | ‚úÖ S√©curis√© | ‚ùå Bugs possibles |

**‚ö†Ô∏è Seuils critiques**

| Cas d'usage | FK | Raison |
|-------------|-----|--------|
| **OLTP standard** | ‚úÖ Activer | Int√©grit√© critique |
| **Bulk loading** | ‚ö†Ô∏è D√©sactiver temporairement | Performance import |
| **OLAP read-only** | üü° Optionnel | Pas de writes |
| **Sharded tables** | ‚ùå Impossible | FK cross-shard |

**üîß Actions correctives**

1. **Ajouter FK manquantes** :
   ```sql
   -- Colonne orders.customer_id sans FK
   ALTER TABLE orders
   ADD CONSTRAINT fk_orders_customer
   FOREIGN KEY (customer_id) REFERENCES customers(id)
   ON DELETE RESTRICT  -- Emp√™cher suppression client avec orders
   ON UPDATE CASCADE;  -- Update ID propage
   
   -- ‚ö†Ô∏è V√©rifier donn√©es valides AVANT
   SELECT DISTINCT o.customer_id
   FROM orders o
   LEFT JOIN customers c ON o.customer_id = c.id
   WHERE c.id IS NULL;
   -- Si r√©sultat non vide : nettoyer donn√©es orphelines
   ```

2. **D√©sactiver FK pour bulk import** :
   ```sql
   -- Import massif (100M lignes)
   SET foreign_key_checks = 0;
   
   LOAD DATA INFILE '/tmp/orders.csv'
   INTO TABLE orders
   FIELDS TERMINATED BY ',';
   
   SET foreign_key_checks = 1;
   
   -- Gain : 20-40% performance import
   ```

3. **CASCADE DELETE avec prudence** :
   ```sql
   -- ‚ö†Ô∏è Dangereux
   FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
   -- DELETE 1 user ‚Üí DELETE tous ses orders/posts/comments
   
   -- ‚úÖ Plus s√ªr : RESTRICT
   FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT
   -- Emp√™che suppression user si donn√©es li√©es
   
   -- Ou soft delete
   UPDATE users SET deleted_at = NOW() WHERE id = 123;
   ```

**üìä Validation**

```sql
-- V√©rifier int√©grit√© r√©f√©rentielle sans FK
SELECT 'orders ‚Üí customers' AS relation, COUNT(*) AS orphans
FROM orders o
LEFT JOIN customers c ON o.customer_id = c.id
WHERE c.id IS NULL

UNION ALL

SELECT 'posts ‚Üí users', COUNT(*)
FROM posts p
LEFT JOIN users u ON p.user_id = u.id
WHERE u.id IS NULL;

-- orphans devrait √™tre 0
```

---

## üìä Script d'audit automatis√©

### audit-schema.sql

```sql
-- ============================================================================
-- SCRIPT D'AUDIT SCH√âMA MARIADB 11.8
-- ============================================================================

SELECT '=' AS '';
SELECT 'AUDIT SCH√âMA DATABASE' AS '';
SELECT '=' AS '';

-- 1. TYPES DE DONN√âES SUBOPTIMAUX
SELECT '\n1. COLONNES BIGINT SOUS-UTILIS√âES' AS '';
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    DATA_TYPE,
    'üü° Downgrade √† INT ?' AS recommendation
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE = 'bigint'
  AND COLUMN_NAME LIKE '%id%'
LIMIT 10;

-- 2. VARCHAR SURDIMENSIONN√âS
SELECT '\n2. VARCHAR POTENTIELLEMENT SURDIMENSIONN√âS' AS '';
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    CHARACTER_MAXIMUM_LENGTH AS declared_length,
    'üü° Analyser usage r√©el' AS recommendation
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE = 'varchar'
  AND CHARACTER_MAXIMUM_LENGTH > 500
ORDER BY CHARACTER_MAXIMUM_LENGTH DESC
LIMIT 10;

-- 3. TABLES SANS PRIMARY KEY
SELECT '\n3. TABLES SANS PRIMARY KEY (üî¥ CRITIQUE)' AS '';
SELECT 
    t.TABLE_NAME,
    t.TABLE_ROWS,
    'üî¥ AJOUTER PK' AS action
FROM information_schema.tables t
WHERE t.TABLE_SCHEMA = DATABASE()
  AND t.TABLE_TYPE = 'BASE TABLE'
  AND NOT EXISTS (
      SELECT 1 FROM information_schema.statistics s
      WHERE s.TABLE_SCHEMA = t.TABLE_SCHEMA
        AND s.TABLE_NAME = t.TABLE_NAME
        AND s.INDEX_NAME = 'PRIMARY'
  );

-- 4. CANDIDATES PARTITIONNEMENT
SELECT '\n4. TABLES CANDIDATES PARTITIONNEMENT' AS '';
SELECT 
    TABLE_NAME,
    TABLE_ROWS,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 / 1024, 2) AS size_gb,
    CASE 
        WHEN TABLE_ROWS > 100000000 THEN 'üî¥ URGENT'
        WHEN TABLE_ROWS > 10000000 THEN 'üü° RECOMMAND√â'
        ELSE 'üü¢ OK'
    END AS status
FROM information_schema.tables
WHERE TABLE_SCHEMA = DATABASE()
  AND TABLE_TYPE = 'BASE TABLE'
  AND TABLE_ROWS > 1000000
ORDER BY TABLE_ROWS DESC
LIMIT 10;

-- 5. COLONNES JSON
SELECT '\n5. COLONNES JSON (Analyser use case)' AS '';
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    'üü° V√©rifier queries fr√©quentes' AS note
FROM information_schema.columns
WHERE TABLE_SCHEMA = DATABASE()
  AND DATA_TYPE = 'json';

-- 6. FOREIGN KEYS MANQUANTES
SELECT '\n6. COLONNES *_ID SANS FOREIGN KEY' AS '';
SELECT 
    TABLE_NAME,
    COLUMN_NAME,
    'üü° V√©rifier si FK requise' AS recommendation
FROM information_schema.columns c
WHERE TABLE_SCHEMA = DATABASE()
  AND COLUMN_NAME LIKE '%\_id'
  AND COLUMN_NAME != 'id'
  AND NOT EXISTS (
      SELECT 1 FROM information_schema.key_column_usage kcu
      WHERE kcu.TABLE_SCHEMA = DATABASE()
        AND kcu.TABLE_NAME = c.TABLE_NAME
        AND kcu.COLUMN_NAME = c.COLUMN_NAME
        AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
  )
LIMIT 20;

SELECT '=' AS '';
SELECT 'FIN AUDIT SCH√âMA' AS '';
```

---

## ‚úÖ Points cl√©s √† retenir

- üî¢ **Types entiers** : INT pour <4B, BIGINT seulement si n√©cessaire (√©conomie 4 bytes/row)
- üìè **VARCHAR(255)** : Threshold magique (1 byte vs 2 bytes pour length)
- üî§ **ENUM** : 1-2 bytes vs 5-20 bytes pour VARCHAR (valeurs fixes)
- üì¶ **JSON** : Flexible mais lent, colonnes g√©n√©r√©es pour queries fr√©quentes
- üìê **3NF** : Optimal OLTP, d√©normaliser seulement si prouv√© n√©cessaire
- üîë **PRIMARY KEY** : Toujours AUTO_INCREMENT INT/BIGINT (UUID = probl√®me I/O)
- üìä **Partitionnement** : Tables >10M lignes + filtre temporel = RANGE partition
- üóÑÔ∏è **Archivage** : DROP PARTITION >> DELETE (instantan√© vs heures)
- üîó **Foreign Keys** : Activer sauf cas sp√©ciaux (bulk import, sharding)
- üÜï **MariaDB 11.8** : ColumnStore pour cold data (compression 10√ó)

---

## üîó Ressources compl√©mentaires

### Documentation MariaDB
- [Data Types](https://mariadb.com/kb/en/data-types/)
- [Partitioning](https://mariadb.com/kb/en/partitioning-overview/)
- [Foreign Keys](https://mariadb.com/kb/en/foreign-keys/)

### Autres checklists
- [E.1 - Audit de configuration](./01-audit-configuration.md)
- [E.2 - Audit d'indexation](./02-audit-indexation.md)
- [E.3 - Audit de requ√™tes](./03-audit-requetes.md)

### Annexes compl√©mentaires
- [Annexe D - Configurations de r√©f√©rence](/annexes/configuration-reference/README.md)
- [Section 15 - Performance et Tuning](/15-performance-tuning/README.md)

---

## üéâ Annexe E - Checklist Performance : COMPL√àTE

Vous disposez maintenant de **4 checklists compl√®tes** :
- ‚úÖ **E.0** : M√©thodologie audit (6 √©tapes)
- ‚úÖ **E.1** : Configuration serveur (20 points)
- ‚úÖ **E.2** : Indexation (15 points)
- ‚úÖ **E.3** : Requ√™tes SQL (18 points)
- ‚úÖ **E.4** : Sch√©ma database (16 points)

**Total : 69 points de v√©rification** pour optimiser MariaDB 11.8 de A √† Z.

---

**MariaDB** : Version 11.8 LTS  

‚è≠Ô∏è [Nouveaut√©s MariaDB 11.8 LTS en un Coup d'≈íil](/annexes/nouveautes-11-8/README.md)
