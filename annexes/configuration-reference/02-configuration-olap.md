ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# D.2 Configuration OLAP (Data warehouse, analytics)

> **Type** : Configuration de rÃ©fÃ©rence  
> **Cas d'usage** : OLAP - Online Analytical Processing  
> **CaractÃ©ristiques** : RequÃªtes complexes, agrÃ©gations massives, analytics  
> **Public** : DBA, Data Engineers, Analytics Engineers

---

## ğŸ¯ Profil du cas d'usage OLAP

### CaractÃ©ristiques d'une charge OLAP

**Online Analytical Processing (OLAP)** dÃ©signe les systÃ¨mes d'analyse de donnÃ©es avec requÃªtes complexes sur de gros volumes :

#### Patterns d'accÃ¨s typiques
- ğŸ“Š **RequÃªtes longues** : Secondes Ã  minutes (vs millisecondes OLTP)
- ğŸ“ˆ **AgrÃ©gations massives** : SUM, AVG, COUNT sur millions de lignes
- ğŸ” **Scans complets** : Full table scans frÃ©quents
- ğŸ“‰ **Faible concurrence** : 5-50 connexions simultanÃ©es (vs 500+ OLTP)
- ğŸ“– **Lectures >> Ã‰critures** : 95/5 ou 99/1 (read-heavy)
- ğŸ—“ï¸ **Analyses temporelles** : Trends, comparaisons pÃ©riodes
- ğŸ”— **Jointures complexes** : 5-10+ tables, datasets volumineux

#### Exemples d'applications OLAP
- ğŸ“Š **Business Intelligence** : Dashboards, KPIs, reporting
- ğŸ“ˆ **Data Warehouse** : EntrepÃ´t de donnÃ©es analytique
- ğŸ”¬ **Data Science** : Exploration, feature engineering, ML
- ğŸ’¹ **Financial Analytics** : Analyses risques, forecasting
- ğŸ›’ **E-commerce Analytics** : Analyses ventes, comportements clients
- ğŸ“± **Product Analytics** : Usage patterns, funnels, retention

### MÃ©triques clÃ©s Ã  optimiser

| MÃ©trique | Objectif OLAP | Importance |
|----------|---------------|------------|
| **Query completion time** | Minutes OK si rÃ©sultats utiles | â­â­â­â­â­ |
| **Throughput analytique** | Queries/heure > Queries/sec | â­â­â­â­ |
| **Scan speed (GB/sec)** | Max possible | â­â­â­â­â­ |
| **RAM pour cache** | 70-80% donnÃ©es actives | â­â­â­â­â­ |
| **ParallÃ©lisme** | Utiliser tous les cores | â­â­â­â­ |
| **Latence** | Secondes acceptables | â­â­ |
| **Concurrence** | 10-50 queries simultanÃ©es | â­â­â­ |

### Contraintes typiques

- ğŸŒ **Latence non critique** : Utilisateurs acceptent attente (secondes/minutes)
- ğŸ’¾ **VolumÃ©trie importante** : TÃ©raoctets de donnÃ©es historiques
- ğŸ”„ **Chargement batch** : ETL nocturne, temps rÃ©el non requis
- ğŸ“Š **RequÃªtes ad-hoc** : Patterns imprÃ©visibles (vs OLTP prÃ©visible)
- ğŸ” **Indexes sÃ©lectifs** : Trop d'index = coÃ»t stockage/maintenance
- ğŸ—‚ï¸ **Partitionnement** : Par date/rÃ©gion/catÃ©gorie (pruning efficace)

### OLTP vs OLAP - Comparaison

| Aspect | OLTP | OLAP |
|--------|------|------|
| **Type requÃªtes** | INSERT/UPDATE/DELETE/SELECT simple | SELECT complexe (JOINs, GROUP BY, analytics) |
| **Latence** | < 10ms | Secondes Ã  minutes |
| **VolumÃ©trie par query** | Lignes : 1-100 | Lignes : 1000-1000000+ |
| **Connexions** | 100-1000+ | 5-50 |
| **Reads/Writes** | 60/40 - 40/60 | 99/1 - 95/5 |
| **Scans** | Index seeks | Full table scans |
| **RAM** | 60-70% | 70-80% |
| **Sort/Join buffers** | 256K-512K | 16M-256M |
| **DurabilitÃ©** | ACID strict | Relaxed OK (si ETL rechargeable) |

---

## ğŸ“ Configuration my.cnf complÃ¨te - OLAP

### Fichier de configuration optimisÃ©

Voici un template `my.cnf` optimisÃ© pour **serveur OLAP/DW avec 128GB RAM, 32 CPU cores, NVMe**.

```ini
# ============================================================================
# MARIADB 11.8 LTS - CONFIGURATION OLAP / DATA WAREHOUSE
# ============================================================================
# Cas d'usage : OLAP - Analytics, requÃªtes complexes, agrÃ©gations massives
# MatÃ©riel cible : 128GB RAM, 32 CPU cores, NVMe RAID 10
# Version : MariaDB 11.8 LTS
# DerniÃ¨re mise Ã  jour : DÃ©cembre 2025
# ============================================================================

[client]
port                        = 3306
socket                      = /var/run/mysqld/mysqld.sock
default-character-set       = utf8mb4

[mysqld]

# ----------------------------------------------------------------------------
# IDENTITÃ‰ SERVEUR
# ----------------------------------------------------------------------------
port                        = 3306
socket                      = /var/run/mysqld/mysqld.sock
pid-file                    = /var/run/mysqld/mysqld.pid
datadir                     = /var/lib/mysql
tmpdir                      = /tmp

user                        = mysql
bind-address                = 0.0.0.0

# ----------------------------------------------------------------------------
# CHARSET ET COLLATION (ğŸ†• MariaDB 11.8)
# ----------------------------------------------------------------------------
character-set-server        = utf8mb4
collation-server            = utf8mb4_unicode_ci  # Ou uca1400_ai_ci

# ----------------------------------------------------------------------------
# MOTEUR DE STOCKAGE
# ----------------------------------------------------------------------------
default-storage-engine      = InnoDB

# Pour colonnes analytiques pures : considÃ©rer ColumnStore
# Voir section dÃ©diÃ©e plus bas

# ----------------------------------------------------------------------------
# CONNEXIONS ET THREADS
# ----------------------------------------------------------------------------
max_connections             = 100
# OLAP : Peu de connexions simultanÃ©es
# RequÃªtes longues = ressources par query Ã©levÃ©es
# 50-100 connexions suffisant gÃ©nÃ©ralement

max_connect_errors          = 100000

thread_cache_size           = 32
# Moins critique qu'OLTP (peu de connexions)

# Thread pool optionnel pour OLAP
# thread_handling           = pool-of-threads
# thread_pool_size          = 32
# GÃ©nÃ©ralement one-thread-per-connection OK pour OLAP
# Sauf si beaucoup de petites queries mÃ©langÃ©es

# ----------------------------------------------------------------------------
# TABLES ET CACHE
# ----------------------------------------------------------------------------
table_open_cache            = 2000
# OLAP : Moins de tables ouvertes simultanÃ©ment qu'OLTP

table_definition_cache      = 1000

open_files_limit            = 5000

# ----------------------------------------------------------------------------
# MÃ‰MOIRE GLOBALE - INNODB BUFFER POOL (ğŸ”¥ CRITIQUE OLAP)
# ----------------------------------------------------------------------------
innodb_buffer_pool_size     = 96G
# ğŸ”¥ OLAP : 70-80% de la RAM totale (plus agressif qu'OLTP)
# 128GB RAM â†’ 96GB buffer pool (75%)
# BUT : Cache maximum de donnÃ©es pour scans rÃ©pÃ©tÃ©s

innodb_buffer_pool_instances = 32
# 1 instance par 2-3GB optimal
# 96GB / 32 = 3GB par instance

innodb_buffer_pool_chunk_size = 128M

# RÃ©chauffement buffer pool
innodb_buffer_pool_load_at_startup = 1
innodb_buffer_pool_dump_at_shutdown = 1

# ----------------------------------------------------------------------------
# MÃ‰MOIRE PAR CONNEXION (ğŸ”¥ BEAUCOUP PLUS Ã‰LEVÃ‰E QU'OLTP)
# ----------------------------------------------------------------------------
# OLAP : RequÃªtes complexes nÃ©cessitent gros buffers de tri/jointure

read_buffer_size            = 8M
# Buffer pour scan sÃ©quentiel
# OLAP : Full table scans frÃ©quents â†’ buffer consÃ©quent
# 8-16MB recommandÃ©

read_rnd_buffer_size        = 16M
# Buffer pour lecture aprÃ¨s tri (ORDER BY)
# OLAP : Tris massifs courants â†’ 16-32MB

sort_buffer_size            = 64M
# ğŸ”¥ CRITIQUE OLAP : Buffer pour ORDER BY, GROUP BY
# RequÃªtes analytiques avec Ã©normes tris
# 64-256MB selon complexitÃ© queries
# âš ï¸ AllouÃ© PAR opÃ©ration de tri !

join_buffer_size            = 64M
# ğŸ”¥ CRITIQUE OLAP : Buffer pour jointures
# Jointures multi-tables sur gros datasets
# 64-128MB recommandÃ©
# AllouÃ© par JOIN sans index

# Calcul mÃ©moire par connexion OLAP :
# 8M + 16M + 64M + 64M = 152MB par query
# 100 connexions Ã— 152MB = 15.2GB
# Buffer pool 96GB + 15.2GB + OS 8GB = 119.2GB / 128GB â†’ OK

# ----------------------------------------------------------------------------
# TEMPORAIRES ET HEAP (ğŸ”¥ CRITIQUE OLAP)
# ----------------------------------------------------------------------------
tmp_table_size              = 1G
max_heap_table_size         = 1G
# OLAP : Tables temporaires massives pour agrÃ©gations
# 1-2GB recommandÃ© (vs 64M OLTP)
# Si dÃ©passÃ© â†’ table temporaire MYISAM sur disque (lent)

# ğŸ†• MariaDB 11.8 : ContrÃ´le espace temporaire total
max_tmp_space_usage         = 50G
# Limite totale espace temporaire par connexion
# OLAP : RequÃªtes peuvent gÃ©nÃ©rer dizaines de GB temporaires
# 50-100GB selon RAM et complexitÃ© queries

# ----------------------------------------------------------------------------
# LOGS INNODB - REDO LOG
# ----------------------------------------------------------------------------
innodb_log_file_size        = 2G
# OLAP : Gros redo log (2-4GB)
# Ã‰critures batch (ETL) bÃ©nÃ©ficient de gros redo log

innodb_log_files_in_group   = 2
# Total : 4GB redo log

innodb_log_buffer_size      = 128M
# Buffer redo log en mÃ©moire
# OLAP : 128-256MB pour ETL intensif

innodb_flush_log_at_trx_commit = 2
# âš ï¸ OLAP : DurabilitÃ© relaxed acceptable
# 2 = Ã‰criture redo log Ã  chaque commit, sync OS toutes les secondes
# Si crash â†’ perte max 1 seconde de transactions
# Acceptable si ETL rechargeable
# Production critique : utiliser 1 (mais -30% perf)

# ----------------------------------------------------------------------------
# I/O ET DISQUES
# ----------------------------------------------------------------------------
innodb_io_capacity          = 10000
# OLAP : IOPS Ã©levÃ©s pour lectures massives
# NVMe : 10000-30000
# Scans sÃ©quentiels bÃ©nÃ©ficient de RAID 10

innodb_io_capacity_max      = 20000

innodb_flush_method         = O_DIRECT
# Toujours O_DIRECT en production

innodb_flush_neighbors      = 0
# SSD/NVMe : 0 optimal

# ğŸ†• MariaDB 11.8
innodb_alter_copy_bulk      = ON

# Lecture anticipÃ©e (read-ahead) IMPORTANTE pour OLAP
innodb_read_ahead_threshold = 0
# ğŸ”¥ OLAP : Activer read-ahead agressif
# 0 = DÃ©clenche dÃ¨s dÃ©tection pattern sÃ©quentiel
# Lectures sÃ©quentielles massives bÃ©nÃ©ficient fortement

# ----------------------------------------------------------------------------
# UNDO LOG
# ----------------------------------------------------------------------------
innodb_undo_tablespaces     = 3
innodb_undo_log_truncate    = ON
innodb_max_undo_log_size    = 2G

# ----------------------------------------------------------------------------
# DURABILITÃ‰ ET BINARY LOGS
# ----------------------------------------------------------------------------
sync_binlog                 = 0
# OLAP : Binlog sync relaxed OK
# 0 = Pas de sync forcÃ© (OS gÃ¨re)
# Si datawarehouse rechargeable par ETL : pas critique

log_bin                     = /var/log/mysql/mysql-bin
binlog_format               = ROW

# OLAP gÃ©nÃ©ralement pas rÃ©pliquÃ© (read-only DW)
# Si rÃ©plication pour DR : activer
# server-id               = 1
# gtid_strict_mode        = ON

expire_logs_days            = 3
# OLAP : RÃ©tention courte si pas de rÃ©plication
# 3 jours suffisant pour backup

max_binlog_size             = 1G

# ----------------------------------------------------------------------------
# OPTIMIZER ET STATISTIQUES (ğŸ”¥ CRITIQUE OLAP)
# ----------------------------------------------------------------------------
optimizer_search_depth      = 62
# Profondeur recherche plans d'exÃ©cution
# OLAP : RequÃªtes complexes bÃ©nÃ©ficient d'exploration approfondie
# 62 = max, considÃ©rer 32-62 pour queries trÃ¨s complexes

optimizer_switch             = 'mrr=on,mrr_cost_based=on,index_merge=on,index_condition_pushdown=on,derived_merge=off'
# derived_merge=off : Parfois meilleures perfs OLAP avec CTE/subqueries matÃ©rialisÃ©es

# ğŸ”¥ CRITIQUE : Statistiques optimizer
innodb_stats_persistent     = ON
innodb_stats_auto_recalc    = ON
innodb_stats_persistent_sample_pages = 100
# OLAP : Plus de pages Ã©chantillonnÃ©es pour meilleures stats
# 100 pages vs 20 OLTP (plus prÃ©cis pour gros volumes)

# Histogrammes de colonnes (MariaDB 10.0+)
# AmÃ©liore estimations cardinalitÃ© pour optimizer
# ANALYZE TABLE table_name PERSISTENT FOR COLUMNS(col1, col2);

# ----------------------------------------------------------------------------
# PARALLÃ‰LISME (ğŸ†• Optimisations OLAP)
# ----------------------------------------------------------------------------
# MariaDB ne supporte pas encore parallÃ©lisme de requÃªtes natif
# (Contrairement Ã  PostgreSQL parallel queries)
# Workarounds :
# 1. Partitionnement + queries par partition
# 2. Application-level parallelism
# 3. ColumnStore (parallÃ©lisme natif)

# ----------------------------------------------------------------------------
# PARTITIONNEMENT (ğŸ”¥ ESSENTIEL OLAP)
# ----------------------------------------------------------------------------
# Activer open_files_limit Ã©levÃ© pour tables partitionnÃ©es
# Une partition = 2 fichiers (.frm, .ibd)
# 100 partitions = 200 fichiers
open_files_limit            = 10000

# ----------------------------------------------------------------------------
# QUERY CACHE (âš ï¸ DÃ‰PRÃ‰CIÃ‰)
# ----------------------------------------------------------------------------
query_cache_type            = 0
query_cache_size            = 0
# OLAP : Cache applicatif (Redis) + rÃ©sultats prÃ©-calculÃ©s

# ----------------------------------------------------------------------------
# MONITORING ET PERFORMANCE SCHEMA
# ----------------------------------------------------------------------------
performance_schema          = ON

# OLAP : Activer instruments pour queries longues
# UPDATE performance_schema.setup_instruments 
# SET ENABLED='YES' WHERE NAME LIKE 'stage/%';

# ----------------------------------------------------------------------------
# LOGS
# ----------------------------------------------------------------------------
log_error                   = /var/log/mysql/error.log

slow_query_log              = ON
slow_query_log_file         = /var/log/mysql/slow-query.log
long_query_time             = 10
# OLAP : 10 secondes dÃ©jÃ  rapide pour analytique
# Ajuster selon SLA (30-60s peut Ãªtre normal)

log_slow_verbosity          = query_plan,explain
log_queries_not_using_indexes = OFF
# OLAP : Full scans normaux, pas besoin de logger

# ----------------------------------------------------------------------------
# TIMEOUTS
# ----------------------------------------------------------------------------
wait_timeout                = 28800
# OLAP : 8 heures (requÃªtes longues normales)

interactive_timeout         = 28800

connect_timeout             = 10

net_read_timeout            = 300
net_write_timeout           = 300
# Timeouts rÃ©seau Ã©levÃ©s pour rÃ©sultats volumineux

# ----------------------------------------------------------------------------
# AUTRES PARAMÃˆTRES
# ----------------------------------------------------------------------------
max_allowed_packet          = 256M
# OLAP : RÃ©sultats volumineux possibles
# 256M-1G selon use case

lower_case_table_names      = 0

sql_mode                    = 'STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION'

# ----------------------------------------------------------------------------
# INNODB AVANCÃ‰
# ----------------------------------------------------------------------------
innodb_adaptive_hash_index  = OFF
# OLAP : Pas d'accÃ¨s rÃ©pÃ©titifs aux mÃªmes lignes
# Adaptive hash index peu utile, dÃ©sactiver Ã©conomise mÃ©moire

innodb_change_buffering     = none
# OLAP : Peu d'Ã©critures, change buffering inutile

innodb_old_blocks_time      = 0
# OLAP : Full scans frÃ©quents, pas de stratÃ©gie LRU agressive

innodb_print_all_deadlocks  = OFF
# OLAP : Peu de contention

# Compression (recommandÃ©e OLAP pour Ã©conomie stockage)
innodb_file_per_table       = ON
# Requis pour compression par table

# Pour tables historiques rarement modifiÃ©es :
# CREATE TABLE archive_data (...) 
# ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;

# ----------------------------------------------------------------------------
# MARIADB COLUMNSTORE (ğŸ”¥ OLAP PUR)
# ----------------------------------------------------------------------------
# ColumnStore : Moteur columnar pour analytics pures
# Installation sÃ©parÃ©e : mariadb-columnstore-engine

# Configuration minimale ColumnStore :
# [columnstore]
# compression_type        = 2
# pm_query_threads        = 16
# pm_max_memory_mb        = 65536  # 64GB
# use_import_for_batchinsert = ALWAYS

# Use cases ColumnStore :
# - AgrÃ©gations massives (SUM, AVG, COUNT)
# - Analyses colonnes spÃ©cifiques (SELECT col1, col2 vs SELECT *)
# - Compression 10:1 typique (vs 2:1 InnoDB)
# - Pas d'UPDATE/DELETE frÃ©quents (insert-only/bulk load)

# Hybrid : InnoDB pour donnÃ©es rÃ©centes + ColumnStore pour historique
# Voir section Architecture OLAP plus bas

# ----------------------------------------------------------------------------
[mysqldump]
quick
quote-names
max_allowed_packet          = 256M

# ----------------------------------------------------------------------------
[mysql]
default-character-set       = utf8mb4

# ----------------------------------------------------------------------------
# FIN DE CONFIGURATION
# ============================================================================
```

---

## ğŸ” Explication des paramÃ¨tres clÃ©s OLAP

### 1. Buffer Pool : 70-80% RAM (vs 60-70% OLTP)

```ini
innodb_buffer_pool_size = 96G  # 75% de 128GB RAM
```

**Pourquoi plus agressif qu'OLTP :**

```
OLAP : RequÃªtes lisent Ã©normÃ©ment de donnÃ©es
- Full table scans sur tables 10-100GB
- Cache maximum de donnÃ©es = moins d'I/O = queries plus rapides

Calcul OLAP :
Serveur 128GB :
- Buffer Pool : 96GB (75%)
- Connexions : 100 Ã— 152MB = 15GB
- OS + FS cache : 8GB
- Marge : 9GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total : 128GB âœ“

OLTP : Seulement 60-70% car :
- Plus de connexions (500+)
- MÃ©moire par connexion pour queries courtes
```

**Working Set OLAP :**

```sql
-- Estimer taille working set (donnÃ©es actives)
SELECT 
    table_schema,
    ROUND(SUM(data_length + index_length) / 1024 / 1024 / 1024, 2) AS total_gb
FROM information_schema.tables
WHERE table_schema NOT IN ('mysql', 'performance_schema', 'information_schema')
GROUP BY table_schema;

-- Si working set < buffer_pool_size : 
-- â†’ Tout en mÃ©moire (optimal)
-- Si working set > buffer_pool_size :
-- â†’ Queries rÃ©pÃ©tÃ©es bÃ©nÃ©ficient toujours du cache partiel
```

### 2. Sort et Join Buffers : 64-128MB (vs 256K-512K OLTP)

```ini
sort_buffer_size = 64M
join_buffer_size = 64M
```

**Impact colossal sur requÃªtes OLAP :**

```sql
-- Exemple query OLAP typique
SELECT 
    p.category,
    DATE_FORMAT(o.order_date, '%Y-%m') AS month,
    COUNT(DISTINCT o.customer_id) AS unique_customers,
    SUM(o.total_amount) AS revenue,
    AVG(o.total_amount) AS avg_order_value
FROM orders o
JOIN products p ON o.product_id = p.id
WHERE o.order_date >= '2023-01-01'
GROUP BY p.category, month
ORDER BY revenue DESC;

-- Cette query nÃ©cessite :
-- 1. Join buffer pour o JOIN p (64M)
-- 2. Temp table pour GROUP BY (tmp_table_size 1G)
-- 3. Sort buffer pour ORDER BY (64M)
```

**Sizing :**

| Buffer | OLTP | OLAP | Impact si trop petit |
|--------|------|------|---------------------|
| `sort_buffer_size` | 512K | 64M | Tri sur disque (tmpdir) 1000Ã— plus lent |
| `join_buffer_size` | 256K | 64M | Nested loop au lieu de hash join |
| `tmp_table_size` | 64M | 1G | Table temp MyISAM sur disque |

**Monitoring :**

```sql
-- Tris utilisant fichiers temporaires (mauvais)
SHOW GLOBAL STATUS LIKE 'Sort_merge_passes';
-- Si > 0 : sort_buffer_size trop petit

-- Tables temporaires sur disque (mauvais)
SHOW GLOBAL STATUS LIKE 'Created_tmp_disk_tables';
SHOW GLOBAL STATUS LIKE 'Created_tmp_tables';

-- Ratio : Created_tmp_disk_tables / Created_tmp_tables
-- Objectif < 10% (90%+ en mÃ©moire)
-- Si > 25% : augmenter tmp_table_size
```

### 3. DurabilitÃ© Relaxed : innodb_flush_log_at_trx_commit = 2

```ini
innodb_flush_log_at_trx_commit = 2
sync_binlog = 0
```

**Pourquoi acceptable en OLAP :**

```
Data Warehouse typique :
1. Chargement ETL nocturne depuis OLTP/sources
2. En cas de crash â†’ recharger ETL (donnÃ©es sources intactes)
3. Perte < 1s de transactions = nÃ©gligeable (pas de transactions rÃ©elles)

Gain performance :
flush_log = 1 â†’ 2 : +30-40% throughput bulk insert
sync_binlog = 1 â†’ 0 : +15-20% throughput

MAIS : Si donnÃ©es critiques non reproductibles
â†’ Utiliser flush_log = 1, sync_binlog = 1 (ACID strict)
```

**Comparaison :**

```sql
-- Benchmark INSERT 1M lignes
-- Config ACID strict (OLTP)
SET GLOBAL innodb_flush_log_at_trx_commit = 1;
SET GLOBAL sync_binlog = 1;
-- Temps : 180 secondes

-- Config relaxed (OLAP)
SET GLOBAL innodb_flush_log_at_trx_commit = 2;
SET GLOBAL sync_binlog = 0;
-- Temps : 120 secondes
-- Gain : 33% plus rapide
```

### 4. Read-Ahead : innodb_read_ahead_threshold = 0

```ini
innodb_read_ahead_threshold = 0  # vs 56 OLTP
```

**Lecture anticipÃ©e agressive pour scans sÃ©quentiels :**

```
OLTP : AccÃ¨s alÃ©atoires (index seeks)
â†’ Read-ahead inutile voire contre-productif

OLAP : Full table scans massifs
â†’ Read-ahead = prÃ©charge pages suivantes en parallÃ¨le
â†’ RÃ©duit latence I/O

Valeur 0 : DÃ©clenche dÃ¨s dÃ©tection pattern sÃ©quentiel
Valeur 56 : Attend 56 pages sÃ©quentielles avant dÃ©clencher

OLAP : 0-16 recommandÃ©
OLTP : 56 (dÃ©faut)
```

**Impact mesurable :**

```sql
-- Query scan sÃ©quentiel 10GB table
SELECT COUNT(*), AVG(amount) FROM huge_table;

-- read_ahead_threshold = 56 :
-- Temps : 45 secondes (I/O wait Ã©levÃ©)

-- read_ahead_threshold = 0 :
-- Temps : 32 secondes (I/O parallÃ©lisÃ©)
-- Gain : 29% plus rapide
```

### 5. Optimizer : Statistics et Search Depth

```ini
optimizer_search_depth = 62
innodb_stats_persistent_sample_pages = 100  # vs 20 OLTP
```

**RequÃªtes complexes = optimizer doit explorer plus :**

```sql
-- Query 8-tables JOIN (TPC-H query 5)
SELECT 
    n.name,
    SUM(l.extendedprice * (1 - l.discount)) AS revenue
FROM customer c
JOIN orders o ON c.custkey = o.custkey
JOIN lineitem l ON l.orderkey = o.orderkey
JOIN supplier s ON l.suppkey = s.suppkey
JOIN nation n ON s.nationkey = n.nationkey
JOIN region r ON n.regionkey = r.regionkey
WHERE r.name = 'ASIA'
  AND o.orderdate >= '1994-01-01'
  AND o.orderdate < '1995-01-01'
GROUP BY n.name
ORDER BY revenue DESC;

-- 8 tables â†’ 8! = 40320 ordres de join possibles
-- optimizer_search_depth = 62 : Explore exhaustivement
-- optimizer_search_depth = 8 : Heuristique rapide mais sous-optimal

-- DiffÃ©rence plan d'exÃ©cution :
-- Bon plan : 5 secondes
-- Plan sous-optimal : 45 secondes
```

**Stats prÃ©cises critiques :**

```sql
-- Mauvaises stats = mauvais plans
-- Exemple : Optimizer estime 1000 lignes, rÃ©alitÃ© 1M lignes

ANALYZE TABLE orders PERSISTENT FOR ALL;
-- Recalcule stats avec Ã©chantillonnage Ã©tendu

-- Histogrammes (MariaDB 10.0+)
ANALYZE TABLE orders PERSISTENT FOR COLUMNS(order_status, order_date);
-- Histogrammes = distribution valeurs
-- AmÃ©liore estimations cardinalitÃ© (nombre lignes)
```

### 6. Partitionnement : Essentiel OLAP

**Configuration :**

```ini
open_files_limit = 10000
# Partitions = fichiers multiples
```

**StratÃ©gies partitionnement OLAP :**

```sql
-- RANGE partitioning par date (le plus courant)
CREATE TABLE sales (
    id BIGINT,
    sale_date DATE NOT NULL,
    amount DECIMAL(10,2),
    ...
) PARTITION BY RANGE (YEAR(sale_date)) (
    PARTITION p2020 VALUES LESS THAN (2021),
    PARTITION p2021 VALUES LESS THAN (2022),
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION pmax VALUES LESS THAN MAXVALUE
);

-- Query avec partition pruning (efficace)
SELECT SUM(amount) FROM sales
WHERE sale_date >= '2024-01-01' 
  AND sale_date < '2025-01-01';
-- Scan uniquement partition p2024 (1/7 des donnÃ©es)

-- Sans partitionnement : scan 100% table
```

**BÃ©nÃ©fices OLAP :**

1. **Partition pruning** : Scan seulement partitions pertinentes
2. **Maintenance facilitÃ©e** : Drop anciennes partitions (archive)
3. **ParallÃ©lisme implicite** : Certaines queries peuvent parallÃ©liser par partition
4. **Performance** : Index plus petits par partition

**Maintenance :**

```sql
-- Ajouter nouvelle partition (dÃ©but d'annÃ©e)
ALTER TABLE sales ADD PARTITION (
    PARTITION p2026 VALUES LESS THAN (2027)
);

-- Archiver/supprimer vieilles donnÃ©es
ALTER TABLE sales DROP PARTITION p2020;
-- InstantanÃ© (vs DELETE FROM ... millions de lignes)
```

---

## ğŸ—„ï¸ MariaDB ColumnStore pour OLAP Pur

### Quand utiliser ColumnStore

**ColumnStore = Moteur columnar pour analytics pures**

| Use Case | InnoDB | ColumnStore |
|----------|--------|-------------|
| **OLTP (INSERT/UPDATE/DELETE)** | âœ…âœ…âœ… Optimal | âŒ InadaptÃ© |
| **OLAP lecture seule** | âœ… OK | âœ…âœ…âœ… Optimal |
| **AgrÃ©gations (SUM, AVG, COUNT)** | âœ… Correct | âœ…âœ…âœ… 10-100Ã— plus rapide |
| **Scans colonnes spÃ©cifiques** | âœ… Correct | âœ…âœ…âœ… 5-20Ã— plus rapide |
| **Compression** | âœ… 2:1 | âœ…âœ…âœ… 10:1 typique |
| **Updates frÃ©quents** | âœ…âœ…âœ… Optimal | âŒ TrÃ¨s lent |

### Architecture Hybrid recommandÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Application                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  InnoDB Tables  â”‚      â”‚ ColumnStore Tablesâ”‚
    â”‚   (Hot Data)    â”‚      â”‚  (Cold Analytics) â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 30 derniers     â”‚      â”‚ DonnÃ©es > 30j     â”‚
    â”‚ jours           â”‚      â”‚ Historique 3 ans  â”‚
    â”‚                 â”‚      â”‚                   â”‚
    â”‚ INSERT/UPDATE   â”‚      â”‚ INSERT batch      â”‚
    â”‚ DELETE rapide   â”‚      â”‚ SELECT analytics  â”‚
    â”‚                 â”‚      â”‚                   â”‚
    â”‚ 100GB           â”‚      â”‚ 5TB (500GB comp.) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                          â–²
            â””â”€â”€â”€â”€â”€â”€â”€ ETL nuit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         (DÃ©placement donnÃ©es anciennes)
```

### Configuration ColumnStore

```sql
-- Installation
-- sudo yum install mariadb-columnstore-engine
-- sudo systemctl restart mariadb

-- CrÃ©er table ColumnStore
CREATE TABLE sales_analytics (
    sale_id BIGINT,
    sale_date DATE,
    product_id INT,
    customer_id INT,
    amount DECIMAL(10,2),
    quantity INT
) ENGINE=ColumnStore;

-- Load data (bulk insert optimal)
LOAD DATA INFILE '/data/sales_2020.csv'
INTO TABLE sales_analytics
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n';

-- Query analytique
SELECT 
    YEAR(sale_date) AS year,
    MONTH(sale_date) AS month,
    product_id,
    SUM(amount) AS total_revenue,
    SUM(quantity) AS total_qty
FROM sales_analytics
WHERE sale_date >= '2020-01-01'
GROUP BY year, month, product_id;

-- ColumnStore : 2 secondes (scan optimisÃ© colonnes)
-- InnoDB : 25 secondes (scan full row format)
```

### Configuration my.cnf ColumnStore

```ini
[columnstore]
# Threads pour exÃ©cution queries
pm_query_threads            = 16
# = Nombre de CPU cores, parallÃ©lisme queries

# MÃ©moire allouÃ©e ColumnStore
pm_max_memory_mb            = 65536
# 64GB pour ColumnStore (en plus de buffer pool InnoDB)

# Compression (essentiel ColumnStore)
compression_type            = 2
# 0 = aucune
# 2 = Snappy (bon compromis vitesse/ratio)

# Batch insert optimization
use_import_for_batchinsert  = ALWAYS
# Bulk load optimisÃ© pour ETL
```

---

## ğŸ’» Recommandations matÃ©rielles OLAP

### Configuration matÃ©rielle optimale OLAP

#### Serveur Entry-Level (BI Ã©quipe, startup)
```
CPU    : 8-16 cores @ 2.5+ GHz
RAM    : 64-128 GB DDR4 ECC
Disque : 2TB NVMe SSD (ou HDD RAID 10 si budget limitÃ©)
RÃ©seau : 10 Gbps
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Prix : 3000-5000â‚¬

Config MariaDB :
- innodb_buffer_pool_size = 48-96G
- sort_buffer_size = 32M
- join_buffer_size = 32M
- tmp_table_size = 512M
- AdaptÃ© : 5-20 queries simultanÃ©es, dataset < 500GB
```

#### Serveur Mid-Range (Enterprise BI, DW)
```
CPU    : 32-48 cores @ 3.0+ GHz (AMD EPYC 7xx3)
RAM    : 256-512 GB DDR4/DDR5 ECC
Disque : 4-8TB NVMe RAID 10 ou cloud EBS io2
RÃ©seau : 25 Gbps
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Prix : 15000-25000â‚¬ (ou AWS r6i.8xlarge)

Config MariaDB :
- innodb_buffer_pool_size = 180-400G
- sort_buffer_size = 64M
- join_buffer_size = 64M
- tmp_table_size = 1G
- AdaptÃ© : 20-50 queries simultanÃ©es, dataset 1-5TB
```

#### Serveur High-End (Large DW, Big Data)
```
CPU    : 64-128 cores @ 3.5+ GHz (AMD EPYC 9xx4)
RAM    : 1-2 TB DDR5 ECC
Disque : 10-20TB NVMe Gen4 RAID 10
RÃ©seau : 100 Gbps
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Prix : 50000-100000â‚¬ (ou AWS r6i.16xlarge+)

Config MariaDB :
- innodb_buffer_pool_size = 700GB-1.5TB
- sort_buffer_size = 128M
- join_buffer_size = 128M
- tmp_table_size = 2G
- AdaptÃ© : 50-100 queries simultanÃ©es, dataset 10-50TB
```

### CPU : Cores > FrÃ©quence (inverse OLTP)

**OLAP favorise :**
- Beaucoup de cores (parallÃ©lisme)
- FrÃ©quence moins critique (queries longues)

```
OLTP : 8 cores @ 3.5 GHz > 16 cores @ 2.5 GHz
OLAP : 16 cores @ 2.5 GHz > 8 cores @ 3.5 GHz

Raison :
- OLAP : Full scans parallÃ©lisables (multi-thread I/O)
- Plus de cores = plus de queries simultanÃ©es
```

### Disques : DÃ©bit sÃ©quentiel > IOPS

**OLAP patterns I/O :**

```
OLTP : Random reads (index seeks)
â†’ MÃ©trique clÃ© : IOPS (random 4K)
â†’ NVMe optimal

OLAP : Sequential scans (full table)
â†’ MÃ©trique clÃ© : Throughput (MB/s sÃ©quentiel)
â†’ RAID 10 HDD acceptable (budget limitÃ©)
â†’ NVMe optimal (mais moins critique qu'OLTP)
```

| Disque | IOPS Random | Throughput Seq | Prix/TB | OLAP ? |
|--------|-------------|----------------|---------|--------|
| **HDD 7200rpm RAID 10** | 200-400 | 300-500 MB/s | 50â‚¬ | âœ… OK budget limitÃ© |
| **SSD SATA** | 3000-5000 | 500-550 MB/s | 100â‚¬ | âœ… Bon |
| **NVMe Gen3** | 15000-30000 | 2000-3500 MB/s | 150â‚¬ | âœ…âœ… RecommandÃ© |
| **NVMe Gen4** | 50000+ | 5000-7000 MB/s | 200â‚¬ | âœ…âœ…âœ… Optimal |

### RAM : Maximum possible

**RÃ¨gle OLAP :**

```
RAM idÃ©al = Taille working set (donnÃ©es actives)

Exemples :
- Dataset 500GB, hot data 100GB â†’ RAM 128-256GB
- Dataset 5TB, hot data 1TB â†’ RAM 1TB
- Dataset 50TB, hot data 10TB â†’ RAM 2TB (+ cache app)

Si budget limitÃ© :
Buffer pool >= 50% hot data = dÃ©jÃ  trÃ¨s bÃ©nÃ©fique
```

---

## ğŸ“Š MÃ©triques de monitoring OLAP

### Dashboard Grafana adaptÃ© OLAP

#### 1. Query Performance
```
â€¢ Query execution time (P50, P95, P99)
  â†’ OLAP : P95 peut Ãªtre minutes, acceptable
  â†’ Investiguer si P95 > SLA (ex: 5 minutes)
  
â€¢ Queries running > 60s
  â†’ Nombre de requÃªtes longues en cours
  â†’ Alert si > 20 (surcharge)
  
â€¢ Queries completed/hour
  â†’ Throughput analytique
  â†’ Tendance baisse = problÃ¨me perf
```

#### 2. Ressources par Query
```sql
-- Top queries par temps CPU
SELECT 
    DIGEST_TEXT,
    COUNT_STAR AS exec_count,
    ROUND(AVG_TIMER_WAIT / 1000000000000, 2) AS avg_sec,
    ROUND(SUM_TIMER_WAIT / 1000000000000, 2) AS total_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT NOT LIKE '%performance_schema%'
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;

-- Queries avec sorts sur disque (mauvais)
SELECT 
    DIGEST_TEXT,
    SUM_SORT_MERGE_PASSES AS disk_sorts,
    SUM_SORT_ROWS AS rows_sorted
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_SORT_MERGE_PASSES > 0
ORDER BY SUM_SORT_MERGE_PASSES DESC;
```

#### 3. Tables Temporaires
```
â€¢ Temp tables created (total)
  â†’ Normal Ã©levÃ© en OLAP (agrÃ©gations)
  
â€¢ Temp tables on disk / total
  â†’ Objectif < 10%
  â†’ Si > 25% : augmenter tmp_table_size

â€¢ Temp table space used (GB)
  â†’ Surveiller vs max_tmp_space_usage
```

#### 4. Buffer Pool (mÃªme qu'OLTP)
```
â€¢ Buffer pool hit rate > 95%
  â†’ OLAP : 95-99% acceptable (vs 99%+ OLTP)
  â†’ Full scans chargent beaucoup de donnÃ©es "cold"
  
â€¢ Buffer pool dirty pages < 20%
  â†’ OLAP : Peu d'Ã©critures, gÃ©nÃ©ralement < 5%
```

#### 5. I/O Patterns
```
â€¢ Sequential reads (MB/s)
  â†’ MÃ©trique principale OLAP
  â†’ Devrait Ãªtre Ã©levÃ© pendant queries
  
â€¢ Random reads (IOPS)
  â†’ Devrait Ãªtre faible (si Ã©levÃ© = index seeks, bon)
  
â€¢ Disk queue depth
  â†’ OLAP : Peut Ãªtre Ã©levÃ© (10-50) pendant scans
  â†’ Si saturÃ© constant : disques sous-dimensionnÃ©s
```

### Alertes spÃ©cifiques OLAP

```yaml
groups:
  - name: mariadb_olap
    rules:
      # Queries trop lentes
      - alert: SlowOLAPQueries
        expr: mysql_query_p95_seconds > 300  # 5 minutes
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "P95 query time > 5 minutes"
          
      # Trop de temp tables sur disque
      - alert: HighDiskTempTables
        expr: (rate(mysql_created_tmp_disk_tables[5m]) / rate(mysql_created_tmp_tables[5m])) > 0.25
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "> 25% temp tables on disk"
          
      # Espace temporaire saturÃ©
      - alert: TempSpaceHigh
        expr: mysql_tmp_space_used_gb > 40  # vs max 50GB
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Temp space usage > 40GB"
```

---

## âš ï¸ Points de vigilance OLAP

### 1. Partitionnement obligatoire pour gros volumes

âŒ **Sans partitionnement :**
```sql
-- Table 500GB, 2 milliards de lignes
CREATE TABLE sales (
    id BIGINT,
    sale_date DATE,
    amount DECIMAL(10,2)
);

-- Query annÃ©e 2024
SELECT SUM(amount) FROM sales
WHERE sale_date >= '2024-01-01' 
  AND sale_date < '2025-01-01';
  
-- Scan FULL TABLE 500GB (30-60 minutes)
```

âœ… **Avec partitionnement :**
```sql
CREATE TABLE sales (
    id BIGINT,
    sale_date DATE,
    amount DECIMAL(10,2)
) PARTITION BY RANGE (YEAR(sale_date)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    ...
);

-- MÃªme query
-- Scan uniquement partition p2024 (70GB, 2-5 minutes)
-- Gain : 7-12Ã— plus rapide
```

### 2. Index sÃ©lectifs (pas tous les colonnes)

âŒ **Sur-indexation :**
```sql
-- Table fact 100 colonnes
CREATE TABLE sales_fact (...);
CREATE INDEX idx1 ON sales_fact(col1);
CREATE INDEX idx2 ON sales_fact(col2);
-- ... 50 index

-- ProblÃ¨mes :
-- - Stockage : 50 index Ã— 10GB = 500GB (vs 100GB donnÃ©es)
-- - Maintenance : ALTER TABLE 10 heures
-- - ETL : Bulk load lent (mise Ã  jour index)
```

âœ… **Index ciblÃ©s :**
```sql
-- Identifier queries frÃ©quentes
-- CrÃ©er index seulement pour WHERE/JOIN critiques

CREATE INDEX idx_date_customer ON sales_fact(sale_date, customer_id);
-- Composite index pour queries pattern frÃ©quent

-- Dimensions (tables petites) : Index OK
-- Facts (tables Ã©normes) : Index minimal
```

### 3. ETL optimisÃ© pour bulk load

âŒ **Row-by-row insert :**
```python
for row in data:
    cursor.execute("INSERT INTO sales VALUES (%s, %s, %s)", row)
    conn.commit()  # Commit Ã  chaque ligne !
    
# 1M lignes : 30-60 minutes
```

âœ… **Bulk insert optimisÃ© :**
```python
# DÃ©sactiver constraints temporairement
cursor.execute("SET foreign_key_checks = 0")
cursor.execute("SET unique_checks = 0")
cursor.execute("ALTER TABLE sales DISABLE KEYS")

# LOAD DATA INFILE (le plus rapide)
cursor.execute("""
    LOAD DATA LOCAL INFILE '/tmp/sales.csv'
    INTO TABLE sales
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
""")

# Ou bulk insert
cursor.executemany("INSERT INTO sales VALUES (%s, %s, %s)", batch)
conn.commit()  # Commit par batch

# RÃ©activer
cursor.execute("ALTER TABLE sales ENABLE KEYS")
cursor.execute("SET foreign_key_checks = 1")
cursor.execute("SET unique_checks = 1")

# 1M lignes : 2-5 minutes
# Gain : 10-30Ã— plus rapide
```

### 4. Ã‰viter SELECT * sur tables larges

âŒ **Transfert donnÃ©es inutiles :**
```sql
SELECT * FROM sales_fact;
-- Table 100 colonnes, 500GB
-- Application utilise seulement 5 colonnes
-- Transfert 500GB rÃ©seau !
```

âœ… **SÃ©lection ciblÃ©e :**
```sql
SELECT 
    sale_date, 
    customer_id, 
    product_id, 
    amount, 
    quantity 
FROM sales_fact;

-- Transfert seulement 50GB (10Ã— moins)
```

### 5. PrÃ©-agrÃ©gation pour dashboards temps rÃ©el

âŒ **Calcul Ã  la volÃ©e :**
```sql
-- Dashboard exÃ©cute query lourde toutes les 30 secondes
SELECT 
    DATE(sale_date) AS day,
    SUM(amount) AS daily_revenue
FROM sales_fact
WHERE sale_date >= CURDATE() - INTERVAL 30 DAY
GROUP BY day;

-- Scan 30 jours, 50M lignes, 5-10 secondes par exÃ©cution
```

âœ… **Table agrÃ©gÃ©e + refresh pÃ©riodique :**
```sql
-- Table prÃ©-calculÃ©e (event scheduler)
CREATE TABLE sales_daily_summary (
    day DATE PRIMARY KEY,
    daily_revenue DECIMAL(15,2),
    updated_at TIMESTAMP
);

-- ETL toutes les heures
INSERT INTO sales_daily_summary
SELECT 
    DATE(sale_date),
    SUM(amount),
    NOW()
FROM sales_fact
WHERE sale_date = CURDATE()
GROUP BY DATE(sale_date)
ON DUPLICATE KEY UPDATE 
    daily_revenue = VALUES(daily_revenue),
    updated_at = NOW();

-- Dashboard query prÃ©-agrÃ©gation (instantanÃ©)
SELECT * FROM sales_daily_summary
WHERE day >= CURDATE() - INTERVAL 30 DAY;

-- < 10ms vs 5-10 secondes
```

### 6. Analyze rÃ©gulier des tables

```sql
-- Stats obsolÃ¨tes = mauvais plans optimizer
-- OLAP : donnÃ©es changent massivement (ETL)

-- Automatique aprÃ¨s ETL
ANALYZE TABLE sales_fact PERSISTENT FOR ALL;

-- Ou event scheduler hebdomadaire
CREATE EVENT analyze_tables
ON SCHEDULE EVERY 1 WEEK
DO
  BEGIN
    ANALYZE TABLE sales_fact;
    ANALYZE TABLE customer_dim;
    ANALYZE TABLE product_dim;
  END;
```

---

## âœ… Points clÃ©s Ã  retenir

- ğŸ“Š **Buffer pool 70-80% RAM** : Cache maximum donnÃ©es analytiques
- ğŸ”§ **Sort/Join buffers 64-128MB** : RequÃªtes complexes nÃ©cessitent gros buffers
- ğŸ’¾ **DurabilitÃ© relaxed OK** : `innodb_flush_log_at_trx_commit = 2` si ETL rechargeable
- ğŸ“– **Read-ahead agressif** : `innodb_read_ahead_threshold = 0` pour scans
- ğŸ—‚ï¸ **Partitionnement essentiel** : Partition pruning Ã©conomise 70-90% scan
- ğŸ›ï¸ **ColumnStore pour analytics pures** : 10-100Ã— plus rapide agrÃ©gations
- ğŸ¯ **Index sÃ©lectifs** : Pas tous les colonnes, cibler queries frÃ©quentes
- ğŸš€ **Bulk load ETL** : LOAD DATA INFILE + dÃ©sactiver constraints
- ğŸ“ˆ **PrÃ©-agrÃ©gation** : Tables summary pour dashboards temps rÃ©el
- ğŸ” **ANALYZE rÃ©gulier** : Stats Ã  jour = bons plans optimizer

---

## ğŸ”— Ressources complÃ©mentaires

### Documentation MariaDB
- [InnoDB Buffer Pool](https://mariadb.com/kb/en/innodb-buffer-pool/)
- [ColumnStore](https://mariadb.com/kb/en/mariadb-columnstore/)
- [Table Partitioning](https://mariadb.com/kb/en/partitioning-overview/)
- [ANALYZE TABLE](https://mariadb.com/kb/en/analyze-table/)

### Outils OLAP/BI
- **Apache Superset** : BI open-source
- **Metabase** : Analytics simple
- **Redash** : Queries et dashboards
- **dbt** : Data transformation pipelines

### Benchmarks
- **TPC-H** : Benchmark OLAP standard (22 queries)
- **TPC-DS** : Decision support benchmark

### Autres annexes
- [D.1 - Configuration OLTP](./01-configuration-oltp.md)
- [D.3 - Configuration Mixed Workload](./03-configuration-mixed-workload.md)
- [Section 7.5 - ColumnStore](/07-moteurs-de-stockage/05-columnstore.md)

---

## â¡ï¸ Section suivante

**[D.3 - Configuration Mixed Workload](./03-configuration-mixed-workload.md)** : Hybride OLTP + OLAP

---

**MariaDB** : Version 11.8 LTS

â­ï¸ [Mixed workload](/annexes/configuration-reference/03-configuration-mixed-workload.md)
