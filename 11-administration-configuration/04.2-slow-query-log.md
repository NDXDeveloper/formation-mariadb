üîù Retour au [Sommaire](/SOMMAIRE.md)

# 11.4.2 Slow query log

> **Niveau** : Avanc√© (DBA/Administrateur Syst√®me)  
> **Dur√©e estim√©e** : 2 heures  
> **Pr√©requis** : 11.4.1 - Error log, SQL avanc√©, analyse de performance

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Configurer et activer le slow query log de mani√®re optimale
- Identifier et analyser les requ√™tes lentes affectant les performances
- Utiliser pt-query-digest pour l'analyse avanc√©e des slow queries
- Exploiter Performance Schema pour le monitoring en temps r√©el
- Mettre en place des strat√©gies d'optimisation bas√©es sur les slow queries
- G√©rer la rotation et l'archivage des slow query logs
- Int√©grer le slow query log dans une d√©marche DevOps/monitoring
- Appliquer les bonnes pratiques de tuning en production

---

## Introduction

Le **slow query log** est l'outil principal pour identifier les probl√®mes de performance au niveau des requ√™tes SQL. Il enregistre toutes les requ√™tes dont le temps d'ex√©cution d√©passe un seuil d√©fini.

### Utilit√© du slow query log

- üéØ **Identifier les goulots d'√©tranglement** : Requ√™tes qui consomment le plus de ressources
- üìä **Optimisation cibl√©e** : Focus sur les requ√™tes √† fort impact
- üîç **D√©tection d'anomalies** : Requ√™tes sans index, full table scans
- üìà **Trend analysis** : √âvolution des performances dans le temps
- üöÄ **Am√©lioration continue** : Base pour le performance tuning it√©ratif

üí° **Best practice** : Le slow query log devrait √™tre **activ√© en permanence en production** (avec un seuil adapt√©) car son overhead est minimal et les b√©n√©fices consid√©rables.

---

## Configuration de base

### Activation et param√®tres essentiels

```ini
# /etc/mysql/mariadb.conf.d/50-server.cnf

[mysqld]
# === Slow Query Log Configuration ===

# Activer le slow query log
slow_query_log = 1

# Emplacement du fichier
slow_query_log_file = /var/log/mysql/slow-query.log

# Seuil de temps (en secondes)
# Requ√™tes > 2 secondes sont logg√©es
long_query_time = 2

# Logger les requ√™tes n'utilisant pas d'index
log_queries_not_using_indexes = 1

# Limiter le taux de requ√™tes sans index logg√©es
# (√©viter flood si beaucoup de requ√™tes sans index)
log_throttle_queries_not_using_indexes = 10

# Logger les requ√™tes administratives lentes
# (ALTER TABLE, CREATE INDEX, etc.)
log_slow_admin_statements = 1

# Logger les requ√™tes des replicas (si applicable)
log_slow_slave_statements = 1

# Seuil minimal pour requ√™tes sans index
# Ne logger que si examined rows > ce seuil
min_examined_row_limit = 100
```

### Variables syst√®me associ√©es

```sql
-- V√©rifier la configuration active
SHOW VARIABLES LIKE 'slow_query%';
SHOW VARIABLES LIKE 'long_query_time';
SHOW VARIABLES LIKE 'log_queries_not_using_indexes';

-- R√©sultat typique
+------------------------------+---------------------------+
| Variable_name                | Value                     |
+------------------------------+---------------------------+
| slow_query_log               | ON                        |
| slow_query_log_file          | /var/log/mysql/slow.log   |
| long_query_time              | 2.000000                  |
| log_queries_not_using_indexes| ON                        |
+------------------------------+---------------------------+
```

### Activation/d√©sactivation dynamique

```sql
-- Activer temporairement (sans red√©marrage)
SET GLOBAL slow_query_log = ON;
SET GLOBAL long_query_time = 1;

-- Pour une session sp√©cifique (debugging)
SET SESSION long_query_time = 0.5;
-- Toutes les requ√™tes > 500ms seront logg√©es pour cette session

-- D√©sactiver temporairement
SET GLOBAL slow_query_log = OFF;

-- Persister les changements (MariaDB 10.5+)
SET PERSIST slow_query_log = ON;
SET PERSIST long_query_time = 2;
```

---

## Param√®tres de filtrage avanc√©s

### long_query_time : Choix du seuil

**Recommandations par type d'environnement** :

| Environnement | Seuil recommand√© | Justification |
|---------------|------------------|---------------|
| **Production OLTP** | 1-2 secondes | Requ√™tes web doivent √™tre < 1s |
| **Production OLAP** | 10-30 secondes | Requ√™tes analytiques plus longues |
| **D√©veloppement** | 0.5 secondes | D√©tecter probl√®mes t√¥t |
| **Debugging** | 0.1 secondes | Analyse fine |

```sql
-- Production OLTP
SET GLOBAL long_query_time = 1;

-- Production OLAP
SET GLOBAL long_query_time = 10;

-- Debugging intensif (temporaire)
SET SESSION long_query_time = 0.01;  -- 10ms
```

üí° **Astuce** : Commencer avec un seuil conservateur (5s) puis r√©duire progressivement selon le volume de logs g√©n√©r√©.

### log_queries_not_using_indexes

**Configuration intelligente** :

```ini
[mysqld]
# Logger requ√™tes sans index
log_queries_not_using_indexes = 1

# MAIS limiter √† 10 occurrences par minute
# (√©viter saturation du log)
log_throttle_queries_not_using_indexes = 10
```

**Comportement** :

```sql
-- Requ√™te sans index (full table scan)
SELECT * FROM users WHERE email = 'john@example.com';
-- ‚ö†Ô∏è Logg√©e m√™me si < long_query_time

-- Mais apr√®s 10 occurrences en 60 secondes
-- Les suivantes sont ignor√©es jusqu'√† la prochaine minute
```

### min_examined_row_limit

Filtrer les requ√™tes triviales :

```ini
[mysqld]
# Ne logger que les requ√™tes examinant > 1000 rows
min_examined_row_limit = 1000
```

```sql
-- Cette requ√™te ne sera PAS logg√©e m√™me si lente
-- car examine seulement 10 rows
SELECT * FROM users WHERE id = 123;  -- 10 rows examined

-- Celle-ci SERA logg√©e (si lente)
-- car examine 50000 rows
SELECT * FROM orders WHERE status = 'pending';  -- 50000 rows examined
```

---

## Format et structure du slow query log

### Format standard

```
# Time: 2025-12-13T14:35:21.123456Z
# User@Host: webapp[webapp] @ web01 [192.168.1.100]
# Thread_id: 12345  Schema: ecommerce  QC_hit: No
# Query_time: 5.234567  Lock_time: 0.000123  Rows_sent: 1  Rows_examined: 125000
SET timestamp=1702476921;
SELECT customers.name, SUM(orders.amount)
FROM customers
JOIN orders ON customers.id = orders.customer_id
WHERE orders.created_at > '2025-01-01'
GROUP BY customers.id;
```

### D√©cryptage des champs

| Champ | Signification | Exemple | Interpr√©tation |
|-------|---------------|---------|----------------|
| **Time** | Timestamp de fin d'ex√©cution | 2025-12-13T14:35:21 | Quand la requ√™te a fini |
| **User@Host** | Utilisateur et origine | webapp@192.168.1.100 | Qui a lanc√© la requ√™te |
| **Thread_id** | ID du thread MySQL | 12345 | Pour corr√©lation |
| **Schema** | Base de donn√©es | ecommerce | Contexte de la requ√™te |
| **Query_time** | Temps total ex√©cution | 5.234567 | **M√©trique principale** |
| **Lock_time** | Temps d'attente de verrous | 0.000123 | Contention ? |
| **Rows_sent** | Lignes retourn√©es | 1 | R√©sultat |
| **Rows_examined** | Lignes examin√©es | 125000 | **Efficacit√© de la requ√™te** |

### M√©triques cl√©s pour l'analyse

```
Query_time vs Rows_examined ‚Üí Ratio d'efficacit√©

Si Query_time = 5s et Rows_examined = 10
  ‚Üí Probl√®me probable : locks, I/O lent

Si Query_time = 0.1s et Rows_examined = 10000000
  ‚Üí Full table scan, manque d'index
```

---

## Analyse manuelle du slow query log

### Commandes de base

```bash
# Afficher les 10 derni√®res requ√™tes lentes
tail -100 /var/log/mysql/slow-query.log

# Suivre en temps r√©el
tail -f /var/log/mysql/slow-query.log

# Compter le nombre de requ√™tes lentes
grep -c "Query_time:" /var/log/mysql/slow-query.log

# Trouver les requ√™tes les plus lentes (> 10s)
grep "Query_time: [1-9][0-9]\." /var/log/mysql/slow-query.log -A 5
```

### Extraction des requ√™tes les plus co√ªteuses

```bash
#!/bin/bash
# extract-slowest-queries.sh

LOG_FILE="/var/log/mysql/slow-query.log"
OUTPUT_FILE="/tmp/slowest-queries.txt"

echo "=== Top 20 Slowest Queries ===" > $OUTPUT_FILE

# Extraire Query_time et la requ√™te correspondante
grep -A 2 "Query_time:" $LOG_FILE | \
  awk '/Query_time:/ {time=$3; getline; getline; print time, $0}' | \
  sort -rn | \
  head -20 >> $OUTPUT_FILE

cat $OUTPUT_FILE
```

### Identification des patterns

```bash
# Requ√™tes les plus fr√©quentes (normalis√©es)
grep "^SELECT" /var/log/mysql/slow-query.log | \
  sed 's/[0-9]\+/N/g' | \
  sed "s/'[^']*'/X/g" | \
  sort | uniq -c | sort -rn | head -10

# Requ√™tes par table
grep -i "FROM" /var/log/mysql/slow-query.log | \
  awk '{for(i=1;i<=NF;i++) if($i=="FROM" || $i=="from") print $(i+1)}' | \
  sed 's/[,;]//g' | sort | uniq -c | sort -rn
```

---

## pt-query-digest : L'outil d'analyse ultime

### Installation

```bash
# Debian/Ubuntu
sudo apt-get install percona-toolkit

# RHEL/CentOS
sudo yum install percona-toolkit

# Depuis source
wget percona.com/get/percona-toolkit.tar.gz
tar xzf percona-toolkit.tar.gz
cd percona-toolkit-*/
perl Makefile.PL
make install
```

### Utilisation basique

```bash
# Analyser le slow query log
pt-query-digest /var/log/mysql/slow-query.log

# Sauvegarder le rapport
pt-query-digest /var/log/mysql/slow-query.log > /tmp/query-digest-report.txt

# Analyser les derni√®res 24h uniquement
pt-query-digest --since '1d ago' /var/log/mysql/slow-query.log
```

### Format du rapport

```
# Profile
# Rank Query ID           Response time    Calls  R/Call  V/M   Item
# ==== ================== ================ ====== ======= ===== ==========
#    1 0x1A2B3C4D5E6F...  1234.5678 45.2%    250  4.9383  1.23 SELECT customers orders
#    2 0x7F8E9D0C1B2A...   892.3456 32.6%    156  5.7202  2.34 UPDATE products
# MISC 0x00000000000...   567.8901 22.2%    892  0.6367  0.12 <78 ITEMS>
```

**Interpr√©tation** :

- **Rank** : Classement par impact total
- **Response time** : Temps cumul√© + % du total
- **Calls** : Nombre d'ex√©cutions
- **R/Call** : Temps moyen par ex√©cution
- **V/M** : Variance/Mean (consistance)

### Analyse d√©taill√©e d'une requ√™te

```bash
# Rapport d√©taill√© pour une requ√™te sp√©cifique
pt-query-digest --limit 1 /var/log/mysql/slow-query.log

# R√©sultat :
# Query 1: 12.5 QPS, 0.52x concurrency, ID 0x1A2B3C4D at byte 1234
# This item is included in the report because it matches --limit.
# Scores: V/M = 1.23
# Time range: 2025-12-13 10:00:00 to 14:00:00
# Attribute    pct   total     min     max     avg     95%  stddev  median
# ============ === ======= ======= ======= ======= ======= ======= =======
# Count         15    3125
# Exec time     45  1234.5     0.5    15.2    0.39    1.23    2.34    0.28
# Lock time     12     5.23   0.001   0.156   0.002   0.003   0.004   0.001
# Rows sent     18  125000       1   50000      40     100     234      25
# Rows examine  42  5000000    100  500000    1600    5000   12000     500
# Query size     8   250KB     80B    1KB     80B    100B    150B     80B
```

### Options avanc√©es

```bash
# Grouper par utilisateur
pt-query-digest --group-by user /var/log/mysql/slow-query.log

# Grouper par host
pt-query-digest --group-by host /var/log/mysql/slow-query.log

# Filtrer par base de donn√©es
pt-query-digest --filter '$event->{db} eq "ecommerce"' \
  /var/log/mysql/slow-query.log

# Afficher les requ√™tes > 10 secondes
pt-query-digest --filter '$event->{Query_time} > 10' \
  /var/log/mysql/slow-query.log

# Top 20 au lieu de 10
pt-query-digest --limit 20 /var/log/mysql/slow-query.log

# Exporter en JSON pour parsing
pt-query-digest --output json /var/log/mysql/slow-query.log > report.json
```

### Comparaison temporelle

```bash
# Comparer deux p√©riodes
pt-query-digest --since '2 days ago' --until '1 day ago' \
  /var/log/mysql/slow-query.log > /tmp/period1.txt

pt-query-digest --since '1 day ago' \
  /var/log/mysql/slow-query.log > /tmp/period2.txt

# Comparer
diff /tmp/period1.txt /tmp/period2.txt
```

### Analyse en direct depuis le serveur

```bash
# Analyser directement depuis MySQL (processlist)
pt-query-digest --processlist h=localhost,u=root,p=password

# Surveiller pendant 60 secondes
pt-query-digest --processlist h=localhost --run-time 60
```

---

## Performance Schema : Monitoring en temps r√©el

### Tables pertinentes

```sql
-- Vue d'ensemble des statements
SELECT * FROM performance_schema.events_statements_summary_by_digest
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 10;

-- Requ√™tes avec full table scan
SELECT DIGEST_TEXT,
       COUNT_STAR,
       SUM_NO_INDEX_USED,
       SUM_NO_GOOD_INDEX_USED,
       ROUND(SUM_TIMER_WAIT/1000000000000, 2) AS total_time_sec
FROM performance_schema.events_statements_summary_by_digest
WHERE SUM_NO_INDEX_USED > 0
   OR SUM_NO_GOOD_INDEX_USED > 0
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;
```

### Requ√™tes les plus lentes en temps r√©el

```sql
-- Top 10 requ√™tes par temps moyen d'ex√©cution
SELECT DIGEST_TEXT,
       COUNT_STAR AS executions,
       ROUND(AVG_TIMER_WAIT/1000000000000, 3) AS avg_time_sec,
       ROUND(MAX_TIMER_WAIT/1000000000000, 3) AS max_time_sec,
       ROUND(SUM_TIMER_WAIT/1000000000000, 2) AS total_time_sec,
       ROUND(SUM_ROWS_EXAMINED/COUNT_STAR, 0) AS avg_rows_examined
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
  AND COUNT_STAR > 10  -- Au moins 10 ex√©cutions
ORDER BY AVG_TIMER_WAIT DESC
LIMIT 10;
```

### Requ√™tes avec le plus d'impact global

```sql
-- Impact = Fr√©quence √ó Temps moyen
SELECT DIGEST_TEXT,
       COUNT_STAR AS frequency,
       ROUND(AVG_TIMER_WAIT/1000000000000, 3) AS avg_sec,
       ROUND(SUM_TIMER_WAIT/1000000000000, 2) AS total_sec,
       ROUND((SUM_TIMER_WAIT/1000000000000) /
             (SELECT SUM(SUM_TIMER_WAIT)/1000000000000
              FROM performance_schema.events_statements_summary_by_digest) * 100, 2)
         AS pct_total_time
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
ORDER BY SUM_TIMER_WAIT DESC
LIMIT 20;
```

### Cr√©er des vues pour monitoring

```sql
-- Vue des requ√™tes probl√©matiques
CREATE OR REPLACE VIEW v_slow_queries AS
SELECT
    DIGEST_TEXT,
    COUNT_STAR AS executions,
    ROUND(AVG_TIMER_WAIT/1000000000000, 3) AS avg_time_sec,
    ROUND(MAX_TIMER_WAIT/1000000000000, 3) AS max_time_sec,
    ROUND(SUM_LOCK_TIME/1000000000000, 3) AS sum_lock_time_sec,
    ROUND(SUM_ROWS_EXAMINED/COUNT_STAR, 0) AS avg_rows_examined,
    SUM_NO_INDEX_USED,
    FIRST_SEEN,
    LAST_SEEN
FROM performance_schema.events_statements_summary_by_digest
WHERE DIGEST_TEXT IS NOT NULL
  AND AVG_TIMER_WAIT/1000000000000 > 1  -- > 1 seconde en moyenne
ORDER BY AVG_TIMER_WAIT DESC;

-- Utilisation
SELECT * FROM v_slow_queries LIMIT 10;
```

### Reset des statistiques

```sql
-- Reset toutes les stats (nouveau d√©part)
TRUNCATE TABLE performance_schema.events_statements_summary_by_digest;

-- OU via variable
CALL sys.ps_truncate_all_tables(FALSE);
```

---

## Strat√©gies d'optimisation

### Workflow d'optimisation bas√© sur slow query log

```
1. Identifier les requ√™tes lentes
   ‚Üì
2. Analyser avec EXPLAIN
   ‚Üì
3. Cr√©er/optimiser index
   ‚Üì
4. Tester la requ√™te optimis√©e
   ‚Üì
5. D√©ployer en production
   ‚Üì
6. Monitorer l'impact
```

### Exemple complet d'optimisation

#### √âtape 1 : Identifier la requ√™te

```bash
# pt-query-digest identifie :
# Query 1: 2.5s average, 1000 calls/day
SELECT c.name, c.email, COUNT(o.id) as order_count
FROM customers c
LEFT JOIN orders o ON c.id = o.customer_id
WHERE c.country = 'FR'
  AND o.created_at > '2025-01-01'
GROUP BY c.id;
```

#### √âtape 2 : Analyser avec EXPLAIN

```sql
EXPLAIN
SELECT c.name, c.email, COUNT(o.id) as order_count
FROM customers c
LEFT JOIN orders o ON c.id = o.customer_id
WHERE c.country = 'FR'
  AND o.created_at > '2025-01-01'
GROUP BY c.id\G

-- R√©sultat :
-- *************************** 1. row ***************************
--            id: 1
--   select_type: SIMPLE
--         table: c
--          type: ALL          ‚ö†Ô∏è FULL TABLE SCAN
-- possible_keys: NULL
--           key: NULL         ‚ö†Ô∏è PAS D'INDEX UTILIS√â
--           rows: 100000      ‚ö†Ô∏è EXAMINE TOUTES LES LIGNES
--         Extra: Using where; Using temporary; Using filesort
```

#### √âtape 3 : Cr√©er les index appropri√©s

```sql
-- Analyser la structure actuelle
SHOW CREATE TABLE customers\G
SHOW CREATE TABLE orders\G

-- Cr√©er index sur customers.country (tr√®s s√©lectif)
CREATE INDEX idx_customers_country ON customers(country);

-- Cr√©er index composite sur orders pour optimiser la jointure
CREATE INDEX idx_orders_customer_created
  ON orders(customer_id, created_at);

-- Analyser la table pour mettre √† jour les stats
ANALYZE TABLE customers;
ANALYZE TABLE orders;
```

#### √âtape 4 : V√©rifier l'am√©lioration

```sql
-- Re-EXPLAIN
EXPLAIN
SELECT c.name, c.email, COUNT(o.id) as order_count
FROM customers c
LEFT JOIN orders o ON c.id = o.customer_id
WHERE c.country = 'FR'
  AND o.created_at > '2025-01-01'
GROUP BY c.id\G

-- R√©sultat am√©lior√© :
-- *************************** 1. row ***************************
--            id: 1
--   select_type: SIMPLE
--         table: c
--          type: ref                ‚úÖ INDEX RANGE SCAN
-- possible_keys: idx_customers_country
--           key: idx_customers_country  ‚úÖ INDEX UTILIS√â
--           rows: 5000               ‚úÖ SEULEMENT 5K LIGNES
--         Extra: Using index condition

-- Mesurer le temps r√©el
SET profiling = 1;
SELECT ...;  -- Ex√©cuter la requ√™te
SHOW PROFILES;

-- Avant : 2.5 secondes
-- Apr√®s : 0.15 secondes  ‚úÖ Am√©lioration 94%
```

#### √âtape 5 : V√©rifier dans slow query log

```bash
# Apr√®s d√©ploiement, surveiller pendant 24h
# La requ√™te ne devrait plus appara√Ætre dans slow query log

tail -f /var/log/mysql/slow-query.log | grep -i "customers.*orders"
# (Aucun r√©sultat = succ√®s ‚úÖ)
```

---

## Rotation et gestion des fichiers

### Configuration logrotate

```bash
# /etc/logrotate.d/mysql-slow-query
/var/log/mysql/slow-query.log {
    weekly                   # Rotation hebdomadaire
    rotate 12                # Garder 12 semaines (3 mois)
    missingok
    notifempty
    compress
    delaycompress
    sharedscripts
    postrotate
        # Flush logs pour cr√©er nouveau fichier
        if [ -x /usr/bin/mysqladmin ]; then
            /usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf \
                                flush-logs > /dev/null 2>&1 || true
        fi
    endscript
}
```

### Rotation manuelle

```bash
#!/bin/bash
# rotate-slow-query-log.sh

SLOW_LOG="/var/log/mysql/slow-query.log"
ARCHIVE_DIR="/var/log/mysql/archive"
DATE=$(date +%Y%m%d_%H%M%S)

# Cr√©er r√©pertoire archive
mkdir -p $ARCHIVE_DIR

# Renommer fichier actuel
mv $SLOW_LOG $ARCHIVE_DIR/slow-query.log.$DATE

# Demander √† MariaDB de cr√©er un nouveau fichier
mysqladmin flush-logs

# Compresser l'archive
gzip $ARCHIVE_DIR/slow-query.log.$DATE

# Analyser avant compression (optionnel)
pt-query-digest $ARCHIVE_DIR/slow-query.log.$DATE \
  > $ARCHIVE_DIR/digest-$DATE.txt

echo "Slow query log rotated successfully"
```

### Purge automatique des anciens logs

```bash
# Cron job : purger logs > 90 jours
0 2 * * 0 find /var/log/mysql/archive -name "slow-query.log.*.gz" -mtime +90 -delete
```

---

## Monitoring et alerting

### Script de surveillance quotidien

```bash
#!/bin/bash
# monitor-slow-queries.sh

LOG_FILE="/var/log/mysql/slow-query.log"
THRESHOLD=50  # Alerte si > 50 slow queries par jour
REPORT_FILE="/tmp/slow-query-daily-$(date +%Y%m%d).txt"
EMAIL="dba@example.com"

# Compter slow queries du jour
TODAY=$(date +%Y-%m-%d)
COUNT=$(grep "$TODAY" $LOG_FILE | grep -c "Query_time:")

echo "=== Slow Query Daily Report - $TODAY ===" > $REPORT_FILE
echo "Total slow queries: $COUNT" >> $REPORT_FILE
echo "" >> $REPORT_FILE

if [ $COUNT -gt $THRESHOLD ]; then
    echo "‚ö†Ô∏è  WARNING: Threshold exceeded ($THRESHOLD)" >> $REPORT_FILE
    echo "" >> $REPORT_FILE

    # Analyser avec pt-query-digest
    echo "Top 10 slowest queries:" >> $REPORT_FILE
    pt-query-digest --limit 10 --since "1 day ago" $LOG_FILE >> $REPORT_FILE

    # Envoyer alerte email
    mail -s "[ALERT] High number of slow queries: $COUNT" $EMAIL < $REPORT_FILE
else
    echo "‚úÖ Normal operation" >> $REPORT_FILE
fi

cat $REPORT_FILE
```

### Int√©gration Prometheus

```yaml
# prometheus-mysqld-exporter.yml
# Les m√©triques slow query sont expos√©es automatiquement

# Exemple de requ√™tes PromQL
# Nombre de slow queries par minute
rate(mysql_global_status_slow_queries[5m])

# Alertes
groups:
  - name: mariadb_slow_queries
    rules:
      - alert: HighSlowQueryRate
        expr: rate(mysql_global_status_slow_queries[5m]) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High slow query rate on {{ $labels.instance }}"
          description: "{{ $value }} slow queries per second"
```

### Dashboard Grafana

```json
{
  "dashboard": {
    "title": "MariaDB Slow Queries",
    "panels": [
      {
        "title": "Slow Query Rate",
        "targets": [
          {
            "expr": "rate(mysql_global_status_slow_queries[5m])"
          }
        ]
      },
      {
        "title": "Top Slow Queries",
        "type": "table",
        "targets": [
          {
            "expr": "topk(10, mysql_perf_schema_events_statements_total{digest!=\"\"})"
          }
        ]
      }
    ]
  }
}
```

---

## Cas d'usage avanc√©s

### Debugging temporaire avec seuil tr√®s bas

```sql
-- Pour une session de debugging sp√©cifique
-- Capturer TOUTES les requ√™tes (m√™me rapides)
SET SESSION long_query_time = 0;
SET SESSION min_examined_row_limit = 0;

-- Ex√©cuter les requ√™tes √† analyser
SELECT ...;
UPDATE ...;

-- D√©sactiver
SET SESSION long_query_time = 2;
```

### Slow query log par application

```ini
# Configuration pour identifier les applications
[mysqld]
# Logger le nom du programme client
log_slow_verbosity = query_plan,innodb,explain
```

R√©sultat dans le log :

```
# User@Host: webapp[webapp] @ web01 [192.168.1.100]
# Thread_id: 12345  Schema: ecommerce  QC_hit: No
# Program_name: python-app-v2.3
```

### Analyse diff√©rentielle avant/apr√®s d√©ploiement

```bash
#!/bin/bash
# compare-slow-queries.sh

# Avant d√©ploiement
pt-query-digest /var/log/mysql/slow-query.log > /tmp/before-deploy.txt

# D√©ploiement application v2.0
# ...

# 24h apr√®s d√©ploiement
pt-query-digest --since '1 day ago' /var/log/mysql/slow-query.log > /tmp/after-deploy.txt

# Comparer
echo "=== Performance Comparison ==="
echo "Before deployment:"
grep "Profile" -A 5 /tmp/before-deploy.txt

echo ""
echo "After deployment:"
grep "Profile" -A 5 /tmp/after-deploy.txt
```

---

## Bonnes pratiques

### 1. Toujours activer en production

```ini
# ‚úÖ Bon : Activ√© avec seuil raisonnable
[mysqld]
slow_query_log = 1
long_query_time = 2

# ‚ùå Mauvais : D√©sactiv√© en production
# slow_query_log = 0
```

**Raison** : Overhead minimal (<1%) vs b√©n√©fice √©norme pour troubleshooting.

### 2. Adapter le seuil au contexte

```sql
-- OLTP : Requ√™tes doivent √™tre rapides
SET GLOBAL long_query_time = 1;

-- OLAP : Requ√™tes analytiques plus longues
SET GLOBAL long_query_time = 10;

-- Debugging ponctuel
SET SESSION long_query_time = 0.1;
```

### 3. Rotation r√©guli√®re

```bash
# Rotation hebdomadaire automatique via logrotate
# √âvite fichiers gigantesques et difficiles √† analyser
```

### 4. Analyse r√©guli√®re avec pt-query-digest

```bash
# Cron quotidien : rapport automatique
0 6 * * * pt-query-digest --since '1 day ago' \
  /var/log/mysql/slow-query.log | \
  mail -s "Daily Slow Query Report" dba@example.com
```

### 5. Combiner avec Performance Schema

```sql
-- Slow query log = Historique
-- Performance Schema = Temps r√©el

-- Les deux sont compl√©mentaires
```

### 6. Logger requ√™tes administratives

```ini
[mysqld]
# ALTER, CREATE INDEX peuvent √™tre longs
log_slow_admin_statements = 1
```

### 7. Monitoring continu

```bash
# Dashboard Grafana + alertes Prometheus
# Surveillance 24/7 automatis√©e
```

---

## Troubleshooting

### Probl√®me : Slow query log vide

```sql
-- V√©rifier que c'est activ√©
SHOW VARIABLES LIKE 'slow_query_log';
-- Si OFF :
SET GLOBAL slow_query_log = ON;

-- V√©rifier le seuil
SHOW VARIABLES LIKE 'long_query_time';
-- Si trop √©lev√© (ex: 100s), r√©duire :
SET GLOBAL long_query_time = 2;

-- V√©rifier que requ√™tes lentes existent
SHOW GLOBAL STATUS LIKE 'Slow_queries';
-- Si 0, aucune requ√™te n'est lente (bon signe !)
```

### Probl√®me : Fichier slow query log gigantesque

```bash
# V√©rifier taille
du -h /var/log/mysql/slow-query.log
# 15GB ‚ö†Ô∏è

# Identifier si flood
tail -1000 /var/log/mysql/slow-query.log | \
  grep "Query_time:" | wc -l
# 1000 requ√™tes dans les 1000 derni√®res lignes = flood

# Solutions :
# 1. Augmenter long_query_time temporairement
SET GLOBAL long_query_time = 5;

# 2. Activer throttling pour requ√™tes sans index
SET GLOBAL log_throttle_queries_not_using_indexes = 5;

# 3. Rotation imm√©diate
mysqladmin flush-logs
mv /var/log/mysql/slow-query.log /var/log/mysql/slow-query.log.old
```

### Probl√®me : Performance impact du slow query log

```sql
-- V√©rifier l'overhead
SHOW GLOBAL STATUS LIKE 'Slow_queries';
-- Si tr√®s √©lev√© (milliers/seconde), probl√®me

-- D√©sactiver temporairement
SET GLOBAL slow_query_log = OFF;

-- Ou augmenter seuil
SET GLOBAL long_query_time = 10;

-- Ou d√©sactiver logging requ√™tes sans index
SET GLOBAL log_queries_not_using_indexes = OFF;
```

---

## Checklist op√©rationnelle

### Configuration initiale

- [ ] Activer slow_query_log dans my.cnf
- [ ] D√©finir long_query_time adapt√© au workload
- [ ] Configurer emplacement du fichier
- [ ] Activer log_queries_not_using_indexes
- [ ] Configurer log_throttle_queries_not_using_indexes
- [ ] Tester avec SET GLOBAL temporairement
- [ ] Red√©marrer et v√©rifier activation

### Analyse hebdomadaire

- [ ] Ex√©cuter pt-query-digest
- [ ] Identifier top 10 requ√™tes par impact
- [ ] Analyser avec EXPLAIN les requ√™tes probl√©matiques
- [ ] Planifier optimisations (index, r√©√©criture)
- [ ] Documenter les r√©sultats

### Optimisation

- [ ] Cr√©er/modifier index identifi√©s
- [ ] ANALYZE TABLE apr√®s cr√©ation index
- [ ] Tester requ√™tes optimis√©es
- [ ] Mesurer am√©lioration (SHOW PROFILES)
- [ ] D√©ployer en production
- [ ] Monitorer pendant 48h
- [ ] Valider disparition du slow query log

### Maintenance

- [ ] V√©rifier rotation automatique (logrotate)
- [ ] Purger archives > 90 jours
- [ ] Archiver rapports pt-query-digest
- [ ] V√©rifier espace disque
- [ ] Mettre √† jour documentation

---

## Scripts de r√©f√©rence

### 1. Analyse automatis√©e compl√®te

```bash
#!/bin/bash
# full-slow-query-analysis.sh

LOG="/var/log/mysql/slow-query.log"
DATE=$(date +%Y%m%d)
REPORT_DIR="/var/reports/slow-queries"
mkdir -p $REPORT_DIR

echo "=== Full Slow Query Analysis - $DATE ==="

# 1. pt-query-digest report
echo "Generating pt-query-digest report..."
pt-query-digest --limit 20 $LOG > $REPORT_DIR/digest-$DATE.txt

# 2. Extraction des requ√™tes uniques
echo "Extracting unique queries..."
grep "^SELECT\|^UPDATE\|^DELETE\|^INSERT" $LOG | \
  sed 's/[0-9]\+/N/g' | sed "s/'[^']*'/X/g" | \
  sort | uniq -c | sort -rn > $REPORT_DIR/unique-queries-$DATE.txt

# 3. Statistiques globales
echo "Computing statistics..."
cat > $REPORT_DIR/stats-$DATE.txt <<EOF
Total slow queries: $(grep -c "Query_time:" $LOG)
Queries without index: $(grep -c "No index used" $LOG)
Average query time: $(grep "Query_time:" $LOG | awk '{sum+=$3; count++} END {print sum/count}')
Max query time: $(grep "Query_time:" $LOG | awk '{if($3>max) max=$3} END {print max}')
EOF

# 4. Top tables
echo "Identifying hot tables..."
grep -i "FROM" $LOG | awk '{for(i=1;i<=NF;i++) if($i=="FROM") print $(i+1)}' | \
  sed 's/[,;]//g' | sort | uniq -c | sort -rn | head -20 \
  > $REPORT_DIR/hot-tables-$DATE.txt

echo "Analysis complete. Reports in $REPORT_DIR"
```

### 2. Monitoring continu

```bash
#!/bin/bash
# continuous-monitoring.sh

while true; do
    SLOW_COUNT=$(mysql -N -e "SHOW GLOBAL STATUS LIKE 'Slow_queries';" | awk '{print $2}')
    echo "$(date '+%Y-%m-%d %H:%M:%S') - Slow queries: $SLOW_COUNT"

    # Alerte si > seuil
    if [ $SLOW_COUNT -gt 1000 ]; then
        echo "‚ö†Ô∏è  WARNING: High slow query count!"
        # Envoyer alerte
    fi

    sleep 60
done
```

---

## ‚úÖ Points cl√©s √† retenir

- **Activer en permanence** : Overhead minimal, b√©n√©fice maximal
- **long_query_time** : Adapter au workload (OLTP: 1-2s, OLAP: 10-30s)
- **pt-query-digest** : Outil indispensable pour analyse approfondie
- **Performance Schema** : Monitoring temps r√©el compl√©mentaire
- **Workflow optimisation** : Identifier ‚Üí EXPLAIN ‚Üí Index ‚Üí Tester ‚Üí D√©ployer ‚Üí Monitorer
- **Rotation automatique** : logrotate hebdomadaire recommand√©
- **log_queries_not_using_indexes** : Activer avec throttling
- **Analyse r√©guli√®re** : Hebdomadaire minimum, quotidienne id√©al
- **EXPLAIN toujours** : Avant toute optimisation
- **Monitoring continu** : Dashboard Grafana + alertes Prometheus

---

## üîó Ressources et r√©f√©rences

- [üìñ Documentation officielle : Slow Query Log](https://mariadb.com/kb/en/slow-query-log/)
- [üìñ Documentation officielle : log_slow_* variables](https://mariadb.com/kb/en/server-system-variables/#log_slow_verbosity)
- [üìñ Performance Schema statements](https://mariadb.com/kb/en/performance-schema-events_statements_summary_by_digest-table/)
- [üìñ Percona Toolkit : pt-query-digest](https://docs.percona.com/percona-toolkit/pt-query-digest.html)
- [Blog : Slow Query Log Analysis Best Practices](https://mariadb.org/slow-query-optimization/)
- [üìñ EXPLAIN documentation](https://mariadb.com/kb/en/explain/)

---

## ‚û°Ô∏è Section suivante

**11.4.3 - General log** : Configuration et utilisation du general log pour l'audit complet des requ√™tes, cas d'usage sp√©cifiques, impact sur les performances, et strat√©gies de gestion en production.

‚è≠Ô∏è [General log](/11-administration-configuration/04.3-general-log.md)
