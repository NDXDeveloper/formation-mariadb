ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.12 Benchmarking

> **Niveau** : Expert  
> **DurÃ©e estimÃ©e** : 3-4 heures  
> **PrÃ©requis** : 
> - Sections 15.1-15.11 (Performance, Optimisation, Sharding)
> - ComprÃ©hension des mÃ©triques de performance
> - ExpÃ©rience en tuning de bases de donnÃ©es
> - Connaissance de l'architecture systÃ¨me (CPU, RAM, I/O)

---

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :

- **Comprendre les types** de benchmarks et leurs objectifs
- **DÃ©finir une mÃ©thodologie** rigoureuse de benchmarking
- **Identifier les mÃ©triques** critiques Ã  mesurer
- **Choisir les outils** appropriÃ©s pour chaque scÃ©nario
- **InterprÃ©ter les rÃ©sultats** correctement et objectivement
- **Ã‰viter les piÃ¨ges** courants du benchmarking
- **Comparer des configurations** de maniÃ¨re fiable
- **Valider les optimisations** avant production
- **RÃ©aliser le capacity planning** basÃ© sur des donnÃ©es rÃ©elles
- **Documenter et communiquer** les rÃ©sultats efficacement

---

## Introduction

Le **benchmarking** est le processus de mesure systÃ©matique et reproductible des performances d'un systÃ¨me de base de donnÃ©es. C'est un outil **essentiel** pour :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POURQUOI BENCHMARKER ?                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. VALIDER LES OPTIMISATIONS                      â”‚
â”‚     â€¢ Avant/aprÃ¨s modification                     â”‚
â”‚     â€¢ Gain rÃ©el vs gain espÃ©rÃ©                     â”‚
â”‚     â€¢ ROI des investissements                      â”‚
â”‚                                                    â”‚
â”‚  2. COMPARER DES CONFIGURATIONS                    â”‚
â”‚     â€¢ MatÃ©riel : SSD vs NVMe                       â”‚
â”‚     â€¢ Configuration : buffer pool 50% vs 75%       â”‚
â”‚     â€¢ Architecture : standalone vs sharded         â”‚
â”‚                                                    â”‚
â”‚  3. CAPACITY PLANNING                              â”‚
â”‚     â€¢ Quelle charge maximale ?                     â”‚
â”‚     â€¢ Quand scaler ?                               â”‚
â”‚     â€¢ Dimensionnement futur                        â”‚
â”‚                                                    â”‚
â”‚  4. IDENTIFIER LES BOTTLENECKS                     â”‚
â”‚     â€¢ CPU bound vs I/O bound                       â”‚
â”‚     â€¢ Limites mÃ©moire                              â”‚
â”‚     â€¢ Saturation rÃ©seau                            â”‚
â”‚                                                    â”‚
â”‚  5. ACCEPTATION PRÃ‰-PRODUCTION                     â”‚
â”‚     â€¢ Validation SLA                               â”‚
â”‚     â€¢ Tests de charge                              â”‚
â”‚     â€¢ Certification performance                    â”‚
â”‚                                                    â”‚
â”‚  6. RÃ‰GRESSION TESTING                             â”‚
â”‚     â€¢ Nouvelle version MariaDB                     â”‚
â”‚     â€¢ Changement configuration                     â”‚
â”‚     â€¢ Mise Ã  jour systÃ¨me                          â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Le principe fondamental

> **"If you can't measure it, you can't improve it."**  
> â€” Peter Drucker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CYCLE D'OPTIMISATION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. MESURER (Baseline)                             â”‚
â”‚     â†“                                              â”‚
â”‚  2. ANALYSER (Identifier bottleneck)               â”‚
â”‚     â†“                                              â”‚
â”‚  3. OPTIMISER (ImplÃ©menter changement)             â”‚
â”‚     â†“                                              â”‚
â”‚  4. BENCHMARKER (Mesurer nouveau)                  â”‚
â”‚     â†“                                              â”‚
â”‚  5. COMPARER (Gain rÃ©el ?)                         â”‚
â”‚     â†“                                              â”‚
â”‚  6. VALIDER ou ROLLBACK                            â”‚
â”‚     â†“                                              â”‚
â”‚  7. DOCUMENTER                                     â”‚
â”‚     â†“                                              â”‚
â”‚  RÃ‰PÃ‰TER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Types de benchmarks

### 1. Benchmarks synthÃ©tiques

**DÃ©finition** : Tests standardisÃ©s avec charge artificielle.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BENCHMARKS SYNTHÃ‰TIQUES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  CaractÃ©ristiques :                                â”‚
â”‚  â€¢ Workload prÃ©dÃ©fini et rÃ©pÃ©table                 â”‚
â”‚  â€¢ Patterns simples (SELECT, INSERT, UPDATE)       â”‚
â”‚  â€¢ Comparaison facile entre systÃ¨mes               â”‚
â”‚  â€¢ RÃ©sultats standardisÃ©s                          â”‚
â”‚                                                    â”‚
â”‚  Outils :                                          â”‚
â”‚  â€¢ sysbench (MySQL benchmark standard)             â”‚
â”‚  â€¢ TPC-C, TPC-H (standards industrie)              â”‚
â”‚  â€¢ mysqlslap (outil natif)                         â”‚
â”‚                                                    â”‚
â”‚  Avantages :                                       â”‚
â”‚  âœ… Reproductible                                  â”‚
â”‚  âœ… Comparaison objective                          â”‚
â”‚  âœ… Facile Ã  automatiser                           â”‚
â”‚  âœ… Baseline rapide                                â”‚
â”‚                                                    â”‚
â”‚  InconvÃ©nients :                                   â”‚
â”‚  âŒ Pas reprÃ©sentatif du workload rÃ©el             â”‚
â”‚  âŒ Peut masquer problÃ¨mes spÃ©cifiques             â”‚
â”‚  âŒ Optimisations artificielles possibles          â”‚
â”‚                                                    â”‚
â”‚  Quand utiliser :                                  â”‚
â”‚  â€¢ Comparer matÃ©riel                               â”‚
â”‚  â€¢ Tester changement configuration                 â”‚
â”‚  â€¢ Baseline initiale                               â”‚
â”‚  â€¢ Tests de rÃ©gression                             â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple** :

```bash
# sysbench OLTP read-only
sysbench oltp_read_only \
  --mysql-host=localhost \
  --mysql-user=bench \
  --mysql-password=bench \
  --tables=10 \
  --table-size=1000000 \
  run

# RÃ©sultat type :
# Transactions: 125000 (2083.33 per sec)
# Queries: 1000000 (16666.67 per sec)
# Latency p95: 12.52ms
```

### 2. Benchmarks applicatifs (Real-world)

**DÃ©finition** : Tests basÃ©s sur le workload rÃ©el de production.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BENCHMARKS APPLICATIFS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  CaractÃ©ristiques :                                â”‚
â”‚  â€¢ Rejeu de traces production                      â”‚
â”‚  â€¢ Queries rÃ©elles de l'application                â”‚
â”‚  â€¢ Distribution de charge authentique              â”‚
â”‚  â€¢ Patterns complexes (JOINs, subqueries)          â”‚
â”‚                                                    â”‚
â”‚  MÃ©thodes :                                        â”‚
â”‚  â€¢ Capture slow query log production               â”‚
â”‚  â€¢ Rejeu avec pt-query-digest                      â”‚
â”‚  â€¢ Tests de charge avec JMeter/Gatling             â”‚
â”‚  â€¢ Clone de traffic (tcpcopy)                      â”‚
â”‚                                                    â”‚
â”‚  Avantages :                                       â”‚
â”‚  âœ… ReprÃ©sentatif du workload rÃ©el                 â”‚
â”‚  âœ… DÃ©tecte problÃ¨mes spÃ©cifiques app              â”‚
â”‚  âœ… Validation prÃ©-production fiable               â”‚
â”‚                                                    â”‚
â”‚  InconvÃ©nients :                                   â”‚
â”‚  âŒ Complexe Ã  mettre en place                     â”‚
â”‚  âŒ Difficile Ã  reproduire exactement              â”‚
â”‚  âŒ NÃ©cessite donnÃ©es production                   â”‚
â”‚  âŒ Chronophage                                    â”‚
â”‚                                                    â”‚
â”‚  Quand utiliser :                                  â”‚
â”‚  â€¢ Validation finale avant dÃ©ploiement             â”‚
â”‚  â€¢ Capacity planning prÃ©cis                        â”‚
â”‚  â€¢ Tests de migration                              â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple** :

```bash
# Capturer queries production (1 heure)
# Analyser avec pt-query-digest
pt-query-digest /var/log/mysql/slow.log > queries_production.txt

# Extraire top 100 queries
# CrÃ©er script de rejeu
# ExÃ©cuter sur serveur test avec mÃªme donnÃ©es
```

### 3. Benchmarks de stress

**DÃ©finition** : Tests aux limites du systÃ¨me.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BENCHMARKS DE STRESS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Objectifs :                                       â”‚
â”‚  â€¢ Trouver limites maximales                       â”‚
â”‚  â€¢ Point de rupture (breaking point)               â”‚
â”‚  â€¢ Comportement sous saturation                    â”‚
â”‚  â€¢ Temps de rÃ©cupÃ©ration                           â”‚
â”‚                                                    â”‚
â”‚  ScÃ©narios :                                       â”‚
â”‚  â€¢ Augmentation progressive de charge              â”‚
â”‚  â€¢ Pics soudains de trafic                         â”‚
â”‚  â€¢ Charge soutenue longue durÃ©e                    â”‚
â”‚  â€¢ Ressources limitÃ©es (RAM, CPU, I/O)             â”‚
â”‚                                                    â”‚
â”‚  MÃ©triques :                                       â”‚
â”‚  â€¢ Point de saturation (TPS max)                   â”‚
â”‚  â€¢ DÃ©gradation latence                             â”‚
â”‚  â€¢ Taux d'erreurs                                  â”‚
â”‚  â€¢ Temps de rÃ©cupÃ©ration                           â”‚
â”‚                                                    â”‚
â”‚  Cas d'usage :                                     â”‚
â”‚  â€¢ Dimensionnement infrastructure                  â”‚
â”‚  â€¢ Tests de rÃ©silience                             â”‚
â”‚  â€¢ Validation SLA                                  â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©thodologie de benchmarking

### Les 7 rÃ¨gles d'or

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RÃˆGLES FONDAMENTALES DU BENCHMARKING              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. ISOLER L'ENVIRONNEMENT                         â”‚
â”‚     â€¢ Serveur dÃ©diÃ© au benchmark                   â”‚
â”‚     â€¢ Pas d'autres processus concurrents           â”‚
â”‚     â€¢ RÃ©seau stable et prÃ©visible                  â”‚
â”‚                                                    â”‚
â”‚  2. ENVIRONNEMENT IDENTIQUE                        â”‚
â”‚     â€¢ MÃªme version MariaDB                         â”‚
â”‚     â€¢ MÃªme configuration OS                        â”‚
â”‚     â€¢ MÃªme jeu de donnÃ©es                          â”‚
â”‚     â€¢ MÃªme matÃ©riel (si comparaison config)        â”‚
â”‚                                                    â”‚
â”‚  3. WARMUP AVANT MESURE                            â”‚
â”‚     â€¢ Buffer pool chaud                            â”‚
â”‚     â€¢ Caches OS remplis                            â”‚
â”‚     â€¢ Ã‰tat stable du systÃ¨me                       â”‚
â”‚     â€¢ Min 5-10 minutes de warmup                   â”‚
â”‚                                                    â”‚
â”‚  4. DURÃ‰E SUFFISANTE                               â”‚
â”‚     â€¢ Minimum 30 minutes par test                  â”‚
â”‚     â€¢ IdÃ©al : 1-2 heures                           â”‚
â”‚     â€¢ Capturer variations temporelles              â”‚
â”‚                                                    â”‚
â”‚  5. RÃ‰PÃ‰TABILITÃ‰                                   â”‚
â”‚     â€¢ ExÃ©cuter 3-5 fois minimum                    â”‚
â”‚     â€¢ Calculer moyenne et Ã©cart-type               â”‚
â”‚     â€¢ Ã‰cart-type < 5% du rÃ©sultat                  â”‚
â”‚                                                    â”‚
â”‚  6. UNE VARIABLE Ã€ LA FOIS                         â”‚
â”‚     â€¢ Ne changer qu'un paramÃ¨tre                   â”‚
â”‚     â€¢ Isoler l'impact du changement                â”‚
â”‚     â€¢ Ã‰viter conclusions erronÃ©es                  â”‚
â”‚                                                    â”‚
â”‚  7. DOCUMENTER TOUT                                â”‚
â”‚     â€¢ Configuration complÃ¨te                       â”‚
â”‚     â€¢ Commandes exÃ©cutÃ©es                          â”‚
â”‚     â€¢ RÃ©sultats bruts                              â”‚
â”‚     â€¢ Conditions du test                           â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processus Ã©tape par Ã©tape

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROCESSUS BENCHMARK COMPLET                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  PHASE 1 : PRÃ‰PARATION (1-2 jours)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  â–¡ DÃ©finir objectif du benchmark                   â”‚
â”‚  â–¡ Choisir mÃ©triques Ã  mesurer                     â”‚
â”‚  â–¡ SÃ©lectionner outil appropriÃ©                    â”‚
â”‚  â–¡ Provisionner infrastructure                     â”‚
â”‚  â–¡ Installer et configurer MariaDB                 â”‚
â”‚  â–¡ Charger jeu de donnÃ©es reprÃ©sentatif            â”‚
â”‚  â–¡ Documenter baseline (hardware, config)          â”‚
â”‚                                                    â”‚
â”‚  PHASE 2 : WARMUP (15-30 min)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â–¡ DÃ©marrer MariaDB                                â”‚
â”‚  â–¡ ExÃ©cuter workload lÃ©ger                         â”‚
â”‚  â–¡ VÃ©rifier buffer pool hit rate > 99%             â”‚
â”‚  â–¡ VÃ©rifier stabilitÃ© mÃ©triques systÃ¨me            â”‚
â”‚                                                    â”‚
â”‚  PHASE 3 : BASELINE (1-2 heures)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â–¡ ExÃ©cuter benchmark configuration actuelle       â”‚
â”‚  â–¡ Capturer toutes mÃ©triques                       â”‚
â”‚  â–¡ RÃ©pÃ©ter 3 fois                                  â”‚
â”‚  â–¡ Calculer moyenne et Ã©cart-type                  â”‚
â”‚  â–¡ Sauvegarder rÃ©sultats bruts                     â”‚
â”‚                                                    â”‚
â”‚  PHASE 4 : MODIFICATION (30 min)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â–¡ Appliquer changement (un seul!)                 â”‚
â”‚  â–¡ RedÃ©marrer MariaDB si nÃ©cessaire                â”‚
â”‚  â–¡ Documenter le changement                        â”‚
â”‚                                                    â”‚
â”‚  PHASE 5 : TEST (1-2 heures)                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  â–¡ Warmup Ã  nouveau                                â”‚
â”‚  â–¡ ExÃ©cuter mÃªme benchmark                         â”‚
â”‚  â–¡ Capturer toutes mÃ©triques                       â”‚
â”‚  â–¡ RÃ©pÃ©ter 3 fois                                  â”‚
â”‚  â–¡ Calculer moyenne et Ã©cart-type                  â”‚
â”‚                                                    â”‚
â”‚  PHASE 6 : ANALYSE (1-2 heures)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  â–¡ Comparer baseline vs nouveau                    â”‚
â”‚  â–¡ Calculer % amÃ©lioration                         â”‚
â”‚  â–¡ VÃ©rifier significativitÃ© statistique            â”‚
â”‚  â–¡ Analyser mÃ©triques secondaires                  â”‚
â”‚  â–¡ Identifier effets de bord                       â”‚
â”‚                                                    â”‚
â”‚  PHASE 7 : RAPPORT (1 heure)                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚
â”‚  â–¡ SynthÃ¨se rÃ©sultats                              â”‚
â”‚  â–¡ Graphiques comparatifs                          â”‚
â”‚  â–¡ Recommandations                                 â”‚
â”‚  â–¡ Archivage documentation                         â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©triques critiques

### MÃ©triques de throughput

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰TRIQUES DE DÃ‰BIT (Throughput)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  TPS (Transactions Per Second)                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ Nombre de transactions complÃ¨tes/sec            â”‚
â”‚  â€¢ MÃ©trique principale pour OLTP                   â”‚
â”‚  â€¢ Plus Ã©levÃ© = meilleur                           â”‚
â”‚  â€¢ Exemple : 5,000 TPS â†’ 10,000 TPS = +100%        â”‚
â”‚                                                    â”‚
â”‚  QPS (Queries Per Second)                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  â€¢ Nombre de requÃªtes SQL/sec                      â”‚
â”‚  â€¢ Inclut SELECT, INSERT, UPDATE, DELETE           â”‚
â”‚  â€¢ Exemple : 50,000 QPS                            â”‚
â”‚                                                    â”‚
â”‚  Reads/sec et Writes/sec                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â€¢ DÃ©bit lecture et Ã©criture sÃ©parÃ©s               â”‚
â”‚  â€¢ Identifier workload read-heavy vs write-heavy   â”‚
â”‚  â€¢ Exemple : 80,000 reads/sec, 5,000 writes/sec    â”‚
â”‚                                                    â”‚
â”‚  MB/sec (I/O throughput)                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  â€¢ Volume de donnÃ©es transferÃ©es                   â”‚
â”‚  â€¢ Identifier saturation I/O                       â”‚
â”‚  â€¢ Exemple : 500 MB/sec reads                      â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©triques de latence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰TRIQUES DE LATENCE (Response Time)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Latence moyenne (Average)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â€¢ Temps moyen d'exÃ©cution requÃªte                 â”‚
â”‚  â€¢ Indicateur gÃ©nÃ©ral                              â”‚
â”‚  â€¢ âš ï¸ Peut masquer outliers                        â”‚
â”‚                                                    â”‚
â”‚  Latence mÃ©diane (p50)                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  â€¢ 50% des requÃªtes plus rapides                   â”‚
â”‚  â€¢ ExpÃ©rience utilisateur "typique"                â”‚
â”‚  â€¢ Moins sensible aux outliers                     â”‚
â”‚                                                    â”‚
â”‚  Latence p95, p99, p999                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â€¢ 95%, 99%, 99.9% des requÃªtes                    â”‚
â”‚  â€¢ CRITIQUES pour SLA                              â”‚
â”‚  â€¢ DÃ©tecte problÃ¨mes ponctuels                     â”‚
â”‚  â€¢ Exemple :                                       â”‚
â”‚    p50 = 5ms (bon)                                 â”‚
â”‚    p95 = 50ms (acceptable)                         â”‚
â”‚    p99 = 500ms (problÃ¨me!)                         â”‚
â”‚                                                    â”‚
â”‚  Latence max                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  â€¢ Pire cas observÃ©                                â”‚
â”‚  â€¢ Outlier extrÃªme                                 â”‚
â”‚  â€¢ Moins utile car peut Ãªtre anomalie              â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Visualisation** :

```
Distribution de latence (exemple) :

Percentile  |  Latency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
p0   (min)  |  1ms     â–ˆâ–ˆâ–ˆâ–ˆ
p25         |  3ms     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
p50  (med)  |  5ms     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
p75         |  8ms     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
p90         |  12ms    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
p95         |  15ms    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
p99         |  50ms    â–ˆâ–ˆ
p99.9       |  200ms   â–ˆ
p100 (max)  |  5000ms  (outlier)

Important : p95-p99 pour SLA !
```

### MÃ©triques systÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MÃ‰TRIQUES SYSTÃˆME                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  CPU                                               â”‚
â”‚  â”€â”€â”€                                               â”‚
â”‚  â€¢ Utilisation % (user, system, iowait)            â”‚
â”‚  â€¢ Load average (1min, 5min, 15min)                â”‚
â”‚  â€¢ Context switches                                â”‚
â”‚  â€¢ Cible : <80% utilisation, pas de saturation     â”‚
â”‚                                                    â”‚
â”‚  MÃ©moire                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  â€¢ RAM utilisÃ©e / totale                           â”‚
â”‚  â€¢ Buffer pool hit rate (>99% cible)               â”‚
â”‚  â€¢ Swap utilisation (0 idÃ©al)                      â”‚
â”‚  â€¢ Page faults                                     â”‚
â”‚                                                    â”‚
â”‚  I/O Disque                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  â€¢ IOPS (read, write)                              â”‚
â”‚  â€¢ MB/sec throughput                               â”‚
â”‚  â€¢ Latency (await, svctm)                          â”‚
â”‚  â€¢ %util (< 90% recommandÃ©)                        â”‚
â”‚  â€¢ Queue depth                                     â”‚
â”‚                                                    â”‚
â”‚  RÃ©seau                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  â€¢ Bytes in/out                                    â”‚
â”‚  â€¢ Packets in/out                                  â”‚
â”‚  â€¢ Errors, drops                                   â”‚
â”‚  â€¢ Saturation liens                                â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©triques MariaDB internes

```sql
-- MÃ©triques critiques MariaDB

-- Threads
SHOW STATUS LIKE 'Threads_connected';
SHOW STATUS LIKE 'Threads_running';
SHOW STATUS LIKE 'Max_used_connections';

-- Queries
SHOW STATUS LIKE 'Questions';  -- Total queries
SHOW STATUS LIKE 'Queries';    -- Total + COM_* commands
SHOW STATUS LIKE 'Slow_queries';

-- InnoDB Buffer Pool
SHOW STATUS LIKE 'Innodb_buffer_pool_read_requests';
SHOW STATUS LIKE 'Innodb_buffer_pool_reads';  -- Disk reads
-- Hit rate = (requests - reads) / requests * 100

-- InnoDB I/O
SHOW STATUS LIKE 'Innodb_data_reads';
SHOW STATUS LIKE 'Innodb_data_writes';
SHOW STATUS LIKE 'Innodb_data_fsyncs';

-- Locks
SHOW STATUS LIKE 'Innodb_row_lock_waits';
SHOW STATUS LIKE 'Innodb_row_lock_time_avg';
```

---

## Vue d'ensemble des outils

### Classification des outils

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTILS DE BENCHMARKING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  BENCHMARKS SYNTHÃ‰TIQUES                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â€¢ sysbench â­                                     â”‚
â”‚    - Standard industrie                            â”‚
â”‚    - OLTP, I/O, CPU tests                          â”‚
â”‚    - TrÃ¨s configurable                             â”‚
â”‚                                                    â”‚
â”‚  â€¢ mysqlslap                                       â”‚
â”‚    - IntÃ©grÃ© Ã  MariaDB                             â”‚
â”‚    - Simple et rapide                              â”‚
â”‚    - Moins puissant que sysbench                   â”‚
â”‚                                                    â”‚
â”‚  â€¢ TPC-C, TPC-H                                    â”‚
â”‚    - Standards industrie                           â”‚
â”‚    - Complexes Ã  mettre en place                   â”‚
â”‚    - Comparaisons officielles                      â”‚
â”‚                                                    â”‚
â”‚  BENCHMARKS APPLICATIFS                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â€¢ pt-query-digest (Percona)                       â”‚
â”‚    - Analyse slow query log                        â”‚
â”‚    - Replay queries                                â”‚
â”‚                                                    â”‚
â”‚  â€¢ Apache JMeter                                   â”‚
â”‚    - Tests de charge HTTP                          â”‚
â”‚    - Scripts complexes                             â”‚
â”‚                                                    â”‚
â”‚  â€¢ Gatling                                         â”‚
â”‚    - Tests de charge modernes                      â”‚
â”‚    - DSL Scala                                     â”‚
â”‚                                                    â”‚
â”‚  MONITORING                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  â€¢ PMM (Percona Monitoring)                        â”‚
â”‚    - Dashboards temps rÃ©el                         â”‚
â”‚    - Historique long terme                         â”‚
â”‚                                                    â”‚
â”‚  â€¢ Grafana + Prometheus                            â”‚
â”‚    - Visualisation mÃ©triques                       â”‚
â”‚    - Alerting                                      â”‚
â”‚                                                    â”‚
â”‚  PROFILING                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  â€¢ perf (Linux)                                    â”‚
â”‚    - CPU profiling                                 â”‚
â”‚    - Flamegraphs                                   â”‚
â”‚                                                    â”‚
â”‚  â€¢ iotop, iostat                                   â”‚
â”‚    - I/O monitoring                                â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## InterprÃ©tation des rÃ©sultats

### Analyse statistique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ANALYSE STATISTIQUE DES RÃ‰SULTATS                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Exemple : Test buffer pool 50% vs 75%             â”‚
â”‚                                                    â”‚
â”‚  Configuration A (50% RAM) - 3 runs :              â”‚
â”‚  Run 1 : 8,234 TPS                                 â”‚
â”‚  Run 2 : 8,156 TPS                                 â”‚
â”‚  Run 3 : 8,301 TPS                                 â”‚
â”‚  Moyenne : 8,230 TPS                               â”‚
â”‚  Ã‰cart-type : 72.5 TPS (0.88%)                     â”‚
â”‚                                                    â”‚
â”‚  Configuration B (75% RAM) - 3 runs :              â”‚
â”‚  Run 1 : 10,523 TPS                                â”‚
â”‚  Run 2 : 10,489 TPS                                â”‚
â”‚  Run 3 : 10,556 TPS                                â”‚
â”‚  Moyenne : 10,523 TPS                              â”‚
â”‚  Ã‰cart-type : 33.5 TPS (0.32%)                     â”‚
â”‚                                                    â”‚
â”‚  AmÃ©lioration :                                    â”‚
â”‚  (10,523 - 8,230) / 8,230 Ã— 100 = +27.9%           â”‚
â”‚                                                    â”‚
â”‚  SignificativitÃ© :                                 â”‚
â”‚  DiffÃ©rence : 2,293 TPS                            â”‚
â”‚  Ã‰cart-types combinÃ©s : âˆš(72.5Â² + 33.5Â²) = 80      â”‚
â”‚  Ratio : 2,293 / 80 = 28.7                         â”‚
â”‚  â†’ TrÃ¨s significatif (ratio >> 2)                  â”‚
â”‚                                                    â”‚
â”‚  Conclusion :                                      â”‚
â”‚  âœ… AmÃ©lioration rÃ©elle de ~28%                    â”‚
â”‚  âœ… Statistiquement significative                  â”‚
â”‚  âœ… RÃ©sultats rÃ©pÃ©tables (faible Ã©cart-type)       â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ¨gle de significativitÃ©

```
DiffÃ©rence significative si :

1. Ã‰cart-type < 5% de la moyenne
   â†’ RÃ©sultats stables

2. AmÃ©lioration > 2 Ã— Ã©cart-type
   â†’ Changement rÃ©el, pas alÃ©atoire

3. Minimum 3 runs
   â†’ Confiance statistique

Exemple :
Moyenne A : 1000 TPS Â± 50 (5%)
Moyenne B : 1200 TPS Â± 40 (3.3%)
DiffÃ©rence : 200 TPS
2 Ã— Ã©cart-types : 2 Ã— âˆš(50Â² + 40Â²) = 128
200 > 128 â†’ SIGNIFICATIF âœ…
```

### Identification des bottlenecks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IDENTIFIER LE BOTTLENECK                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  CPU-bound :                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  â€¢ CPU utilisation > 80%                           â”‚
â”‚  â€¢ iowait < 10%                                    â”‚
â”‚  â€¢ Disk %util < 50%                                â”‚
â”‚  â†’ Solution : Plus de CPU cores ou optimiser queries
â”‚                                                    â”‚
â”‚  I/O-bound :                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚  â€¢ iowait > 20%                                    â”‚
â”‚  â€¢ Disk %util > 80%                                â”‚
â”‚  â€¢ CPU idle > 40%                                  â”‚
â”‚  â†’ Solution : SSD/NVMe, plus d'IOPS                â”‚
â”‚                                                    â”‚
â”‚  Memory-bound :                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  â€¢ Buffer pool hit rate < 95%                      â”‚
â”‚  â€¢ Swap utilisation > 0                            â”‚
â”‚  â€¢ Page faults Ã©levÃ©s                              â”‚
â”‚  â†’ Solution : Plus de RAM                          â”‚
â”‚                                                    â”‚
â”‚  Lock contention :                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  â€¢ Innodb_row_lock_waits Ã©levÃ©                     â”‚
â”‚  â€¢ Threads_running << Threads_connected            â”‚
â”‚  â€¢ CPU faible mais TPS faible                      â”‚
â”‚  â†’ Solution : Optimiser transactions, partitioning â”‚
â”‚                                                    â”‚
â”‚  Network-bound :                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  â€¢ Bytes_sent/received proche limite rÃ©seau        â”‚
â”‚  â€¢ Retransmissions TCP Ã©levÃ©es                     â”‚
â”‚  â†’ Solution : Optimiser queries, compression       â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## PiÃ¨ges courants Ã  Ã©viter

### Les 10 erreurs frÃ©quentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIÃˆGES Ã€ Ã‰VITER                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. âŒ Pas de warmup                               â”‚
â”‚     âœ… Toujours warmer 5-10 minutes                â”‚
â”‚                                                    â”‚
â”‚  2. âŒ Test trop court (<5 min)                    â”‚
â”‚     âœ… Minimum 30 minutes                          â”‚
â”‚                                                    â”‚
â”‚  3. âŒ Un seul run                                 â”‚
â”‚     âœ… 3-5 runs minimum                            â”‚
â”‚                                                    â”‚
â”‚  4. âŒ Environnement diffÃ©rent                     â”‚
â”‚     âœ… Exact mÃªme setup pour comparaison           â”‚
â”‚                                                    â”‚
â”‚  5. âŒ Multiples changements simultanÃ©s            â”‚
â”‚     âœ… Un paramÃ¨tre Ã  la fois                      â”‚
â”‚                                                    â”‚
â”‚  6. âŒ Jeu de donnÃ©es trop petit                   â”‚
â”‚     âœ… > 2x RAM pour Ã©viter cache complet          â”‚
â”‚                                                    â”‚
â”‚  7. âŒ Ignorer mÃ©triques systÃ¨me                   â”‚
â”‚     âœ… Toujours monitorer CPU, I/O, RAM            â”‚
â”‚                                                    â”‚
â”‚  8. âŒ Comparer versions diffÃ©rentes               â”‚
â”‚     âœ… MÃªme version MariaDB/OS pour comparaison    â”‚
â”‚                                                    â”‚
â”‚  9. âŒ NÃ©gliger variance                           â”‚
â”‚     âœ… Calculer Ã©cart-type, vÃ©rifier rÃ©pÃ©tabilitÃ©  â”‚
â”‚                                                    â”‚
â”‚  10. âŒ Pas de documentation                       â”‚
â”‚      âœ… Tout documenter (config, commandes)        â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemple d'erreur classique

```
âŒ MAUVAIS BENCHMARK :

# Test 1 : Configuration A
sysbench oltp_read_only ... run  # 1 minute
# RÃ©sultat : 5000 TPS

# Changer buffer pool size
# RedÃ©marrer MariaDB

# Test 2 : Configuration B
sysbench oltp_read_only ... run  # 1 minute
# RÃ©sultat : 8000 TPS

# Conclusion : +60% de gain ! ğŸ‰

PROBLÃˆMES :
â€¢ Pas de warmup aprÃ¨s redÃ©marrage (cache froid)
â€¢ Un seul run (pas de variance)
â€¢ Test trop court (1 min)
â€¢ Pas de mÃ©triques systÃ¨me vÃ©rifiÃ©es
â†’ RÃ©sultats NON fiables


âœ… BON BENCHMARK :

# Test 1 : Configuration A
# RedÃ©marrer MariaDB
sysbench ... prepare
sysbench ... warmup --time=600  # 10 min warmup
sysbench ... run --time=3600    # 1h run (1/3)
# Nettoyer et rÃ©pÃ©ter 2 fois
# Moyenne de 3 runs : 5,234 TPS Â± 123

# Test 2 : Configuration B  
# RedÃ©marrer MariaDB
sysbench ... warmup --time=600
sysbench ... run --time=3600    # 1h run (1/3)
# RÃ©pÃ©ter 2 fois
# Moyenne de 3 runs : 5,456 TPS Â± 98

# AmÃ©lioration : (5456 - 5234) / 5234 = +4.2%
# Ã‰cart-type combinÃ© : 154
# DiffÃ©rence / Ã©cart : 222 / 154 = 1.44
â†’ AmÃ©lioration MARGINALE, peu significative
â†’ Autre facteur Ã  optimiser prioritaire
```

---

## Documentation et rapports

### Template de rapport

```markdown
# Benchmark Report

## Objectif
Comparer performances MariaDB 11.7 vs 11.8 (cost optimizer SSD)

## Configuration
**Hardware :**
- CPU : Intel Xeon E5-2680 v4 (28 cores, 56 threads)
- RAM : 256 GB DDR4
- Stockage : NVMe Gen3 Samsung 980 Pro (2 TB)
- RÃ©seau : 10 Gbps

**Software :**
- OS : Ubuntu 22.04 LTS
- MariaDB A : 11.7.1
- MariaDB B : 11.8.0
- Kernel : 5.15.0

**Dataset :**
- Tables : 10 tables
- Lignes par table : 10M
- Taille totale : 80 GB
- Distribution : TPC-C like

## MÃ©thodologie
- Outil : sysbench 1.0.20
- Test : oltp_read_write
- Threads : 64
- Warmup : 10 minutes
- DurÃ©e test : 60 minutes
- Runs : 3 par configuration

## RÃ©sultats

### Configuration A (MariaDB 11.7.1)
Run 1 : 12,456 TPS
Run 2 : 12,389 TPS
Run 3 : 12,501 TPS
**Moyenne : 12,449 TPS Â± 56 (0.45%)**

### Configuration B (MariaDB 11.8.0)
Run 1 : 13,234 TPS
Run 2 : 13,189 TPS
Run 3 : 13,267 TPS
**Moyenne : 13,230 TPS Â± 39 (0.29%)**

### AmÃ©lioration
**+6.3%** (781 TPS)
Statistiquement significatif (> 2Ïƒ)

## MÃ©triques secondaires

| Metric          | 11.7   | 11.8   | Diff   |
|-----------------|--------|--------|--------|
| Latency p95     | 8.2ms  | 7.6ms  | -7.3%  |
| Latency p99     | 15.3ms | 14.1ms | -7.8%  |
| CPU %           | 72%    | 68%    | -5.6%  |
| BP hit rate     | 99.2%  | 99.3%  | +0.1%  |

## Analyse
Le cost optimizer amÃ©liorÃ© de 11.8 rÃ©duit le nombre de full scans
sur SSD, rÃ©sultant en :
- Throughput supÃ©rieur (+6.3%)
- Latence rÃ©duite (~7% sur p95/p99)
- CPU lÃ©gÃ¨rement moins sollicitÃ©

## Recommandation
âœ… Migration vers 11.8 recommandÃ©e
Gain de performance significatif sans risque identifiÃ©

## Annexes
- Configuration complÃ¨te : config_11.7.cnf, config_11.8.cnf
- Logs complets : benchmark_11.7.log, benchmark_11.8.log
- Graphiques : graphs/
```

---

## âœ… Points clÃ©s Ã  retenir

- ğŸ“Š **Mesurer = amÃ©liorer** : Sans benchmark, optimisation aveugle
- ğŸ¯ **3 types** : SynthÃ©tique, applicatif, stress
- ğŸ“ **MÃ©thodologie rigoureuse** : 7 rÃ¨gles d'or Ã  respecter
- ğŸ”¢ **MÃ©triques multiples** : TPS, latence (p95/p99), systÃ¨me
- ğŸ”„ **RÃ©pÃ©tabilitÃ©** : 3-5 runs minimum, Ã©cart-type <5%
- â±ï¸ **Warmup essentiel** : 5-10 min avant mesure
- ğŸ“ˆ **Analyse statistique** : VÃ©rifier significativitÃ©
- ğŸ›ï¸ **Un changement Ã  la fois** : Isolation des variables
- ğŸ“ **Documentation** : Tout documenter pour reproductibilitÃ©
- âš ï¸ **Ã‰viter piÃ¨ges** : Test trop court, pas de warmup, un seul run

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Documentation officielle

- [ğŸ“– MariaDB Performance Tuning](https://mariadb.com/kb/en/optimization-and-tuning/)
- [ğŸ“– InnoDB Performance](https://mariadb.com/kb/en/innodb-performance/)

### Outils

- [sysbench](https://github.com/akopytov/sysbench)
- [Percona Toolkit](https://www.percona.com/software/database-tools/percona-toolkit)
- [MySQL Performance Blog](https://www.percona.com/blog/)

### Standards industrie

- [TPC Benchmarks](http://www.tpc.org/)

---

## â¡ï¸ Sections suivantes

Les sections suivantes dÃ©taillent chaque outil de benchmarking :

### **Section 15.12.1** : [sysbench](/15-performance-tuning/12.1-sysbench.md)
*Outil de rÃ©fÃ©rence pour benchmarks synthÃ©tiques. Configuration, tests OLTP/I/O, interprÃ©tation.*

### **Section 15.12.2** : [mysqlslap](/15-performance-tuning/12.2-mysqlslap.md)
*Outil natif MariaDB pour tests rapides. GÃ©nÃ©ration de charge, comparaisons simples.*


---

*"Premature optimization is the root of all evil, but informed optimization based on solid benchmarks is the path to performance heaven."*

â­ï¸ [sysbench](/15-performance-tuning/12.1-sysbench.md)
