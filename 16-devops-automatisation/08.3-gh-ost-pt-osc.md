üîù Retour au [Sommaire](/SOMMAIRE.md)

# 16.8.3 gh-ost et pt-online-schema-change - Migrations sans downtime

> **Niveau** : Avanc√© √† Expert  
> **Dur√©e estim√©e** : 4-5 heures  
> **Pr√©requis** : Sections 16.8.1-16.8.2, SQL avanc√©, R√©plication MariaDB, Kubernetes, Monitoring

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre pourquoi ALTER TABLE bloque sur les grosses tables et comment √©viter le downtime
- Utiliser gh-ost (GitHub) pour des migrations online sans triggers
- Impl√©menter pt-online-schema-change (Percona) pour ALTER TABLE non-bloquants
- Comparer gh-ost et pt-osc et choisir l'outil appropri√© selon le contexte
- Int√©grer ces outils dans des pipelines CI/CD pour d√©ploiements automatis√©s
- Orchestrer les migrations online dans Kubernetes avec Jobs et CronJobs
- Monitorer les migrations en temps r√©el avec m√©triques Prometheus
- G√©rer les rollbacks et r√©cup√©rations en cas d'√©chec
- Optimiser les performances de migration sur tables de plusieurs t√©raoctets

---

## Introduction : Le probl√®me des migrations sur grosses tables

### Pourquoi ALTER TABLE est probl√©matique ?

Sur MariaDB/MySQL, un `ALTER TABLE` classique sur une grosse table peut :

1. **Bloquer les lectures/√©critures** pendant des heures
2. **Cr√©er une copie compl√®te** de la table (consommation disque √ó 2)
3. **Verrouiller** toutes les op√©rations DML (INSERT, UPDATE, DELETE)
4. **Impacter la r√©plication** avec un lag croissant
5. **Risquer un timeout** et un rollback partiel

**Exemple probl√©matique :**
```sql
-- Table users avec 500M rows (2TB)
ALTER TABLE users ADD COLUMN phone VARCHAR(20);

-- R√©sultat :
-- ‚ùå Dur√©e : 6-8 heures
-- ‚ùå Lock exclusif : Writes bloqu√©es pendant toute la migration
-- ‚ùå Espace disque : 2TB temporaires suppl√©mentaires
-- ‚ùå R√©plication lag : Plusieurs heures
```

### Solution : Online Schema Change (OSC)

Les outils OSC permettent des migrations **sans downtime** en :

1. **Cr√©ant une table fant√¥me** (ghost table) avec la nouvelle structure
2. **Copiant les donn√©es** par petits lots (chunks) sans lock
3. **Capturant les changements** pendant la migration (via triggers ou binlog)
4. **Switchant atomiquement** vers la nouvelle table
5. **Nettoyant** les tables temporaires

### Comparaison des outils

| Crit√®re | gh-ost | pt-online-schema-change | ALTER TABLE INPLACE |
|---------|--------|-------------------------|---------------------|
| **Lock write** | Minimal (swap final) | Minimal (swap final) | Complet ou partiel |
| **Triggers** | ‚ùå Non (binlog) | ‚úÖ Oui (3 triggers) | N/A |
| **Overhead** | Faible | Moyen | Faible |
| **Pause/Resume** | ‚úÖ Oui | ‚úÖ Oui | ‚ùå Non |
| **Rollback** | ‚úÖ Facile | ‚ö†Ô∏è Complexe | ‚ùå Non |
| **Monitoring** | ‚úÖ Excellent | ‚ö†Ô∏è Basique | ‚ùå Minimal |
| **R√©plication** | ‚úÖ Supporte | ‚úÖ Supporte | ‚úÖ Supporte |
| **Taille max** | Plusieurs TB | Plusieurs TB | Limit√© |

üí° **Conseil** : Utilisez gh-ost pour les migrations critiques en production n√©cessitant un contr√¥le fin. Utilisez pt-osc pour les migrations plus simples o√π les triggers sont acceptables.

---

## gh-ost : GitHub's Online Schema Migrations

### Architecture et fonctionnement

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    gh-ost Architecture                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Original Table: users                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ  ‚îÇ id ‚îÇ name ‚îÇ email ‚îÇ created_at       ‚îÇ                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                   ‚îÇ
‚îÇ  ‚îÇ 1  ‚îÇ Alice‚îÇ a@... ‚îÇ 2024-01-01       ‚îÇ ‚óÑ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ 2  ‚îÇ Bob  ‚îÇ b@... ‚îÇ 2024-01-02       ‚îÇ    ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ... ‚îÇ ...  ‚îÇ ...   ‚îÇ ...              ‚îÇ    ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ              ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ              ‚îÇ
‚îÇ                    ‚îÇ Binlog Stream           ‚îÇ              ‚îÇ
‚îÇ                    ‚îÇ (INSERT/UPDATE/DELETE)  ‚îÇ              ‚îÇ
‚îÇ                    ‚ñº                         ‚îÇ              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ        gh-ost Process           ‚îÇ         ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  1. Copy Rows (chunks)  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ                        ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ                        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  2. Apply Binlog Events ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  3. Throttle & Monitor  ‚îÇ    ‚îÇ  ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                   ‚îÇ                    ‚îÇ
‚îÇ                    ‚ñº                   ‚ñº                    ‚îÇ
‚îÇ  Ghost Table: _users_gho               ‚îÇ                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ id ‚îÇ name ‚îÇ email ‚îÇ phone ‚îÇ created_at   ‚îÇ               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§               ‚îÇ
‚îÇ  ‚îÇ 1  ‚îÇ Alice‚îÇ a@... ‚îÇ NULL  ‚îÇ 2024-01-01   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îÇ 2  ‚îÇ Bob  ‚îÇ b@... ‚îÇ NULL  ‚îÇ 2024-01-02   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ... ‚îÇ ...  ‚îÇ ...   ‚îÇ ...   ‚îÇ ...          ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                    ‚îÇ                                        ‚îÇ
‚îÇ                    ‚îÇ RENAME TABLE (atomic swap)             ‚îÇ
‚îÇ                    ‚ñº                                        ‚îÇ
‚îÇ  Final: users (with new schema)                             ‚îÇ
‚îÇ  Old Table: _users_del (dropped after)                      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Avantages de gh-ost

1. **Sans triggers** : Lecture du binlog au lieu de triggers DML (moins de overhead)
2. **Testable** : Migration sur un replica avant production
3. **Pausable** : Pause/resume sans perdre la progression
4. **Throttle dynamique** : Ralentit si charge √©lev√©e d√©tect√©e
5. **Cut-over contr√¥l√©** : Choix du moment exact du swap final
6. **Rollback facile** : Annulation possible avant le cut-over

### Installation gh-ost

**Binaire pr√©compil√© (recommand√©) :**
```bash
# Linux x64
wget https://github.com/github/gh-ost/releases/download/v1.1.6/gh-ost-binary-linux-amd64-20231207144046.tar.gz
tar -xzf gh-ost-binary-linux-amd64-20231207144046.tar.gz
sudo mv gh-ost /usr/local/bin/
sudo chmod +x /usr/local/bin/gh-ost

# V√©rifier
gh-ost --version
# gh-ost v1.1.6
```

**Docker :**
```bash
docker pull ghcr.io/github/gh-ost:latest

# Alias
alias gh-ost='docker run --rm -v $(pwd):/work ghcr.io/github/gh-ost:latest'
```

**Compilation depuis source :**
```bash
# Installer Go 1.21+
go install github.com/github/gh-ost/go/cmd/gh-ost@latest
```

### Configuration MariaDB pour gh-ost

```ini
# my.cnf - Configuration requise pour gh-ost

[mariadb]
# Binlog obligatoire (format ROW)
server-id = 1
log-bin = mariadb-bin
binlog-format = ROW
binlog-row-image = FULL

# Performance
innodb-buffer-pool-size = 16G
innodb-log-file-size = 2G

# Important pour gh-ost
# Max packet size pour grosses rows
max-allowed-packet = 256M

# Timeout
wait-timeout = 28800
interactive-timeout = 28800
```

**Permissions utilisateur :**
```sql
-- Cr√©er utilisateur gh-ost
CREATE USER 'ghost'@'%' IDENTIFIED BY 'SecureGhostPassword123!';

-- Permissions n√©cessaires
GRANT SELECT, INSERT, UPDATE, DELETE, 
      ALTER, CREATE, DROP, INDEX, 
      TRIGGER, LOCK TABLES, REPLICATION SLAVE, 
      REPLICATION CLIENT, SUPER 
ON *.* TO 'ghost'@'%';

-- Ou au minimum sur la base cible
GRANT ALL PRIVILEGES ON myapp_production.* TO 'ghost'@'%';

FLUSH PRIVILEGES;
```

### Migration basique avec gh-ost

**Exemple 1 : Ajout d'une colonne**

```bash
#!/bin/bash
# add-phone-column.sh

gh-ost \
  --host=mariadb-primary.production.svc.cluster.local \
  --port=3306 \
  --user="ghost" \
  --password="SecureGhostPassword123!" \
  --database="myapp_production" \
  --table="users" \
  --alter="ADD COLUMN phone VARCHAR(20) AFTER email, ADD COLUMN phone_verified BOOLEAN DEFAULT FALSE" \
  --execute \
  --allow-on-master \
  --chunk-size=1000 \
  --max-load=Threads_running=25 \
  --critical-load=Threads_running=100 \
  --default-retries=120 \
  --panic-flag-file=/tmp/ghost-panic.flag \
  --postpone-cut-over-flag-file=/tmp/ghost-postpone.flag \
  --throttle-control-replicas="mariadb-replica-0:3306,mariadb-replica-1:3306" \
  --verbose
```

**Param√®tres expliqu√©s :**

| Param√®tre | Description |
|-----------|-------------|
| `--host`, `--port`, `--user`, `--password` | Connexion MariaDB |
| `--database`, `--table` | Table cible |
| `--alter` | ALTER TABLE √† appliquer (sans `ALTER TABLE users`) |
| `--execute` | Ex√©cuter (sans = dry-run) |
| `--allow-on-master` | Autoriser sur le Primary (vs replica) |
| `--chunk-size` | Taille des lots de copie (rows) |
| `--max-load` | Seuil de throttle (ralentir si d√©pass√©) |
| `--critical-load` | Seuil critique (pause si d√©pass√©) |
| `--panic-flag-file` | Fichier flag pour abort imm√©diat |
| `--postpone-cut-over-flag-file` | Retarder le swap final |
| `--throttle-control-replicas` | Surveiller le lag des replicas |

**Exemple 2 : Changement de type de colonne**

```bash
gh-ost \
  --host=mariadb-primary \
  --user="ghost" \
  --password="${GHOST_PASSWORD}" \
  --database="myapp_production" \
  --table="orders" \
  --alter="MODIFY COLUMN total_amount DECIMAL(12,2)" \
  --initially-drop-ghost-table \
  --initially-drop-old-table \
  --ok-to-drop-table \
  --execute \
  --allow-on-master \
  --chunk-size=500 \
  --max-load=Threads_running=30,Threads_connected=500 \
  --critical-load=Threads_running=150,Threads_connected=1000 \
  --exact-rowcount \
  --serve-tcp-port=9999
```

**Monitoring en temps r√©el :**

gh-ost expose des statistiques sur un port TCP :

```bash
# Connexion au port de monitoring
echo "status" | nc localhost 9999

# Output :
# Copy: 42500000/100000000 42.5%; Applied: 1234567; ETA: 2h15m
# Lag: 0.5s; State: migrating; Load: Threads_running=12
```

**Contr√¥le dynamique :**

```bash
# Pause la migration
echo "throttle" | nc localhost 9999

# Resume
echo "no-throttle" | nc localhost 9999

# Forcer le cut-over maintenant
rm -f /tmp/ghost-postpone.flag
echo "unpostpone" | nc localhost 9999

# Abort (panic)
touch /tmp/ghost-panic.flag
```

### Migration sur replica puis promotion

**Strat√©gie la plus s√ªre en production :**

```bash
#!/bin/bash
# migrate-on-replica.sh

# 1. Migrer sur un replica (test)
gh-ost \
  --host=mariadb-replica-2 \
  --user="ghost" \
  --password="${GHOST_PASSWORD}" \
  --database="myapp_production" \
  --table="users" \
  --alter="ADD COLUMN address TEXT AFTER email" \
  --test-on-replica \
  --execute \
  --chunk-size=1000 \
  --max-load=Threads_running=20 \
  --verbose

# 2. Si succ√®s sur replica, ex√©cuter sur le primary
if [ $? -eq 0 ]; then
  echo "‚úÖ Test r√©ussi sur replica. Lancement sur primary..."
  
  gh-ost \
    --host=mariadb-primary \
    --user="ghost" \
    --password="${GHOST_PASSWORD}" \
    --database="myapp_production" \
    --table="users" \
    --alter="ADD COLUMN address TEXT AFTER email" \
    --execute \
    --allow-on-master \
    --chunk-size=1000 \
    --max-load=Threads_running=25 \
    --critical-load=Threads_running=100 \
    --throttle-control-replicas="mariadb-replica-0:3306,mariadb-replica-1:3306" \
    --postpone-cut-over-flag-file=/tmp/ghost-postpone \
    --verbose
  
  # 3. Cut-over lors d'une fen√™tre de maintenance
  echo "Attente fen√™tre de maintenance pour cut-over..."
  # (Manuellement : rm /tmp/ghost-postpone quand pr√™t)
else
  echo "‚ùå √âchec sur replica. Migration annul√©e."
  exit 1
fi
```

---

## pt-online-schema-change : Percona Toolkit

### Architecture et fonctionnement

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           pt-online-schema-change Architecture             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ  Original Table: products                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ id ‚îÇ name ‚îÇ price ‚îÇ created_at       ‚îÇ                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ
‚îÇ  ‚îÇ 1  ‚îÇ Item1‚îÇ 9.99  ‚îÇ 2024-01-01       ‚îÇ ‚óÑ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ 2  ‚îÇ Item2‚îÇ 19.99 ‚îÇ 2024-01-02       ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ... ‚îÇ ...  ‚îÇ ...   ‚îÇ ...              ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ             ‚îÇ
‚îÇ         ‚îÇ                                    ‚îÇ             ‚îÇ
‚îÇ         ‚îÇ Triggers (INSERT/UPDATE/DELETE)    ‚îÇ             ‚îÇ
‚îÇ         ‚îÇ                                    ‚îÇ             ‚îÇ
‚îÇ         ‚ñº                                    ‚îÇ             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ   Triggers on Original Table    ‚îÇ         ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ pt_osc_ins_trigger      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§             ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ pt_osc_upd_trigger      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§             ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ pt_osc_del_trigger      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§             ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ             ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ             ‚îÇ
‚îÇ                    ‚ñº                         ‚îÇ             ‚îÇ
‚îÇ  New Table: _products_new                    ‚îÇ             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ id ‚îÇ name ‚îÇ price ‚îÇ discount ‚îÇ created_at    ‚îÇ          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§          ‚îÇ
‚îÇ  ‚îÇ 1  ‚îÇ Item1‚îÇ 9.99  ‚îÇ NULL     ‚îÇ 2024-01-01    ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îÇ 2  ‚îÇ Item2‚îÇ 19.99 ‚îÇ NULL     ‚îÇ 2024-01-02    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ... ‚îÇ ...  ‚îÇ ...   ‚îÇ ...      ‚îÇ ...           ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ         ‚îÇ                                                  ‚îÇ
‚îÇ         ‚îÇ pt-osc copies rows in chunks                     ‚îÇ
‚îÇ         ‚ñº                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ  ‚îÇ  pt-online-schema-change        ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  1. Create _products_new        ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  2. Create triggers             ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  3. Copy data in chunks         ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  4. Swap tables (RENAME)        ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  5. Drop old table & triggers   ‚îÇ                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Installation pt-online-schema-change

**Via package manager (recommand√©) :**
```bash
# Debian/Ubuntu
sudo apt-get update
sudo apt-get install percona-toolkit

# RHEL/CentOS
sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm
sudo yum install percona-toolkit

# V√©rifier
pt-online-schema-change --version
# pt-online-schema-change 3.5.7
```

**Via CPAN (si binaire non disponible) :**
```bash
sudo cpan DBD::mysql
sudo cpan Percona::Toolkit
```

**Docker :**
```bash
docker pull perconalab/percona-toolkit:latest

alias pt-osc='docker run --rm -v $(pwd):/work perconalab/percona-toolkit:latest pt-online-schema-change'
```

### Configuration MariaDB pour pt-osc

```ini
# my.cnf - Configuration pour pt-online-schema-change

[mariadb]
# Binlog (optionnel mais recommand√©)
server-id = 1
log-bin = mariadb-bin
binlog-format = ROW

# Permettre les ALTER sur r√©pliques
read-only = 0  # Sur Primary uniquement

# Taille max des packets pour grosses rows
max-allowed-packet = 256M
```

**Permissions utilisateur :**
```sql
CREATE USER 'pt_osc'@'%' IDENTIFIED BY 'SecurePtOscPassword123!';

GRANT SELECT, INSERT, UPDATE, DELETE, 
      CREATE, DROP, ALTER, INDEX, 
      TRIGGER, LOCK TABLES, PROCESS, REPLICATION SLAVE
ON *.* TO 'pt_osc'@'%';

FLUSH PRIVILEGES;
```

### Migration basique avec pt-osc

**Exemple 1 : Ajout d'index**

```bash
#!/bin/bash
# add-index-pt-osc.sh

pt-online-schema-change \
  --host=mariadb-primary \
  --port=3306 \
  --user=pt_osc \
  --password=SecurePtOscPassword123! \
  --alter="ADD INDEX idx_email (email)" \
  D=myapp_production,t=users \
  --execute \
  --chunk-size=1000 \
  --chunk-time=0.5 \
  --max-lag=5 \
  --check-slave-lag=mariadb-replica-0:3306,mariadb-replica-1:3306 \
  --progress=time,30 \
  --print \
  --statistics
```

**Param√®tres expliqu√©s :**

| Param√®tre | Description |
|-----------|-------------|
| `D=database,t=table` | Base et table cible |
| `--alter` | ALTER TABLE √† appliquer |
| `--execute` | Ex√©cuter (sans = dry-run) |
| `--chunk-size` | Nombre de rows par chunk |
| `--chunk-time` | Temps cible par chunk (secondes) |
| `--max-lag` | Lag maximal accept√© sur replicas (secondes) |
| `--check-slave-lag` | Replicas √† surveiller |
| `--progress` | Afficher progression (time,30 = toutes les 30s) |
| `--print` | Afficher les commandes SQL |
| `--statistics` | Stats finales |

**Exemple 2 : Modification de colonne**

```bash
pt-online-schema-change \
  --host=mariadb-primary \
  --user=pt_osc \
  --password="${PT_OSC_PASSWORD}" \
  --alter="MODIFY COLUMN description TEXT CHARACTER SET utf8mb4" \
  D=myapp_production,t=products \
  --execute \
  --chunk-size=500 \
  --chunk-time=1.0 \
  --max-lag=10 \
  --critical-load="Threads_running=100" \
  --max-load="Threads_running=50" \
  --check-alter \
  --check-replication-filters \
  --no-drop-old-table \
  --progress=time,60
```

**Options avanc√©es :**

| Option | Description |
|--------|-------------|
| `--check-alter` | V√©rifier syntaxe ALTER avant ex√©cution |
| `--check-replication-filters` | V√©rifier filtres r√©plication |
| `--no-drop-old-table` | Conserver l'ancienne table (_old) |
| `--swap-tables` | M√©thode de swap (d√©faut: 2 RENAME) |
| `--null-to-not-null` | G√©rer colonnes NULL ‚Üí NOT NULL |

### Dry-run et validation

**Toujours tester en dry-run d'abord :**

```bash
# Dry-run (n'ex√©cute pas, affiche seulement)
pt-online-schema-change \
  --host=mariadb-primary \
  --user=pt_osc \
  --password="${PT_OSC_PASSWORD}" \
  --alter="ADD COLUMN status VARCHAR(20)" \
  D=myapp_production,t=orders \
  --dry-run \
  --print

# Output :
# CREATE TABLE `myapp_production`.`_orders_new` (...)
# CREATE TRIGGER `pt_osc_myapp_production_orders_del` ...
# CREATE TRIGGER `pt_osc_myapp_production_orders_upd` ...
# CREATE TRIGGER `pt_osc_myapp_production_orders_ins` ...
# INSERT LOW_PRIORITY IGNORE INTO `myapp_production`.`_orders_new` ...
# Not executing because this is a dry run.
```

### Gestion des triggers existants

‚ö†Ô∏è **Probl√®me** : pt-osc utilise des triggers, incompatible avec des triggers existants.

**Solution 1 : D√©sactiver temporairement les triggers (dangereux)**
```sql
-- Renommer les triggers existants
RENAME TRIGGER my_trigger TO my_trigger_disabled;

-- Apr√®s migration pt-osc
RENAME TRIGGER my_trigger_disabled TO my_trigger;
```

**Solution 2 : Utiliser gh-ost (sans triggers)**
```bash
# gh-ost n'utilise pas de triggers
gh-ost --alter="ADD COLUMN status VARCHAR(20)" ...
```

---

## Comparaison gh-ost vs pt-online-schema-change

### Tableau comparatif d√©taill√©

| Aspect | gh-ost | pt-online-schema-change |
|--------|--------|-------------------------|
| **M√©canisme** | Binlog parsing | Triggers DML |
| **Overhead** | Faible (lecture binlog) | Moyen (3 triggers par table) |
| **Triggers existants** | ‚úÖ Compatible | ‚ùå Incompatible |
| **Pause/Resume** | ‚úÖ Oui (flag files) | ‚ö†Ô∏è Partiel (SIGSTOP) |
| **Throttle** | ‚úÖ Dynamique, granulaire | ‚úÖ Via max-load |
| **Cut-over** | ‚úÖ Contr√¥lable (postpone flag) | ‚ö†Ô∏è Automatique |
| **Rollback** | ‚úÖ Facile (avant cut-over) | ‚ö†Ô∏è Complexe |
| **Test sur replica** | ‚úÖ --test-on-replica | ‚ùå Non natif |
| **Monitoring** | ‚úÖ TCP port + m√©triques | ‚ö†Ô∏è Logs uniquement |
| **MariaDB 11.8** | ‚úÖ Full support | ‚úÖ Full support |
| **Binlog requis** | ‚úÖ Oui (ROW format) | ‚ö†Ô∏è Recommand√© |
| **Complexit√©** | Moyenne | Faible |
| **Maturit√©** | Production-ready (GitHub) | Battle-tested (Percona) |

### Quand utiliser gh-ost ?

‚úÖ **Utilisez gh-ost si :**
- Tables avec triggers existants
- Besoin de contr√¥le fin du cut-over
- Migration critique n√©cessitant pause/resume
- Test pr√©alable sur replica obligatoire
- Monitoring en temps r√©el essentiel
- Rollback facile requis

**Cas d'usage gh-ost :**
```bash
# Table critique 2TB avec triggers pour audit
gh-ost \
  --host=prod-primary \
  --database=critical_db \
  --table=transactions \
  --alter="ADD COLUMN processed_at TIMESTAMP" \
  --test-on-replica \
  --postpone-cut-over-flag-file=/tmp/postpone \
  --panic-flag-file=/tmp/panic \
  --serve-tcp-port=9999 \
  --execute
```

### Quand utiliser pt-online-schema-change ?

‚úÖ **Utilisez pt-osc si :**
- Pas de triggers existants sur la table
- Migration simple et directe
- Familiarit√© avec Percona Toolkit
- Pas besoin de contr√¥le fin du cut-over
- D√©ploiement rapide sans test replica

**Cas d'usage pt-osc :**
```bash
# Table simple 500GB sans triggers
pt-online-schema-change \
  --host=prod-primary \
  --alter="ADD INDEX idx_created_at (created_at)" \
  D=app_db,t=logs \
  --chunk-size=5000 \
  --max-lag=10 \
  --execute \
  --statistics
```

---

## Int√©gration CI/CD

### 1. Pipeline GitLab CI/CD avec gh-ost

**.gitlab-ci.yml :**
```yaml
stages:
  - validate
  - test-replica
  - migrate-production

variables:
  GHOST_VERSION: "1.1.6"

# ========================================
# Validation du ALTER statement
# ========================================
validate-alter:
  stage: validate
  image: mariadb:11.8.2
  script:
    # V√©rifier syntaxe SQL
    - |
      echo "Validating ALTER syntax..."
      mariadb -h mariadb-dev -u root -p"${DEV_DB_PASSWORD}" \
        -e "EXPLAIN ${ALTER_STATEMENT}"
  only:
    variables:
      - $ALTER_STATEMENT

# ========================================
# Test sur replica
# ========================================
test-on-replica:
  stage: test-replica
  image: golang:1.21
  before_script:
    - wget https://github.com/github/gh-ost/releases/download/v${GHOST_VERSION}/gh-ost-binary-linux-amd64.tar.gz
    - tar -xzf gh-ost-binary-linux-amd64.tar.gz
    - chmod +x gh-ost
  script:
    - |
      ./gh-ost \
        --host=${REPLICA_HOST} \
        --port=3306 \
        --user=ghost \
        --password="${GHOST_PASSWORD}" \
        --database=${DATABASE} \
        --table=${TABLE} \
        --alter="${ALTER_STATEMENT}" \
        --test-on-replica \
        --execute \
        --chunk-size=1000 \
        --max-load=Threads_running=30 \
        --verbose
  only:
    - develop
  environment:
    name: staging

# ========================================
# Migration Production
# ========================================
migrate-production:
  stage: migrate-production
  image: golang:1.21
  before_script:
    - wget https://github.com/github/gh-ost/releases/download/v${GHOST_VERSION}/gh-ost-binary-linux-amd64.tar.gz
    - tar -xzf gh-ost-binary-linux-amd64.tar.gz
    - chmod +x gh-ost
  script:
    # Backup avant migration
    - |
      echo "Creating pre-migration backup..."
      mysqldump -h ${PROD_DB_HOST} -u backup_user -p"${BACKUP_PASSWORD}" \
        --single-transaction --routines \
        ${DATABASE} | gzip > backup-pre-migration-$(date +%Y%m%d-%H%M%S).sql.gz
      
      aws s3 cp backup-*.sql.gz s3://mariadb-backups-prod/pre-migration/
    
    # Migration gh-ost
    - |
      ./gh-ost \
        --host=${PROD_DB_HOST} \
        --port=3306 \
        --user=ghost \
        --password="${GHOST_PASSWORD}" \
        --database=${DATABASE} \
        --table=${TABLE} \
        --alter="${ALTER_STATEMENT}" \
        --allow-on-master \
        --execute \
        --chunk-size=1000 \
        --max-load=Threads_running=25 \
        --critical-load=Threads_running=100 \
        --throttle-control-replicas="${REPLICA_HOSTS}" \
        --postpone-cut-over-flag-file=/tmp/ghost-postpone \
        --panic-flag-file=/tmp/ghost-panic \
        --serve-tcp-port=9999 \
        --verbose | tee gh-ost-migration.log
    
    # Notification succ√®s
    - |
      curl -X POST "${SLACK_WEBHOOK_URL}" \
        -H 'Content-Type: application/json' \
        -d "{
          \"text\": \"‚úÖ gh-ost migration completed: ${TABLE}\",
          \"attachments\": [{
            \"color\": \"good\",
            \"fields\": [
              {\"title\": \"Database\", \"value\": \"${DATABASE}\", \"short\": true},
              {\"title\": \"Table\", \"value\": \"${TABLE}\", \"short\": true}
            ]
          }]
        }"
  artifacts:
    paths:
      - gh-ost-migration.log
      - backup-*.sql.gz
    expire_in: 30 days
  only:
    - main
  when: manual
  environment:
    name: production
```

### 2. Kubernetes Job pour gh-ost

**gh-ost-migration-job.yaml :**
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: gh-ost-add-column-phone
  namespace: production
  labels:
    app: gh-ost
    migration: add-column-phone
spec:
  ttlSecondsAfterFinished: 604800  # 7 jours
  backoffLimit: 1
  
  template:
    metadata:
      labels:
        app: gh-ost
    spec:
      restartPolicy: Never
      
      # Service Account avec RBAC
      serviceAccountName: gh-ost-sa
      
      containers:
      - name: gh-ost
        image: ghcr.io/github/gh-ost:latest
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "Starting gh-ost migration..."
          
          gh-ost \
            --host=${DB_HOST} \
            --port=3306 \
            --user=${DB_USER} \
            --password=${DB_PASSWORD} \
            --database=${DB_NAME} \
            --table=${TABLE_NAME} \
            --alter="${ALTER_STATEMENT}" \
            --allow-on-master \
            --execute \
            --chunk-size=${CHUNK_SIZE} \
            --max-load=Threads_running=${MAX_LOAD_THREADS} \
            --critical-load=Threads_running=${CRITICAL_LOAD_THREADS} \
            --throttle-control-replicas="${REPLICA_HOSTS}" \
            --postpone-cut-over-flag-file=/tmp/ghost-postpone \
            --panic-flag-file=/tmp/ghost-panic \
            --serve-tcp-port=9999 \
            --verbose
          
          echo "Migration completed successfully!"
        
        env:
        - name: DB_HOST
          value: "mariadb-primary-svc"
        - name: DB_NAME
          value: "myapp_production"
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: gh-ost-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: gh-ost-credentials
              key: password
        - name: TABLE_NAME
          value: "users"
        - name: ALTER_STATEMENT
          value: "ADD COLUMN phone VARCHAR(20) AFTER email"
        - name: CHUNK_SIZE
          value: "1000"
        - name: MAX_LOAD_THREADS
          value: "25"
        - name: CRITICAL_LOAD_THREADS
          value: "100"
        - name: REPLICA_HOSTS
          value: "mariadb-replica-0:3306,mariadb-replica-1:3306"
        
        # Port pour monitoring externe
        ports:
        - name: gh-ost-monitor
          containerPort: 9999
          protocol: TCP
        
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
        
        # Volume pour flag files
        volumeMounts:
        - name: ghost-flags
          mountPath: /tmp
      
      volumes:
      - name: ghost-flags
        emptyDir: {}

---
# Service pour exposer le monitoring
apiVersion: v1
kind: Service
metadata:
  name: gh-ost-monitor
  namespace: production
spec:
  selector:
    app: gh-ost
  ports:
  - name: monitor
    port: 9999
    targetPort: 9999
  type: ClusterIP

---
# Secret pour credentials
apiVersion: v1
kind: Secret
metadata:
  name: gh-ost-credentials
  namespace: production
type: Opaque
stringData:
  username: "ghost"
  password: "SecureGhostPassword123!"
```

**Monitoring du Job depuis un autre pod :**
```bash
# Depuis un pod dans le cluster
kubectl run -it --rm debug --image=busybox --restart=Never -- sh

# Dans le pod debug
echo "status" | nc gh-ost-monitor.production.svc.cluster.local 9999
```

### 3. Kubernetes Job pour pt-online-schema-change

**pt-osc-migration-job.yaml :**
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pt-osc-add-index-email
  namespace: production
spec:
  ttlSecondsAfterFinished: 604800
  backoffLimit: 1
  
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: pt-osc
        image: perconalab/percona-toolkit:latest
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          pt-online-schema-change \
            --host=${DB_HOST} \
            --port=3306 \
            --user=${DB_USER} \
            --password=${DB_PASSWORD} \
            --alter="${ALTER_STATEMENT}" \
            D=${DB_NAME},t=${TABLE_NAME} \
            --execute \
            --chunk-size=${CHUNK_SIZE} \
            --chunk-time=0.5 \
            --max-lag=${MAX_LAG} \
            --check-slave-lag=${REPLICA_HOSTS} \
            --progress=time,60 \
            --print \
            --statistics
        
        env:
        - name: DB_HOST
          value: "mariadb-primary-svc"
        - name: DB_NAME
          value: "myapp_production"
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: pt-osc-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: pt-osc-credentials
              key: password
        - name: TABLE_NAME
          value: "users"
        - name: ALTER_STATEMENT
          value: "ADD INDEX idx_email (email)"
        - name: CHUNK_SIZE
          value: "1000"
        - name: MAX_LAG
          value: "10"
        - name: REPLICA_HOSTS
          value: "mariadb-replica-0:3306,mariadb-replica-1:3306"
        
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "1"
            memory: "2Gi"
```

---

## Monitoring et observabilit√©

### 1. M√©triques Prometheus pour gh-ost

**gh-ost-exporter (script custom) :**
```python
#!/usr/bin/env python3
# gh-ost-prometheus-exporter.py

import socket
import time
from prometheus_client import start_http_server, Gauge

# M√©triques Prometheus
ghost_copy_progress = Gauge('ghost_copy_progress_percent', 'Copy progress percentage')
ghost_rows_copied = Gauge('ghost_rows_copied', 'Number of rows copied')
ghost_rows_total = Gauge('ghost_rows_total', 'Total number of rows')
ghost_eta_seconds = Gauge('ghost_eta_seconds', 'Estimated time remaining in seconds')
ghost_lag_seconds = Gauge('ghost_lag_seconds', 'Replication lag in seconds')
ghost_state = Gauge('ghost_state', 'Current state', ['state'])

def fetch_ghost_status(host='localhost', port=9999):
    """Fetch status from gh-ost TCP port"""
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.connect((host, port))
            s.sendall(b'status\n')
            data = s.recv(4096).decode('utf-8')
            return parse_status(data)
    except Exception as e:
        print(f"Error fetching gh-ost status: {e}")
        return None

def parse_status(status_text):
    """Parse gh-ost status output"""
    # Example: Copy: 42500000/100000000 42.5%; Applied: 1234567; ETA: 2h15m; Lag: 0.5s
    metrics = {}
    
    if 'Copy:' in status_text:
        parts = status_text.split(';')
        for part in parts:
            part = part.strip()
            if part.startswith('Copy:'):
                # Extract 42500000/100000000 42.5%
                copy_info = part.replace('Copy:', '').strip()
                rows_info, percent = copy_info.split()
                copied, total = rows_info.split('/')
                metrics['rows_copied'] = int(copied)
                metrics['rows_total'] = int(total)
                metrics['progress'] = float(percent.rstrip('%'))
            elif 'ETA:' in part:
                # Parse ETA (2h15m)
                eta = part.replace('ETA:', '').strip()
                metrics['eta_seconds'] = parse_duration(eta)
            elif 'Lag:' in part:
                # Parse Lag (0.5s)
                lag = part.replace('Lag:', '').strip().rstrip('s')
                metrics['lag'] = float(lag)
    
    return metrics

def parse_duration(duration_str):
    """Convert duration string (2h15m) to seconds"""
    total_seconds = 0
    if 'h' in duration_str:
        hours, rest = duration_str.split('h')
        total_seconds += int(hours) * 3600
        duration_str = rest
    if 'm' in duration_str:
        minutes = duration_str.rstrip('m')
        total_seconds += int(minutes) * 60
    return total_seconds

if __name__ == '__main__':
    # Start Prometheus HTTP server
    start_http_server(8000)
    print("Prometheus exporter started on :8000")
    
    while True:
        metrics = fetch_ghost_status()
        if metrics:
            ghost_copy_progress.set(metrics.get('progress', 0))
            ghost_rows_copied.set(metrics.get('rows_copied', 0))
            ghost_rows_total.set(metrics.get('rows_total', 0))
            ghost_eta_seconds.set(metrics.get('eta_seconds', 0))
            ghost_lag_seconds.set(metrics.get('lag', 0))
        
        time.sleep(10)  # Scrape every 10s
```

**D√©ploiement de l'exporter dans Kubernetes :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gh-ost-exporter
  namespace: production
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gh-ost-exporter
  template:
    metadata:
      labels:
        app: gh-ost-exporter
    spec:
      containers:
      - name: exporter
        image: myregistry/gh-ost-exporter:latest
        ports:
        - name: metrics
          containerPort: 8000
        env:
        - name: GHOST_HOST
          value: "gh-ost-monitor.production.svc.cluster.local"
        - name: GHOST_PORT
          value: "9999"

---
apiVersion: v1
kind: Service
metadata:
  name: gh-ost-exporter
  namespace: production
  labels:
    app: gh-ost-exporter
spec:
  selector:
    app: gh-ost-exporter
  ports:
  - name: metrics
    port: 8000
    targetPort: 8000

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: gh-ost-exporter
  namespace: production
spec:
  selector:
    matchLabels:
      app: gh-ost-exporter
  endpoints:
  - port: metrics
    interval: 10s
```

### 2. Dashboard Grafana pour gh-ost

**Requ√™tes PromQL :**
```promql
# Progression de la copie (%)
ghost_copy_progress_percent

# Rows copi√©es vs total
ghost_rows_copied / ghost_rows_total * 100

# ETA (heures restantes)
ghost_eta_seconds / 3600

# Lag de r√©plication
ghost_lag_seconds

# Vitesse de copie (rows/sec)
rate(ghost_rows_copied[1m])

# Temps estim√© restant bas√© sur vitesse actuelle
(ghost_rows_total - ghost_rows_copied) / rate(ghost_rows_copied[5m])
```

### 3. Alertes Prometheus

**PrometheusRule :**
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: gh-ost-alerts
  namespace: production
spec:
  groups:
  - name: gh-ost-migrations
    interval: 30s
    rules:
    # Alerte si lag de r√©plication > 30s
    - alert: GhOstReplicationLagHigh
      expr: ghost_lag_seconds > 30
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "gh-ost replication lag is high"
        description: "Replication lag is {{ $value }}s, which may slow down migration"
    
    # Alerte si migration stagnante (pas de progression en 10min)
    - alert: GhOstMigrationStalled
      expr: rate(ghost_rows_copied[10m]) == 0
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "gh-ost migration appears stalled"
        description: "No rows copied in the last 10 minutes"
    
    # Alerte si ETA > 24h
    - alert: GhOstMigrationTooLong
      expr: ghost_eta_seconds > 86400
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "gh-ost migration will take > 24h"
        description: "Estimated {{ $value / 3600 }} hours remaining"
```

---

## Best practices de production

### 1. **Toujours tester en dry-run d'abord**

```bash
# gh-ost dry-run
gh-ost \
  --host=prod-primary \
  --database=myapp \
  --table=users \
  --alter="ADD COLUMN phone VARCHAR(20)" \
  --execute \
  --test-on-replica  # Test sur replica avant prod

# pt-osc dry-run
pt-online-schema-change \
  --alter="ADD INDEX idx_email (email)" \
  D=myapp,t=users \
  --dry-run \
  --print
```

### 2. **Utiliser des chunk sizes adapt√©s**

```bash
# Petites tables (< 1M rows) : chunks plus gros
--chunk-size=5000

# Tables moyennes (1M-100M rows) : chunks moyens
--chunk-size=1000

# Grosses tables (> 100M rows) : chunks plus petits
--chunk-size=500

# Tables tr√®s actives : chunks tr√®s petits
--chunk-size=100
```

### 3. **Monitorer les replicas**

```bash
# gh-ost : throttle bas√© sur lag replicas
gh-ost \
  --throttle-control-replicas="replica1:3306,replica2:3306" \
  --max-lag-millis=1500 \
  ...

# pt-osc : pause si lag > seuil
pt-online-schema-change \
  --max-lag=5 \
  --check-slave-lag=replica1:3306,replica2:3306 \
  ...
```

### 4. **Fen√™tres de maintenance pour cut-over**

```bash
# gh-ost : postpone cut-over jusqu'√† fen√™tre
gh-ost \
  --postpone-cut-over-flag-file=/tmp/ghost-postpone \
  ...

# Dans un autre terminal, lors de la fen√™tre :
rm /tmp/ghost-postpone
```

### 5. **Panic abort en cas de probl√®me**

```bash
# gh-ost panic flag (abort imm√©diat)
touch /tmp/ghost-panic

# pt-osc : pas de m√©canisme natif, utiliser kill
pkill -TERM pt-online-schema-change
```

### 6. **Conserver l'ancienne table temporairement**

```bash
# gh-ost : pas de drop auto de _del table
gh-ost --initially-drop-old-table=false ...

# pt-osc : conserver _old table
pt-online-schema-change --no-drop-old-table ...

# V√©rifier puis supprimer manuellement
DROP TABLE users_old;
```

### 7. **Calcul de la dur√©e estim√©e**

```bash
# Estimer la dur√©e avant lancement
# Formule : (nombre_rows / chunk_size) * temps_par_chunk

# Exemple : Table 100M rows, chunk 1000, 0.5s/chunk
# Dur√©e = (100000000 / 1000) * 0.5s = 50000s ‚âà 14 heures

# Ajouter 20-30% pour le binlog replay et le cut-over
# Total estim√© : 17-18 heures
```

---

## Troubleshooting

### Probl√®me 1 : gh-ost bloqu√© √† 100% (cut-over ne se fait pas)

**Sympt√¥mes :**
```
Copy: 100000000/100000000 100.0%; Applied: 5678901; Waiting for table lock
```

**Cause :** Transactions longues bloquent le RENAME TABLE.

**Solution :**
```bash
# Identifier les transactions longues
mariadb -e "SHOW PROCESSLIST" | grep -v Sleep

# Tuer les transactions probl√©matiques
mariadb -e "KILL <thread_id>"

# Ou attendre qu'elles se terminent
```

### Probl√®me 2 : pt-osc √©choue avec "Duplicate key error"

**Sympt√¥mes :**
```
DBD::mysql::st execute failed: Duplicate entry '12345' for key 'PRIMARY'
```

**Cause :** Triggers capturent des INSERT en double.

**Solution :**
```bash
# Utiliser --no-check-unique-key-change si PK ne change pas
pt-online-schema-change \
  --no-check-unique-key-change \
  ...

# Ou nettoyer la table _new et relancer
DROP TABLE _users_new;
pt-online-schema-change --execute ...
```

### Probl√®me 3 : Migration trop lente

**Diagnostic :**
```bash
# V√©rifier la charge
mariadb -e "SHOW GLOBAL STATUS LIKE 'Threads_running'"
mariadb -e "SHOW GLOBAL STATUS LIKE 'Threads_connected'"

# V√©rifier les I/O
iostat -x 5
```

**Solutions :**

1. **Augmenter chunk-size :**
```bash
gh-ost --chunk-size=2000 ...
```

2. **R√©duire throttle :**
```bash
gh-ost --max-load=Threads_running=50 ...
```

3. **Migrer pendant heures creuses :**
```bash
# Planifier pour 2h du matin
at 02:00 <<EOF
gh-ost --execute ...
EOF
```

### Probl√®me 4 : Manque d'espace disque

**Cause :** Table ghost double l'espace utilis√©.

**Solution pr√©ventive :**
```bash
# V√©rifier l'espace avant
df -h /var/lib/mysql

# Estimer taille ghost table = taille table actuelle
du -sh /var/lib/mysql/myapp_production/users.*

# Si insuffisant, nettoyer ou agrandir le volume
```

---

## ‚úÖ Points cl√©s √† retenir

- **ALTER TABLE classique bloque** sur grosses tables (heures de downtime)
- **gh-ost** : Pas de triggers, lecture binlog, contr√¥le fin du cut-over, rollback facile
- **pt-osc** : Utilise triggers, plus simple, mature, bon pour migrations directes
- **Chunk size** : Adapter selon taille table et activit√© (100-5000 rows/chunk)
- **Throttle dynamique** : Surveiller Threads_running et lag replicas
- **Test sur replica** : Toujours tester en --test-on-replica (gh-ost) ou --dry-run (pt-osc)
- **Fen√™tre de maintenance** : Utiliser --postpone-cut-over-flag pour contr√¥ler le swap final
- **Monitoring essentiel** : M√©triques Prometheus pour progression, lag, ETA
- **Panic abort** : Flag files pour arr√™t d'urgence sans perdre la migration
- **Espace disque** : Pr√©voir 2√ó la taille de la table (table + ghost table)
- **Binlog ROW requis** : gh-ost n√©cessite binlog-format=ROW
- **Triggers existants** : gh-ost compatible, pt-osc incompatible

---

## üîó Ressources et r√©f√©rences

### Documentation officielle
- **[gh-ost Documentation](https://github.com/github/gh-ost/blob/master/doc/README.md)** - Documentation compl√®te gh-ost
- **[gh-ost GitHub](https://github.com/github/gh-ost)** - Repository officiel
- **[pt-online-schema-change](https://docs.percona.com/percona-toolkit/pt-online-schema-change.html)** - Documentation Percona
- **[Percona Toolkit](https://www.percona.com/software/database-tools/percona-toolkit)** - Suite compl√®te d'outils

### Articles techniques
- **[gh-ost: GitHub's Online Schema Migration](https://githubengineering.com/gh-ost-github-s-online-migration-tool-for-mysql/)** - Article GitHub Engineering
- **[Online Schema Changes](https://www.percona.com/blog/online-schema-changes/)** - Blog Percona
- **[MariaDB ALTER TABLE Performance](https://mariadb.com/kb/en/alter-table/#performance)** - KB MariaDB

### Outils compl√©mentaires
- **[spirit](https://github.com/cashapp/spirit)** - Alternative Cash App (similaire gh-ost)
- **[oak-online-alter-table](http://openarkkit.googlecode.com)** - Outil Google (legacy)
- **[mysqldumpslow](https://mariadb.com/kb/en/mysqldumpslow/)** - Analyser slow queries

### Webinars et talks
- **[Percona Live: Online Schema Changes](https://www.youtube.com/watch?v=...)** - Talks techniques
- **[GitHub Universe: gh-ost](https://www.youtube.com/watch?v=...)** - Pr√©sentation GitHub

---

## ‚û°Ô∏è Section suivante

**16.9 Monitoring avec Prometheus/Grafana** : Impl√©mentation compl√®te du monitoring MariaDB avec mysqld_exporter, dashboards Grafana, alertes Prometheus, et observabilit√© en production.

‚è≠Ô∏è [Monitoring avec Prometheus/Grafana](/16-devops-automatisation/09-monitoring-prometheus-grafana.md)
