ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 16.4.2 PersistentVolumes et StorageClasses

> **Niveau** : AvancÃ© Ã  Expert  
> **DurÃ©e estimÃ©e** : 3-4 heures  
> **PrÃ©requis** : Kubernetes fundamentals, Storage concepts, StatefulSets, MariaDB architecture

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- Comprendre l'architecture du stockage persistant dans Kubernetes
- Configurer des PersistentVolumes (PV) et PersistentVolumeClaims (PVC) pour MariaDB
- CrÃ©er et gÃ©rer des StorageClasses pour diffÃ©rents besoins de performance
- ImplÃ©menter le provisionnement dynamique de volumes
- Optimiser les performances de stockage pour bases de donnÃ©es
- GÃ©rer les snapshots et la sauvegarde de volumes
- Appliquer les meilleures pratiques de stockage pour workloads stateful
- RÃ©soudre les problÃ¨mes courants de persistance

---

## Introduction

Le stockage persistant est critique pour les bases de donnÃ©es dans Kubernetes. Contrairement aux applications stateless, MariaDB nÃ©cessite un stockage durable qui survit aux redÃ©marrages de pods, aux migrations de nÅ“uds et aux mises Ã  jour. Kubernetes offre une abstraction puissante du stockage via les PersistentVolumes.

### Pourquoi le stockage est-il complexe dans Kubernetes ?

**DÃ©fis spÃ©cifiques** :
- âœ… **Persistance** : Les donnÃ©es doivent survivre Ã  la destruction des pods
- âœ… **Performance** : IOPS et latence critiques pour les bases de donnÃ©es
- âœ… **Topologie** : AffinitÃ© pod-volume pour Ã©viter les latences rÃ©seau
- âœ… **Snapshots** : Sauvegardes et restauration rapides
- âœ… **Expansion** : CapacitÃ© Ã  augmenter la taille sans downtime
- âœ… **RÃ©plication** : Synchronisation des donnÃ©es entre zones/rÃ©gions
- âœ… **SÃ©curitÃ©** : Chiffrement at-rest et in-transit

**Cas d'usage MariaDB** :
- Stockage de donnÃ©es InnoDB (tablespaces)
- Logs binaires pour rÃ©plication
- Slow query logs et error logs
- Backups et snapshots
- Temporary tables et sorts

---

## Architecture du stockage Kubernetes

### Composants clÃ©s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Application                          â”‚
â”‚                    (MariaDB StatefulSet)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ mount
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PersistentVolumeClaim (PVC)                    â”‚
â”‚         (Request: 100Gi, StorageClass: fast-ssd)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ bound to
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PersistentVolume (PV)                          â”‚
â”‚           (Capacity: 100Gi, AccessMode: RWO)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ provisioned by
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   StorageClass                              â”‚
â”‚        (Provisioner: kubernetes.io/aws-ebs)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ creates
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Physical Storage                               â”‚
â”‚           (AWS EBS gp3, Azure Disk, etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow de provisionnement

1. **Demande** : Pod demande un PVC
2. **Matching** : Kubernetes cherche un PV existant ou dÃ©clenche le provisionnement dynamique
3. **Binding** : PVC est liÃ© (bound) Ã  un PV
4. **Montage** : Volume est montÃ© dans le pod
5. **Utilisation** : Application Ã©crit/lit les donnÃ©es
6. **LibÃ©ration** : Pod supprimÃ© â†’ PVC peut Ãªtre conservÃ© ou supprimÃ© selon ReclaimPolicy

---

## PersistentVolume (PV)

### DÃ©finition d'un PV statique

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mariadb-pv-manual
  labels:
    type: local
    app: mariadb
spec:
  # CapacitÃ© du volume
  capacity:
    storage: 100Gi
  
  # Mode d'accÃ¨s
  accessModes:
    - ReadWriteOnce  # RWO - Un seul nÅ“ud peut monter en lecture/Ã©criture
  
  # Politique de rÃ©cupÃ©ration
  persistentVolumeReclaimPolicy: Retain  # Retain, Delete, Recycle (deprecated)
  
  # Classe de stockage (optionnel pour PV statique)
  storageClassName: manual
  
  # Type de volume (local dans cet exemple)
  local:
    path: /mnt/data/mariadb
  
  # AffinitÃ© de nÅ“ud (requis pour volumes locaux)
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1
```

### Types de volumes supportÃ©s

```yaml
# 1. hostPath (dev/test uniquement)
hostPath:
  path: /data/mariadb
  type: DirectoryOrCreate

# 2. local (meilleure performance, mais liÃ© au nÅ“ud)
local:
  path: /mnt/fast-disks/mariadb

# 3. NFS
nfs:
  server: nfs-server.example.com
  path: /exports/mariadb

# 4. iSCSI
iscsi:
  targetPortal: 10.0.2.15:3260
  iqn: iqn.2001-04.com.example:storage.mariadb
  lun: 0
  fsType: ext4

# 5. Cloud providers (provisionnement dynamique recommandÃ©)
# AWS EBS
awsElasticBlockStore:
  volumeID: vol-0123456789abcdef0
  fsType: ext4

# Azure Disk
azureDisk:
  diskName: mariadb-disk
  diskURI: /subscriptions/.../disks/mariadb-disk

# GCE Persistent Disk
gcePersistentDisk:
  pdName: mariadb-disk
  fsType: ext4

# Ceph RBD
rbd:
  monitors:
    - 10.16.154.78:6789
    - 10.16.154.82:6789
  image: mariadb-image
  pool: kube
  user: admin
  secretRef:
    name: ceph-secret
  fsType: ext4
```

### Access Modes

```yaml
# ReadWriteOnce (RWO) - RecommandÃ© pour MariaDB
accessModes:
  - ReadWriteOnce  # Volume montÃ© en RW par un seul nÅ“ud
  
# ReadOnlyMany (ROX) - Pour partage en lecture
accessModes:
  - ReadOnlyMany  # Volume montÃ© en RO par plusieurs nÅ“uds

# ReadWriteMany (RWX) - Non supportÃ© pour la plupart des stockages block
# Ne PAS utiliser pour MariaDB (corruption de donnÃ©es)
accessModes:
  - ReadWriteMany  # Volume montÃ© en RW par plusieurs nÅ“uds
```

ğŸ’¡ **Conseil** : Pour MariaDB, utilisez **TOUJOURS** ReadWriteOnce (RWO).

---

## PersistentVolumeClaim (PVC)

### PVC basique pour MariaDB

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-pvc
  namespace: database
  labels:
    app: mariadb
    tier: database
spec:
  # Mode d'accÃ¨s demandÃ©
  accessModes:
    - ReadWriteOnce
  
  # Classe de stockage
  storageClassName: fast-ssd
  
  # Ressources demandÃ©es
  resources:
    requests:
      storage: 100Gi
  
  # SÃ©lecteur de labels (optionnel)
  selector:
    matchLabels:
      type: ssd
      environment: production
```

### PVC avec annotations pour provisionnement

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-data-pvc
  namespace: production
  annotations:
    # ğŸ†• Volume expansion
    volume.beta.kubernetes.io/storage-class: "fast-ssd"
    
    # Snapshot source (restauration)
    snapshot.storage.kubernetes.io/snapshot-name: "mariadb-snapshot-20251214"
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 500Gi
    # Limite max (si supportÃ© par le provisioner)
    limits:
      storage: 1Ti
```

### Volume Expansion (Resize)

```yaml
# 1. VÃ©rifier que la StorageClass supporte l'expansion
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs
allowVolumeExpansion: true  # IMPORTANT
parameters:
  type: gp3

---
# 2. Modifier la taille du PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 200Gi  # AugmentÃ© de 100Gi â†’ 200Gi
```

```bash
# Expansion via kubectl
kubectl patch pvc mariadb-pvc -p '{"spec":{"resources":{"requests":{"storage":"200Gi"}}}}'

# VÃ©rifier l'Ã©tat
kubectl get pvc mariadb-pvc -w

# Statut attendu :
# NAME           STATUS   CAPACITY   ...   CONDITIONS
# mariadb-pvc    Bound    200Gi            FileSystemResizePending
# puis
# mariadb-pvc    Bound    200Gi            (vide aprÃ¨s redÃ©marrage du pod)
```

âš ï¸ **Attention** : La rÃ©duction de taille n'est **PAS supportÃ©e**. Seule l'expansion est possible.

---

## StorageClass

### StorageClass AWS EBS

```yaml
# GP3 (General Purpose SSD v3) - RecommandÃ© pour MariaDB
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-gp3
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  iops: "3000"              # IOPS de base (max 16000)
  throughput: "125"         # MB/s (max 1000)
  encrypted: "true"
  kmsKeyId: arn:aws:kms:eu-west-1:123456789012:key/12345678-1234-1234-1234-123456789012
  fsType: ext4
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer  # IMPORTANT pour topologie
```

```yaml
# IO2 (High Performance SSD) - Pour workloads intensifs
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-io2-high-perf
provisioner: ebs.csi.aws.com
parameters:
  type: io2
  iops: "64000"             # Max 64000 IOPS
  encrypted: "true"
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

```yaml
# ST1 (Throughput Optimized HDD) - Pour archives/backups
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-backup-st1
provisioner: ebs.csi.aws.com
parameters:
  type: st1
  encrypted: "true"
allowVolumeExpansion: true
reclaimPolicy: Delete  # Delete pour backups temporaires
volumeBindingMode: Immediate
```

### StorageClass Azure Disk

```yaml
# Premium SSD (RecommandÃ© pour production)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-premium-ssd
provisioner: disk.csi.azure.com
parameters:
  storageaccounttype: Premium_LRS  # Premium_LRS, StandardSSD_LRS, Standard_LRS
  kind: Managed
  cachingMode: ReadOnly  # None, ReadOnly, ReadWrite
  diskEncryptionSetID: /subscriptions/.../diskEncryptionSets/myDES
  fsType: ext4
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

```yaml
# Ultra Disk (Performance maximale)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-ultra-disk
provisioner: disk.csi.azure.com
parameters:
  storageaccounttype: UltraSSD_LRS
  diskIOPSReadWrite: "160000"  # Max 160k IOPS
  diskMBpsReadWrite: "2000"    # Max 2000 MB/s
  fsType: ext4
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

### StorageClass GCP Persistent Disk

```yaml
# SSD Persistent Disk (pd-ssd)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-pd-ssd
provisioner: pd.csi.storage.gke.io
parameters:
  type: pd-ssd
  replication-type: regional-pd  # regional-pd ou none
  disk-encryption-kms-key: projects/PROJECT_ID/locations/LOCATION/keyRings/RING/cryptoKeys/KEY
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

```yaml
# Balanced Persistent Disk (pd-balanced) - Bon ratio prix/perf
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-pd-balanced
provisioner: pd.csi.storage.gke.io
parameters:
  type: pd-balanced
  replication-type: none
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

### StorageClass Local Storage

```yaml
# Local SSD (performance maximale, pas de rÃ©plication)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-local-ssd
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete

---
# PV associÃ© (crÃ©Ã© manuellement sur chaque nÅ“ud)
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mariadb-local-pv-node1
spec:
  capacity:
    storage: 1Ti
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: mariadb-local-ssd
  local:
    path: /mnt/disks/ssd0
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node-1
```

### StorageClass Ceph RBD

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-ceph-rbd
provisioner: rbd.csi.ceph.com
parameters:
  clusterID: ceph-cluster-id
  pool: kubernetes
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: ceph-secret
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: ceph-secret
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: ceph-secret
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
  csi.storage.k8s.io/fstype: ext4
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
```

---

## Volume Binding Modes

### WaitForFirstConsumer (RecommandÃ© pour MariaDB)

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mariadb-topology-aware
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer  # Attend que le pod soit schedulÃ©
```

**Avantages** :
- âœ… CrÃ©e le volume dans la mÃªme zone que le pod
- âœ… Ã‰vite les problÃ¨mes de topologie
- âœ… Optimise la latence rÃ©seau

**Fonctionnement** :
1. PVC crÃ©Ã© â†’ reste en Ã©tat `Pending`
2. Pod crÃ©Ã© avec rÃ©fÃ©rence au PVC
3. Scheduler place le pod sur un nÅ“ud
4. Volume provisionnÃ© dans la mÃªme zone
5. PVC devient `Bound`
6. Pod dÃ©marre

### Immediate

```yaml
volumeBindingMode: Immediate  # Provisionne immÃ©diatement
```

**Avantages** :
- âœ… Volume crÃ©Ã© dÃ¨s la crÃ©ation du PVC
- âœ… Utile pour prÃ©-provisionnement

**InconvÃ©nients** :
- âŒ Peut crÃ©er des problÃ¨mes de topologie
- âŒ Pod peut ne pas pouvoir dÃ©marrer si volume dans une autre zone

ğŸ’¡ **Conseil** : Utilisez **WaitForFirstConsumer** pour toutes les bases de donnÃ©es.

---

## Reclaim Policies

### Retain (RecommandÃ© pour production)

```yaml
reclaimPolicy: Retain
```

- Volume conservÃ© aprÃ¨s suppression du PVC
- DonnÃ©es prÃ©servÃ©es pour rÃ©cupÃ©ration manuelle
- Administrateur doit nettoyer manuellement

```bash
# Workflow de rÃ©cupÃ©ration avec Retain
# 1. PVC supprimÃ©
kubectl delete pvc mariadb-pvc

# 2. PV passe en Ã©tat "Released"
kubectl get pv

# 3. RÃ©cupÃ©ration manuelle
kubectl patch pv pv-name -p '{"spec":{"claimRef": null}}'

# 4. PV redevient "Available" et peut Ãªtre rÃ©clamÃ©
```

### Delete

```yaml
reclaimPolicy: Delete
```

- Volume supprimÃ© automatiquement avec le PVC
- DonnÃ©es perdues dÃ©finitivement
- Utiliser pour environnements non-critiques

### Recycle (Deprecated)

```yaml
reclaimPolicy: Recycle  # âš ï¸ Deprecated, ne pas utiliser
```

---

## Snapshots de volumes

### VolumeSnapshotClass

```yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: mariadb-snapshot-class
  annotations:
    snapshot.storage.kubernetes.io/is-default-class: "true"
driver: ebs.csi.aws.com  # ou disk.csi.azure.com, pd.csi.storage.gke.io
deletionPolicy: Retain  # Retain ou Delete
parameters:
  # AWS EBS
  # (aucun paramÃ¨tre requis)
  
  # Azure
  # incremental: "true"
  
  # GCP
  # storage-locations: europe-west1
```

### CrÃ©ation d'un snapshot

```yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: mariadb-snapshot-20251214
  namespace: database
spec:
  volumeSnapshotClassName: mariadb-snapshot-class
  source:
    persistentVolumeClaimName: mariadb-pvc
```

```bash
# CrÃ©er un snapshot
kubectl apply -f mariadb-snapshot.yaml

# VÃ©rifier le snapshot
kubectl get volumesnapshot
kubectl describe volumesnapshot mariadb-snapshot-20251214

# Statut :
# NAME                        READYTOUSE   SOURCEPVC      RESTORESIZE   ...
# mariadb-snapshot-20251214   true         mariadb-pvc    100Gi
```

### Restauration depuis un snapshot

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-restored-pvc
  namespace: database
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi
  dataSource:
    name: mariadb-snapshot-20251214
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
```

### Clonage de volumes

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-clone-pvc
  namespace: database
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi
  dataSource:
    name: mariadb-pvc  # PVC source
    kind: PersistentVolumeClaim
```

---

## Utilisation avec StatefulSet

### StatefulSet avec volumeClaimTemplates

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mariadb
  namespace: database
spec:
  serviceName: mariadb
  replicas: 3
  selector:
    matchLabels:
      app: mariadb
  
  template:
    metadata:
      labels:
        app: mariadb
    spec:
      containers:
      - name: mariadb
        image: mariadb:11.8
        env:
        - name: MARIADB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mariadb-secret
              key: root-password
        
        ports:
        - containerPort: 3306
          name: mysql
        
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
        - name: config
          mountPath: /etc/mysql/conf.d
          readOnly: true
        - name: logs
          mountPath: /var/log/mysql
      
      volumes:
      - name: config
        configMap:
          name: mariadb-config
  
  # VolumeClaimTemplates pour stockage persistant
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: mariadb
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: mariadb-gp3
      resources:
        requests:
          storage: 100Gi
  
  - metadata:
      name: logs
      labels:
        app: mariadb
        type: logs
    spec:
      accessModes:
        - ReadWriteOnce
      storageClassName: mariadb-gp3
      resources:
        requests:
          storage: 20Gi
```

### Nommage des PVCs crÃ©Ã©s

```bash
# Format : <claim-name>-<statefulset-name>-<ordinal>
data-mariadb-0    # Pod mariadb-0
data-mariadb-1    # Pod mariadb-1
data-mariadb-2    # Pod mariadb-2

logs-mariadb-0
logs-mariadb-1
logs-mariadb-2
```

### Gestion du cycle de vie

```bash
# Scale down (PVCs conservÃ©s)
kubectl scale statefulset mariadb --replicas=1

# PVCs data-mariadb-1 et data-mariadb-2 existent toujours

# Scale up (PVCs rÃ©utilisÃ©s)
kubectl scale statefulset mariadb --replicas=3

# mariadb-1 rÃ©utilise data-mariadb-1
# mariadb-2 rÃ©utilise data-mariadb-2

# Suppression StatefulSet (PVCs conservÃ©s par dÃ©faut)
kubectl delete statefulset mariadb

# PVCs toujours prÃ©sents, donnÃ©es intactes

# Suppression manuelle des PVCs si nÃ©cessaire
kubectl delete pvc data-mariadb-0 data-mariadb-1 data-mariadb-2
```

---

## Optimisations de performance

### 1. Filesystem et mount options

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mariadb-optimized
spec:
  containers:
  - name: mariadb
    image: mariadb:11.8
    volumeMounts:
    - name: data
      mountPath: /var/lib/mysql
      # Mount options pour performance
      # Ces options sont dÃ©finies au niveau du PV ou StorageClass
  
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: mariadb-pvc

---
# Mount options au niveau du PV
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mariadb-pv
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteOnce
  mountOptions:
    - noatime      # Pas de mise Ã  jour atime (performance)
    - nodiratime   # Pas de mise Ã  jour diratime
    - discard      # TRIM pour SSD
  # ...
```

### 2. I/O Scheduler

```yaml
# DaemonSet pour configurer le I/O scheduler sur les nÅ“uds
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: configure-io-scheduler
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: configure-io-scheduler
  template:
    metadata:
      labels:
        name: configure-io-scheduler
    spec:
      hostPID: true
      hostNetwork: true
      containers:
      - name: configure
        image: busybox
        command:
        - sh
        - -c
        - |
          # Configurer deadline scheduler pour SSD
          for disk in /sys/block/sd*/queue/scheduler; do
            echo deadline > "$disk" || echo none > "$disk"
          done
          sleep infinity
        securityContext:
          privileged: true
```

### 3. Topologie et affinitÃ©

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mariadb
spec:
  # ...
  template:
    spec:
      # Placer les pods sur des nÅ“uds avec SSD local
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: storage-type
                operator: In
                values:
                - local-ssd
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - eu-west-1a  # Zone spÃ©cifique
      
      # Anti-affinitÃ© pour distribuer les replicas
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app: mariadb
          topologyKey: kubernetes.io/hostname
```

### 4. PrÃ©allocation de volumes

```yaml
# Job pour prÃ©allouer et formater les volumes
apiVersion: batch/v1
kind: Job
metadata:
  name: preallocate-volume
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: preallocate
        image: busybox
        command:
        - sh
        - -c
        - |
          # CrÃ©er un fichier de 100GB
          dd if=/dev/zero of=/data/preallocated bs=1M count=102400
          
          # CrÃ©er la structure de rÃ©pertoires MariaDB
          mkdir -p /data/mysql
          mkdir -p /data/binlog
          mkdir -p /data/tmp
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: mariadb-pvc
```

---

## Monitoring du stockage

### MÃ©triques avec kubelet

```yaml
# ServiceMonitor pour Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kubelet-volumes
  namespace: monitoring
spec:
  endpoints:
  - port: https-metrics
    scheme: https
    path: /metrics/cadvisor
    tlsConfig:
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabelings:
    - sourceLabels: [__metrics_path__]
      targetLabel: metrics_path
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet
```

### Alertes Prometheus

```yaml
# PrometheusRule pour alertes stockage
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: mariadb-storage-alerts
  namespace: monitoring
spec:
  groups:
  - name: mariadb.storage
    interval: 30s
    rules:
    # Espace disque faible
    - alert: MariaDBLowDiskSpace
      expr: |
        (
          kubelet_volume_stats_available_bytes{persistentvolumeclaim=~"data-mariadb-.*"}
          /
          kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~"data-mariadb-.*"}
        ) < 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "MariaDB PVC {{ $labels.persistentvolumeclaim }} low on space"
        description: "Less than 10% space available ({{ $value | humanizePercentage }})"
    
    # Utilisation d'inodes Ã©levÃ©e
    - alert: MariaDBHighInodeUsage
      expr: |
        (
          kubelet_volume_stats_inodes_used{persistentvolumeclaim=~"data-mariadb-.*"}
          /
          kubelet_volume_stats_inodes{persistentvolumeclaim=~"data-mariadb-.*"}
        ) > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High inode usage on {{ $labels.persistentvolumeclaim }}"
        description: "Inode usage: {{ $value | humanizePercentage }}"
    
    # PVC en attente
    - alert: MariaDBPVCPending
      expr: |
        kube_persistentvolumeclaim_status_phase{
          phase="Pending",
          persistentvolumeclaim=~"data-mariadb-.*"
        } == 1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "PVC {{ $labels.persistentvolumeclaim }} stuck in Pending state"
        description: "Check volume provisioning issues"
```

### Dashboard Grafana

```json
{
  "dashboard": {
    "title": "MariaDB Storage Metrics",
    "panels": [
      {
        "title": "PVC Capacity",
        "targets": [
          {
            "expr": "kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~\"data-mariadb-.*\"}"
          }
        ]
      },
      {
        "title": "PVC Available Space",
        "targets": [
          {
            "expr": "kubelet_volume_stats_available_bytes{persistentvolumeclaim=~\"data-mariadb-.*\"}"
          }
        ]
      },
      {
        "title": "PVC Usage %",
        "targets": [
          {
            "expr": "(1 - kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes) * 100"
          }
        ]
      }
    ]
  }
}
```

---

## Backup et Disaster Recovery

### Snapshot automatique avec CronJob

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mariadb-snapshot
  namespace: database
spec:
  schedule: "0 2 * * *"  # Tous les jours Ã  2h
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: snapshot-creator
          restartPolicy: OnFailure
          
          containers:
          - name: create-snapshot
            image: bitnami/kubectl:latest
            command:
            - sh
            - -c
            - |
              # Date du jour
              DATE=$(date +%Y%m%d-%H%M%S)
              
              # CrÃ©er le snapshot
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: mariadb-snapshot-${DATE}
                namespace: database
              spec:
                volumeSnapshotClassName: mariadb-snapshot-class
                source:
                  persistentVolumeClaimName: data-mariadb-0
              EOF
              
              # Attendre que le snapshot soit prÃªt
              kubectl wait --for=condition=ready \
                volumesnapshot/mariadb-snapshot-${DATE} \
                --timeout=300s \
                -n database
              
              # Nettoyer les anciens snapshots (garder 7 jours)
              kubectl get volumesnapshot -n database \
                -o json | jq -r \
                '.items[] | select(.metadata.creationTimestamp < "'$(date -d '7 days ago' -Iseconds)'") | .metadata.name' \
                | xargs -r kubectl delete volumesnapshot -n database
              
              echo "Snapshot created successfully: mariadb-snapshot-${DATE}"

---
# ServiceAccount avec permissions
apiVersion: v1
kind: ServiceAccount
metadata:
  name: snapshot-creator
  namespace: database

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: snapshot-creator
  namespace: database
rules:
- apiGroups: ["snapshot.storage.k8s.io"]
  resources: ["volumesnapshots"]
  verbs: ["create", "get", "list", "delete", "watch"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: snapshot-creator
  namespace: database
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: snapshot-creator
subjects:
- kind: ServiceAccount
  name: snapshot-creator
  namespace: database
```

### Velero pour backup complet

```yaml
# Backup MariaDB avec Velero
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: mariadb-backup
  namespace: velero
spec:
  # Inclure namespace database
  includedNamespaces:
  - database
  
  # Inclure les PVCs
  includedResources:
  - persistentvolumeclaims
  - persistentvolumes
  - volumesnapshots
  
  # Labels pour filtrer
  labelSelector:
    matchLabels:
      app: mariadb
  
  # Snapshot des volumes
  snapshotVolumes: true
  
  # Retention
  ttl: 720h  # 30 jours
  
  # Storage location
  storageLocation: default
  volumeSnapshotLocations:
  - default

---
# Schedule de backup automatique
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: mariadb-daily-backup
  namespace: velero
spec:
  schedule: "0 2 * * *"
  template:
    includedNamespaces:
    - database
    labelSelector:
      matchLabels:
        app: mariadb
    snapshotVolumes: true
    ttl: 720h
```

### Restauration avec Velero

```bash
# Lister les backups
velero backup get

# Restaurer un backup
velero restore create --from-backup mariadb-backup-20251214

# Restaurer dans un nouveau namespace
velero restore create --from-backup mariadb-backup-20251214 \
  --namespace-mappings database:database-restore

# VÃ©rifier la restauration
velero restore describe mariadb-backup-20251214-restore

# Logs de restauration
velero restore logs mariadb-backup-20251214-restore
```

---

## Troubleshooting

### PVC stuck in Pending

```bash
# 1. VÃ©rifier l'Ã©tat du PVC
kubectl describe pvc mariadb-pvc

# Causes courantes :
# - StorageClass inexistante
# - Quota de stockage dÃ©passÃ©
# - Provisioner non disponible
# - ProblÃ¨me de permissions

# 2. VÃ©rifier les events
kubectl get events --sort-by='.lastTimestamp' | grep -i mariadb-pvc

# 3. VÃ©rifier le provisioner
kubectl get storageclass mariadb-gp3 -o yaml

# 4. Logs du provisioner (exemple AWS EBS)
kubectl logs -n kube-system -l app=ebs-csi-controller
```

### Volume ne se monte pas

```bash
# 1. VÃ©rifier l'Ã©tat du pod
kubectl describe pod mariadb-0

# Dans Events, chercher :
# - FailedAttachVolume
# - FailedMount
# - MountVolume.SetUp failed

# 2. VÃ©rifier l'attachement du volume
kubectl get volumeattachment

# 3. VÃ©rifier le CSI driver
kubectl get csidrivers
kubectl get csinodes

# 4. Logs du CSI node driver
kubectl logs -n kube-system -l app=ebs-csi-node

# 5. VÃ©rifier les mount points sur le nÅ“ud
kubectl debug node/node-1 -it --image=busybox
# Dans le debug pod :
mount | grep /var/lib/kubelet/pods
```

### Performance lente

```bash
# 1. VÃ©rifier les IOPS
# AWS CloudWatch
aws cloudwatch get-metric-statistics \
  --namespace AWS/EBS \
  --metric-name VolumeReadOps \
  --dimensions Name=VolumeId,Value=vol-xxx \
  --start-time 2025-12-14T00:00:00Z \
  --end-time 2025-12-14T23:59:59Z \
  --period 300 \
  --statistics Average

# 2. VÃ©rifier la latence I/O dans le pod
kubectl exec mariadb-0 -- iostat -x 1

# 3. VÃ©rifier le filesystem
kubectl exec mariadb-0 -- df -h /var/lib/mysql
kubectl exec mariadb-0 -- tune2fs -l /dev/xvdf | grep -i "block size"

# 4. Tester les performances
kubectl exec mariadb-0 -- fio --name=randwrite \
  --ioengine=libaio --iodepth=16 --rw=randwrite \
  --bs=4k --direct=1 --size=1G --numjobs=1 \
  --runtime=60 --time_based --group_reporting \
  --filename=/var/lib/mysql/fio-test
```

### Expansion Ã©chouÃ©e

```bash
# 1. VÃ©rifier l'Ã©tat du PVC
kubectl describe pvc mariadb-pvc

# Chercher condition :
# Type: FileSystemResizePending

# 2. RedÃ©marrer le pod pour dÃ©clencher le resize
kubectl delete pod mariadb-0

# 3. VÃ©rifier dans les logs du pod
kubectl logs mariadb-0 -c mariadb

# 4. Manuellement resize le filesystem (si nÃ©cessaire)
kubectl exec mariadb-0 -- resize2fs /dev/xvdf
```

---

## Bonnes pratiques

### 1. Choix du stockage

```yaml
# âœ… PRODUCTION - SSD haute performance
storageClassName: mariadb-io2  # AWS io2, Azure Premium SSD, GCP pd-ssd

# âœ… DEVELOPMENT - SSD standard
storageClassName: mariadb-gp3  # AWS gp3, Azure StandardSSD, GCP pd-balanced

# âŒ Ã‰VITER - HDD pour bases de donnÃ©es
storageClassName: mariadb-st1  # Uniquement pour backups/archives
```

### 2. Sizing

```yaml
# Calcul de la taille :
# - DonnÃ©es actuelles
# - Croissance prÃ©vue (12-24 mois)
# - Espace pour opÃ©rations (ALTER TABLE, sorts)
# - Margin de sÃ©curitÃ© (20-30%)

# Exemple :
# DonnÃ©es : 80GB
# Croissance : 40GB/an â†’ 80GB sur 2 ans
# OpÃ©rations : 30GB
# Total : 190GB
# Avec marge 30% : 250GB

resources:
  requests:
    storage: 250Gi
```

### 3. Monitoring

```yaml
# âœ… Toujours monitorer :
- Espace disque utilisÃ© / disponible
- IOPS et throughput
- Latence I/O
- Utilisation inodes
- Ã‰tat des snapshots
```

### 4. Backup

```yaml
# âœ… StratÃ©gie 3-2-1
# 3 copies des donnÃ©es
# 2 types de stockage diffÃ©rents
# 1 copie off-site

# Exemple :
# 1. DonnÃ©es primaires (PVC)
# 2. Snapshot quotidien (mÃªme rÃ©gion)
# 3. Backup Velero (autre rÃ©gion)
```

### 5. SÃ©curitÃ©

```yaml
# âœ… Toujours chiffrer
parameters:
  encrypted: "true"  # Encryption at-rest
  kmsKeyId: "..."    # CMK pour contrÃ´le des clÃ©s

# âœ… Reclaim Policy
reclaimPolicy: Retain  # Production
reclaimPolicy: Delete  # Dev/Test uniquement

# âœ… Access Modes
accessModes:
  - ReadWriteOnce  # Jamais ReadWriteMany pour MariaDB
```

---

## âœ… Points clÃ©s Ã  retenir

- **WaitForFirstConsumer** : Utilisez ce mode pour Ã©viter les problÃ¨mes de topologie
- **StorageClass** : CrÃ©ez des classes adaptÃ©es Ã  chaque workload (IOPS, throughput)
- **Reclaim Policy** : Retain en production pour Ã©viter la perte de donnÃ©es
- **Snapshots** : Automatisez avec CronJobs pour backup rÃ©guliers
- **Expansion** : VÃ©rifiez que allowVolumeExpansion est activÃ©
- **Monitoring** : Surveillez l'espace, IOPS et latence
- **Performance** : SSD obligatoire, mount options optimisÃ©es
- **Backup** : StratÃ©gie 3-2-1 avec Velero ou Ã©quivalent
- **SÃ©curitÃ©** : Chiffrement at-rest et in-transit
- **MariaDB 11.8** : Aucune spÃ©cificitÃ© stockage, mÃªmes best practices

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Documentation officielle
- [ğŸ“– Kubernetes Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
- [ğŸ“– Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/)
- [ğŸ“– Volume Snapshots](https://kubernetes.io/docs/concepts/storage/volume-snapshots/)
- [ğŸ“– Dynamic Volume Provisioning](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/)

### CSI Drivers
- [AWS EBS CSI Driver](https://github.com/kubernetes-sigs/aws-ebs-csi-driver)
- [Azure Disk CSI Driver](https://github.com/kubernetes-sigs/azuredisk-csi-driver)
- [GCP PD CSI Driver](https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver)
- [Ceph CSI](https://github.com/ceph/ceph-csi)

### Outils
- [Velero](https://velero.io/) - Backup et migration
- [Stash](https://stash.run/) - Backup avec hooks
- [KubeDB](https://kubedb.com/) - Gestion databases avec storage

### Benchmarks
- [Kubernetes Storage Benchmark](https://github.com/yasker/kbench)
- [FIO](https://fio.readthedocs.io/) - I/O benchmarking

---

## â¡ï¸ Section suivante

**16.5 mariadb-operator pour Kubernetes** : DÃ©couvrez comment automatiser le dÃ©ploiement et la gestion de MariaDB dans Kubernetes avec l'operator pattern.

---

**MariaDB** : 11.8 LTS

â­ï¸ [mariadb-operator pour Kubernetes](/16-devops-automatisation/05-mariadb-operator.md)
