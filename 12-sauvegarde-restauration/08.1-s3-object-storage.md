ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.8.1 S3 et Object Storage

> **Niveau** : AvancÃ©  
> **DurÃ©e estimÃ©e** : 3.5 heures  
> **PrÃ©requis** : Sections 12.3 (Mariabackup), 12.5 (Restauration), connaissances AWS/cloud, CLI aws/gsutil/mc

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- Comprendre l'architecture object storage pour backups MariaDB
- Configurer AWS S3, MinIO, Google Cloud Storage pour stockage de backups
- Streamer directement les backups vers S3 (sans disque local)
- ImplÃ©menter le chiffrement cÃ´tÃ© client et serveur
- Optimiser les coÃ»ts avec lifecycle policies et storage classes
- Restaurer rapidement depuis S3 avec parallÃ©lisme
- Configurer la rÃ©plication multi-rÃ©gion pour disaster recovery
- Automatiser les backups vers S3 avec scripts robustes
- Monitorer et alerter sur les Ã©checs de backup S3
- SÃ©curiser l'accÃ¨s avec IAM policies et bucket policies

---

## Introduction

Le **Object Storage** (S3, GCS, Azure Blob, MinIO) est devenu le standard pour le stockage de backups MariaDB en production, offrant durabilitÃ©, scalabilitÃ© et coÃ»ts optimisÃ©s. Contrairement aux disques locaux, l'object storage permet une **rÃ©tention longue**, une **rÃ©plication automatique**, et une **intÃ©gration cloud-native**.

### Pourquoi Object Storage pour les backups ?

```
STOCKAGE LOCAL vs OBJECT STORAGE (S3) :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STOCKAGE LOCAL (/backups/mariadb/) :
âŒ LimitÃ© par capacitÃ© disque serveur
âŒ Pas de rÃ©plication automatique (SPOF)
âŒ Difficile Ã  gÃ©rer la rÃ©tention longue (coÃ»t)
âŒ Restauration limitÃ©e au mÃªme serveur
âŒ Pas de versioning natif
âŒ VulnÃ©rable aux sinistres locaux (incendie, panne)

OBJECT STORAGE (S3, MinIO, GCS) :
âœ… CapacitÃ© illimitÃ©e (scale infini)
âœ… RÃ©plication multi-AZ automatique (11 9s durabilitÃ©)
âœ… Lifecycle policies (archivage Glacier aprÃ¨s 30j)
âœ… Restauration depuis n'importe oÃ¹
âœ… Versioning intÃ©grÃ© (protection ransomware)
âœ… Geo-replication pour DR multi-rÃ©gion
âœ… CoÃ»t optimisÃ© (0.023$/GB/mois S3 Standard)
âœ… IntÃ©gration native cloud (AWS, GCP, Azure)
```

### Comparaison des solutions Object Storage

| Provider | Service | DurabilitÃ© | API | Cas d'usage |
|----------|---------|------------|-----|-------------|
| **AWS** | S3 | 99.999999999% | S3 API | Production cloud AWS |
| **Google Cloud** | GCS | 99.999999999% | GCS API (compatible S3) | Production GCP |
| **Azure** | Blob Storage | 99.999999999% | Azure API | Production Azure |
| **MinIO** | Self-hosted | DÃ©pend infra | S3 API | On-premise, multi-cloud |
| **Wasabi** | Hot Cloud Storage | 99.999999999% | S3 API | Alternative low-cost |
| **Backblaze B2** | B2 Cloud Storage | 99.999999% | S3-compatible | Alternative low-cost |

ğŸ’¡ **Recommandation** : AWS S3 (production cloud), MinIO (on-premise/hybrid).

---

## Architecture de backup vers S3

### Flux complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MARIADB SERVER                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. BACKUP (Mariabackup)                                        â”‚
â”‚     â”œâ”€ Option A : Local puis upload                             â”‚
â”‚     â”‚   mariabackup --backup â†’ /tmp/backup/                     â”‚
â”‚     â”‚   aws s3 cp /tmp/backup/ s3://bucket/                     â”‚
â”‚     â”‚                                                           â”‚
â”‚     â””â”€ Option B : Streaming direct (OPTIMAL) âœ…                 â”‚
â”‚         mariabackup --stream=xbstream | \                       â”‚
â”‚         gzip | \                                                â”‚
â”‚         aws s3 cp - s3://bucket/backup.xbstream.gz              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Upload HTTPS (chiffrÃ© TLS)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS S3 BUCKET : my-mariadb-backups                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“ backups/                                                    â”‚
â”‚     â”œâ”€ full/                                                    â”‚
â”‚     â”‚   â”œâ”€ 2025-12-13_full.xbstream.gz (500 GB â†’ 60 GB)         â”‚
â”‚     â”‚   â”œâ”€ 2025-12-06_full.xbstream.gz                          â”‚
â”‚     â”‚   â””â”€ ...                                                  â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”œâ”€ incremental/                                             â”‚
â”‚     â”‚   â”œâ”€ 2025-12-14_inc.xbstream.gz (6 GB)                    â”‚
â”‚     â”‚   â”œâ”€ 2025-12-15_inc.xbstream.gz (6 GB)                    â”‚
â”‚     â”‚   â””â”€ ...                                                  â”‚
â”‚     â”‚                                                           â”‚
â”‚     â””â”€ binlogs/                                                 â”‚
â”‚         â”œâ”€ 2025-12-13/mariadb-bin.000042                        â”‚
â”‚         â”œâ”€ 2025-12-14/mariadb-bin.000043                        â”‚
â”‚         â””â”€ ...                                                  â”‚
â”‚                                                                 â”‚
â”‚  âš™ï¸  Configuration :                                            â”‚
â”‚  â”œâ”€ Versioning : Enabled                                        â”‚
â”‚  â”œâ”€ Encryption : AES-256 (SSE-S3)                               â”‚
â”‚  â”œâ”€ Lifecycle : STANDARD â†’ GLACIER aprÃ¨s 30 jours               â”‚
â”‚  â””â”€ Replication : Cross-region (us-east-1 â†’ eu-west-1)          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Download (restauration)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVEUR DR / NOUVEAU SERVEUR                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  aws s3 cp s3://bucket/backup.xbstream.gz - | \                 â”‚
â”‚  gunzip | \                                                     â”‚
â”‚  mbstream -x -C /var/lib/mysql/                                 â”‚
â”‚                                                                 â”‚
â”‚  â†’ Restauration en < 30 minutes (parallÃ¨le) âœ…                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration AWS S3

### CrÃ©er un bucket S3 dÃ©diÃ©

```bash
#!/bin/bash
# create_s3_backup_bucket.sh
# CrÃ©ation bucket S3 pour backups MariaDB

set -euo pipefail

BUCKET_NAME="my-mariadb-backups-$(date +%s)"
REGION="us-east-1"

echo "ğŸ“¦ Creating S3 bucket for MariaDB backups..."

# CrÃ©er le bucket
aws s3api create-bucket \
  --bucket "$BUCKET_NAME" \
  --region "$REGION" \
  --create-bucket-configuration LocationConstraint="$REGION"

# Activer le versioning (protection ransomware)
aws s3api put-bucket-versioning \
  --bucket "$BUCKET_NAME" \
  --versioning-configuration Status=Enabled

echo "âœ… Versioning enabled"

# Activer le chiffrement par dÃ©faut (AES-256)
aws s3api put-bucket-encryption \
  --bucket "$BUCKET_NAME" \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      },
      "BucketKeyEnabled": true
    }]
  }'

echo "âœ… Encryption enabled (AES-256)"

# Bloquer l'accÃ¨s public (sÃ©curitÃ©)
aws s3api put-public-access-block \
  --bucket "$BUCKET_NAME" \
  --public-access-block-configuration \
    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"

echo "âœ… Public access blocked"

# Lifecycle policy : STANDARD â†’ GLACIER aprÃ¨s 30 jours
aws s3api put-bucket-lifecycle-configuration \
  --bucket "$BUCKET_NAME" \
  --lifecycle-configuration '{
    "Rules": [
      {
        "Id": "ArchiveOldBackups",
        "Status": "Enabled",
        "Filter": {
          "Prefix": "backups/full/"
        },
        "Transitions": [
          {
            "Days": 30,
            "StorageClass": "GLACIER"
          }
        ]
      },
      {
        "Id": "DeleteOldIncrementals",
        "Status": "Enabled",
        "Filter": {
          "Prefix": "backups/incremental/"
        },
        "Expiration": {
          "Days": 14
        }
      }
    ]
  }'

echo "âœ… Lifecycle policies configured"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… S3 bucket created: $BUCKET_NAME"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "Next steps:"
echo "  1. Configure IAM user/role for backups"
echo "  2. Test upload: aws s3 cp test.txt s3://$BUCKET_NAME/"
echo "  3. Configure backup scripts"
```

---

### IAM Policy pour backups

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "MariaDBBackupUpload",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:PutObjectAcl",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::my-mariadb-backups",
        "arn:aws:s3:::my-mariadb-backups/*"
      ]
    },
    {
      "Sid": "S3ListAllBuckets",
      "Effect": "Allow",
      "Action": [
        "s3:ListAllMyBuckets",
        "s3:GetBucketLocation"
      ],
      "Resource": "*"
    }
  ]
}
```

**Appliquer la policy** :

```bash
# CrÃ©er un utilisateur IAM dÃ©diÃ©
aws iam create-user --user-name mariadb-backup

# Attacher la policy
aws iam put-user-policy \
  --user-name mariadb-backup \
  --policy-name MariaDBBackupS3Policy \
  --policy-document file://s3-backup-policy.json

# CrÃ©er des access keys
aws iam create-access-key --user-name mariadb-backup

# Output :
# AccessKeyId: AKIAIOSFODNN7EXAMPLE
# SecretAccessKey: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

**Configurer AWS CLI sur le serveur MariaDB** :

```bash
# /root/.aws/credentials
[default]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

# /root/.aws/config
[default]
region = us-east-1
output = json
```

```bash
# Tester la configuration
aws s3 ls s3://my-mariadb-backups/

# Output attendu : (vide ou liste des objets)
```

---

## Streaming direct vers S3 (sans disque local)

### Avantages du streaming

```
BACKUP LOCAL PUIS UPLOAD :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. mariabackup --backup â†’ /tmp/backup/ (500 GB requis)
2. tar + gzip â†’ /tmp/backup.tar.gz (60 GB)
3. aws s3 cp â†’ S3
4. rm -rf /tmp/backup*

ProblÃ¨mes :
âŒ Espace disque requis : 500 GB + 60 GB = 560 GB
âŒ DurÃ©e totale : Backup (45 min) + Compress (15 min) + Upload (20 min) = 80 min
âŒ IOPS disque : 3x lectures/Ã©critures


STREAMING DIRECT :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. mariabackup --stream=xbstream | gzip | aws s3 cp - s3://...

Avantages :
âœ… Espace disque requis : 0 GB (streaming)
âœ… DurÃ©e totale : 50 min (parallÃ¨le)
âœ… IOPS disque : 1x lecture uniquement
âœ… Pas de fichiers temporaires Ã  nettoyer
```

---

### Script backup streaming vers S3

```bash
#!/bin/bash
# backup_to_s3_stream.sh
# Backup MariaDB streaming direct vers S3

set -euo pipefail

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

S3_BUCKET="my-mariadb-backups"
S3_PREFIX="backups/full"
BACKUP_TYPE="full"  # full | incremental
MARIADB_USER="mariabackup"
MARIADB_PASSWORD="${MARIADB_BACKUP_PASSWORD}"

# Noms de fichiers
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="${BACKUP_TYPE}_${DATE}.xbstream.gz"
S3_PATH="s3://${S3_BUCKET}/${S3_PREFIX}/${BACKUP_NAME}"

# Slack webhook pour notifications
SLACK_WEBHOOK_URL="${SLACK_WEBHOOK_URL:-}"

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fonctions
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

log() {
    echo "[$(date -Iseconds)] $*"
}

notify_slack() {
    local message="$1"
    local color="${2:-good}"  # good, warning, danger
    
    if [ -n "$SLACK_WEBHOOK_URL" ]; then
        curl -X POST "$SLACK_WEBHOOK_URL" \
          -H 'Content-Type: application/json' \
          -d "{
            \"attachments\": [{
              \"color\": \"$color\",
              \"text\": \"$message\",
              \"footer\": \"MariaDB Backup Bot\",
              \"ts\": $(date +%s)
            }]
          }" &>/dev/null || true
    fi
}

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Validation prÃ©-backup
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

log "ğŸ”„ Starting MariaDB backup to S3 (streaming)"
log "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# VÃ©rifier connectivitÃ© S3
if ! aws s3 ls "s3://${S3_BUCKET}/" &>/dev/null; then
    log "âŒ Cannot access S3 bucket: $S3_BUCKET"
    notify_slack "âŒ Backup FAILED: Cannot access S3 bucket" "danger"
    exit 1
fi

log "âœ… S3 bucket accessible"

# VÃ©rifier connectivitÃ© MariaDB
if ! mariadb -u "$MARIADB_USER" -p"$MARIADB_PASSWORD" -e "SELECT 1;" &>/dev/null; then
    log "âŒ Cannot connect to MariaDB"
    notify_slack "âŒ Backup FAILED: Cannot connect to MariaDB" "danger"
    exit 1
fi

log "âœ… MariaDB connection OK"

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Backup streaming
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

log "ğŸ“¦ Starting backup stream to S3..."
START_TIME=$(date +%s)

# Streaming : mariabackup â†’ gzip â†’ S3
mariabackup \
  --backup \
  --stream=xbstream \
  --user="$MARIADB_USER" \
  --password="$MARIADB_PASSWORD" \
  --parallel=8 \
  --compress \
  --compress-threads=8 2>&1 | \
  tee >(logger -t mariabackup) | \
  aws s3 cp - "$S3_PATH" \
    --expected-size 64424509440 \
    --storage-class STANDARD

BACKUP_STATUS=${PIPESTATUS[0]}
UPLOAD_STATUS=${PIPESTATUS[1]}

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VÃ©rification et rÃ©sultats
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if [ $BACKUP_STATUS -ne 0 ] || [ $UPLOAD_STATUS -ne 0 ]; then
    log "âŒ Backup FAILED"
    log "  - Mariabackup exit code: $BACKUP_STATUS"
    log "  - AWS S3 exit code: $UPLOAD_STATUS"
    
    notify_slack "âŒ Backup FAILED\nDuration: ${DURATION}s\nBackup: $BACKUP_STATUS\nUpload: $UPLOAD_STATUS" "danger"
    exit 1
fi

# VÃ©rifier que le fichier existe sur S3
if ! aws s3 ls "$S3_PATH" &>/dev/null; then
    log "âŒ Backup file not found on S3: $S3_PATH"
    notify_slack "âŒ Backup FAILED: File not found on S3" "danger"
    exit 1
fi

# Obtenir la taille du backup
BACKUP_SIZE=$(aws s3 ls "$S3_PATH" | awk '{print $3}')
BACKUP_SIZE_GB=$(echo "scale=2; $BACKUP_SIZE / 1024 / 1024 / 1024" | bc)

log "âœ… Backup completed successfully"
log "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
log "ğŸ“Š Summary:"
log "  - Duration: ${DURATION}s ($(($DURATION / 60))min)"
log "  - Size: ${BACKUP_SIZE_GB} GB"
log "  - Location: $S3_PATH"
log "  - Type: $BACKUP_TYPE"

notify_slack "âœ… Backup SUCCESS\nDuration: ${DURATION}s\nSize: ${BACKUP_SIZE_GB} GB\nLocation: $S3_PATH" "good"

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MÃ©triques Prometheus (optionnel)
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

cat > /var/lib/node_exporter/textfile_collector/mariadb_backup.prom <<EOF
# HELP mariadb_backup_duration_seconds Duration of the backup in seconds
# TYPE mariadb_backup_duration_seconds gauge
mariadb_backup_duration_seconds{type="$BACKUP_TYPE"} $DURATION

# HELP mariadb_backup_size_bytes Size of the backup in bytes
# TYPE mariadb_backup_size_bytes gauge
mariadb_backup_size_bytes{type="$BACKUP_TYPE"} $BACKUP_SIZE

# HELP mariadb_backup_timestamp_seconds Unix timestamp of the backup
# TYPE mariadb_backup_timestamp_seconds gauge
mariadb_backup_timestamp_seconds{type="$BACKUP_TYPE"} $END_TIME

# HELP mariadb_backup_success Success status of the backup (1=success, 0=failure)
# TYPE mariadb_backup_success gauge
mariadb_backup_success{type="$BACKUP_TYPE"} 1
EOF

log "âœ… Prometheus metrics updated"

exit 0
```

**Utilisation** :

```bash
# Variables d'environnement
export MARIADB_BACKUP_PASSWORD="SecurePassword123!"
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/XXX/YYY/ZZZ"

# ExÃ©cution
./backup_to_s3_stream.sh

# Output :
# [2025-12-13T15:00:00+01:00] ğŸ”„ Starting MariaDB backup to S3 (streaming)
# [2025-12-13T15:00:01+01:00] âœ… S3 bucket accessible
# [2025-12-13T15:00:02+01:00] âœ… MariaDB connection OK
# [2025-12-13T15:00:02+01:00] ğŸ“¦ Starting backup stream to S3...
# ... (45 minutes) ...
# [2025-12-13T15:45:23+01:00] âœ… Backup completed successfully
# [2025-12-13T15:45:23+01:00] ğŸ“Š Summary:
#   - Duration: 2721s (45min)
#   - Size: 62.34 GB
#   - Location: s3://my-mariadb-backups/backups/full/full_20251213_150000.xbstream.gz
```

---

## Restauration depuis S3

### TÃ©lÃ©chargement parallÃ¨le avec aws s3 cp

```bash
#!/bin/bash
# restore_from_s3.sh
# Restauration MariaDB depuis S3

set -euo pipefail

S3_PATH="${1:-}"
DATADIR="/var/lib/mysql"
TEMP_DIR="/tmp/mariadb_restore_$(date +%s)"

if [ -z "$S3_PATH" ]; then
    echo "Usage: $0 s3://bucket/path/to/backup.xbstream.gz"
    exit 1
fi

echo "ğŸ”„ MariaDB restore from S3"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  Source: $S3_PATH"
echo ""

# Ã‰tape 1 : CrÃ©er rÃ©pertoire temporaire
mkdir -p "$TEMP_DIR"

# Ã‰tape 2 : TÃ©lÃ©charger et extraire en streaming
echo "ğŸ“¥ Downloading and extracting backup..."
START_TIME=$(date +%s)

aws s3 cp "$S3_PATH" - | \
  gunzip | \
  mbstream -x -C "$TEMP_DIR"

DOWNLOAD_STATUS=$?
END_TIME=$(date +%s)
DOWNLOAD_DURATION=$((END_TIME - START_TIME))

if [ $DOWNLOAD_STATUS -ne 0 ]; then
    echo "âŒ Download/extract FAILED"
    rm -rf "$TEMP_DIR"
    exit 1
fi

echo "âœ… Downloaded in ${DOWNLOAD_DURATION}s"

# Ã‰tape 3 : PrÃ©parer le backup
echo ""
echo "ğŸ”§ Preparing backup..."
START_TIME=$(date +%s)

mariabackup --prepare --target-dir="$TEMP_DIR"

PREPARE_STATUS=$?
END_TIME=$(date +%s)
PREPARE_DURATION=$((END_TIME - START_TIME))

if [ $PREPARE_STATUS -ne 0 ]; then
    echo "âŒ Backup preparation FAILED"
    rm -rf "$TEMP_DIR"
    exit 1
fi

echo "âœ… Prepared in ${PREPARE_DURATION}s"

# Ã‰tape 4 : ArrÃªter MariaDB
echo ""
echo "â¸ï¸  Stopping MariaDB..."
systemctl stop mariadb

# Ã‰tape 5 : Sauvegarder ancien datadir
echo ""
echo "ğŸ’¾ Backing up old datadir..."
mv "$DATADIR" "${DATADIR}_old_$(date +%s)"
mkdir -p "$DATADIR"

# Ã‰tape 6 : Copier le backup
echo ""
echo "ğŸ“‹ Copying backup to datadir..."
START_TIME=$(date +%s)

mariabackup --copy-back --target-dir="$TEMP_DIR" --datadir="$DATADIR"

COPY_STATUS=$?
END_TIME=$(date +%s)
COPY_DURATION=$((END_TIME - START_TIME))

if [ $COPY_STATUS -ne 0 ]; then
    echo "âŒ Copy-back FAILED"
    exit 1
fi

echo "âœ… Copied in ${COPY_DURATION}s"

# Ã‰tape 7 : Permissions
echo ""
echo "ğŸ”’ Fixing permissions..."
chown -R mysql:mysql "$DATADIR"

# Ã‰tape 8 : DÃ©marrer MariaDB
echo ""
echo "â–¶ï¸  Starting MariaDB..."
systemctl start mariadb

sleep 5

if systemctl is-active --quiet mariadb; then
    echo "âœ… MariaDB started successfully"
else
    echo "âŒ MariaDB failed to start"
    exit 1
fi

# Ã‰tape 9 : Nettoyage
echo ""
echo "ğŸ§¹ Cleaning up..."
rm -rf "$TEMP_DIR"

TOTAL_DURATION=$((DOWNLOAD_DURATION + PREPARE_DURATION + COPY_DURATION))

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Restore completed successfully"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸ“Š Summary:"
echo "  - Download: ${DOWNLOAD_DURATION}s"
echo "  - Prepare: ${PREPARE_DURATION}s"
echo "  - Copy: ${COPY_DURATION}s"
echo "  - Total: ${TOTAL_DURATION}s ($(($TOTAL_DURATION / 60))min)"
```

**Utilisation** :

```bash
./restore_from_s3.sh s3://my-mariadb-backups/backups/full/full_20251213_150000.xbstream.gz

# RTO typique : 25-40 minutes (500 GB database)
```

---

## Chiffrement et sÃ©curitÃ©

### Chiffrement cÃ´tÃ© serveur (SSE-S3)

**Activation par dÃ©faut** (dÃ©jÃ  fait dans la crÃ©ation du bucket) :

```bash
aws s3api put-bucket-encryption \
  --bucket my-mariadb-backups \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      },
      "BucketKeyEnabled": true
    }]
  }'
```

ğŸ’¡ **Transparent** : Aucune modification nÃ©cessaire dans les scripts de backup.

---

### Chiffrement cÃ´tÃ© client (avant upload)

```bash
#!/bin/bash
# backup_to_s3_encrypted.sh
# Backup avec chiffrement cÃ´tÃ© client (AES-256)

set -euo pipefail

S3_PATH="s3://my-mariadb-backups/backups/full/encrypted_$(date +%Y%m%d).xbstream.gz.enc"
ENCRYPTION_KEY="/etc/mariadb/backup_encryption.key"

# GÃ©nÃ©rer une clÃ© si elle n'existe pas
if [ ! -f "$ENCRYPTION_KEY" ]; then
    openssl rand -base64 32 > "$ENCRYPTION_KEY"
    chmod 600 "$ENCRYPTION_KEY"
    echo "ğŸ”‘ Encryption key generated: $ENCRYPTION_KEY"
fi

echo "ğŸ”’ Backup with client-side encryption (AES-256)"

# Backup â†’ Compress â†’ Encrypt â†’ S3
mariabackup \
  --backup \
  --stream=xbstream \
  --parallel=8 | \
  gzip | \
  openssl enc -aes-256-cbc -salt -pbkdf2 -pass file:"$ENCRYPTION_KEY" | \
  aws s3 cp - "$S3_PATH"

echo "âœ… Encrypted backup uploaded to S3"
```

**Restauration** :

```bash
#!/bin/bash
# restore_from_s3_encrypted.sh

S3_PATH="$1"
ENCRYPTION_KEY="/etc/mariadb/backup_encryption.key"

aws s3 cp "$S3_PATH" - | \
  openssl enc -aes-256-cbc -d -pbkdf2 -pass file:"$ENCRYPTION_KEY" | \
  gunzip | \
  mbstream -x -C /tmp/restore/
```

âš ï¸ **CRITIQUE** : Stocker la clÃ© de chiffrement dans un **vault sÃ©curisÃ©** (AWS Secrets Manager, HashiCorp Vault) et **jamais** dans Git.

---

## Lifecycle Policies et optimisation des coÃ»ts

### Storage Classes AWS S3

| Storage Class | DurabilitÃ© | DisponibilitÃ© | CoÃ»t ($/GB/mois) | Use case |
|---------------|------------|---------------|------------------|----------|
| **STANDARD** | 99.999999999% | 99.99% | 0.023 | Backups rÃ©cents (< 30j) |
| **STANDARD_IA** | 99.999999999% | 99.9% | 0.0125 | Backups 30-90 jours |
| **GLACIER** | 99.999999999% | 99.99% | 0.004 | Archives longue durÃ©e |
| **DEEP_ARCHIVE** | 99.999999999% | 99.99% | 0.00099 | Archives > 1 an |

ğŸ’¡ **Ã‰conomies** : STANDARD (30j) â†’ GLACIER = **83% de rÃ©duction** des coÃ»ts.

---

### Lifecycle Policy complÃ¨te

```json
{
  "Rules": [
    {
      "Id": "FullBackupLifecycle",
      "Status": "Enabled",
      "Filter": {
        "Prefix": "backups/full/"
      },
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        },
        {
          "Days": 365,
          "StorageClass": "DEEP_ARCHIVE"
        }
      ],
      "Expiration": {
        "Days": 2555
      },
      "NoncurrentVersionExpiration": {
        "NoncurrentDays": 30
      }
    },
    {
      "Id": "IncrementalBackupLifecycle",
      "Status": "Enabled",
      "Filter": {
        "Prefix": "backups/incremental/"
      },
      "Expiration": {
        "Days": 14
      }
    },
    {
      "Id": "BinlogLifecycle",
      "Status": "Enabled",
      "Filter": {
        "Prefix": "backups/binlogs/"
      },
      "Transitions": [
        {
          "Days": 7,
          "StorageClass": "STANDARD_IA"
        }
      ],
      "Expiration": {
        "Days": 30
      }
    }
  ]
}
```

```bash
# Appliquer la policy
aws s3api put-bucket-lifecycle-configuration \
  --bucket my-mariadb-backups \
  --lifecycle-configuration file://lifecycle-policy.json
```

**RÃ©sultat** :
- Jour 0-30 : STANDARD (rapide Ã  restaurer)
- Jour 30-90 : STANDARD_IA (Ã©conomies 46%)
- Jour 90-365 : GLACIER (Ã©conomies 83%)
- Jour 365+ : DEEP_ARCHIVE (Ã©conomies 96%)
- Jour 2555 : Suppression automatique (7 ans)

---

### Calcul des coÃ»ts

**Exemple : Base 500 GB, backup quotidien, rÃ©tention 1 an**

```
StratÃ©gie STANDARD uniquement :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
500 GB Ã— 365 jours Ã— 0.023 $/GB/mois Ã· 30 = 140 $/mois
CoÃ»t annuel : 1680 $


StratÃ©gie avec Lifecycle :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Mois 1 (STANDARD) : 500 GB Ã— 0.023 = 11.50 $
Mois 2-3 (STANDARD_IA) : 1000 GB Ã— 0.0125 = 12.50 $
Mois 4-12 (GLACIER) : 4500 GB Ã— 0.004 = 18.00 $

CoÃ»t annuel : (11.50 + 12.50 + 18.00) Ã— 12 = 504 $

Ã‰conomies : 1680 - 504 = 1176 $ /an (70% de rÃ©duction) âœ…
```

---

## RÃ©plication multi-rÃ©gion (Disaster Recovery)

### Configuration Cross-Region Replication (CRR)

```bash
#!/bin/bash
# setup_cross_region_replication.sh
# RÃ©plication S3 cross-region pour DR

SOURCE_BUCKET="my-mariadb-backups-us-east-1"
DEST_BUCKET="my-mariadb-backups-eu-west-1"
REPLICATION_ROLE="arn:aws:iam::123456789012:role/S3ReplicationRole"

# CrÃ©er le bucket de destination
aws s3api create-bucket \
  --bucket "$DEST_BUCKET" \
  --region eu-west-1 \
  --create-bucket-configuration LocationConstraint=eu-west-1

# Activer versioning (requis pour CRR)
aws s3api put-bucket-versioning \
  --bucket "$DEST_BUCKET" \
  --versioning-configuration Status=Enabled

# Configuration de la rÃ©plication
aws s3api put-bucket-replication \
  --bucket "$SOURCE_BUCKET" \
  --replication-configuration '{
    "Role": "'"$REPLICATION_ROLE"'",
    "Rules": [
      {
        "Status": "Enabled",
        "Priority": 1,
        "Filter": {
          "Prefix": "backups/"
        },
        "Destination": {
          "Bucket": "arn:aws:s3:::'"$DEST_BUCKET"'",
          "ReplicationTime": {
            "Status": "Enabled",
            "Time": {
              "Minutes": 15
            }
          },
          "Metrics": {
            "Status": "Enabled",
            "EventThreshold": {
              "Minutes": 15
            }
          },
          "StorageClass": "STANDARD_IA"
        },
        "DeleteMarkerReplication": {
          "Status": "Enabled"
        }
      }
    ]
  }'

echo "âœ… Cross-region replication configured"
echo "  Source: $SOURCE_BUCKET (us-east-1)"
echo "  Destination: $DEST_BUCKET (eu-west-1)"
echo "  RTO: < 15 minutes"
```

**RÃ©sultat** :
- Backup vers `us-east-1` (rÃ©gion primaire)
- RÃ©plication automatique vers `eu-west-1` (rÃ©gion DR)
- RTO en cas de sinistre rÃ©gional : < 15 minutes

---

## Configuration MinIO (On-Premise)

### Installation MinIO

```bash
#!/bin/bash
# install_minio.sh
# Installation MinIO server (S3-compatible on-premise)

# TÃ©lÃ©charger MinIO
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
mv minio /usr/local/bin/

# CrÃ©er rÃ©pertoire de stockage
mkdir -p /mnt/minio-data

# CrÃ©er utilisateur systÃ¨me
useradd -r -s /sbin/nologin minio

# Permissions
chown -R minio:minio /mnt/minio-data

# Systemd service
cat > /etc/systemd/system/minio.service <<'EOF'
[Unit]
Description=MinIO Object Storage
After=network.target

[Service]
Type=notify
User=minio
Group=minio
Environment="MINIO_ROOT_USER=admin"
Environment="MINIO_ROOT_PASSWORD=SecureMinIOPassword123!"
ExecStart=/usr/local/bin/minio server /mnt/minio-data --console-address ":9001"
Restart=always
LimitNOFILE=65536
TasksMax=infinity

[Install]
WantedBy=multi-user.target
EOF

# DÃ©marrer MinIO
systemctl daemon-reload
systemctl enable minio
systemctl start minio

echo "âœ… MinIO installed and started"
echo "  Web UI: http://localhost:9001"
echo "  API: http://localhost:9000"
```

---

### Configuration AWS CLI pour MinIO

```bash
# ~/.aws/config
[profile minio]
region = us-east-1
output = json

# ~/.aws/credentials
[minio]
aws_access_key_id = admin
aws_secret_access_key = SecureMinIOPassword123!
```

```bash
# CrÃ©er un bucket sur MinIO
aws s3 mb s3://mariadb-backups \
  --endpoint-url http://localhost:9000 \
  --profile minio

# Lister les buckets
aws s3 ls \
  --endpoint-url http://localhost:9000 \
  --profile minio
```

---

### Backup vers MinIO

```bash
#!/bin/bash
# backup_to_minio.sh

MINIO_ENDPOINT="http://minio.internal.example.com:9000"
MINIO_BUCKET="mariadb-backups"
BACKUP_NAME="full_$(date +%Y%m%d).xbstream.gz"

mariabackup \
  --backup \
  --stream=xbstream \
  --parallel=8 | \
  gzip | \
  aws s3 cp - "s3://${MINIO_BUCKET}/backups/${BACKUP_NAME}" \
    --endpoint-url "$MINIO_ENDPOINT" \
    --profile minio

echo "âœ… Backup uploaded to MinIO"
```

---

## Monitoring et alerting

### CloudWatch Metrics pour S3

```bash
#!/bin/bash
# monitor_s3_backups.sh
# Envoyer mÃ©triques CloudWatch

NAMESPACE="MariaDB/Backups"
BUCKET="my-mariadb-backups"

# Compter le nombre de backups
BACKUP_COUNT=$(aws s3 ls s3://${BUCKET}/backups/full/ | wc -l)

# Taille totale des backups
TOTAL_SIZE=$(aws s3 ls s3://${BUCKET}/backups/full/ --recursive | \
  awk '{sum+=$3} END {print sum}')

# Publier mÃ©triques
aws cloudwatch put-metric-data \
  --namespace "$NAMESPACE" \
  --metric-name BackupCount \
  --value "$BACKUP_COUNT" \
  --unit Count

aws cloudwatch put-metric-data \
  --namespace "$NAMESPACE" \
  --metric-name TotalBackupSize \
  --value "$TOTAL_SIZE" \
  --unit Bytes

echo "âœ… CloudWatch metrics published"
```

---

### Alerting SNS

```bash
#!/bin/bash
# Alerting en cas d'Ã©chec de backup

SNS_TOPIC_ARN="arn:aws:sns:us-east-1:123456789012:mariadb-backup-alerts"

if [ $BACKUP_STATUS -ne 0 ]; then
    aws sns publish \
      --topic-arn "$SNS_TOPIC_ARN" \
      --subject "âŒ MariaDB Backup FAILED" \
      --message "Backup to S3 failed at $(date -Iseconds)\nExit code: $BACKUP_STATUS"
fi
```

---

## âœ… Points clÃ©s Ã  retenir

- **Object Storage** (S3/MinIO) = Standard moderne pour backups MariaDB
- **Streaming direct** : 0 GB disque local requis (vs 500+ GB backup local)
- **DurabilitÃ© S3** : 99.999999999% (11 9s) avec rÃ©plication multi-AZ
- **Lifecycle policies** : 70-90% Ã©conomies (STANDARD â†’ GLACIER â†’ DEEP_ARCHIVE)
- **Chiffrement** : SSE-S3 transparent, SSE-C pour contrÃ´le clÃ© client
- **Cross-Region Replication** : DR automatique multi-rÃ©gion (RTO < 15 min)
- **Versioning** : Protection ransomware (restaurer versions antÃ©rieures)
- **IAM Policies** : AccÃ¨s minimum nÃ©cessaire (principe du moindre privilÃ¨ge)
- **MinIO** : Alternative on-premise S3-compatible (hybrid/multi-cloud)
- **RTO depuis S3** : 25-40 min (500 GB database, streaming parallÃ¨le)

---

## ğŸ”— Ressources et rÃ©fÃ©rences

- ğŸ“– [AWS S3 Documentation](https://docs.aws.amazon.com/s3/)
- ğŸ“– [S3 Storage Classes](https://aws.amazon.com/s3/storage-classes/)
- ğŸ“– [S3 Lifecycle Policies](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)
- ğŸ“– [MinIO Documentation](https://min.io/docs/minio/linux/index.html)
- ğŸ› ï¸ [AWS CLI S3 Commands](https://docs.aws.amazon.com/cli/latest/reference/s3/)
- ğŸ’° [S3 Pricing Calculator](https://calculator.aws/)

---

## â¡ï¸ Section suivante

**12.8.2 Kubernetes VolumeSnapshots** : Backups natifs Kubernetes avec CSI snapshots, restauration automatique de PVC, intÃ©gration CI/CD, et stratÃ©gies cloud-native pour bases de donnÃ©es conteneurisÃ©es.

â­ï¸ [Kubernetes VolumeSnapshots](/12-sauvegarde-restauration/08.2-kubernetes-volumesnapshots.md)
