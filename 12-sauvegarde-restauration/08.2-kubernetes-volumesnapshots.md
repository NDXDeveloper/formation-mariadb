ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 12.8.2 Kubernetes VolumeSnapshots

> **Niveau** : AvancÃ©  
> **DurÃ©e estimÃ©e** : 4 heures  
> **PrÃ©requis** : Section 12.8.1 (S3), connaissances Kubernetes (StatefulSets, PVC, StorageClass), CSI drivers

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- Comprendre l'architecture CSI VolumeSnapshot pour backups cloud-native
- Configurer les VolumeSnapshotClass pour diffÃ©rents providers (AWS, GCP, Azure)
- CrÃ©er des snapshots de volumes MariaDB avec cohÃ©rence applicative
- Restaurer des PVC depuis des snapshots en quelques minutes
- Automatiser les snapshots avec CronJobs et Velero
- Combiner VolumeSnapshots et binary logs pour PITR complet
- ImplÃ©menter des stratÃ©gies de rÃ©tention automatiques
- GÃ©rer le disaster recovery multi-cluster avec cross-region snapshots
- Monitorer et alerter sur les Ã©checs de snapshot
- Optimiser les coÃ»ts de stockage snapshot

---

## Introduction

Les **VolumeSnapshots Kubernetes** sont une fonctionnalitÃ© CSI (Container Storage Interface) permettant de crÃ©er des **copies point-in-time** de PersistentVolumeClaims. Pour MariaDB, cela offre des backups **instantanÃ©s** (< 1 seconde), **cohÃ©rents**, et **cloud-native**, s'intÃ©grant parfaitement aux workflows Kubernetes.

### Pourquoi VolumeSnapshots pour MariaDB ?

```
BACKUP TRADITIONNEL (Mariabackup â†’ S3) :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. CronJob lance mariabackup
2. Lecture complÃ¨te du datadir (500 GB)
3. Compression (CPU intensif)
4. Upload vers S3 (rÃ©seau)
5. DurÃ©e totale : 45-60 minutes
6. Impact I/O : Ã‰levÃ©

VOLUMESNAPSHOT (CSI) :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Appel API VolumeSnapshot
2. Provider (AWS EBS, GCP PD) crÃ©e snapshot
3. Snapshot COW (Copy-on-Write) au niveau bloc
4. DurÃ©e totale : < 1 seconde (crÃ©ation) âœ…
5. Impact I/O : Nul (snapshot storage-level)
6. RTO restauration : 2-5 minutes (vs 30-60 min)

RÃ©sultat :
âœ… Backup instantanÃ© (< 1s vs 45 min)
âœ… Pas d'impact I/O sur production
âœ… RTO rÃ©duit de 90% (5 min vs 60 min)
âœ… Natif cloud (pas de tooling externe)
âœ… IntÃ©gration GitOps (manifests YAML)
```

### Comparaison mÃ©thodes de backup Kubernetes

| MÃ©thode | DurÃ©e backup | RTO restore | Impact prod | GranularitÃ© | CoÃ»t storage |
|---------|--------------|-------------|-------------|-------------|--------------|
| **Mariabackup â†’ S3** | 45-60 min | 30-60 min | Moyen (I/O) | Fichier | Faible (S3) |
| **mysqldump â†’ S3** | 2-6h | 3-8h | Ã‰levÃ© (CPU) | Logique | TrÃ¨s faible |
| **VolumeSnapshot** | < 1s | 2-5 min | Nul | Bloc | Moyen (snapshot) |
| **Velero + CSI** | < 1s | 2-5 min | Nul | Bloc + metadata | Moyen |

ğŸ’¡ **Recommandation** : VolumeSnapshot (production) + Mariabackup S3 (offsite, long terme).

---

## Architecture CSI VolumeSnapshot

### Composants Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KUBERNETES CLUSTER                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“¦ MARIADB POD (StatefulSet)                                   â”‚
â”‚     â””â”€ Container : mariadb:11.8                                 â”‚
â”‚        â””â”€ Volume mount : /var/lib/mysql                         â”‚
â”‚           â””â”€ PVC : mariadb-data-pvc (500Gi)                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ CSI Driver
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSI DRIVER (aws-ebs-csi-driver, gce-pd-csi-driver, etc.)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  VolumeSnapshotClass : mariadb-snapshot-class                   â”‚
â”‚  â”œâ”€ Driver : ebs.csi.aws.com                                    â”‚
â”‚  â”œâ”€ DeletionPolicy : Retain                                     â”‚
â”‚  â””â”€ Parameters :                                                â”‚
â”‚      â””â”€ type : gp3                                              â”‚
â”‚                                                                 â”‚
â”‚  VolumeSnapshot : mariadb-snapshot-20251213                     â”‚
â”‚  â”œâ”€ Source : mariadb-data-pvc                                   â”‚
â”‚  â”œâ”€ VolumeSnapshotClass : mariadb-snapshot-class                â”‚
â”‚  â””â”€ Status : Ready (< 1 seconde)                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Snapshot API
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLOUD PROVIDER STORAGE                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  AWS EBS Snapshot : snap-0abc1234def56789                       â”‚
â”‚  â”œâ”€ Volume : vol-0123456789abcdef0                              â”‚
â”‚  â”œâ”€ Size : 500 GiB                                              â”‚
â”‚  â”œâ”€ Type : Incremental (delta depuis dernier snapshot)          â”‚
â”‚  â”œâ”€ CrÃ©ation : < 1 seconde                                      â”‚
â”‚  â”œâ”€ DurabilitÃ© : 99.999999999%                                  â”‚
â”‚  â””â”€ CoÃ»t : 0.05 $/GB/mois (stockage snapshot)                   â”‚
â”‚                                                                 â”‚
â”‚  Restauration :                                                 â”‚
â”‚  â””â”€ CrÃ©er nouveau volume depuis snapshot (2-5 minutes)          â”‚
â”‚     â””â”€ Attacher au nouveau PVC                                  â”‚
â”‚        â””â”€ Pod MariaDB redÃ©marre avec volume restaurÃ© âœ…         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration initiale

### VÃ©rifier le support VolumeSnapshot

```bash
# VÃ©rifier que les CRDs VolumeSnapshot sont installÃ©s
kubectl get crd | grep snapshot

# Output attendu :
# volumesnapshotclasses.snapshot.storage.k8s.io
# volumesnapshotcontents.snapshot.storage.k8s.io
# volumesnapshots.snapshot.storage.k8s.io
```

**Si absents** (Kubernetes < 1.20) :

```bash
# Installer les CRDs VolumeSnapshot
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml

# Installer le snapshot-controller
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml
```

---

### Configuration AWS EBS CSI Driver

```yaml
# volumesnapshotclass-aws.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: mariadb-snapshot-class
  annotations:
    snapshot.storage.kubernetes.io/is-default-class: "true"
driver: ebs.csi.aws.com
deletionPolicy: Retain  # Retain | Delete
parameters:
  # Aucun paramÃ¨tre nÃ©cessaire pour EBS
  # Les snapshots EBS sont automatiquement incrementaux
```

```bash
# Appliquer la VolumeSnapshotClass
kubectl apply -f volumesnapshotclass-aws.yaml

# VÃ©rifier
kubectl get volumesnapshotclass
# NAME                      DRIVER            DELETIONPOLICY   AGE
# mariadb-snapshot-class    ebs.csi.aws.com   Retain           5s
```

---

### Configuration GCP Persistent Disk CSI Driver

```yaml
# volumesnapshotclass-gcp.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: mariadb-snapshot-class-gcp
driver: pd.csi.storage.gke.io
deletionPolicy: Retain
parameters:
  storage-locations: us-central1  # RÃ©gion du snapshot
  snapshot-type: pd-standard      # pd-standard | pd-ssd
```

---

### Configuration Azure Disk CSI Driver

```yaml
# volumesnapshotclass-azure.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: mariadb-snapshot-class-azure
driver: disk.csi.azure.com
deletionPolicy: Retain
parameters:
  incremental: "true"  # Snapshots incrÃ©mentiels
```

---

## CrÃ©ation de snapshots

### Snapshot manuel (test)

```yaml
# mariadb-snapshot-manual.yaml
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: mariadb-snapshot-20251213
  namespace: databases
spec:
  volumeSnapshotClassName: mariadb-snapshot-class
  source:
    persistentVolumeClaimName: mariadb-data-pvc
```

```bash
# CrÃ©er le snapshot
kubectl apply -f mariadb-snapshot-manual.yaml -n databases

# Suivre la crÃ©ation (quasi-instantanÃ©e)
kubectl get volumesnapshot -n databases -w

# Output :
# NAME                        READYTOUSE   SOURCEPVC           RESTORESIZE   SNAPSHOTCONTENT                                    CREATIONTIME   AGE
# mariadb-snapshot-20251213   false        mariadb-data-pvc                  snapcontent-abc123...                              0s             0s
# mariadb-snapshot-20251213   true         mariadb-data-pvc    500Gi         snapcontent-abc123...                              3s             3s

# VÃ©rifier les dÃ©tails
kubectl describe volumesnapshot mariadb-snapshot-20251213 -n databases
```

---

### Snapshot avec cohÃ©rence applicative (flush + lock)

âš ï¸ **Important** : VolumeSnapshot capture l'Ã©tat disque au moment T, mais pas nÃ©cessairement cohÃ©rent avec MariaDB.

**Solution** : Flush + lock avant snapshot.

```yaml
# mariadb-snapshot-job.yaml
# Job Kubernetes pour snapshot cohÃ©rent
apiVersion: batch/v1
kind: Job
metadata:
  name: mariadb-snapshot-coherent
  namespace: databases
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: snapshot-creator
        image: bitnami/kubectl:latest
        env:
        - name: PVC_NAME
          value: "mariadb-data-pvc"
        - name: NAMESPACE
          value: "databases"
        - name: SNAPSHOT_NAME
          value: "mariadb-snapshot-$(date +%Y%m%d-%H%M%S)"
        command:
        - /bin/bash
        - -c
        - |
          set -euo pipefail
          
          echo "ğŸ”’ Step 1: Flush MariaDB tables"
          kubectl exec -n $NAMESPACE mariadb-0 -- \
            mariadb -u root -p$MARIADB_ROOT_PASSWORD \
            -e "FLUSH TABLES WITH READ LOCK; SYSTEM sleep 5;"
          
          echo "ğŸ“¸ Step 2: Create VolumeSnapshot"
          cat <<EOF | kubectl apply -f -
          apiVersion: snapshot.storage.k8s.io/v1
          kind: VolumeSnapshot
          metadata:
            name: $SNAPSHOT_NAME
            namespace: $NAMESPACE
          spec:
            volumeSnapshotClassName: mariadb-snapshot-class
            source:
              persistentVolumeClaimName: $PVC_NAME
          EOF
          
          echo "â³ Step 3: Wait for snapshot ready"
          kubectl wait --for=condition=ready \
            volumesnapshot/$SNAPSHOT_NAME \
            -n $NAMESPACE \
            --timeout=60s
          
          echo "ğŸ”“ Step 4: Unlock MariaDB tables"
          kubectl exec -n $NAMESPACE mariadb-0 -- \
            mariadb -u root -p$MARIADB_ROOT_PASSWORD \
            -e "UNLOCK TABLES;"
          
          echo "âœ… Snapshot created: $SNAPSHOT_NAME"
      serviceAccountName: mariadb-backup-sa
```

**ServiceAccount et RBAC** :

```yaml
# mariadb-backup-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mariadb-backup-sa
  namespace: databases
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: mariadb-backup-role
  namespace: databases
rules:
- apiGroups: ["snapshot.storage.k8s.io"]
  resources: ["volumesnapshots"]
  verbs: ["create", "get", "list", "delete"]
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mariadb-backup-binding
  namespace: databases
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: mariadb-backup-role
subjects:
- kind: ServiceAccount
  name: mariadb-backup-sa
  namespace: databases
```

---

## Automatisation avec CronJobs

### CronJob snapshots quotidiens

```yaml
# mariadb-snapshot-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mariadb-daily-snapshot
  namespace: databases
spec:
  schedule: "0 2 * * *"  # Tous les jours Ã  2h du matin
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          serviceAccountName: mariadb-backup-sa
          containers:
          - name: snapshot-creator
            image: bitnami/kubectl:latest
            env:
            - name: PVC_NAME
              value: "mariadb-data-pvc"
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: MARIADB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mariadb-secret
                  key: mariadb-root-password
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: slack-webhook
                  key: url
            command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              
              SNAPSHOT_NAME="mariadb-snapshot-$(date +%Y%m%d-%H%M%S)"
              
              echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
              echo "ğŸ”„ MariaDB Daily Snapshot"
              echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
              echo "  Snapshot: $SNAPSHOT_NAME"
              echo "  PVC: $PVC_NAME"
              echo "  Namespace: $NAMESPACE"
              echo ""
              
              # Fonction notification Slack
              notify_slack() {
                local message="$1"
                local color="${2:-good}"
                
                if [ -n "$SLACK_WEBHOOK_URL" ]; then
                  curl -X POST "$SLACK_WEBHOOK_URL" \
                    -H 'Content-Type: application/json' \
                    -d "{
                      \"attachments\": [{
                        \"color\": \"$color\",
                        \"text\": \"$message\",
                        \"footer\": \"MariaDB Snapshot Bot\",
                        \"ts\": $(date +%s)
                      }]
                    }" || true
                fi
              }
              
              # Step 1 : Flush tables
              echo "ğŸ”’ Step 1: Flushing MariaDB tables..."
              
              kubectl exec mariadb-0 -n $NAMESPACE -- \
                mariadb -u root -p$MARIADB_ROOT_PASSWORD \
                -e "FLUSH TABLES WITH READ LOCK; SELECT SLEEP(3); UNLOCK TABLES;" &
              
              FLUSH_PID=$!
              sleep 2  # Attendre que le FTWRL soit actif
              
              # Step 2 : CrÃ©er snapshot
              echo "ğŸ“¸ Step 2: Creating VolumeSnapshot..."
              
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: $SNAPSHOT_NAME
                namespace: $NAMESPACE
                labels:
                  app: mariadb
                  type: daily
                  created-by: cronjob
              spec:
                volumeSnapshotClassName: mariadb-snapshot-class
                source:
                  persistentVolumeClaimName: $PVC_NAME
              EOF
              
              # Attendre fin du flush
              wait $FLUSH_PID
              
              # Step 3 : Attendre snapshot ready
              echo "â³ Step 3: Waiting for snapshot ready..."
              
              if ! kubectl wait --for=condition=ready \
                volumesnapshot/$SNAPSHOT_NAME \
                -n $NAMESPACE \
                --timeout=120s; then
                
                echo "âŒ Snapshot creation FAILED"
                notify_slack "âŒ MariaDB snapshot FAILED\nSnapshot: $SNAPSHOT_NAME" "danger"
                exit 1
              fi
              
              # Step 4 : RÃ©cupÃ©rer infos snapshot
              SNAPSHOT_SIZE=$(kubectl get volumesnapshot $SNAPSHOT_NAME -n $NAMESPACE -o jsonpath='{.status.restoreSize}')
              SNAPSHOT_CONTENT=$(kubectl get volumesnapshot $SNAPSHOT_NAME -n $NAMESPACE -o jsonpath='{.status.boundVolumeSnapshotContentName}')
              
              echo "âœ… Snapshot created successfully"
              echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
              echo "ğŸ“Š Summary:"
              echo "  - Name: $SNAPSHOT_NAME"
              echo "  - Size: $SNAPSHOT_SIZE"
              echo "  - Content: $SNAPSHOT_CONTENT"
              
              notify_slack "âœ… MariaDB snapshot SUCCESS\nSnapshot: $SNAPSHOT_NAME\nSize: $SNAPSHOT_SIZE" "good"
              
              # Step 5 : Nettoyer vieux snapshots (rÃ©tention 7 jours)
              echo ""
              echo "ğŸ§¹ Step 5: Cleaning old snapshots (retention: 7 days)..."
              
              CUTOFF_DATE=$(date -d '7 days ago' +%Y%m%d)
              
              kubectl get volumesnapshot -n $NAMESPACE \
                -l app=mariadb,type=daily \
                -o json | \
                jq -r '.items[] | select(.metadata.creationTimestamp < "'$CUTOFF_DATE'") | .metadata.name' | \
                while read old_snapshot; do
                  echo "  Deleting: $old_snapshot"
                  kubectl delete volumesnapshot $old_snapshot -n $NAMESPACE || true
                done
              
              echo "âœ… Cleanup completed"
              
              exit 0
```

**DÃ©ploiement** :

```bash
# CrÃ©er les RBAC
kubectl apply -f mariadb-backup-rbac.yaml

# CrÃ©er le CronJob
kubectl apply -f mariadb-snapshot-cronjob.yaml

# VÃ©rifier
kubectl get cronjob -n databases
# NAME                       SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
# mariadb-daily-snapshot     0 2 * * *     False     0        <none>          10s

# Tester immÃ©diatement (sans attendre 2h du matin)
kubectl create job --from=cronjob/mariadb-daily-snapshot \
  mariadb-snapshot-manual-test -n databases

# Suivre les logs
kubectl logs -f job/mariadb-snapshot-manual-test -n databases
```

---

## Restauration depuis VolumeSnapshot

### Restauration complÃ¨te (nouveau PVC)

```yaml
# mariadb-pvc-restore.yaml
# CrÃ©er un nouveau PVC depuis un snapshot
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb-data-pvc-restored
  namespace: databases
spec:
  storageClassName: gp3  # MÃªme StorageClass que l'original
  dataSource:
    name: mariadb-snapshot-20251213
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi  # MÃªme taille ou plus grande
```

```bash
# CrÃ©er le PVC restaurÃ©
kubectl apply -f mariadb-pvc-restore.yaml

# Attendre que le PVC soit Bound
kubectl get pvc mariadb-data-pvc-restored -n databases -w

# Output :
# NAME                          STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
# mariadb-data-pvc-restored     Pending                                                                       gp3            0s
# mariadb-data-pvc-restored     Bound     pvc-xyz789                                 500Gi      RWO            gp3            5s
```

**Utiliser le PVC restaurÃ©** :

```yaml
# mariadb-statefulset-restore.yaml
# StatefulSet MariaDB pointant vers le PVC restaurÃ©
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mariadb-restored
  namespace: databases
spec:
  serviceName: mariadb-restored
  replicas: 1
  selector:
    matchLabels:
      app: mariadb-restored
  template:
    metadata:
      labels:
        app: mariadb-restored
    spec:
      containers:
      - name: mariadb
        image: mariadb:11.8
        env:
        - name: MARIADB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mariadb-secret
              key: mariadb-root-password
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: mariadb-data-pvc-restored  # PVC restaurÃ©
```

```bash
# DÃ©ployer
kubectl apply -f mariadb-statefulset-restore.yaml

# VÃ©rifier
kubectl get pods -n databases -l app=mariadb-restored

# Tester connexion
kubectl exec -it mariadb-restored-0 -n databases -- mariadb -u root -p

# Valider donnÃ©es
MariaDB> SHOW DATABASES;
MariaDB> USE production_db;
MariaDB> SELECT COUNT(*) FROM users;
```

---

### Restauration in-place (remplacer PVC actuel)

âš ï¸ **ProcÃ©dure dangereuse** : Sauvegardez avant !

```bash
#!/bin/bash
# restore_mariadb_inplace.sh
# Restauration in-place depuis snapshot

set -euo pipefail

NAMESPACE="databases"
STATEFULSET="mariadb"
OLD_PVC="mariadb-data-pvc"
SNAPSHOT="mariadb-snapshot-20251213"
NEW_PVC="mariadb-data-pvc-new"

echo "âš ï¸  IN-PLACE RESTORE (DESTRUCTIVE)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  Snapshot: $SNAPSHOT"
echo "  This will DELETE the current PVC!"
echo ""
read -p "Are you sure? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    echo "âŒ Aborted"
    exit 1
fi

# Ã‰tape 1 : Scale down StatefulSet
echo "â¸ï¸  Step 1: Scaling down StatefulSet..."
kubectl scale statefulset $STATEFULSET -n $NAMESPACE --replicas=0

kubectl wait --for=delete pod/${STATEFULSET}-0 -n $NAMESPACE --timeout=60s || true

# Ã‰tape 2 : CrÃ©er nouveau PVC depuis snapshot
echo "ğŸ“¦ Step 2: Creating new PVC from snapshot..."

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: $NEW_PVC
  namespace: $NAMESPACE
spec:
  storageClassName: gp3
  dataSource:
    name: $SNAPSHOT
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
EOF

kubectl wait --for=jsonpath='{.status.phase}'=Bound \
  pvc/$NEW_PVC -n $NAMESPACE --timeout=120s

echo "âœ… New PVC created and bound"

# Ã‰tape 3 : Supprimer ancien PVC
echo "ğŸ—‘ï¸  Step 3: Deleting old PVC..."
kubectl delete pvc $OLD_PVC -n $NAMESPACE

# Ã‰tape 4 : Renommer nouveau PVC
echo "ğŸ”„ Step 4: Renaming new PVC..."
# Note : Renommer un PVC n'est pas possible directement
# Approche : Patcher le StatefulSet pour utiliser le nouveau nom

kubectl patch statefulset $STATEFULSET -n $NAMESPACE --type='json' \
  -p='[{"op": "replace", "path": "/spec/volumeClaimTemplates/0/metadata/name", "value":"'$NEW_PVC'"}]'

# Ou : RecrÃ©er le StatefulSet avec le nouveau PVC

# Ã‰tape 5 : Scale up
echo "â–¶ï¸  Step 5: Scaling up StatefulSet..."
kubectl scale statefulset $STATEFULSET -n $NAMESPACE --replicas=1

kubectl wait --for=condition=ready pod/${STATEFULSET}-0 -n $NAMESPACE --timeout=120s

echo "âœ… Restore completed"
```

ğŸ’¡ **Alternative recommandÃ©e** : CrÃ©er un nouveau StatefulSet avec le PVC restaurÃ©, tester, puis basculer.

---

## PITR avec VolumeSnapshot + Binary logs

### Architecture PITR complÃ¨te

```
VolumeSnapshot (base de restauration) + Binary logs (transactions) = PITR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. ğŸ“¸ VolumeSnapshot quotidien (2h du matin)
   â””â”€ Ã‰tat : Snapshot du volume au 13/12/2025 02:00:00

2. ğŸ“ Binary logs archivÃ©s vers S3 (continus)
   â”œâ”€ 02:00 - 03:00 : mariadb-bin.000042
   â”œâ”€ 03:00 - 04:00 : mariadb-bin.000043
   â”œâ”€ ...
   â””â”€ 14:00 - 14:30 : mariadb-bin.000050 (DROP TABLE Ã  14:30)

3. ğŸ¯ Restauration PITR au 13/12/2025 14:29:59
   â”œâ”€ Restaurer VolumeSnapshot (02:00)
   â”œâ”€ Rejouer binlogs 000042 â†’ 000050 (jusqu'Ã  14:29:59)
   â””â”€ Ã‰tat final : Base au 14:29:59 (avant DROP TABLE) âœ…
```

---

### CronJob archivage binlogs vers S3

```yaml
# mariadb-binlog-archive-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mariadb-binlog-archive
  namespace: databases
spec:
  schedule: "*/15 * * * *"  # Toutes les 15 minutes
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: binlog-archiver
            image: mariadb:11.8
            env:
            - name: S3_BUCKET
              value: "my-mariadb-backups"
            - name: S3_PREFIX
              value: "binlogs/$(date +%Y%m%d)"
            - name: MARIADB_HOST
              value: "mariadb-0.mariadb.databases.svc.cluster.local"
            - name: MARIADB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mariadb-secret
                  key: mariadb-root-password
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
            command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              
              echo "ğŸ“¦ Archiving binary logs to S3..."
              
              # Installer AWS CLI
              apt-get update && apt-get install -y awscli
              
              # Obtenir liste des binlogs
              BINLOGS=$(mariadb -h $MARIADB_HOST -u root -p$MARIADB_ROOT_PASSWORD \
                -N -e "SHOW BINARY LOGS;" | awk '{print $1}' | head -n -1)
              
              # Copier binlogs depuis pod MariaDB vers S3
              for binlog in $BINLOGS; do
                echo "  Archiving: $binlog"
                
                kubectl cp databases/mariadb-0:/var/lib/mysql/$binlog /tmp/$binlog
                
                aws s3 cp /tmp/$binlog s3://${S3_BUCKET}/${S3_PREFIX}/$binlog
                
                rm -f /tmp/$binlog
              done
              
              echo "âœ… Binary logs archived"
```

---

### Script PITR combinÃ© (Snapshot + Binlogs)

```bash
#!/bin/bash
# pitr_from_snapshot.sh
# PITR depuis VolumeSnapshot + binlogs S3

set -euo pipefail

SNAPSHOT_NAME="${1:-}"
TARGET_DATETIME="${2:-}"
S3_BINLOG_BUCKET="my-mariadb-backups"
NAMESPACE="databases"

if [ -z "$SNAPSHOT_NAME" ] || [ -z "$TARGET_DATETIME" ]; then
    echo "Usage: $0 <snapshot-name> <target-datetime>"
    echo "Example: $0 mariadb-snapshot-20251213 '2025-12-13 14:29:59'"
    exit 1
fi

echo "ğŸ”„ PITR from VolumeSnapshot + Binlogs"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  Snapshot: $SNAPSHOT_NAME"
echo "  Target: $TARGET_DATETIME"
echo ""

# Ã‰tape 1 : CrÃ©er PVC depuis snapshot
echo "ğŸ“¦ Step 1: Creating PVC from snapshot..."

PVC_NAME="mariadb-pitr-$(date +%s)"

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: $PVC_NAME
  namespace: $NAMESPACE
spec:
  storageClassName: gp3
  dataSource:
    name: $SNAPSHOT_NAME
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
EOF

kubectl wait --for=jsonpath='{.status.phase}'=Bound \
  pvc/$PVC_NAME -n $NAMESPACE --timeout=120s

echo "âœ… PVC created: $PVC_NAME"

# Ã‰tape 2 : DÃ©marrer MariaDB temporaire avec PVC restaurÃ©
echo ""
echo "â–¶ï¸  Step 2: Starting temporary MariaDB..."

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: mariadb-pitr-temp
  namespace: $NAMESPACE
spec:
  containers:
  - name: mariadb
    image: mariadb:11.8
    env:
    - name: MARIADB_ROOT_PASSWORD
      value: "temp-password"
    - name: MARIADB_SKIP_NETWORKING
      value: "1"  # Pas d'accÃ¨s rÃ©seau pendant PITR
    volumeMounts:
    - name: data
      mountPath: /var/lib/mysql
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: $PVC_NAME
EOF

kubectl wait --for=condition=ready pod/mariadb-pitr-temp -n $NAMESPACE --timeout=120s

echo "âœ… Temporary MariaDB started"

# Ã‰tape 3 : TÃ©lÃ©charger binlogs depuis S3
echo ""
echo "ğŸ“¥ Step 3: Downloading binlogs from S3..."

BINLOG_DIR="/tmp/binlogs-$(date +%s)"
mkdir -p $BINLOG_DIR

aws s3 sync s3://${S3_BINLOG_BUCKET}/binlogs/ $BINLOG_DIR/

echo "âœ… Binlogs downloaded"

# Ã‰tape 4 : Obtenir position binlog du snapshot
echo ""
echo "ğŸ“Š Step 4: Getting binlog position from snapshot..."

BINLOG_INFO=$(kubectl exec mariadb-pitr-temp -n $NAMESPACE -- \
  cat /var/lib/mysql/xtrabackup_binlog_info 2>/dev/null || echo "")

if [ -z "$BINLOG_INFO" ]; then
    echo "âš ï¸  No binlog info in snapshot, starting from beginning"
    BINLOG_FILE="mariadb-bin.000001"
    BINLOG_POS="4"
else
    BINLOG_FILE=$(echo $BINLOG_INFO | cut -d' ' -f1)
    BINLOG_POS=$(echo $BINLOG_INFO | cut -d' ' -f2)
fi

echo "  Binlog: $BINLOG_FILE:$BINLOG_POS"

# Ã‰tape 5 : Rejouer binlogs
echo ""
echo "â™»ï¸  Step 5: Replaying binlogs to $TARGET_DATETIME..."

REPLAY_SQL="/tmp/pitr_replay.sql"

mysqlbinlog \
  --disable-log-bin \
  --start-position=$BINLOG_POS \
  $BINLOG_DIR/$BINLOG_FILE \
  $BINLOG_DIR/mariadb-bin.* \
  --stop-datetime="$TARGET_DATETIME" \
  > $REPLAY_SQL

# Copier SQL dans le pod
kubectl cp $REPLAY_SQL databases/mariadb-pitr-temp:/tmp/replay.sql

# Rejouer
kubectl exec mariadb-pitr-temp -n $NAMESPACE -- \
  mariadb -u root -ptemp-password < /tmp/replay.sql

echo "âœ… Binlogs replayed"

# Ã‰tape 6 : ArrÃªter MariaDB temporaire
echo ""
echo "â¸ï¸  Step 6: Stopping temporary MariaDB..."

kubectl delete pod mariadb-pitr-temp -n $NAMESPACE

echo "âœ… PITR completed"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“¦ PVC with PITR data: $PVC_NAME"
echo ""
echo "To use this PVC:"
echo "  1. Create a StatefulSet using PVC: $PVC_NAME"
echo "  2. Validate data"
echo "  3. Switch production traffic"
```

---

## Disaster Recovery multi-cluster

### Copie snapshots cross-cluster (AWS)

```bash
#!/bin/bash
# cross_cluster_snapshot_copy.sh
# Copier snapshots EBS vers autre rÃ©gion (DR)

SOURCE_REGION="us-east-1"
DEST_REGION="eu-west-1"
SNAPSHOT_ID="snap-0abc1234def56789"

echo "ğŸ“¦ Copying EBS snapshot cross-region..."

# Copier snapshot
aws ec2 copy-snapshot \
  --source-region $SOURCE_REGION \
  --source-snapshot-id $SNAPSHOT_ID \
  --destination-region $DEST_REGION \
  --description "DR copy of $SNAPSHOT_ID"

echo "âœ… Snapshot copied to $DEST_REGION"
```

---

### Velero pour backup multi-cluster

**Installation Velero** :

```bash
# Installer Velero avec support VolumeSnapshot
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.8.0 \
  --bucket my-velero-backups \
  --backup-location-config region=us-east-1 \
  --snapshot-location-config region=us-east-1 \
  --features=EnableCSI
```

**Backup Velero** :

```yaml
# mariadb-velero-backup.yaml
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: mariadb-backup-20251213
  namespace: velero
spec:
  includedNamespaces:
  - databases
  includedResources:
  - statefulsets
  - persistentvolumeclaims
  - volumesnapshots
  - secrets
  - configmaps
  labelSelector:
    matchLabels:
      app: mariadb
  snapshotVolumes: true  # Utiliser VolumeSnapshots
  ttl: 720h  # 30 jours
```

```bash
# CrÃ©er backup
velero backup create mariadb-backup-$(date +%Y%m%d) \
  --include-namespaces databases \
  --labels app=mariadb \
  --snapshot-volumes

# Restaurer dans autre cluster
velero restore create --from-backup mariadb-backup-20251213
```

---

## Monitoring et alerting

### Prometheus metrics

```yaml
# prometheus-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mariadb-snapshot-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: mariadb-snapshot-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

**MÃ©triques custom** :

```bash
# Script exportant mÃ©triques Prometheus
cat > /var/lib/node_exporter/textfile_collector/mariadb_snapshots.prom <<EOF
# HELP mariadb_snapshot_count Number of VolumeSnapshots
# TYPE mariadb_snapshot_count gauge
mariadb_snapshot_count $(kubectl get volumesnapshot -n databases -l app=mariadb --no-headers | wc -l)

# HELP mariadb_snapshot_latest_timestamp Unix timestamp of latest snapshot
# TYPE mariadb_snapshot_latest_timestamp gauge
mariadb_snapshot_latest_timestamp $(kubectl get volumesnapshot -n databases -l app=mariadb --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.creationTimestamp}' | date -f - +%s)
EOF
```

---

## Optimisation des coÃ»ts

### StratÃ©gie de rÃ©tention

```
RÃ‰TENTION INTELLIGENTE :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Snapshots quotidiens :
â”œâ”€ J-0 Ã  J-7 : Conserver tous (7 snapshots)
â”œâ”€ J-8 Ã  J-30 : 1 par semaine (3 snapshots)
â”œâ”€ J-31 Ã  J-90 : 1 par mois (2 snapshots)
â””â”€ > J-90 : Supprimer

RÃ©sultat : 12 snapshots au lieu de 90 (Ã©conomie 87%)
```

**Script de rÃ©tention** :

```bash
#!/bin/bash
# cleanup_old_snapshots.sh

NAMESPACE="databases"

# Supprimer snapshots > 7 jours sauf 1 par semaine
kubectl get volumesnapshot -n $NAMESPACE \
  -l app=mariadb \
  --sort-by=.metadata.creationTimestamp \
  -o json | \
  jq -r '.items[] | 
    select(
      (.metadata.creationTimestamp | fromdateiso8601) < (now - 604800) and
      (.metadata.creationTimestamp | fromdateiso8601) % 604800 != 0
    ) | .metadata.name' | \
  xargs -I {} kubectl delete volumesnapshot {} -n $NAMESPACE
```

---

## âœ… Points clÃ©s Ã  retenir

- **VolumeSnapshots** = Backups instantanÃ©s (< 1s) au niveau bloc (CSI)
- **RTO optimisÃ©** : 2-5 min (vs 30-60 min Mariabackup)
- **Impact I/O** : Nul sur production (snapshot storage-level)
- **CSI drivers** : aws-ebs, gce-pd, azure-disk (support natif)
- **CohÃ©rence applicative** : FLUSH TABLES avant snapshot (obligatoire)
- **PITR complet** : VolumeSnapshot (base) + binary logs S3 (transactions)
- **Automatisation** : CronJobs quotidiens + archivage binlogs
- **DR multi-cluster** : Velero + cross-region snapshot copy
- **RÃ©tention intelligente** : 87% Ã©conomies (7j tous + 1/semaine + 1/mois)
- **Cloud-native** : Manifests YAML, GitOps, Kubernetes-first

---

## ğŸ”— Ressources et rÃ©fÃ©rences

- ğŸ“– [Kubernetes VolumeSnapshots Documentation](https://kubernetes.io/docs/concepts/storage/volume-snapshots/)
- ğŸ“– [CSI Drivers List](https://kubernetes-csi.github.io/docs/drivers.html)
- ğŸ“– [AWS EBS CSI Driver](https://github.com/kubernetes-sigs/aws-ebs-csi-driver)
- ğŸ“– [Velero Documentation](https://velero.io/docs/)
- ğŸ› ï¸ [VolumeSnapshot Examples](https://github.com/kubernetes-csi/external-snapshotter/tree/master/examples)
- ğŸ“Š [Snapshot Cost Optimization](https://aws.amazon.com/ebs/pricing/)

---

## â¡ï¸ Section suivante

**12.9 Tests de restauration** : ProcÃ©dures de tests rÃ©guliers, validation automatisÃ©e, mesure RTO/RPO, simulations DR, et reporting pour garantir la fiabilitÃ© des backups en production.

â­ï¸ [RÃ©plication](/13-replication/README.md)
