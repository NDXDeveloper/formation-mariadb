ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 19.1.3 Outils de migration

> **Niveau** : AvancÃ© Ã  Expert  
> **DurÃ©e estimÃ©e** : 6-7 heures  
> **PrÃ©requis** : Sections 19.1.1 et 19.1.2, expÃ©rience en administration de bases de donnÃ©es, connaissance des protocoles de sauvegarde/restauration

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- SÃ©lectionner l'outil de migration optimal selon le contexte (volume, downtime, source)
- MaÃ®triser les workflows complets de mysqldump, mydumper et Mariabackup
- Utiliser les outils Percona Toolkit pour validation et synchronisation
- Mettre en Å“uvre des migrations depuis Oracle, SQL Server et PostgreSQL
- Orchestrer des migrations cloud-native avec AWS DMS et Azure DMS
- Automatiser et monitorer les processus de migration Ã  grande Ã©chelle

---

## Introduction

Le choix de l'outil de migration est dÃ©terminant pour le succÃ¨s d'un projet. Un outil inadaptÃ© peut transformer une migration de quelques heures en cauchemar de plusieurs jours, voire compromettre l'intÃ©gritÃ© des donnÃ©es.

Cette section prÃ©sente l'arsenal complet des outils disponibles, organisÃ©s par catÃ©gorie et cas d'usage. Chaque outil est analysÃ© sous l'angle de ses forces, limitations, et contextes d'utilisation optimaux.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TAXONOMIE DES OUTILS DE MIGRATION                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   LOGIQUES      â”‚  â”‚   PHYSIQUES     â”‚  â”‚   RÃ‰PLICATION   â”‚      â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚      â”‚
â”‚  â”‚ â€¢ mysqldump     â”‚  â”‚ â€¢ Mariabackup   â”‚  â”‚ â€¢ Binlog-based  â”‚      â”‚
â”‚  â”‚ â€¢ mydumper      â”‚  â”‚ â€¢ xtrabackup    â”‚  â”‚ â€¢ GTID (intra)  â”‚      â”‚
â”‚  â”‚ â€¢ mysqlpump     â”‚  â”‚ â€¢ LVM snapshot  â”‚  â”‚ â€¢ CDC tools     â”‚      â”‚
â”‚  â”‚ â€¢ DMS           â”‚  â”‚ â€¢ Filesystem    â”‚  â”‚ â€¢ Debezium      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚           â”‚                    â”‚                    â”‚               â”‚
â”‚           â–¼                    â–¼                    â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              VALIDATION & SYNCHRONISATION                   â”‚    â”‚
â”‚  â”‚  â€¢ pt-table-checksum  â€¢ pt-table-sync  â€¢ pt-online-schema   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Outils natifs MySQL/MariaDB

### mysqldump / mariadb-dump

L'outil historique de sauvegarde logique, prÃ©sent sur toute installation MySQL/MariaDB.

#### CaractÃ©ristiques

| Aspect | DÃ©tail |
|--------|--------|
| Type | Export SQL logique (DDL + DML) |
| ParallÃ©lisme | Non (single-threaded) |
| Consistance | Via `--single-transaction` (InnoDB) |
| Compression | Externe (gzip, zstd) |
| Performance | ~10-50 MB/s selon configuration |
| Cas optimal | Bases < 50 GB, schÃ©mas complexes |

#### Syntaxe complÃ¨te pour migration

```bash
# Export complet avec toutes les options recommandÃ©es
mysqldump \
    --host=mysql-source.example.com \
    --user=backup_user \
    --password='SecureP@ss' \
    --single-transaction \
    --routines \
    --triggers \
    --events \
    --set-gtid-purged=OFF \
    --column-statistics=0 \
    --skip-lock-tables \
    --quick \
    --default-character-set=utf8mb4 \
    --result-file=/backup/full_export.sql \
    production_db

# Explication des options critiques :
# --single-transaction : Snapshot consistant sans verrouillage (InnoDB)
# --routines           : Inclut procÃ©dures stockÃ©es et fonctions
# --triggers           : Inclut les triggers
# --events             : Inclut les Ã©vÃ©nements planifiÃ©s
# --set-gtid-purged=OFF: Ã‰vite les problÃ¨mes GTID MySQLâ†’MariaDB
# --column-statistics=0: DÃ©sactive stats colonnes MySQL 8.0 (incompatible)
# --quick              : Ne bufferise pas en mÃ©moire (large tables)
```

#### Export sÃ©lectif et filtrage

```bash
# Export de tables spÃ©cifiques
mysqldump --single-transaction \
    production_db orders customers products \
    > selected_tables.sql

# Export structure uniquement (schÃ©ma)
mysqldump --no-data --routines --triggers \
    production_db > schema_only.sql

# Export donnÃ©es uniquement
mysqldump --no-create-info \
    production_db > data_only.sql

# Export avec condition WHERE
mysqldump --single-transaction \
    --where="created_at > '2025-01-01'" \
    production_db orders > orders_recent.sql

# Exclusion de tables
mysqldump --single-transaction \
    --ignore-table=production_db.logs \
    --ignore-table=production_db.sessions \
    production_db > export_sans_logs.sql
```

#### Import et restauration

```bash
# Import basique
mysql -h mariadb-target -u root -p production_db < full_export.sql

# Import avec monitoring de progression
pv full_export.sql | mysql -h mariadb-target -u root -p production_db

# Import optimisÃ© (dÃ©sactive checks temporairement)
mysql -h mariadb-target -u root -p production_db << 'EOF'
SET FOREIGN_KEY_CHECKS=0;
SET UNIQUE_CHECKS=0;
SET AUTOCOMMIT=0;
SOURCE /backup/full_export.sql;
SET FOREIGN_KEY_CHECKS=1;
SET UNIQUE_CHECKS=1;
COMMIT;
EOF

# Import parallÃ¨le manuel (split par table)
# NÃ©cessite export prÃ©alable par table
for sql_file in /backup/tables/*.sql; do
    mysql -h mariadb-target -u root -p production_db < "$sql_file" &
done
wait
```

ğŸ’¡ **Conseil** : Pour les bases > 10 GB, utilisez `pv` (Pipe Viewer) pour suivre la progression et estimer le temps restant.

#### Transformations post-export

```bash
# Conversion collations MySQL 8.0 â†’ MariaDB 11.8
sed -i 's/utf8mb4_0900_ai_ci/utf8mb4_uca1400_ai_ci/g' export.sql
sed -i 's/utf8mb4_0900_as_cs/utf8mb4_uca1400_as_cs/g' export.sql

# Suppression des directives GTID MySQL
sed -i '/SET @@GLOBAL.GTID_PURGED/d' export.sql
sed -i '/SET @@SESSION.SQL_LOG_BIN/d' export.sql

# Remplacement du moteur si nÃ©cessaire
sed -i 's/ENGINE=MyISAM/ENGINE=InnoDB/g' export.sql

# Script de transformation complet
#!/bin/bash
# transform_mysql_to_mariadb.sh

INPUT_FILE=$1
OUTPUT_FILE="${INPUT_FILE%.sql}_mariadb.sql"

cat "$INPUT_FILE" | \
    sed 's/utf8mb4_0900_ai_ci/utf8mb4_uca1400_ai_ci/g' | \
    sed 's/utf8mb4_0900_as_cs/utf8mb4_uca1400_as_cs/g' | \
    sed '/SET @@GLOBAL.GTID_PURGED/d' | \
    sed '/SET @@SESSION.SQL_LOG_BIN/d' | \
    sed 's/ENGINE=MyISAM/ENGINE=InnoDB/g' | \
    sed 's/ALGORITHM=INSTANT/ALGORITHM=INPLACE/g' \
    > "$OUTPUT_FILE"

echo "Transformed: $OUTPUT_FILE"
```

### mysqlpump (MySQL 8.0+)

Ã‰volution de mysqldump avec support du parallÃ©lisme natif.

```bash
# Export parallÃ¨le avec mysqlpump
mysqlpump \
    --host=mysql-source \
    --user=backup_user \
    --password='SecureP@ss' \
    --default-parallelism=4 \
    --databases production_db \
    --defer-table-indexes \
    --skip-definer \
    > parallel_export.sql

# Options spÃ©cifiques mysqlpump
# --default-parallelism=N : Nombre de threads
# --defer-table-indexes   : CrÃ©e les index aprÃ¨s les donnÃ©es
# --skip-definer          : Omet les clauses DEFINER

# Export avec compression intÃ©grÃ©e
mysqlpump \
    --compress-output=ZLIB \
    --databases production_db \
    > export.sql.zlib
```

âš ï¸ **Attention** : mysqlpump est un outil MySQL uniquement. Il peut Ãªtre utilisÃ© pour exporter depuis MySQL vers MariaDB, mais n'existe pas sur MariaDB.

---

## Outils tiers haute performance

### mydumper / myloader

Outil de sauvegarde/restauration parallÃ¨le open-source, significativement plus rapide que mysqldump.

#### Installation

```bash
# Ubuntu/Debian
sudo apt-get install mydumper

# CentOS/RHEL
sudo yum install mydumper

# Compilation depuis source (derniÃ¨re version)
git clone https://github.com/mydumper/mydumper.git
cd mydumper
cmake .
make
sudo make install
```

#### CaractÃ©ristiques

| Aspect | mydumper | mysqldump |
|--------|----------|-----------|
| ParallÃ©lisme | Natif (N threads) | Non |
| Format sortie | Fichiers multiples | Fichier unique |
| Compression | IntÃ©grÃ©e (gzip, zstd) | Externe |
| Consistance | Snapshot lock minimal | --single-transaction |
| Performance | ~100-500 MB/s | ~10-50 MB/s |
| Reprise | Possible (par fichier) | Non |

#### Export avec mydumper

```bash
# Export parallÃ¨le basique
mydumper \
    --host=mysql-source \
    --user=backup_user \
    --password='SecureP@ss' \
    --database=production_db \
    --outputdir=/backup/mydumper_export \
    --threads=8 \
    --compress \
    --verbose=3

# Export avec toutes les options optimales
mydumper \
    --host=mysql-source \
    --user=backup_user \
    --password='SecureP@ss' \
    --database=production_db \
    --outputdir=/backup/mydumper_export \
    --threads=16 \
    --compress \
    --compress-protocol \
    --triggers \
    --routines \
    --events \
    --rows=500000 \
    --chunk-filesize=256 \
    --long-query-guard=300 \
    --kill-long-queries \
    --verbose=3 \
    --logfile=/var/log/mydumper.log

# Options expliquÃ©es :
# --threads=16         : 16 threads parallÃ¨les
# --rows=500000        : Split tables en chunks de 500K lignes
# --chunk-filesize=256 : Fichiers de max 256 MB
# --long-query-guard   : Timeout pour requÃªtes longues
# --kill-long-queries  : Kill les requÃªtes bloquantes
```

#### Structure de sortie mydumper

```
/backup/mydumper_export/
â”œâ”€â”€ metadata                           # Infos position binlog
â”œâ”€â”€ production_db-schema-create.sql    # CREATE DATABASE
â”œâ”€â”€ production_db.orders-schema.sql    # Structure table orders
â”œâ”€â”€ production_db.orders.00000.sql.gz  # DonnÃ©es chunk 1
â”œâ”€â”€ production_db.orders.00001.sql.gz  # DonnÃ©es chunk 2
â”œâ”€â”€ production_db.orders.00002.sql.gz  # DonnÃ©es chunk 3
â”œâ”€â”€ production_db.customers-schema.sql
â”œâ”€â”€ production_db.customers.00000.sql.gz
â”œâ”€â”€ production_db-schema-triggers.sql  # Tous les triggers
â”œâ”€â”€ production_db-schema-post.sql      # Contraintes FK, etc.
â””â”€â”€ ...
```

#### Import avec myloader

```bash
# Import parallÃ¨le
myloader \
    --host=mariadb-target \
    --user=root \
    --password='SecureP@ss' \
    --database=production_db \
    --directory=/backup/mydumper_export \
    --threads=16 \
    --overwrite-tables \
    --verbose=3

# Import avec options avancÃ©es
myloader \
    --host=mariadb-target \
    --user=root \
    --password='SecureP@ss' \
    --database=production_db \
    --directory=/backup/mydumper_export \
    --threads=16 \
    --queries-per-transaction=10000 \
    --overwrite-tables \
    --enable-binlog \
    --innodb-optimize-keys \
    --verbose=3

# Options importantes :
# --queries-per-transaction : Batch size pour commits
# --innodb-optimize-keys    : CrÃ©e index aprÃ¨s donnÃ©es (plus rapide)
# --enable-binlog           : Log dans binlog (pour rÃ©plication)
```

#### Reprise aprÃ¨s Ã©chec

```bash
# mydumper crÃ©e des fichiers de mÃ©tadonnÃ©es permettant la reprise

# VÃ©rifier les fichiers dÃ©jÃ  importÃ©s
ls -la /backup/mydumper_export/*.sql.gz

# Supprimer les fichiers dÃ©jÃ  traitÃ©s (si import partiel)
# puis relancer myloader

# Alternative : import table par table
myloader \
    --threads=4 \
    --directory=/backup/mydumper_export \
    --source-db=production_db \
    --tables-list=orders,customers \
    --database=production_db
```

### Percona Toolkit

Suite d'outils indispensables pour la migration et la maintenance.

#### pt-table-checksum

VÃ©rifie la cohÃ©rence des donnÃ©es entre source et cible.

```bash
# Installation
sudo apt-get install percona-toolkit

# VÃ©rification de cohÃ©rence MySQL â†’ MariaDB
pt-table-checksum \
    --host=mysql-source \
    --user=checksum_user \
    --password='SecureP@ss' \
    --databases=production_db \
    --replicate=percona.checksums \
    --no-check-binlog-format \
    --chunk-size=10000 \
    --chunk-time=1.0

# RÃ©sultats stockÃ©s dans percona.checksums
# InterprÃ©tation :
# DIFFS=0 : Tables identiques
# DIFFS>0 : DiffÃ©rences dÃ©tectÃ©es
```

```sql
-- Visualisation des rÃ©sultats
SELECT db, tbl, chunk, 
       this_crc, master_crc,
       this_cnt, master_cnt
FROM percona.checksums
WHERE this_crc != master_crc
   OR this_cnt != master_cnt;

-- RÃ©sumÃ© par table
SELECT db, tbl, 
       SUM(this_cnt) as rows_checked,
       SUM(CASE WHEN this_crc != master_crc THEN 1 ELSE 0 END) as chunks_different
FROM percona.checksums
GROUP BY db, tbl
HAVING chunks_different > 0;
```

#### pt-table-sync

Synchronise les diffÃ©rences dÃ©tectÃ©es.

```bash
# PrÃ©visualisation des corrections (dry-run)
pt-table-sync \
    --print \
    --replicate=percona.checksums \
    h=mysql-source,u=sync_user,p='SecureP@ss' \
    h=mariadb-target

# Application des corrections
pt-table-sync \
    --execute \
    --replicate=percona.checksums \
    h=mysql-source,u=sync_user,p='SecureP@ss' \
    h=mariadb-target \
    --verbose

# Synchronisation directe (sans checksums prÃ©alables)
pt-table-sync \
    --execute \
    --databases=production_db \
    h=mysql-source,u=user,p='pass' \
    h=mariadb-target,u=user,p='pass'
```

#### pt-show-grants

Exporte les privilÃ¨ges utilisateurs dans un format rÃ©exÃ©cutable.

```bash
# Export de tous les grants
pt-show-grants \
    --host=mysql-source \
    --user=root \
    --password='SecureP@ss' \
    > grants.sql

# Export filtrÃ© (exclure utilisateurs systÃ¨me)
pt-show-grants \
    --host=mysql-source \
    --user=root \
    --password='SecureP@ss' \
    --ignore='mysql.%,root' \
    > app_grants.sql

# Import sur MariaDB
mysql -h mariadb-target -u root -p < grants.sql
```

#### pt-online-schema-change

Migrations de schÃ©ma sans verrouillage (utile prÃ©/post migration).

```bash
# Exemple : Ajout de colonne sur table volumineuse
pt-online-schema-change \
    --host=mariadb-target \
    --user=root \
    --password='SecureP@ss' \
    --alter="ADD COLUMN new_field VARCHAR(100)" \
    --execute \
    D=production_db,t=orders

# Avec options de throttling
pt-online-schema-change \
    --host=mariadb-target \
    --alter="ADD INDEX idx_date (created_at)" \
    --max-load="Threads_running=50" \
    --critical-load="Threads_running=100" \
    --chunk-size=1000 \
    --execute \
    D=production_db,t=orders
```

---

## Outils de sauvegarde physique

### Mariabackup

Outil de sauvegarde physique officiel MariaDB, fork de Percona XtraBackup.

#### Sauvegarde complÃ¨te

```bash
# Sauvegarde full
mariabackup \
    --backup \
    --target-dir=/backup/full \
    --user=backup_user \
    --password='SecureP@ss' \
    --parallel=4

# PrÃ©paration (apply logs)
mariabackup \
    --prepare \
    --target-dir=/backup/full

# Restauration
sudo systemctl stop mariadb
sudo rm -rf /var/lib/mysql/*
mariabackup \
    --copy-back \
    --target-dir=/backup/full
sudo chown -R mysql:mysql /var/lib/mysql
sudo systemctl start mariadb
```

#### Sauvegarde incrÃ©mentale

```bash
# Full backup initial
mariabackup \
    --backup \
    --target-dir=/backup/full \
    --user=backup_user \
    --password='SecureP@ss'

# IncrÃ©mental jour 1
mariabackup \
    --backup \
    --target-dir=/backup/inc1 \
    --incremental-basedir=/backup/full \
    --user=backup_user \
    --password='SecureP@ss'

# IncrÃ©mental jour 2
mariabackup \
    --backup \
    --target-dir=/backup/inc2 \
    --incremental-basedir=/backup/inc1 \
    --user=backup_user \
    --password='SecureP@ss'

# PrÃ©paration pour restauration
mariabackup --prepare --target-dir=/backup/full
mariabackup --prepare --target-dir=/backup/full --incremental-dir=/backup/inc1
mariabackup --prepare --target-dir=/backup/full --incremental-dir=/backup/inc2

# Restauration
mariabackup --copy-back --target-dir=/backup/full
```

ğŸ†• **MariaDB 11.8** : Support BACKUP STAGE pour coordination amÃ©liorÃ©e

```sql
-- Utilisation de BACKUP STAGE pour sauvegarde coordonnÃ©e
BACKUP STAGE START;    -- PrÃ©pare le serveur
BACKUP STAGE FLUSH;    -- Flush et lock tables non-transactionnelles
BACKUP STAGE BLOCK_DDL; -- Bloque les DDL
BACKUP STAGE BLOCK_COMMIT; -- Bloque les commits (snapshot consistant)

-- Effectuer la sauvegarde ici (copie fichiers ou mariabackup)

BACKUP STAGE END;      -- LibÃ¨re tout
```

### Percona XtraBackup

Alternative Ã  Mariabackup, recommandÃ© pour migrations depuis MySQL.

```bash
# Installation
sudo apt-get install percona-xtrabackup-80  # Pour MySQL 8.0

# Sauvegarde depuis MySQL 8.0
xtrabackup \
    --backup \
    --host=mysql-source \
    --user=backup_user \
    --password='SecureP@ss' \
    --target-dir=/backup/mysql_full

# Note : XtraBackup MySQL 8.0 ne peut pas restaurer vers MariaDB
# Utiliser pour export, puis migration logique
# Ou utiliser Mariabackup pour les versions compatibles
```

âš ï¸ **Attention** : Les sauvegardes physiques MySQL 8.0 (XtraBackup 8.0) ne sont **pas compatibles** avec MariaDB. Utilisez la migration logique depuis MySQL 8.0+.

---

## Outils de migration cloud

### AWS Database Migration Service (DMS)

Service managÃ© pour migrations vers/depuis AWS.

#### Configuration source MySQL

```json
{
    "EndpointType": "source",
    "EngineName": "mysql",
    "ServerName": "mysql-source.example.com",
    "Port": 3306,
    "Username": "dms_user",
    "Password": "SecureP@ss",
    "DatabaseName": "production_db",
    "SslMode": "require",
    "ExtraConnectionAttributes": "afterConnectScript=SET SQL_MODE='NO_ENGINE_SUBSTITUTION'"
}
```

#### Configuration cible MariaDB

```json
{
    "EndpointType": "target",
    "EngineName": "mariadb",
    "ServerName": "mariadb-target.example.com",
    "Port": 3306,
    "Username": "dms_user",
    "Password": "SecureP@ss",
    "DatabaseName": "production_db",
    "SslMode": "require"
}
```

#### Task settings pour migration complÃ¨te + CDC

```json
{
    "TargetMetadata": {
        "TargetSchema": "production_db",
        "SupportLobs": true,
        "FullLobMode": false,
        "LobChunkSize": 64,
        "LimitedSizeLobMode": true,
        "LobMaxSize": 32768
    },
    "FullLoadSettings": {
        "TargetTablePrepMode": "DROP_AND_CREATE",
        "CreatePkAfterFullLoad": true,
        "StopTaskCachedChangesApplied": false,
        "StopTaskCachedChangesNotApplied": false,
        "MaxFullLoadSubTasks": 8,
        "TransactionConsistencyTimeout": 600,
        "CommitRate": 10000
    },
    "Logging": {
        "EnableLogging": true,
        "LogComponents": [
            {"Id": "SOURCE_UNLOAD", "Severity": "LOGGER_SEVERITY_DEFAULT"},
            {"Id": "TARGET_LOAD", "Severity": "LOGGER_SEVERITY_DEFAULT"},
            {"Id": "SOURCE_CAPTURE", "Severity": "LOGGER_SEVERITY_DEFAULT"},
            {"Id": "TARGET_APPLY", "Severity": "LOGGER_SEVERITY_DEFAULT"}
        ]
    },
    "ChangeProcessingTuning": {
        "BatchApplyEnabled": true,
        "BatchApplyPreserveTransaction": true,
        "BatchSplitSize": 0,
        "BatchApplyTimeoutMin": 1,
        "BatchApplyTimeoutMax": 30,
        "BatchApplyMemoryLimit": 500,
        "MinTransactionSize": 1000,
        "CommitTimeout": 1,
        "MemoryLimitTotal": 1024,
        "MemoryKeepTime": 60,
        "StatementCacheSize": 50
    }
}
```

#### CLI AWS pour gestion DMS

```bash
# CrÃ©er endpoint source
aws dms create-endpoint \
    --endpoint-identifier mysql-source-endpoint \
    --endpoint-type source \
    --engine-name mysql \
    --username dms_user \
    --password 'SecureP@ss' \
    --server-name mysql-source.example.com \
    --port 3306 \
    --database-name production_db

# CrÃ©er endpoint cible
aws dms create-endpoint \
    --endpoint-identifier mariadb-target-endpoint \
    --endpoint-type target \
    --engine-name mariadb \
    --username dms_user \
    --password 'SecureP@ss' \
    --server-name mariadb-target.example.com \
    --port 3306 \
    --database-name production_db

# CrÃ©er et dÃ©marrer la tÃ¢che
aws dms create-replication-task \
    --replication-task-identifier mysql-to-mariadb-task \
    --source-endpoint-arn arn:aws:dms:...:endpoint:source \
    --target-endpoint-arn arn:aws:dms:...:endpoint:target \
    --replication-instance-arn arn:aws:dms:...:rep:instance \
    --migration-type full-load-and-cdc \
    --table-mappings file://table-mappings.json \
    --replication-task-settings file://task-settings.json

aws dms start-replication-task \
    --replication-task-arn arn:aws:dms:...:task:xxx \
    --start-replication-task-type start-replication
```

### Azure Database Migration Service

```bash
# CrÃ©ation via Azure CLI
az dms project create \
    --resource-group myResourceGroup \
    --service-name myDmsService \
    --name MySQLToMariaDB \
    --source-platform MySQL \
    --target-platform MariaDB

# Configuration de la tÃ¢che de migration
az dms project task create \
    --resource-group myResourceGroup \
    --service-name myDmsService \
    --project-name MySQLToMariaDB \
    --name MigrationTask \
    --source-connection-json @source-connection.json \
    --target-connection-json @target-connection.json \
    --database-options-json @database-options.json
```

### Comparaison des outils cloud

| FonctionnalitÃ© | AWS DMS | Azure DMS | GCP Database Migration |
|---------------|---------|-----------|------------------------|
| MySQL source | âœ… | âœ… | âœ… |
| MariaDB cible | âœ… | âœ… | âš ï¸ (via MySQL) |
| CDC continu | âœ… | âœ… | âœ… |
| Validation donnÃ©es | âœ… | âœ… | LimitÃ©e |
| Zero-downtime | âœ… | âœ… | âœ… |
| CoÃ»t | ~$0.20/h | ~$0.15/h | ~$0.18/h |
| LOB support | âœ… | âœ… | âœ… |
| Transformation | Basique | AvancÃ©e | Basique |

---

## Outils spÃ©cialisÃ©s par SGBD source

### Migration depuis Oracle

#### Oracle to MariaDB avec ora2mariadb

```bash
# Installation ora2mariadb (outil communautaire)
git clone https://github.com/nicklaskjaer/ora2mariadb.git
cd ora2mariadb
pip install -r requirements.txt

# Configuration
cat > config.yaml << 'EOF'
oracle:
  host: oracle-server.example.com
  port: 1521
  service_name: ORCL
  user: migration_user
  password: SecureP@ss

mariadb:
  host: mariadb-target.example.com
  port: 3306
  user: root
  password: SecureP@ss
  database: migrated_db

options:
  convert_clob_to_text: true
  convert_blob_to_blob: true
  preserve_case: false
  batch_size: 10000
EOF

# ExÃ©cution
python ora2mariadb.py --config config.yaml --schema HR
```

#### Mapping des types Oracle â†’ MariaDB

```sql
-- Conversions automatiques typiques
-- Oracle                â†’ MariaDB
-- NUMBER(p,s)          â†’ DECIMAL(p,s)
-- NUMBER               â†’ DOUBLE ou DECIMAL(65,30)
-- VARCHAR2(n)          â†’ VARCHAR(n)
-- NVARCHAR2(n)         â†’ VARCHAR(n) CHARACTER SET utf8mb4
-- CHAR(n)              â†’ CHAR(n)
-- CLOB                 â†’ LONGTEXT
-- BLOB                 â†’ LONGBLOB
-- DATE                 â†’ DATETIME (Oracle DATE inclut l'heure!)
-- TIMESTAMP            â†’ DATETIME(6)
-- RAW(n)               â†’ VARBINARY(n)
-- ROWID                â†’ VARCHAR(18) ou supprimÃ©

-- Script de conversion manuelle
-- Extraction Oracle (via SQL*Plus)
SET COLSEP ','
SET PAGESIZE 0
SET TRIMSPOOL ON
SET HEADSEP OFF
SET LINESIZE 32767
SPOOL orders.csv
SELECT order_id, customer_id, order_date, total 
FROM orders;
SPOOL OFF

-- Import MariaDB
LOAD DATA LOCAL INFILE 'orders.csv'
INTO TABLE orders
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
(order_id, customer_id, @order_date, total)
SET order_date = STR_TO_DATE(@order_date, '%Y-%m-%d %H:%i:%s');
```

#### ProcÃ©dures PL/SQL vers MariaDB

```sql
-- MariaDB supporte un mode de compatibilitÃ© Oracle
SET sql_mode = 'ORACLE';

-- ProcÃ©dure PL/SQL style
CREATE OR REPLACE PROCEDURE calculate_bonus(
    p_employee_id IN NUMBER,
    p_bonus OUT NUMBER
) AS
    v_salary NUMBER;
    v_years NUMBER;
BEGIN
    SELECT salary, years_of_service
    INTO v_salary, v_years
    FROM employees
    WHERE employee_id = p_employee_id;
    
    p_bonus := v_salary * v_years * 0.01;
    
EXCEPTION
    WHEN NO_DATA_FOUND THEN
        p_bonus := 0;
END;
/

-- Cette syntaxe fonctionne sur MariaDB avec sql_mode=ORACLE
```

### Migration depuis SQL Server

#### SQL Server Migration Assistant (SSMA)

```powershell
# SSMA for MySQL/MariaDB (outil Microsoft gratuit)
# TÃ©lÃ©chargement : https://www.microsoft.com/en-us/download/details.aspx?id=54257

# SSMA supporte :
# - Conversion automatique du schÃ©ma
# - Migration des donnÃ©es
# - Rapport de compatibilitÃ©
# - Conversion des procÃ©dures T-SQL
```

#### Mapping des types SQL Server â†’ MariaDB

```sql
-- Conversions principales
-- SQL Server           â†’ MariaDB
-- INT                  â†’ INT
-- BIGINT               â†’ BIGINT
-- SMALLINT             â†’ SMALLINT
-- TINYINT              â†’ TINYINT UNSIGNED (0-255 vs -128-127!)
-- DECIMAL(p,s)         â†’ DECIMAL(p,s)
-- MONEY                â†’ DECIMAL(19,4)
-- FLOAT                â†’ DOUBLE
-- REAL                 â†’ FLOAT
-- VARCHAR(n)           â†’ VARCHAR(n)
-- NVARCHAR(n)          â†’ VARCHAR(n) CHARACTER SET utf8mb4
-- VARCHAR(MAX)         â†’ LONGTEXT
-- DATETIME             â†’ DATETIME
-- DATETIME2            â†’ DATETIME(6)
-- DATETIMEOFFSET       â†’ DATETIME(6) + colonne timezone
-- BIT                  â†’ TINYINT(1) ou BIT(1)
-- UNIQUEIDENTIFIER     â†’ CHAR(36) ou UUID
-- XML                  â†’ LONGTEXT (avec validation app)
-- GEOGRAPHY/GEOMETRY   â†’ GEOMETRY (syntaxe diffÃ©rente)

-- Attention : IDENTITY vs AUTO_INCREMENT
-- SQL Server
CREATE TABLE orders (
    id INT IDENTITY(1,1) PRIMARY KEY,
    ...
);

-- MariaDB
CREATE TABLE orders (
    id INT AUTO_INCREMENT PRIMARY KEY,
    ...
);
```

#### Export BCP et import LOAD DATA

```bash
# Export SQL Server avec BCP
bcp "SELECT * FROM production.dbo.orders" queryout orders.csv \
    -S sqlserver.example.com \
    -U export_user -P 'SecureP@ss' \
    -c -t ',' -r '\n'

# Ou avec format natif pour performance
bcp production.dbo.orders out orders.bcp \
    -S sqlserver.example.com \
    -U export_user -P 'SecureP@ss' \
    -n

# Import dans MariaDB
LOAD DATA LOCAL INFILE '/path/orders.csv'
INTO TABLE orders
CHARACTER SET utf8mb4
FIELDS TERMINATED BY ','
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES;  -- Si header prÃ©sent
```

### Migration depuis PostgreSQL

#### pgloader

Outil de migration puissant supportant PostgreSQL â†’ MySQL/MariaDB.

```bash
# Installation
sudo apt-get install pgloader

# Configuration pgloader
cat > pg_to_mariadb.load << 'EOF'
LOAD DATABASE
    FROM postgresql://pg_user:password@postgres-server/source_db
    INTO mysql://root:password@mariadb-server/target_db

WITH include drop,
     create tables,
     create indexes,
     reset sequences,
     workers = 8,
     concurrency = 4,
     batch rows = 25000,
     prefetch rows = 100000

SET work_mem to '512MB',
    maintenance_work_mem to '1GB'

CAST type uuid to varchar(36),
     type jsonb to json,
     type inet to varchar(45),
     type cidr to varchar(45),
     type macaddr to varchar(17),
     type interval to varchar(50),
     type point to point,
     type money to decimal(19,2),
     type bytea to blob,
     type boolean to tinyint

EXCLUDING TABLE NAMES MATCHING 'pg_*', '_*'

AFTER LOAD DO
    $$ ALTER TABLE orders ADD CONSTRAINT fk_customer 
       FOREIGN KEY (customer_id) REFERENCES customers(id); $$;
EOF

# ExÃ©cution
pgloader pg_to_mariadb.load
```

#### Mapping des types PostgreSQL â†’ MariaDB

```sql
-- Types avec correspondance directe
-- PostgreSQL           â†’ MariaDB
-- INTEGER              â†’ INT
-- BIGINT               â†’ BIGINT
-- SMALLINT             â†’ SMALLINT
-- DECIMAL/NUMERIC      â†’ DECIMAL
-- REAL                 â†’ FLOAT
-- DOUBLE PRECISION     â†’ DOUBLE
-- VARCHAR(n)           â†’ VARCHAR(n)
-- CHAR(n)              â†’ CHAR(n)
-- TEXT                 â†’ LONGTEXT
-- BYTEA                â†’ LONGBLOB
-- BOOLEAN              â†’ TINYINT(1) ou BOOLEAN (alias)
-- DATE                 â†’ DATE
-- TIMESTAMP            â†’ DATETIME(6)
-- TIME                 â†’ TIME(6)

-- Types nÃ©cessitant conversion
-- PostgreSQL           â†’ MariaDB (conversion)
-- SERIAL               â†’ INT AUTO_INCREMENT
-- BIGSERIAL            â†’ BIGINT AUTO_INCREMENT
-- UUID                 â†’ CHAR(36) ou UUID (MariaDB 10.7+)
-- JSONB                â†’ JSON (perte indexation GIN)
-- ARRAY[]              â†’ JSON ou tables relationnelles
-- INET/CIDR            â†’ VARCHAR(45) ou INET6
-- INTERVAL             â†’ VARCHAR ou INT (secondes)
-- TSVECTOR             â†’ FULLTEXT index
-- HSTORE               â†’ JSON

-- Exemple conversion ARRAY
-- PostgreSQL
CREATE TABLE tags (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    categories TEXT[]
);

-- MariaDB (option 1 : JSON)
CREATE TABLE tags (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    categories JSON
);

-- MariaDB (option 2 : table relationnelle - meilleur)
CREATE TABLE tags (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100)
);
CREATE TABLE tag_categories (
    tag_id INT,
    category VARCHAR(100),
    PRIMARY KEY (tag_id, category),
    FOREIGN KEY (tag_id) REFERENCES tags(id)
);
```

---

## Comparaison et sÃ©lection des outils

### Matrice de dÃ©cision

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SÃ‰LECTION D'OUTIL PAR CONTEXTE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Volume des donnÃ©es                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚
â”‚  < 10 GB          â”‚ mysqldump                                               â”‚
â”‚  10-100 GB        â”‚ mydumper/myloader                                       â”‚
â”‚  100 GB - 1 TB    â”‚ mydumper + rÃ©plication || DMS                           â”‚
â”‚  > 1 TB           â”‚ DMS CDC || rÃ©plication native + cutover                 â”‚
â”‚                                                                             â”‚
â”‚  Downtime acceptable                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚  IllimitÃ©         â”‚ mysqldump (simple, fiable)                              â”‚
â”‚  < 1 heure        â”‚ mydumper + rÃ©plication courte                           â”‚
â”‚  < 10 minutes     â”‚ RÃ©plication + switchover                                â”‚
â”‚  < 1 minute       â”‚ DMS CDC ou rÃ©plication native + VIP                     â”‚
â”‚  Zero-downtime    â”‚ RÃ©plication continue + application dual-write           â”‚
â”‚                                                                             â”‚
â”‚  Source database                                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                            â”‚
â”‚  MySQL 5.x        â”‚ mysqldump, mydumper, rÃ©plication binlog                 â”‚
â”‚  MySQL 8.x        â”‚ mysqldump, mydumper, DMS (pas de backup physique!)      â”‚
â”‚  Oracle           â”‚ ora2mariadb, DMS, scripts custom                        â”‚
â”‚  SQL Server       â”‚ SSMA, DMS, BCP export                                   â”‚
â”‚  PostgreSQL       â”‚ pgloader, DMS                                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benchmark des performances

| Outil | Export 100 GB | Import 100 GB | Threads | Notes |
|-------|--------------|---------------|---------|-------|
| mysqldump | ~3h | ~5h | 1 | Simple, universel |
| mydumper/myloader | ~30min | ~1h | 16 | 5-10x plus rapide |
| Mariabackup | ~20min | ~30min | 4 | Physique, mÃªme version |
| AWS DMS | ~2h | ~2h | Auto | ManagÃ©, CDC inclus |
| pgloader | - | ~1.5h | 8 | SpÃ©cifique PostgreSQL |

### Arbre de dÃ©cision

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Source = MySQL? â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                            â”‚
                   Oui                          Non
                    â”‚                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â”‚ Version MySQL?        â”‚         â”‚ Oracle/     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ SQLServer/  â”‚
                    â”‚                     â”‚ PostgreSQL  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚             â”‚              â”‚
        5.x        8.0           8.4+       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         â”‚          â”‚             â”‚         â”‚         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”   DMS    Outils
    â”‚RÃ©plicationâ”‚ â”‚DMS ou  â”‚  â”‚DMS ou  â”‚          natifs
    â”‚possible   â”‚ â”‚mydumperâ”‚  â”‚mydumperâ”‚             â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
         â”‚            â”‚           â”‚              â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”       â”‚           â”‚            Oracle     PG/SQL
    â”‚Downtime â”‚       â”‚           â”‚              â”‚       Server
    â”‚requis?  â”‚       â”‚           â”‚              â”‚          â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚           â”‚           ora2mariadb   â”‚
         â”‚            â”‚           â”‚                         â”‚
      â”Œâ”€â”€â”´â”€â”€â”         â”‚           â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”
     Oui   Non        â”‚           â”‚                 pgloader   SSMA
      â”‚     â”‚         â”‚           â”‚
  mydumper  â”‚         â”‚           â”‚
      â”‚     RÃ©plication           â”‚
      â”‚     +cutover              â”‚
      â”‚      â”‚                    â”‚
      â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Workflows de migration complets

### Workflow 1 : Migration simple MySQL 5.7 â†’ MariaDB 11.8

**Contexte** : Base 20 GB, downtime acceptable 2h, weekend

```bash
#!/bin/bash
# simple_migration.sh

set -e

# Variables
MYSQL_HOST="mysql-source"
MARIADB_HOST="mariadb-target"
DATABASE="production_db"
BACKUP_DIR="/backup/migration"

echo "=== Migration MySQL 5.7 â†’ MariaDB 11.8 ==="
echo "Start: $(date)"

# 1. PrÃ©-vÃ©rifications
echo "[1/7] PrÃ©-vÃ©rifications..."
mysql -h $MYSQL_HOST -u root -p -e "SELECT VERSION();"
mysql -h $MARIADB_HOST -u root -p -e "SELECT VERSION();"

# 2. Export avec mysqldump
echo "[2/7] Export en cours..."
mysqldump \
    --host=$MYSQL_HOST \
    --user=backup_user \
    --password='SecureP@ss' \
    --single-transaction \
    --routines --triggers --events \
    --set-gtid-purged=OFF \
    --column-statistics=0 \
    $DATABASE | pv > $BACKUP_DIR/export.sql

# 3. Transformation pour MariaDB
echo "[3/7] Transformation du dump..."
sed -i 's/utf8mb4_0900_ai_ci/utf8mb4_uca1400_ai_ci/g' $BACKUP_DIR/export.sql

# 4. CrÃ©ation de la base cible
echo "[4/7] CrÃ©ation base cible..."
mysql -h $MARIADB_HOST -u root -p -e "CREATE DATABASE IF NOT EXISTS $DATABASE;"

# 5. Import
echo "[5/7] Import en cours..."
pv $BACKUP_DIR/export.sql | mysql -h $MARIADB_HOST -u root -p $DATABASE

# 6. VÃ©rification
echo "[6/7] VÃ©rification..."
MYSQL_COUNT=$(mysql -h $MYSQL_HOST -u root -p -N -e \
    "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='$DATABASE';")
MARIADB_COUNT=$(mysql -h $MARIADB_HOST -u root -p -N -e \
    "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='$DATABASE';")

if [ "$MYSQL_COUNT" != "$MARIADB_COUNT" ]; then
    echo "ERREUR: Nombre de tables diffÃ©rent ($MYSQL_COUNT vs $MARIADB_COUNT)"
    exit 1
fi

# 7. Migration utilisateurs
echo "[7/7] Migration utilisateurs..."
pt-show-grants --host=$MYSQL_HOST --user=root --password='SecureP@ss' | \
    grep -v 'mysql\.' | \
    mysql -h $MARIADB_HOST -u root -p

echo "=== Migration terminÃ©e ==="
echo "End: $(date)"
```

### Workflow 2 : Migration large scale avec mydumper

**Contexte** : Base 500 GB, downtime max 30 minutes

```bash
#!/bin/bash
# large_scale_migration.sh

set -e

MYSQL_HOST="mysql-source"
MARIADB_HOST="mariadb-target"
DATABASE="production_db"
BACKUP_DIR="/backup/mydumper_export"
THREADS=16

echo "=== Migration Large Scale ==="

# Phase 1 : Export parallÃ¨le (peut Ãªtre fait en avance)
echo "[Phase 1] Export parallÃ¨le avec mydumper..."
mydumper \
    --host=$MYSQL_HOST \
    --user=backup_user \
    --password='SecureP@ss' \
    --database=$DATABASE \
    --outputdir=$BACKUP_DIR \
    --threads=$THREADS \
    --compress \
    --triggers \
    --routines \
    --events \
    --rows=500000 \
    --verbose=3 \
    --logfile=/var/log/mydumper.log

# Phase 2 : Transformation fichiers
echo "[Phase 2] Transformation des fichiers..."
find $BACKUP_DIR -name "*.sql.gz" -exec zcat {} \; | \
    sed 's/utf8mb4_0900_ai_ci/utf8mb4_uca1400_ai_ci/g' | \
    gzip > {}.transformed

# Phase 3 : Import parallÃ¨le
echo "[Phase 3] Import parallÃ¨le avec myloader..."
myloader \
    --host=$MARIADB_HOST \
    --user=root \
    --password='SecureP@ss' \
    --database=$DATABASE \
    --directory=$BACKUP_DIR \
    --threads=$THREADS \
    --overwrite-tables \
    --innodb-optimize-keys \
    --verbose=3

# Phase 4 : Setup rÃ©plication pour synchronisation finale
echo "[Phase 4] Configuration rÃ©plication catch-up..."
# RÃ©cupÃ©rer position depuis metadata mydumper
BINLOG_FILE=$(grep "Log:" $BACKUP_DIR/metadata | awk '{print $2}')
BINLOG_POS=$(grep "Pos:" $BACKUP_DIR/metadata | awk '{print $2}')

mysql -h $MARIADB_HOST -u root -p << EOF
CHANGE MASTER TO
    MASTER_HOST='$MYSQL_HOST',
    MASTER_USER='repl_user',
    MASTER_PASSWORD='repl_pass',
    MASTER_LOG_FILE='$BINLOG_FILE',
    MASTER_LOG_POS=$BINLOG_POS;
START SLAVE;
EOF

# Phase 5 : Attendre synchronisation
echo "[Phase 5] Attente synchronisation..."
while true; do
    LAG=$(mysql -h $MARIADB_HOST -u root -p -N -e \
        "SHOW SLAVE STATUS\G" | grep "Seconds_Behind_Master" | awk '{print $2}')
    echo "Lag: $LAG secondes"
    if [ "$LAG" = "0" ]; then
        break
    fi
    sleep 10
done

# Phase 6 : Cutover (fenÃªtre de downtime minimale)
echo "[Phase 6] Cutover..."
echo "ArrÃªt des Ã©critures MySQL..."
mysql -h $MYSQL_HOST -u root -p -e "SET GLOBAL read_only = ON;"

echo "Attente derniÃ¨re synchronisation..."
sleep 5

echo "Promotion MariaDB..."
mysql -h $MARIADB_HOST -u root -p -e "STOP SLAVE; RESET SLAVE ALL;"

echo "=== Cutover terminÃ© - MariaDB est le nouveau primary ==="
```

### Workflow 3 : Zero-downtime avec DMS

**Contexte** : Application 24/7, aucun downtime acceptable

```bash
#!/bin/bash
# zero_downtime_dms.sh

# Ce workflow utilise AWS DMS pour une migration continue
# puis un switchover applicatif progressif

# Phase 1 : Configuration DMS (prÃ©alable, via console ou CLI)
# - CrÃ©er endpoints source (MySQL) et target (MariaDB)
# - CrÃ©er instance de rÃ©plication
# - CrÃ©er tÃ¢che full-load-and-cdc

# Phase 2 : DÃ©marrage migration
aws dms start-replication-task \
    --replication-task-arn $TASK_ARN \
    --start-replication-task-type start-replication

# Phase 3 : Monitoring
watch -n 60 'aws dms describe-replication-tasks \
    --filters Name=replication-task-arn,Values=$TASK_ARN \
    --query "ReplicationTasks[0].ReplicationTaskStats"'

# Phase 4 : Validation donnÃ©es (pendant que CDC tourne)
pt-table-checksum \
    --host=mysql-source \
    --replicate=percona.checksums \
    --databases=production_db

# Phase 5 : Switchover applicatif progressif
# 5a. Dual-write : Application Ã©crit MySQL ET MariaDB
# 5b. Read de MariaDB pour % du trafic (canary)
# 5c. Augmentation progressive jusqu'Ã  100%
# 5d. ArrÃªt Ã©critures MySQL
# 5e. ArrÃªt tÃ¢che DMS

aws dms stop-replication-task \
    --replication-task-arn $TASK_ARN

echo "=== Migration zero-downtime terminÃ©e ==="
```

---

## Gestion des erreurs et reprise

### Erreurs courantes et solutions

```bash
# Erreur 1 : Collation inconnue
# ERROR 1273 (HY000): Unknown collation: 'utf8mb4_0900_ai_ci'

# Solution
sed -i 's/utf8mb4_0900_ai_ci/utf8mb4_uca1400_ai_ci/g' dump.sql

# Erreur 2 : Packet trop grand
# ERROR 1153 (08S01): Got a packet bigger than 'max_allowed_packet' bytes

# Solution : augmenter la limite
mysql -h target -e "SET GLOBAL max_allowed_packet = 1073741824;"

# Erreur 3 : Foreign key constraint fails
# ERROR 1215 (HY000): Cannot add foreign key constraint

# Solution : dÃ©sactiver temporairement
mysql -h target << 'EOF'
SET FOREIGN_KEY_CHECKS = 0;
SOURCE dump.sql;
SET FOREIGN_KEY_CHECKS = 1;
EOF

# Erreur 4 : Duplicate entry for key
# ERROR 1062 (23000): Duplicate entry 'xxx' for key 'PRIMARY'

# Solution : utiliser REPLACE ou INSERT IGNORE
sed -i 's/INSERT INTO/REPLACE INTO/g' dump.sql
# Ou
sed -i 's/INSERT INTO/INSERT IGNORE INTO/g' dump.sql

# Erreur 5 : Access denied for user
# ERROR 1045 (28000): Access denied for user 'xxx'@'host'

# Solution : recrÃ©er l'utilisateur avec bon plugin
mysql -h target << 'EOF'
CREATE USER 'xxx'@'host' IDENTIFIED VIA mysql_native_password 
    USING PASSWORD('password');
GRANT ALL PRIVILEGES ON database.* TO 'xxx'@'host';
EOF
```

### Script de reprise aprÃ¨s Ã©chec

```bash
#!/bin/bash
# resume_migration.sh

BACKUP_DIR="/backup/mydumper_export"
MARIADB_HOST="mariadb-target"
DATABASE="production_db"
STATE_FILE="$BACKUP_DIR/.migration_state"

# Fonction pour sauver l'Ã©tat
save_state() {
    echo "$1" > $STATE_FILE
}

# Fonction pour charger l'Ã©tat
load_state() {
    if [ -f $STATE_FILE ]; then
        cat $STATE_FILE
    else
        echo "0"
    fi
}

LAST_STATE=$(load_state)

echo "Reprise depuis Ã©tat: $LAST_STATE"

# Trouver les tables non importÃ©es
IMPORTED_TABLES=$(mysql -h $MARIADB_HOST -u root -p -N -e \
    "SELECT table_name FROM information_schema.tables 
     WHERE table_schema='$DATABASE';")

ALL_TABLES=$(ls $BACKUP_DIR/*.schema.sql | \
    sed 's/.*\.\(.*\)-schema\.sql/\1/' | sort -u)

for table in $ALL_TABLES; do
    if ! echo "$IMPORTED_TABLES" | grep -q "^$table$"; then
        echo "Import table: $table"
        
        # Import schema
        mysql -h $MARIADB_HOST -u root -p $DATABASE < \
            "$BACKUP_DIR/$DATABASE.$table-schema.sql"
        
        # Import data (tous les chunks)
        for chunk in $BACKUP_DIR/$DATABASE.$table.*.sql.gz; do
            zcat "$chunk" | mysql -h $MARIADB_HOST -u root -p $DATABASE
        done
        
        save_state "$table"
    fi
done

echo "Reprise terminÃ©e"
```

---

## âœ… Points clÃ©s Ã  retenir

- **mysqldump** : Simple et universel, suffisant pour bases < 50 GB avec downtime acceptable

- **mydumper/myloader** : 5-10x plus rapide grÃ¢ce au parallÃ©lisme, indispensable pour bases > 50 GB

- **Mariabackup** : Sauvegarde physique ultra-rapide, mais uniquement pour migrations entre versions MariaDB compatibles

- **AWS DMS / Azure DMS** : Solutions managÃ©es idÃ©ales pour zero-downtime et CDC continu, coÃ»t Ã  considÃ©rer

- **Percona Toolkit** : Indispensable pour validation (pt-table-checksum) et synchronisation (pt-table-sync)

- **Transformations post-export** : Toujours convertir les collations `utf8mb4_0900_*` et supprimer les directives GTID MySQL

- **StratÃ©gie de reprise** : PrÃ©voir systÃ©matiquement un mÃ©canisme de checkpoint pour reprendre aprÃ¨s Ã©chec

---

## ğŸ”— Ressources et rÃ©fÃ©rences

- [ğŸ“– MariaDB Knowledge Base - Backup and Restore](https://mariadb.com/kb/en/backup-and-restore-overview/)
- [ğŸ“– mydumper Documentation](https://github.com/mydumper/mydumper)
- [ğŸ“– Percona Toolkit Documentation](https://docs.percona.com/percona-toolkit/)
- [ğŸ“– AWS DMS User Guide](https://docs.aws.amazon.com/dms/latest/userguide/)
- [ğŸ“– Azure Database Migration Service](https://docs.microsoft.com/en-us/azure/dms/)
- [ğŸ“– pgloader Documentation](https://pgloader.readthedocs.io/)
- [ğŸ“– Mariabackup Overview](https://mariadb.com/kb/en/mariabackup-overview/)

---

## â¡ï¸ Section suivante

**[19.2 Migration depuis d'autres SGBD](./02-migration-autres-sgbd.md)** : Approfondissement des migrations Oracle, SQL Server et PostgreSQL avec cas d'usage spÃ©cifiques, conversion des procÃ©dures stockÃ©es et stratÃ©gies de validation mÃ©tier.

â­ï¸ [Migration depuis d'autres SGBD](/19-migration-compatibilite/02-migration-autres-sgbd.md)
