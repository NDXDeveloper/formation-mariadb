ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.3 Split-Brain et Quorum

> **Niveau** : Expert  
> **DurÃ©e estimÃ©e** : 2-3 heures  
> **PrÃ©requis** : Section 14.2 (Galera Cluster), comprÃ©hension des systÃ¨mes distribuÃ©s

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :

- **Comprendre** le phÃ©nomÃ¨ne de split-brain et ses consÃ©quences catastrophiques
- **Configurer** le quorum Galera pour prÃ©venir les split-brains
- **DÃ©tecter** rapidement les situations de partition rÃ©seau
- **Mettre en Å“uvre** des stratÃ©gies de fencing et de rÃ©solution
- **RÃ©cupÃ©rer** d'un split-brain avec perte de donnÃ©es minimale
- **Concevoir** des architectures rÃ©sistantes aux partitions rÃ©seau
- **OpÃ©rer** un cluster multi-datacenter avec gestion du quorum avancÃ©e

---

## Introduction

Le **split-brain** (cerveau divisÃ©) est l'un des problÃ¨mes les plus redoutÃ©s dans les systÃ¨mes distribuÃ©s. Dans le contexte Galera Cluster, il survient lorsque plusieurs segments du cluster se croient lÃ©gitimes et continuent Ã  accepter des Ã©critures de maniÃ¨re indÃ©pendante, crÃ©ant des **divergences de donnÃ©es irrÃ©conciliables**.

Le **quorum** est le mÃ©canisme fondamental qui prÃ©vient ce scÃ©nario catastrophique. Comprendre son fonctionnement et savoir le configurer correctement est **absolument critique** pour toute architecture Galera en production.

> âš ï¸ **Warning Critical** : Un split-brain mal gÃ©rÃ© peut entraÃ®ner une perte de donnÃ©es dÃ©finitive et nÃ©cessiter une reconstruction complÃ¨te du cluster. Ce n'est pas une simple indisponibilitÃ©, c'est une corruption de donnÃ©es.

---

## 1. Le PhÃ©nomÃ¨ne de Split-Brain

### 1.1 DÃ©finition et Anatomie

**Split-brain** : Ã‰tat oÃ¹ un cluster distribuÃ© se scinde en deux (ou plus) partitions indÃ©pendantes, chacune se considÃ©rant comme le cluster lÃ©gitime et continuant Ã  accepter des transactions.

#### **ScÃ©nario Classique de Split-Brain**

```
Ã‰tat Initial : Cluster 3 nÅ“uds sain
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Servers             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Node 1  â”‚â”€â”‚ Node 2  â”‚â”€â”‚ Node 3  â”‚
    â”‚ (DC1)   â”‚ â”‚ (DC1)   â”‚ â”‚ (DC2)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All synchronized âœ…


T+0 : Partition rÃ©seau entre DC1 et DC2
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        PARTITION 1 (DC1)         â”‚ âœ–   â”‚ PARTITION 2  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Node 1 â”‚â”€â”‚ Node 2 â”‚          â”‚     â”‚  â”‚ Node 3 â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   Size: 2 (Majority âœ…)          â”‚     â”‚  Size: 1     â”‚
â”‚   Status: PRIMARY                â”‚     â”‚  Status: NON-PRIMARY
â”‚   Accepts writes âœ…              â”‚     â”‚  Read-only âœ…â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… GOOD : Quorum empÃªche le split-brain
â†’ Partition 1 continue seule (a le quorum 2/3)
â†’ Partition 2 se met automatiquement en read-only


T+0 : ScÃ©nario SANS quorum (2 nÅ“uds initiaux)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PARTITION 1      â”‚ âœ– âœ– âœ–           â”‚   PARTITION 2      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                 â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚ Node 1 â”‚       â”‚                 â”‚   â”‚ Node 2 â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                 â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚   Size: 1          â”‚                 â”‚   Size: 1          â”‚
â”‚   Thinks: I'm aloneâ”‚                 â”‚   Thinks: I'm aloneâ”‚
â”‚   Accepts writes âŒâ”‚                 â”‚   Accepts writes âŒâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âŒ DISASTER : Les deux partitions acceptent des writes divergents !

-- Partition 1
UPDATE accounts SET balance = 1000 WHERE id = 123;

-- Partition 2 (simultanÃ©)
UPDATE accounts SET balance = 500 WHERE id = 123;

â†’ DonnÃ©es irrÃ©conciliables sans intervention manuelle
```

### 1.2 Causes FrÃ©quentes de Split-Brain

#### **1. Partition RÃ©seau (Network Partition)**

**Causes techniques** :
```
- DÃ©faillance switch/routeur
- CÃ¢ble rÃ©seau dÃ©branchÃ©/coupÃ©
- Configuration firewall erronÃ©e
- Saturation bande passante
- ProblÃ¨mes routing (BGP flapping)
- Maintenance rÃ©seau mal planifiÃ©e
```

**Exemple rÃ©el** :
```bash
# VÃ©rification logs systÃ¨me lors partition
tail -f /var/log/mysql/error.log

2025-12-13 14:32:15 [Warning] WSREP: (node1) gcs_core(EVS): 
  Unable to receive from tcp://10.0.2.10:4567
2025-12-13 14:32:20 [Warning] WSREP: gcs_core(EVS): 
  evs::proto(node1, OPERATIONAL, view_id(REG,node1,5)): 
  suspecting node: node3
2025-12-13 14:32:30 [Note] WSREP: declaring node3 at tcp://10.0.2.10:4567 stable
2025-12-13 14:32:30 [Note] WSREP: forgetting node3 (tcp://10.0.2.10:4567)
2025-12-13 14:32:31 [Note] WSREP: New cluster view: global state: 
  a1b2c3d4:123, view#6: PRIMARY (2)
```

#### **2. Asymmetric Network Failure**

**Partition asymÃ©trique** : Cas particuliÃ¨rement vicieux
```
Node1 peut communiquer avec Node2 : âœ…
Node2 peut communiquer avec Node1 : âœ…
Node1 peut communiquer avec Node3 : âŒ
Node2 peut communiquer avec Node3 : âœ…
Node3 peut communiquer avec Node1 : âŒ
Node3 peut communiquer avec Node2 : âœ…

RÃ©sultat :
- Node1 voit : {Node1, Node2} = 2 nÅ“uds
- Node2 voit : {Node1, Node2, Node3} = 3 nÅ“uds (all OK)
- Node3 voit : {Node2, Node3} = 2 nÅ“uds

â†’ Situation instable, peut gÃ©nÃ©rer flapping
```

#### **3. Tuning Agressif de Timeouts**

```ini
# Configuration DANGEREUSE
[galera]
wsrep_provider_options = "
    evs.suspect_timeout = PT1S;    # Trop court !
    evs.inactive_timeout = PT3S;   # Trop court !
"

# ConsÃ©quence : False positives
# â†’ NÅ“ud temporairement lent marquÃ© suspect
# â†’ Ã‰viction prÃ©maturÃ©e
# â†’ RÃ©intÃ©gration â†’ Ã‰viction â†’ Cycle
```

ğŸ’¡ **Recommandation** : Timeouts conservateurs, surtout pour WAN.

#### **4. DÃ©faillances en Cascade**

```
Initial state: 5 nÅ“uds sains

T+0  : Node1 crash (hardware)
       â†’ Cluster: 4 nÅ“uds (quorum OK: 3/5)

T+30s: Node2 surchargÃ© (prend la charge de Node1)
       â†’ Ralentissement
       â†’ Heartbeat tardifs

T+45s: Node2 suspectÃ© par Node3, Node4, Node5
       â†’ Ã‰viction Node2
       â†’ Cluster: 3 nÅ“uds (quorum OK: 2/5)

T+60s: Node3 surchargÃ© Ã  son tour
       â†’ MÃªme scÃ©nario

â†’ Effet domino jusqu'Ã  perte de quorum
```

### 1.3 ConsÃ©quences Catastrophiques

#### **Divergence de DonnÃ©es**

```sql
-- Ã‰tat avant split-brain
SELECT * FROM orders WHERE id = 999;
-- +-----+--------+--------+
-- | id  | status | amount |
-- +-----+--------+--------+
-- | 999 | PAID   | 100.00 |
-- +-----+--------+--------+

-- SPLIT-BRAIN COMMENCE

-- Partition 1 (Node1, Node2)
UPDATE orders SET status = 'SHIPPED', amount = 95.00 
WHERE id = 999;
-- Client applique un discount

-- Partition 2 (Node3) - simultanÃ©
UPDATE orders SET status = 'CANCELLED', amount = 0.00 
WHERE id = 999;
-- Annulation commande

-- APRÃˆS RÃ‰SOLUTION
-- Node1: status = SHIPPED, amount = 95.00
-- Node2: status = SHIPPED, amount = 95.00
-- Node3: status = CANCELLED, amount = 0.00

â†’ IncohÃ©rence irrÃ©conciliable
â†’ NÃ©cessite arbitrage manuel (quelle est la vraie version ?)
```

#### **Violations d'IntÃ©gritÃ©**

```sql
-- Partition 1
INSERT INTO users (id, email) VALUES (123, 'user@example.com');

-- Partition 2 (simultanÃ©)
INSERT INTO users (id, email) VALUES (123, 'different@example.com');

-- AprÃ¨s rÃ©solution
â†’ ERREUR: Duplicate key violation
â†’ Impossible de fusionner automatiquement
```

#### **Impact Business**

```
Exemples rÃ©els de coÃ»ts split-brain :

E-commerce :
- Commandes facturÃ©es 2 fois
- Stock inventory incohÃ©rent
- Pertes estimÃ©es : 50k-500kâ‚¬ / incident

Banking :
- Transactions dupliquÃ©es
- Soldes de comptes divergents
- Implications rÃ©glementaires + amendes

SaaS :
- DonnÃ©es clients corrompues
- Perte de confiance
- Churn client massif
```

---

## 2. Le Quorum : MÃ©canisme de Protection

### 2.1 Principe du Quorum

**DÃ©finition** : Le quorum est le nombre minimal de nÅ“uds qui doivent Ãªtre connectÃ©s pour qu'une partition soit considÃ©rÃ©e comme **PRIMARY** (apte Ã  accepter des Ã©critures).

**Formule** :
```
Quorum = floor(n_nodes / 2) + 1

Exemples :
3 nÅ“uds : Quorum = floor(3/2) + 1 = 2
5 nÅ“uds : Quorum = floor(5/2) + 1 = 3
7 nÅ“uds : Quorum = floor(7/2) + 1 = 4
```

**Garantie** : Au maximum **une seule** partition peut avoir le quorum Ã  un instant donnÃ©.

```
Cluster 5 nÅ“uds, partition en 3-2 :

Partition A (3 nÅ“uds) : 3 â‰¥ 3 (quorum) â†’ PRIMARY âœ…
Partition B (2 nÅ“uds) : 2 < 3 (quorum) â†’ NON-PRIMARY âŒ

â†’ Impossible d'avoir 2 partitions PRIMARY simultanÃ©ment
```

### 2.2 Ã‰tats de Partition

#### **PRIMARY (OpÃ©rationnel)**

```sql
SHOW STATUS LIKE 'wsrep_cluster_status';
-- +----------------------+---------+
-- | Variable_name        | Value   |
-- +----------------------+---------+
-- | wsrep_cluster_status | Primary |
-- +----------------------+---------+

-- CaractÃ©ristiques :
-- âœ… Accepte les Ã©critures (READ/WRITE)
-- âœ… RÃ©plication active
-- âœ… Peut servir de donneur SST/IST
```

**Configuration visible** :
```sql
SHOW STATUS LIKE 'wsrep%';

wsrep_cluster_size          : 3      -- Taille partition
wsrep_cluster_status        : Primary
wsrep_local_state_comment   : Synced
wsrep_ready                 : ON
wsrep_connected             : ON
```

#### **NON-PRIMARY (Read-Only ForcÃ©)**

```sql
SHOW STATUS LIKE 'wsrep_cluster_status';
-- +----------------------+--------------+
-- | Variable_name        | Value        |
-- +----------------------+--------------+
-- | wsrep_cluster_status | Non-primary  |
-- +----------------------+--------------+

-- CaractÃ©ristiques :
-- âŒ Refuse les Ã©critures
-- âŒ Pas de rÃ©plication
-- âœ… Lectures possibles (donnÃ©es potentiellement obsolÃ¨tes)
```

**Comportement automatique** :
```sql
-- Tentative INSERT dans partition NON-PRIMARY
INSERT INTO users (name) VALUES ('Test');
-- ERROR 1047 (08S01): WSREP has not yet prepared node for application use

-- Mode effectif
SHOW VARIABLES LIKE 'read_only';
-- +---------------+-------+
-- | Variable_name | Value |
-- +---------------+-------+
-- | read_only     | ON    |
-- +---------------+-------+
```

### 2.3 Configuration du Quorum

#### **Configuration Standard (Automatique)**

```ini
# /etc/mysql/conf.d/galera.cnf
[galera]
wsrep_provider = /usr/lib/libgalera_smm.so

# Quorum automatique basÃ© sur cluster_size
# PAS BESOIN de configurer explicitement

# Liste des nÅ“uds du cluster
wsrep_cluster_address = "gcomm://node1,node2,node3"

# Le quorum est calculÃ© automatiquement :
# - 3 nÅ“uds â†’ quorum = 2
# - La partition avec 2+ nÅ“uds sera PRIMARY
```

#### **Bootstrap du Cluster (Premier DÃ©marrage)**

```bash
# Sur le PREMIER nÅ“ud uniquement
# /etc/mysql/conf.d/galera.cnf

[galera]
wsrep_cluster_address = "gcomm://"  # Adresse vide = bootstrap

# OU via ligne de commande
galera_new_cluster

# OU systemd
systemctl start mariadb@bootstrap
```

âš ï¸ **CRITICAL** : Ne jamais bootstrapper plusieurs nÅ“uds simultanÃ©ment â†’ split-brain garanti !

**ProcÃ©dure de bootstrap correcte** :
```bash
# 1. Bootstrap Node1
node1$ systemctl start mariadb@bootstrap

node1$ mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
# wsrep_cluster_size = 1

# 2. DÃ©marrer Node2
node2$ systemctl start mariadb
# Rejoint automatiquement Node1

node1$ mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
# wsrep_cluster_size = 2  (quorum atteint âœ…)

# 3. DÃ©marrer Node3
node3$ systemctl start mariadb

node1$ mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
# wsrep_cluster_size = 3

# 4. Remettre Node1 en mode normal (redÃ©marrage)
node1$ systemctl stop mariadb@bootstrap
node1$ systemctl start mariadb  # Rejoint le cluster normalement
```

#### **Quorum ForcÃ© (wsrep_provider_options)**

```ini
# Configuration avancÃ©e (rarement nÃ©cessaire)
[galera]
wsrep_provider_options = "
    pc.ignore_sb = false;           # Default: Respect quorum strict
    pc.ignore_quorum = false;       # Default: Quorum obligatoire
    pc.bootstrap = false;           # Ne pas bootstrap automatiquement
"
```

âš ï¸ **DANGER** : `pc.ignore_sb = true` dÃ©sactive la protection split-brain â†’ **JAMAIS en production !**

### 2.4 Quorum dans Architectures SpÃ©ciales

#### **Cluster 2 NÅ“uds (Anti-Pattern)**

```
ProblÃ¨me : 2 nÅ“uds, quorum = 2

Partition rÃ©seau :
- Node1 (size=1) : 1 < 2 â†’ NON-PRIMARY âŒ
- Node2 (size=1) : 1 < 2 â†’ NON-PRIMARY âŒ

â†’ Cluster COMPLÃˆTEMENT down (les deux en read-only)
```

**Solutions de contournement** :

**A. Utiliser Arbitrator (Garbd)** 
```bash
# DÃ©ployer garbd (pas de donnÃ©es, juste vote quorum)
apt-get install galera-arbitrator-4

# /etc/default/garbd
GALERA_NODES="node1:4567,node2:4567"
GALERA_GROUP="production_cluster"

systemctl start garbd

# Cluster effectif : 3 membres (2 DB + 1 arbitrator)
# Quorum = 2
# Perte Node1 â†’ {Node2, Garbd} = 2 â†’ quorum OK âœ…
```

**B. PC Weight (Poids personnalisÃ©)** âš ï¸ RisquÃ©
```ini
# Node1 (serveur principal)
wsrep_provider_options = "pc.weight=2"  # Compte double

# Node2 (standby)
wsrep_provider_options = "pc.weight=1"

# Quorum basÃ© sur poids total, pas nombre de nÅ“uds
# Partition Node1 seul : weight=2 â‰¥ 2 â†’ PRIMARY
# Partition Node2 seul : weight=1 < 2 â†’ NON-PRIMARY

# âš ï¸ DANGER : En cas de panne Node1, Node2 ne peut pas prendre le relais !
```

ğŸ’¡ **Recommandation forte** : **Toujours 3+ nÅ“uds** ou utiliser garbd. Jamais 2 nÅ“uds en production.

#### **Multi-Datacenter avec Segments**

```ini
# Segmentation pour optimiser communication intra-DC
[galera]
wsrep_provider_options = "
    gmcast.segment = 0;  # DC1 (Paris)
"

# Node3, Node4 (Londres)
wsrep_provider_options = "
    gmcast.segment = 1;  # DC2 (Londres)
"

# Garbd (Dublin)
wsrep_provider_options = "
    gmcast.segment = 2;  # DC3 (Dublin - arbitre)
"

# Avantage : Optimise traffic rÃ©seau intra-segment
# Quorum global maintenu sur l'ensemble
```

**ScÃ©nario perte DC1** :
```
5 nÅ“uds : DC1(2) + DC2(2) + Garbd(1)
Quorum = 3

Perte DC1 :
Partition DC2+Garbd : 2+1 = 3 â‰¥ 3 â†’ PRIMARY âœ…
```

---

## 3. DÃ©tection de Split-Brain

### 3.1 Monitoring Proactif

#### **MÃ©triques ClÃ©s Ã  Surveiller**

```sql
-- Script de monitoring (Ã  exÃ©cuter pÃ©riodiquement)
SELECT 
    @@hostname AS node_name,
    -- Statut cluster
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_cluster_status') AS cluster_status,
    
    -- Taille cluster
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_cluster_size') AS cluster_size,
    
    -- Taille configurÃ©e
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_cluster_conf_id') AS conf_id,
    
    -- Ã‰tat local
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_local_state_comment') AS local_state,
    
    -- ConnectÃ© ?
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_connected') AS connected,
    
    -- Ready ?
    (SELECT VARIABLE_VALUE FROM information_schema.GLOBAL_STATUS 
     WHERE VARIABLE_NAME='wsrep_ready') AS ready;

-- RÃ©sultat SAIN :
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node_name | cluster_status | cluster_size | conf_id | local_state | connected | ready |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node1     | Primary        | 3            | 42      | Synced      | ON        | ON    |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+

-- RÃ©sultat SPLIT-BRAIN :
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node_name | cluster_status | cluster_size | conf_id | local_state | connected | ready |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node1     | Primary        | 2            | 43      | Synced      | ON        | ON    |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+

-- SimultanÃ©ment sur node3 :
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node_name | cluster_status | cluster_size | conf_id | local_state | connected | ready |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
-- | node3     | Non-primary    | 1            | 43      | Synced      | ON        | OFF   |
-- +-----------+----------------+--------------+---------+-------------+-----------+-------+
```

**Alertes critiques** :
```bash
#!/bin/bash
# galera_monitor.sh

EXPECTED_SIZE=5  # Nombre total de nÅ“uds

current_size=$(mysql -N -e "SHOW STATUS LIKE 'wsrep_cluster_size'" | awk '{print $2}')
cluster_status=$(mysql -N -e "SHOW STATUS LIKE 'wsrep_cluster_status'" | awk '{print $2}')

if [ "$cluster_status" != "Primary" ]; then
    echo "CRITICAL: Node is NON-PRIMARY !"
    # Envoyer alerte PagerDuty/OpsGenie
    exit 2
fi

if [ "$current_size" -lt "$((EXPECTED_SIZE / 2 + 1))" ]; then
    echo "WARNING: Cluster size ($current_size) below quorum threshold"
    exit 1
fi

if [ "$current_size" -lt "$EXPECTED_SIZE" ]; then
    echo "WARNING: Cluster degraded ($current_size/$EXPECTED_SIZE nodes)"
    exit 1
fi

echo "OK: Cluster healthy ($current_size nodes, Primary)"
exit 0
```

#### **Prometheus Exporters**

```yaml
# mysqld_exporter configuration
# /etc/mysqld_exporter/mysqld_exporter.cnf

[client]
user = exporter
password = secure_password

# MÃ©triques Galera exposÃ©es
[mysqld_exporter]
collect.global_status = true
collect.info_schema.innodb_metrics = true
```

**RequÃªtes PromQL pour alerting** :
```promql
# Alerte : NÅ“ud NON-PRIMARY
mysql_global_status_wsrep_cluster_status != 1

# Alerte : Cluster size rÃ©duit
mysql_global_status_wsrep_cluster_size < 5

# Alerte : NÅ“ud dÃ©connectÃ©
mysql_global_status_wsrep_connected != 1

# Alerte : NÅ“ud not ready
mysql_global_status_wsrep_ready != 1
```

### 3.2 Analyse des Logs

#### **Patterns de Logs Suspects**

```bash
# /var/log/mysql/error.log

# 1. DÃ©tection perte de connexion
2025-12-13 15:42:10 [Warning] WSREP: gcs_core(EVS): Unable to receive from tcp://10.0.2.12:4567
2025-12-13 15:42:15 [Warning] WSREP: gcs_core(EVS): suspecting node: node3 (tcp://10.0.2.12:4567)

# 2. Ã‰viction d'un nÅ“ud
2025-12-13 15:42:30 [Note] WSREP: forgetting node3 (tcp://10.0.2.12:4567)
2025-12-13 15:42:31 [Note] WSREP: New cluster view: global state: uuid:123, view#44: Primary (2)

# 3. Perte de quorum (DANGER !)
2025-12-13 15:45:00 [Note] WSREP: New cluster view: global state: uuid:123, view#45: Non-Primary (1)
2025-12-13 15:45:00 [Note] WSREP: Current view of cluster as seen by this node:
view (view_id(NON_PRIM,node1,45) memb {
    node1,tcp://10.0.1.10:4567
} joined {
} left {
} partitioned {
    node2,tcp://10.0.1.11:4567
    node3,tcp://10.0.2.12:4567
})

# 4. Basculement en read_only
2025-12-13 15:45:01 [Note] WSREP: Server status change connected -> donor/desynced
2025-12-13 15:45:01 [Note] WSREP: wsrep_ready changed from ON to OFF
```

**Parser automatique** :
```bash
#!/bin/bash
# detect_split_brain.sh

LOG_FILE="/var/log/mysql/error.log"

# Recherche patterns critiques dans les 5 derniÃ¨res minutes
SINCE=$(date --date='5 minutes ago' '+%Y-%m-%d %H:%M')

grep -A 5 "Non-Primary" $LOG_FILE | grep "$SINCE" && {
    echo "CRITICAL: Split-brain detected!"
    echo "Node is in NON-PRIMARY state"
    
    # Extraire taille partition
    cluster_size=$(mysql -N -e "SHOW STATUS LIKE 'wsrep_cluster_size'" | awk '{print $2}')
    echo "Current partition size: $cluster_size"
    
    # Alerter Ã©quipe
    send_alert "Split-brain on $(hostname)"
}
```

---

## 4. RÃ©solution de Split-Brain

### 4.1 ScÃ©narios de RÃ©solution

#### **ScÃ©nario 1 : Split-Brain avec Partition Gagnante Claire**

```
Situation :
- Partition A (3 nÅ“uds) : PRIMARY âœ…
- Partition B (2 nÅ“uds) : NON-PRIMARY âŒ

RÃ©solution automatique :
â†’ Pas d'intervention nÃ©cessaire
â†’ Partition B attend reconnexion
â†’ AprÃ¨s reconnexion, IST depuis Partition A
```

**Reconnexion rÃ©seau** :
```bash
# Sur les nÅ“uds de Partition B
# Logs automatiques aprÃ¨s rÃ©tablissement rÃ©seau

2025-12-13 16:00:00 [Note] WSREP: Received NON-PRIMARY view
2025-12-13 16:00:05 [Note] WSREP: Connection restored to node1 (tcp://10.0.1.10:4567)
2025-12-13 16:00:06 [Note] WSREP: Requesting IST from node1
2025-12-13 16:00:10 [Note] WSREP: IST received: 234 transactions
2025-12-13 16:00:11 [Note] WSREP: New cluster view: Primary (5)
2025-12-13 16:00:11 [Note] WSREP: Synchronized with group, ready for connections

# VÃ©rification
mysql -e "SHOW STATUS LIKE 'wsrep%'"
wsrep_cluster_size     : 5
wsrep_cluster_status   : Primary
wsrep_local_state      : 4 (Synced)
```

âœ… **RÃ©sultat** : Synchronisation automatique, aucune perte de donnÃ©es.

#### **ScÃ©nario 2 : Split-Brain 50-50 (Toutes Partitions NON-PRIMARY)**

```
Situation critique :
Cluster 4 nÅ“uds split 2-2

- Partition A (2 nÅ“uds) : 2 < 3 â†’ NON-PRIMARY âŒ
- Partition B (2 nÅ“uds) : 2 < 3 â†’ NON-PRIMARY âŒ

â†’ Cluster COMPLÃˆTEMENT down (catastrophe !)
```

**RÃ©solution manuelle requise** :

**MÃ©thode 1 : Bootstrap une partition (si rÃ©seau restaurÃ©)**
```bash
# 1. ArrÃªter tous les nÅ“uds proprement
node1$ systemctl stop mariadb
node2$ systemctl stop mariadb
node3$ systemctl stop mariadb
node4$ systemctl stop mariadb

# 2. Identifier le nÅ“ud avec seqno le plus rÃ©cent
node1$ galera_recovery
# Recovered position: uuid:seqno = a1b2c3:1234

node2$ galera_recovery
# Recovered position: uuid:seqno = a1b2c3:1234

node3$ galera_recovery
# Recovered position: uuid:seqno = a1b2c3:1220  # Plus ancien

node4$ galera_recovery
# Recovered position: uuid:seqno = a1b2c3:1220

# 3. Bootstrap depuis le nÅ“ud le plus rÃ©cent (node1 ou node2)
node1$ systemctl start mariadb@bootstrap

# 4. Rejoindre les autres nÅ“uds
node2$ systemctl start mariadb
node3$ systemctl start mariadb
node4$ systemctl start mariadb

# 5. VÃ©rifier cluster
mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
# wsrep_cluster_size = 4 âœ…
```

**MÃ©thode 2 : Forcer quorum (DANGER - dernier recours)**
```sql
-- SUR UN SEUL NÅ’UD de la partition Ã  privilÃ©gier
SET GLOBAL wsrep_provider_options = 'pc.bootstrap=true';

-- VÃ©rification
SHOW STATUS LIKE 'wsrep_cluster_status';
-- wsrep_cluster_status : Primary âœ…

-- âš ï¸ ATTENTION : Les autres nÅ“uds doivent Ãªtre arrÃªtÃ©s
-- avant d'utiliser cette commande !
```

#### **ScÃ©nario 3 : Split-Brain avec Ã‰critures Divergentes (PIRE CAS)**

```
Situation catastrophique :
- 2 partitions ont acceptÃ© des Ã©critures
- DonnÃ©es divergentes irrÃ©conciliables

Exemple :
Partition A :
  UPDATE users SET email='a@example.com' WHERE id=1;
  
Partition B :
  UPDATE users SET email='b@example.com' WHERE id=1;
```

**RÃ©solution nÃ©cessite arbitrage humain** :

```bash
# 1. Identifier quelle partition contient les donnÃ©es "correctes"
# CritÃ¨res de dÃ©cision :
#   - Quelle partition a le plus de nÅ“uds ?
#   - Quelle partition a les donnÃ©es les plus rÃ©centes ?
#   - Impact business : quelle version accepter ?

# 2. Backup exhaustif des DEUX partitions
# Partition A
node1$ mysqldump --all-databases > /backup/partition_a_$(date +%s).sql

# Partition B
node3$ mysqldump --all-databases > /backup/partition_b_$(date +%s).sql

# 3. DÃ©cision : Partition A = source de vÃ©ritÃ©

# 4. DÃ©truire et reconstruire Partition B
node3$ systemctl stop mariadb
node3$ rm -rf /var/lib/mysql/*
node3$ systemctl start mariadb  # SST complet depuis Partition A

# 5. Analyse manuelle des diffÃ©rences pour rÃ©cupÃ©ration donnÃ©es
diff /backup/partition_a_*.sql /backup/partition_b_*.sql > divergences.txt

# 6. RÃ©appliquer manuellement les transactions perdues si nÃ©cessaire
# (aprÃ¨s validation business)
```

âš ï¸ **IMPORTANT** : Documenter exhaustivement l'incident et les dÃ©cisions prises.

### 4.2 Outils de RÃ©cupÃ©ration

#### **galera_recovery**

```bash
# DÃ©terminer le dernier Ã©tat connu du nÅ“ud
/usr/bin/galera_recovery

# Output :
# WSREP: Recovered position: uuid:seqno = a1b2c3d4-e5f6-7890-abcd-ef1234567890:1234

# InterprÃ©tation :
# uuid : Identifiant unique du cluster
# seqno : NumÃ©ro de sÃ©quence (transaction)
# â†’ Ce nÅ“ud a appliquÃ© jusqu'Ã  la transaction #1234
```

**Usage dans bootstrap** :
```bash
# Comparer seqno de tous les nÅ“uds
for node in node1 node2 node3; do
    echo "=== $node ==="
    ssh $node "/usr/bin/galera_recovery"
done

# Bootstrapper depuis le nÅ“ud avec seqno le plus Ã©levÃ©
```

#### **grastate.dat**

```bash
# Fichier d'Ã©tat Galera
cat /var/lib/mysql/grastate.dat

# version: 2.1
# uuid:    a1b2c3d4-e5f6-7890-abcd-ef1234567890
# seqno:   1234
# safe_to_bootstrap: 0

# safe_to_bootstrap:
#   0 = Shutdown non gracieux (crash) â†’ VÃ©rifier avec d'autres nÅ“uds
#   1 = Dernier nÅ“ud Ã  se dÃ©connecter proprement â†’ Bootstrap OK
```

**Manipulation manuelle (cas extrÃªme)** :
```bash
# SI ET SEULEMENT SI :
# - Cluster complÃ¨tement down
# - Ce nÅ“ud a les donnÃ©es les plus rÃ©centes
# - Backup effectuÃ©

vim /var/lib/mysql/grastate.dat
# Modifier :
# safe_to_bootstrap: 1

# Puis bootstrap
systemctl start mariadb@bootstrap
```

âš ï¸ **DANGER** : Ne modifier grastate.dat qu'en dernier recours et avec backup !

---

## 5. StratÃ©gies de PrÃ©vention

### 5.1 Architecture RÃ©siliante

#### **Nombre de NÅ“uds Optimal**

```
Production recommandÃ©e :

Small cluster  : 3 nÅ“uds  (tolÃ¨re 1 panne)
Medium cluster : 5 nÅ“uds  (tolÃ¨re 2 pannes)
Large cluster  : 7 nÅ“uds  (tolÃ¨re 3 pannes)

RÃ¨gle d'or : Toujours un nombre IMPAIR de nÅ“uds
â†’ Ã‰vite les partitions 50-50
```

**Distribution multi-DC** :
```
Exemple 5 nÅ“uds, 3 DC :

DC1 (Paris)   : 2 nÅ“uds
DC2 (Londres) : 2 nÅ“uds
DC3 (Dublin)  : 1 Garbd (arbitrator)

Perte DC1 â†’ {DC2 + DC3} = 2+1 = 3 â‰¥ 3 âœ…
Perte DC2 â†’ {DC1 + DC3} = 2+1 = 3 â‰¥ 3 âœ…
Perte DC3 â†’ {DC1 + DC2} = 2+2 = 4 â‰¥ 3 âœ…
```

#### **Redondance RÃ©seau**

```bash
# Configuration multi-path (bonding)
# /etc/network/interfaces

auto bond0
iface bond0 inet static
    address 10.0.1.10
    netmask 255.255.255.0
    bond-slaves eth0 eth1
    bond-mode active-backup
    bond-miimon 100
    bond-primary eth0

# Galera utilise l'interface bonding
# â†’ TolÃ©rance panne d'une NIC
```

**VLAN dÃ©diÃ© Galera** :
```
RÃ©seau application : VLAN 10 (10.10.0.0/24)
RÃ©seau Galera      : VLAN 20 (10.20.0.0/24)
RÃ©seau management  : VLAN 30 (10.30.0.0/24)

Avantages :
- Isolation du trafic de rÃ©plication
- QoS configurable
- Debugging facilitÃ©
```

### 5.2 Configuration Conservatrice

```ini
# /etc/mysql/conf.d/galera.cnf
[galera]

# Timeouts gÃ©nÃ©reux (surtout multi-DC)
wsrep_provider_options = "
    # Keepalive lÃ©ger
    evs.keepalive_period = PT1S;
    
    # DÃ©lai avant suspicion (gÃ©nÃ©rique)
    evs.suspect_timeout = PT10S;
    
    # Timeout inactivitÃ© (multi-DC : 30s+)
    evs.inactive_timeout = PT30S;
    
    # Timeout installation vue
    evs.install_timeout = PT30S;
    
    # Send window (limiter burst)
    evs.send_window = 512;
    
    # User messages (heartbeat applicatif)
    evs.user_send_window = 256;
    
    # Consensus timeout
    evs.consensus_timeout = PT30S;
"

# Ã‰viter Ã©victions prÃ©maturÃ©es
# Multi-DC avec latence WAN : doubler/tripler ces valeurs
```

**Tuning rÃ©seau WAN** :
```ini
# Configuration pour latence 50-100ms inter-DC
wsrep_provider_options = "
    evs.suspect_timeout = PT30S;
    evs.inactive_timeout = PT60S;
    evs.install_timeout = PT60S;
    
    # Augmenter buffers
    evs.send_window = 1024;
    evs.user_send_window = 512;
    
    # Segment markers
    gmcast.segment = 0;  # Ajuster par DC
"
```

### 5.3 Monitoring et Alerting Agressif

```yaml
# prometheus_alerts.yml
groups:
  - name: galera_cluster
    interval: 10s
    rules:
      - alert: GaleraNodeNonPrimary
        expr: mysql_global_status_wsrep_cluster_status != 1
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Galera node {{ $labels.instance }} is NON-PRIMARY"
          description: "Split-brain possible, immediate investigation required"
      
      - alert: GaleraClusterSizeReduced
        expr: mysql_global_status_wsrep_cluster_size < 5
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Galera cluster degraded on {{ $labels.instance }}"
          description: "Cluster size: {{ $value }}/5 - Risk of quorum loss"
      
      - alert: GaleraNodeDisconnected
        expr: mysql_global_status_wsrep_connected != 1
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Galera node {{ $labels.instance }} disconnected"
      
      - alert: GaleraNodeNotReady
        expr: mysql_global_status_wsrep_ready != 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Galera node {{ $labels.instance }} not ready"
```

### 5.4 Runbooks et ProcÃ©dures

**Checklist incident split-brain** :
```markdown
# RUNBOOK : Split-Brain Galera

## DÃ©tection
- [ ] Alerte Prometheus/Nagios reÃ§ue
- [ ] VÃ©rifier wsrep_cluster_status sur tous les nÅ“uds
- [ ] Identifier taille de chaque partition

## Investigation
- [ ] Analyser /var/log/mysql/error.log (patterns partition)
- [ ] VÃ©rifier connectivitÃ© rÃ©seau entre nÅ“uds (ping, nc)
- [ ] Consulter monitoring rÃ©seau (switch, firewall)

## RÃ©solution (si partition rÃ©seau rÃ©solue)
- [ ] Attendre reconnexion automatique (5 min max)
- [ ] VÃ©rifier IST sur nÅ“uds NON-PRIMARY
- [ ] Valider cluster_size = attendu

## RÃ©solution (si cluster complÃ¨tement down)
- [ ] BACKUP immÃ©diat de tous les nÅ“uds
- [ ] galera_recovery sur tous les nÅ“uds
- [ ] Identifier seqno max
- [ ] Bootstrap depuis nÅ“ud seqno max
- [ ] Rejoindre autres nÅ“uds sÃ©quentiellement

## RÃ©solution (Ã©critures divergentes)
- [ ] BACKUP exhaustif TOUTES les partitions
- [ ] Arbitrage business (quelle version garder)
- [ ] Reconstruction partition perdante (SST complet)
- [ ] Analyse diff pour rÃ©cupÃ©ration manuelle

## Post-Mortem
- [ ] Documenter incident timeline
- [ ] Identifier root cause
- [ ] Plan d'action prÃ©ventif
- [ ] Mise Ã  jour runbook
```

---

## 6. Cas AvancÃ©s et Edge Cases

### 6.1 Garagekeeper (Arbitrator) - Configuration AvancÃ©e

```bash
# Installation garbd
apt-get install galera-arbitrator-4

# Configuration systemd
cat > /etc/systemd/system/garbd.service <<EOF
[Unit]
Description=Galera Arbitrator Daemon
After=network.target

[Service]
Type=simple
User=nobody
ExecStart=/usr/bin/garbd \\
    --group production_cluster \\
    --address "gcomm://node1:4567,node2:4567,node3:4567,node4:4567" \\
    --options "gmcast.listen_addr=tcp://0.0.0.0:4567;gmcast.segment=2" \\
    --log /var/log/garbd.log \\
    --sst rsync

Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable garbd
systemctl start garbd
```

**Monitoring garbd** :
```bash
# VÃ©rifier logs
tail -f /var/log/garbd.log

# VÃ©rifier depuis nÅ“uds DB
mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'"
# Doit inclure garbd (ex: 5 si 4 DB + 1 garbd)

mysql -e "SHOW STATUS LIKE 'wsrep_incoming_addresses'"
# Liste tous les membres incluant garbd
```

### 6.2 Weighted Quorum (PC Weight)

**Configuration poids personnalisÃ©** :
```ini
# Use case : Cluster asymÃ©trique

# Node1 (Datacenter principal, hardware puissant)
[galera]
wsrep_provider_options = "pc.weight=3"

# Node2 (Datacenter principal)
wsrep_provider_options = "pc.weight=3"

# Node3 (Datacenter DR, hardware moindre)
wsrep_provider_options = "pc.weight=1"

# Node4 (Datacenter DR)
wsrep_provider_options = "pc.weight=1"

# Quorum basÃ© sur poids :
# Total weight = 3+3+1+1 = 8
# Quorum weight = 8/2 + 1 = 5

# ScÃ©narios :
# Perte DC principal (Node1+2) : weight=1+1=2 < 5 â†’ NON-PRIMARY âŒ
# Perte DC DR (Node3+4)        : weight=3+3=6 â‰¥ 5 â†’ PRIMARY âœ…

# â†’ DC principal peut fonctionner seul
```

âš ï¸ **ATTENTION** : Usage avancÃ©, nÃ©cessite comprÃ©hension profonde des implications.

### 6.3 Last Committed (pc.recovery)

```ini
# Active automatiquement la rÃ©cupÃ©ration intelligente
[galera]
wsrep_provider_options = "pc.recovery=true"

# Comportement :
# - En cas de crash cluster complet
# - NÅ“uds tentent automatiquement de dÃ©terminer
#   lequel a le seqno le plus rÃ©cent
# - Bootstrap automatique depuis ce nÅ“ud
# - SANS intervention manuelle

# âš ï¸ Utiliser avec prÃ©caution :
# - Risque de bootstrap non intentionnel
# - PrÃ©fÃ©rer procÃ©dure manuelle contrÃ´lÃ©e en prod
```

---

## âœ… Points ClÃ©s Ã  Retenir

- **Split-brain = divergence de donnÃ©es irrÃ©conciliable**, le pire scÃ©nario en systÃ¨me distribuÃ©
- **Quorum = seul mÃ©canisme fiable** pour prÃ©venir split-brain (â‰¥ 50% + 1)
- **Toujours 3+ nÅ“uds** (5 recommandÃ© production), **jamais 2 nÅ“uds** seuls
- **Arbitrator (garbd)** excellent pour 3áµ‰ site ou cluster 2+1
- **Monitoring proactif** : alerting immÃ©diat sur cluster_status, cluster_size
- **Logs critiques** : surveiller patterns "Non-Primary", "forgetting node"
- **RÃ©solution automatique** si une partition a quorum clair (IST)
- **RÃ©solution manuelle** si cluster complÃ¨tement down (bootstrap + galera_recovery)
- **Arbitrage humain** si Ã©critures divergentes (backup + reconstruction)
- **PrÃ©vention** : architecture multi-DC, rÃ©seau redondant, timeouts conservateurs
- **Runbooks essentiels** : procÃ©dures documentÃ©es et testÃ©es rÃ©guliÃ¨rement

---

## ğŸ”— Ressources et RÃ©fÃ©rences

### Documentation Officielle
- [ğŸ“– Galera Cluster Quorum](https://galeracluster.com/library/documentation/quorum.html)
- [ğŸ“– PC (Primary Component) Protocol](https://galeracluster.com/library/documentation/pc-protocol.html)
- [ğŸ“– Split-Brain Scenarios](https://galeracluster.com/library/kb/split-brain-and-quorum.html)

### Whitepapers et Articles
- **"Understanding Quorum in Distributed Systems"** - Academic Paper
- **"Split-Brain Resolution Strategies"** - Codership Blog
- **"Galera Arbitrator Deep Dive"** - MariaDB Knowledge Base

### Outils
- [garbd Documentation](https://galeracluster.com/library/documentation/arbitrator.html)
- [myq_gadgets - Galera Monitoring](https://github.com/jayjanssen/myq_gadgets)
- [Chaos Monkey for Galera](https://github.com/galera-chaos) - Testing tool

---

## â¡ï¸ Section Suivante

**[14.4 MaxScale](/14-haute-disponibilite/04-maxscale.md)**

Maintenant que vous maÃ®trisez la gestion du quorum et la rÃ©solution de split-brain, la section suivante introduit **MaxScale**, le proxy intelligent qui :
- DÃ©tecte automatiquement les nÅ“uds PRIMARY/NON-PRIMARY
- Route les connexions vers les nÅ“uds sains
- Fournit le failover transparent pour les applications
- Offre des fonctionnalitÃ©s avancÃ©es (Database Firewall, Query Routing)

MaxScale est la couche qui rend Galera rÃ©ellement transparent pour les applications.

---

**Le split-brain n'est pas une fatalitÃ©. Une comprÃ©hension solide du quorum et des procÃ©dures de rÃ©cupÃ©ration bien rodÃ©es sont votre meilleure assurance.**

â­ï¸ [MaxScale](/14-haute-disponibilite/04-maxscale.md)
