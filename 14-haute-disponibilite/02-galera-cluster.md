ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.2 MariaDB Galera Cluster

> **Niveau** : Expert  
> **DurÃ©e estimÃ©e** : 3-4 heures  
> **PrÃ©requis** : Section 14.1, maÃ®trise de la rÃ©plication MariaDB, concepts de systÃ¨mes distribuÃ©s

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :

- **Comprendre** l'architecture interne de Galera Cluster et le protocole wsrep
- **DiffÃ©rencier** Galera des solutions de rÃ©plication traditionnelles
- **Ã‰valuer** les avantages et limitations pour vos use cases
- **Identifier** les prÃ©requis rÃ©seau, matÃ©riel et logiciel pour un dÃ©ploiement production
- **Planifier** une architecture Galera adaptÃ©e Ã  vos contraintes (single-DC, multi-DC)
- **Anticiper** les challenges opÃ©rationnels et leurs solutions

---

## Introduction

**MariaDB Galera Cluster** reprÃ©sente une rupture paradigmatique dans le monde de la rÃ©plication MariaDB. Contrairement aux modÃ¨les master-slave traditionnels, Galera implÃ©mente une **rÃ©plication synchrone multi-master** basÃ©e sur la certification des transactions, offrant un **RPO de zÃ©ro** et une disponibilitÃ© quasi-continue.

Galera n'est pas simplement une couche de rÃ©plication ajoutÃ©e Ã  MariaDB, c'est une **intÃ©gration profonde** au niveau du moteur de stockage via l'API wsrep (Write Set Replication). Cette architecture permet Ã  tous les nÅ“uds d'accepter simultanÃ©ment des Ã©critures tout en garantissant la cohÃ©rence des donnÃ©es Ã  travers le cluster.

### ğŸ” Pourquoi Galera ?

Dans un monde oÃ¹ l'indisponibilitÃ© coÃ»te cher, Galera rÃ©pond Ã  des besoins critiques :

**ProblÃ¨mes rÃ©solus** :
- âŒ **Perte de donnÃ©es** lors d'une panne master (rÃ©plication async)
- âŒ **Downtime prolongÃ©** pendant un failover manuel
- âŒ **ComplexitÃ©** de gestion des topologies master-slave
- âŒ **Sous-utilisation** des serveurs standby
- âŒ **Latence** de lecture sur les replicas (slave lag)

**Solutions Galera** :
- âœ… **RPO = 0** : Aucune perte de donnÃ©es garantie
- âœ… **RTO < 30 sec** : Failover automatique quasi-instantanÃ©
- âœ… **SimplicitÃ©** : Tous les nÅ“uds sont Ã©gaux (peer-to-peer)
- âœ… **Utilisation 100%** : Tous les nÅ“uds actifs simultanÃ©ment
- âœ… **CohÃ©rence** : Lectures toujours Ã  jour (configurable)

> ğŸ’¡ **Citation** : "Galera Cluster turns the database itself into a highly available service, not just a replicated data store." - Codership (crÃ©ateurs de Galera)

---

## 1. Vue d'Ensemble de Galera Cluster

### 1.1 Architecture Fondamentale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚              â”‚  App 1   â”‚  â”‚  App 2   â”‚  â”‚  App 3   â”‚      â”‚
â”‚              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚             â”‚             â”‚
                    â”‚    Load Balancing Layer   â”‚
                    â”‚    (MaxScale/HAProxy)     â”‚
                    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â–¼             â–¼             â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   GALERA NODE 1  â”‚  â”‚   GALERA NODE 2  â”‚  â”‚  NODE 3   â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   MariaDB  â”‚  â”‚  â”‚  â”‚   MariaDB  â”‚  â”‚  â”‚ â”‚MariaDBâ”‚ â”‚
â”‚  â”‚  â”‚   Server   â”‚â—„â”€â”¼â”€â”€â”¼â”€â–ºâ”‚   Server   â”‚â—„â”€â”¼â”€â”€â”¼â–ºâ”‚Server â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚        â”‚         â”‚  â”‚        â”‚         â”‚  â”‚    â”‚      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â–¼â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   wsrep    â”‚  â”‚  â”‚  â”‚   wsrep    â”‚  â”‚  â”‚ â”‚wsrep â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Provider  â”‚  â”‚  â”‚  â”‚  Provider  â”‚  â”‚  â”‚ â”‚Provdrâ”‚  â”‚ â”‚
â”‚  â”‚  â”‚(Galera lib)â”‚  â”‚  â”‚  â”‚(Galera lib)â”‚  â”‚  â”‚ â”‚      â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”¬â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚        â”‚         â”‚  â”‚        â”‚         â”‚  â”‚    â”‚      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”Œâ”€â”€â–¼â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  InnoDB    â”‚  â”‚  â”‚  â”‚  InnoDB    â”‚  â”‚  â”‚ â”‚InnoDBâ”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Storage   â”‚  â”‚  â”‚  â”‚  Storage   â”‚  â”‚  â”‚ â”‚      â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚         Group Communication (gcomm://)                     â”‚
â”‚         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cluster Coordination â”€â”€â”€â”€â”€â”€â”€â”€â–º          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants ClÃ©s** :

1. **MariaDB Server** : Moteur de base standard
2. **wsrep API** : Interface de rÃ©plication (Write Set Replication)
3. **Galera Replication Plugin** : BibliothÃ¨que libgalera_smm.so
4. **Group Communication** : Protocole de communication inter-nÅ“uds (gcomm)
5. **Certification Layer** : Validation des transactions

### 1.2 DiffÃ©rences avec la RÃ©plication Traditionnelle

| Aspect | RÃ©plication Async | RÃ©plication Semi-Sync | Galera Cluster |
|--------|-------------------|----------------------|----------------|
| **Topologie** | Master â†’ Slave(s) | Master â†’ Slave(s) | Peer-to-peer mesh |
| **Writes** | Master uniquement | Master uniquement | Tous les nÅ“uds |
| **Synchronisation** | Asynchrone (lag) | Commit Master + 1 ACK | Synchrone globale |
| **Validation** | AprÃ¨s application | Avant commit master | Avant commit cluster |
| **CohÃ©rence** | Ã‰ventuelle | Forte (1 slave min) | Stricte (tous nÅ“uds) |
| **Perte donnÃ©es** | Possible | TrÃ¨s rare | Impossible |
| **Latence commit** | Faible | Moyenne | Moyenne-Haute |
| **Conflits** | Impossibles | Impossibles | Possibles (rares) |
| **Failover** | Manuel/Scripts | Manuel/Scripts | Automatique |
| **ComplexitÃ©** | Faible | Faible | Moyenne-Haute |

### 1.3 Versions et Composants

**Galera Cluster disponible en deux variantes** :

#### **MariaDB Galera Cluster (IntÃ©grÃ©)**
```bash
# DÃ©jÃ  intÃ©grÃ© dans MariaDB depuis 10.1
apt-get install mariadb-server galera-4

# VÃ©rification version
mysql -e "SHOW STATUS LIKE 'wsrep_provider_version'"
# +-----------------------+---------+
# | Variable_name         | Value   |
# +-----------------------+---------+
# | wsrep_provider_version| 4.16    |
# +-----------------------+---------+
```

**Versions Galera** :
- **Galera 3.x** : Legacy (MariaDB 10.1-10.3)
- **Galera 4.x** : Current (MariaDB 10.4+) ğŸ†•
  - Streaming Replication (grandes transactions)
  - Parallel applying amÃ©liorÃ©
  - Automatic IST optimisÃ©

#### **Codership Galera (Standalone)**
Alternative maintenue par les crÃ©ateurs originaux de Galera :
```bash
# Installation alternative
wget https://releases.galeracluster.com/galera-4/galera-4-26.4.16.tar.gz
```

ğŸ’¡ **Recommandation** : Utiliser MariaDB Galera Cluster intÃ©grÃ© pour simplifier la maintenance.

---

## 2. Concepts Fondamentaux

### 2.1 Write Set Replication (wsrep)

Galera n'utilise pas les binary logs traditionnels pour la rÃ©plication. Ã€ la place, il implÃ©mente **wsrep** :

**Workflow d'une transaction** :

```
1. Client envoie: BEGIN; UPDATE ...; COMMIT;
                        â”‚
                        â–¼
2. ExÃ©cution locale (optimistic execution)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Transaction exÃ©cutÃ©e en local      â”‚
   â”‚  Modifications en mÃ©moire InnoDB    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
3. PrÃ©-commit: CrÃ©ation du Write Set
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Write Set = {                      â”‚
   â”‚    - Rows modifiÃ©es (PK)            â”‚
   â”‚    - Valeurs BEFORE/AFTER           â”‚
   â”‚    - Transaction metadata           â”‚
   â”‚    - ClÃ©s primaires touchÃ©es        â”‚
   â”‚  }                                  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
4. Broadcast au cluster (TOTEM protocol)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Envoi Write Set Ã  tous les nÅ“uds   â”‚
   â”‚  via Group Communication            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼              â–¼              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Node 1  â”‚    â”‚ Node 2  â”‚    â”‚ Node 3  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
5. Certification (sur tous les nÅ“uds)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  VÃ©rification conflits:             â”‚
   â”‚  - MÃªme PK modifiÃ©e simultanÃ©ment?  â”‚
   â”‚  - Violations contraintes?          â”‚
   â”‚  - Deadlock potentiel?              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                             â–¼
    âœ… PASS                         âŒ FAIL
         â”‚                             â”‚
         â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ COMMIT  â”‚                   â”‚ROLLBACK â”‚
   â”‚ (local) â”‚                   â”‚ (local) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                             â”‚
         â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Apply sur       â”‚           â”‚ Client reÃ§oit   â”‚
   â”‚ autres nÅ“uds    â”‚           â”‚ ER_LOCK_DEADLOCKâ”‚
   â”‚ (async aprÃ¨s)   â”‚           â”‚                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques clÃ©s** :
- âœ… **ExÃ©cution optimiste** : Transaction d'abord exÃ©cutÃ©e localement
- âœ… **Certification distribuÃ©e** : Validation parallÃ¨le sur tous les nÅ“uds
- âœ… **Ordre dÃ©terministe** : Total Order Broadcast garantit mÃªme ordre partout
- âœ… **Rollback automatique** : Si conflit dÃ©tectÃ©, rollback local immÃ©diat

### 2.2 Virtual Synchrony et Group Communication

Galera utilise un modÃ¨le de **synchronie virtuelle** :

**Garanties** :
1. **Total Order** : Tous les nÅ“uds reÃ§oivent les write sets dans le mÃªme ordre
2. **Atomic Broadcast** : Un message est soit reÃ§u par tous, soit par aucun
3. **View Synchrony** : Tous les nÅ“uds ont la mÃªme vision du cluster

**Protocoles utilisÃ©s** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application Layer (MariaDB/wsrep)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Certification Based Replication       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   EVS (Extended Virtual Synchrony)      â”‚
â”‚   - Membership management               â”‚
â”‚   - Message ordering                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   gcomm (Group Communication)           â”‚
â”‚   - TOTEM: Message delivery             â”‚
â”‚   - UDP/TCP transport                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Ã‰tat du Cluster (Cluster State)

Chaque nÅ“ud maintient un **Ã©tat de cluster** :

**Variables wsrep critiques** :
```sql
-- Taille du cluster
SHOW STATUS LIKE 'wsrep_cluster_size';
-- Doit Ãªtre Ã©gal au nombre total de nÅ“uds (ex: 3, 5, 7)

-- Statut du nÅ“ud local
SHOW STATUS LIKE 'wsrep_local_state_comment';
-- Valeurs possibles:
--   'Joining'    : NÅ“ud en cours de jonction (SST/IST)
--   'Donor'      : NÅ“ud donneur pour SST/IST
--   'Joined'     : SynchronisÃ© mais pas ready
--   'Synced'     : PrÃªt Ã  recevoir des transactions âœ…
--   'Desync'     : Temporairement dÃ©synchro (ex: backup)

-- NumÃ©ro de vue du cluster
SHOW STATUS LIKE 'wsrep_cluster_conf_id';
-- IncrÃ©mentÃ© Ã  chaque changement de membership

-- Statut de connexion
SHOW STATUS LIKE 'wsrep_connected';
-- ON = connectÃ© au cluster
```

**Diagramme des Ã‰tats** :
```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OPEN    â”‚ â† DÃ©marrage initial
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PRIMARY  â”‚ â† Cluster a le quorum
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚          â”‚
    â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚JOINER  â”‚  â”‚ DONOR  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JOINED â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SYNCED â”‚ â† Ã‰tat opÃ©rationnel âœ…
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚DONOR/  â”‚ â† Fournit SST/IST
â”‚DESYNC  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Avantages et BÃ©nÃ©fices

### 3.1 Avantages Techniques

#### **1. RPO = 0 (Zero Data Loss)**
```sql
-- Configuration pour garantir RPO zÃ©ro
[galera]
wsrep_sync_wait = 1  -- Attendre sync avant retourner rÃ©sultat
```

**Garantie** : Si `COMMIT` rÃ©ussit, donnÃ©es prÃ©sentes sur tous les nÅ“uds actifs.

**Exemple de reprise aprÃ¨s panne** :
```
# Avant panne
Node1: Transaction T1 commitÃ©e âœ…
Node2: Transaction T1 commitÃ©e âœ…
Node3: Transaction T1 commitÃ©e âœ…

# Panne brutale Node1 (crash disque)
Node1: âŒ OFFLINE

# AprÃ¨s failover
Node2: Transaction T1 prÃ©sente âœ…
Node3: Transaction T1 prÃ©sente âœ…
â†’ Aucune perte de donnÃ©es
```

#### **2. RTO Minimal (< 30 secondes)**

**DÃ©tection automatique de panne** :
```ini
# Configuration rÃ©seau optimisÃ©e
wsrep_provider_options = "
    evs.keepalive_period = PT1S;      # Heartbeat chaque seconde
    evs.suspect_timeout = PT5S;       # Suspect aprÃ¨s 5s
    evs.inactive_timeout = PT15S;     # Ã‰viction aprÃ¨s 15s
    evs.install_timeout = PT15S;      # Timeout installation vue
"
```

**Timeline failover typique** :
```
T+0s   : Node1 crash (panne matÃ©rielle)
T+1s   : DerniÃ¨re rÃ©ponse heartbeat manquÃ©e
T+5s   : Node1 marquÃ© "suspect" par Node2 et Node3
T+10s  : Node1 Ã©vincÃ© du cluster
T+12s  : Nouvelle vue cluster installÃ©e (size=2)
T+15s  : Applications redirigÃ©es vers Node2/Node3
         (via MaxScale/HAProxy)
â†’ RTO = 15 secondes
```

#### **3. Multi-Master Actif**

Contrairement au master-slave, **tous les nÅ“uds acceptent des writes** :

```sql
-- Application 1 Ã©crit sur Node1
-- Transaction simultanÃ©e
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE user_id = 123;
COMMIT; -- âœ… SuccÃ¨s

-- Application 2 Ã©crit sur Node2 (mÃªme temps)
-- Transaction diffÃ©rente
BEGIN;
UPDATE accounts SET balance = balance + 50 WHERE user_id = 456;
COMMIT; -- âœ… SuccÃ¨s

-- Les deux transactions rÃ©pliquÃ©es sur tous les nÅ“uds
-- Ordre dÃ©terministe garanti par Total Order Broadcast
```

**BÃ©nÃ©fice** : Pas de SPOF au niveau write, scalabilitÃ© horizontale partielle.

#### **4. CohÃ©rence Stricte**

```sql
-- Configuration cohÃ©rence maximale
SET GLOBAL wsrep_sync_wait = 7;  -- Bitmask complet
-- Bit 1 (1)  : READ
-- Bit 2 (2)  : UPDATE/DELETE
-- Bit 4 (4)  : INSERT/REPLACE

-- Avec wsrep_sync_wait=7, garantie:
SELECT * FROM users WHERE id = 123;
-- âœ… Retourne TOUJOURS la derniÃ¨re version commitÃ©e cluster-wide
```

**Trade-off** : Latence accrue (+5-50ms selon rÃ©seau) vs cohÃ©rence parfaite.

### 3.2 Avantages OpÃ©rationnels

#### **1. Maintenance Sans Downtime**

**Rolling upgrade** :
```bash
# Upgrade Node1
systemctl stop mysql@node1
apt-get upgrade mariadb-server
systemctl start mysql@node1  # Rejoint automatiquement via IST

# Cluster reste opÃ©rationnel sur Node2+Node3 pendant l'upgrade
# RÃ©pÃ©ter pour Node2, puis Node3

â†’ Zero downtime upgrade
```

#### **2. Backup Sans Impact**

```bash
# Backup depuis nÅ“ud donneur sans bloquer le cluster
mysql -e "SET GLOBAL wsrep_desync = ON"  # Node3 se dÃ©synchro temporairement

# Backup physique
mariabackup --backup --target-dir=/backup/full

mysql -e "SET GLOBAL wsrep_desync = OFF"  # Resynchronisation automatique (IST)

# Cluster a continuÃ© Ã  fonctionner sur Node1+Node2
```

#### **3. Ã‰lasticitÃ© Dynamique**

```bash
# Ajout d'un nouveau nÅ“ud Ã  chaud
# Node4 dÃ©marre et rejoint automatiquement
systemctl start mysql@node4

# SST automatique depuis Node1 (donneur choisi par Galera)
# AprÃ¨s sync, Node4 devient actif
# Cluster passe de 3 Ã  4 nÅ“uds sans interruption
```

---

## 4. Limitations et Contraintes

### 4.1 Limitations Techniques

#### **1. ScalabilitÃ© Writes LimitÃ©e**

**ProblÃ¨me** : Chaque write doit Ãªtre rÃ©pliquÃ© et certifiÃ© sur **tous** les nÅ“uds.

```
Writes/sec maximum â‰ˆ (Single node writes) Ã— 0.7-0.9

Exemple:
- 1 nÅ“ud : 5000 writes/sec
- 3 nÅ“uds Galera : ~4000 writes/sec (80%)
- 5 nÅ“uds Galera : ~3500 writes/sec (70%)

â†’ Anti-scaling pour writes au-delÃ  de 5 nÅ“uds
```

ğŸ’¡ **Mitigation** : Sharding applicatif, optimisation requÃªtes, caching.

#### **2. Contraintes RÃ©seau Strictes**

**Exigences rÃ©seau** :
```
Latence:
- Single DC : < 1ms (idÃ©al)
- Single DC : < 5ms (acceptable)
- Multi-DC : < 10ms (LAN extension)
- Multi-DC : 10-100ms (possiblewith tuning)
- > 100ms : Non recommandÃ©

Bande passante:
- Minimum : 100 Mbps
- RecommandÃ© : 1 Gbps
- Multi-DC : 100 Mbps dÃ©diÃ© inter-DC

Perte de paquets:
- < 0.1% impÃ©ratif
- Jitter < 10ms
```

**Test rÃ©seau** :
```bash
# Entre tous les nÅ“uds
ping -c 100 node2.example.com | tail -1
# rtt min/avg/max/mdev = 0.234/0.456/1.234/0.123 ms
# â†’ avg < 1ms âœ…

iperf3 -c node2.example.com
# [ ID] Interval           Transfer     Bitrate
# [  5]   0.00-10.00  sec  1.09 GBytes   938 Mbits/sec
# â†’ > 100 Mbps âœ…
```

#### **3. Moteurs de Stockage SupportÃ©s**

```sql
-- Uniquement InnoDB et XtraDB supportÃ©s pour rÃ©plication
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100)
) ENGINE=InnoDB;  -- âœ… OK

CREATE TABLE logs (
    message TEXT
) ENGINE=MyISAM;  -- âŒ Ne sera PAS rÃ©pliquÃ©

SHOW WARNINGS;
-- Warning: wsrep_mode does not support MyISAM
```

âš ï¸ **Critical** : MyISAM, Memory, Archive non rÃ©pliquÃ©s â†’ risque de divergence.

#### **4. Transactions DDL (ALTER TABLE)**

**Limitations DDL** :
```sql
-- Les DDL sont rÃ©pliquÃ©s mais bloquent le cluster
ALTER TABLE large_table ADD COLUMN email VARCHAR(255);

-- Impact:
-- 1. TOI (Total Order Isolation) par dÃ©faut
--    â†’ Bloque TOUS les nÅ“uds pendant l'exÃ©cution
--    â†’ Si ALTER prend 5 minutes, cluster bloquÃ© 5 min

-- 2. Alternative: RSU (Rolling Schema Upgrade)
SET SESSION wsrep_OSU_method='RSU';
ALTER TABLE large_table ADD COLUMN email VARCHAR(255);
-- â†’ ExÃ©cutÃ© uniquement localement
-- â†’ NÃ©cessite rÃ©pÃ©ter sur chaque nÅ“ud manuellement
```

ğŸ’¡ **Best Practice** : Utiliser `pt-online-schema-change` ou `gh-ost`.

#### **5. ImpossibilitÃ© de LOCK TABLES Global**

```sql
-- Ne fonctionne PAS comme attendu en Galera
LOCK TABLES users WRITE;
-- Verrouille uniquement le nÅ“ud local
-- Autres nÅ“uds peuvent toujours modifier 'users'

-- RÃ©sultat: PossibilitÃ© de deadlock distribuÃ©
```

### 4.2 Contraintes OpÃ©rationnelles

#### **1. Quorum Strict (Minimum 3 NÅ“uds)**

```
2 nÅ“uds: Dangereux - perte d'un nÅ“ud = perte quorum = cluster DOWN
3 nÅ“uds: Minimum viable - tolÃ¨re 1 panne
5 nÅ“uds: RecommandÃ© production - tolÃ¨re 2 pannes
```

**CoÃ»t quorum** :
```
3 nÅ“uds Ã— (Serveur + Storage + RÃ©seau) = CoÃ»t Ã©levÃ©
vs
1 Master + 1 Standby = CoÃ»t modÃ©rÃ©
```

#### **2. ComplexitÃ© de Troubleshooting**

**ScÃ©narios complexes** :
- Split-brain multi-segments
- Deadlocks distribuÃ©s
- Slow joiner (nÅ“ud lent retarde cluster)
- Flow control (backpressure automatique)

**Expertise requise** : DBA senior avec expÃ©rience systÃ¨mes distribuÃ©s.

#### **3. Conflits d'Ã‰criture**

```sql
-- Conflit de certification possible (rare mais existe)
-- Node1
BEGIN;
UPDATE inventory SET quantity = quantity - 1 WHERE product_id = 99;
-- Local quantity: 5 â†’ 4
COMMIT;

-- Node2 (simultanÃ©, mÃªme milliseconde)
BEGIN;
UPDATE inventory SET quantity = quantity - 2 WHERE product_id = 99;
-- Local quantity: 5 â†’ 3
COMMIT;

-- RÃ©sultat certification:
-- Node1 COMMIT: âœ… Success (arrivÃ© en premier)
-- Node2 COMMIT: âŒ Deadlock (conflit dÃ©tectÃ©, rollback)

-- Application Node2 reÃ§oit:
-- ERROR 1213 (40001): Deadlock found when trying to get lock
```

**FrÃ©quence** : < 0.01% des transactions dans un cluster bien conÃ§u, mais nÃ©cessite gestion applicative (retry).

---

## 5. PrÃ©requis et PrÃ©paration

### 5.1 PrÃ©requis MatÃ©riels

**Configuration minimale par nÅ“ud** :
```
CPU:      4 cores (8+ recommandÃ©)
RAM:      16 GB (32+ recommandÃ©)
          - Buffer Pool: 70% RAM
          - wsrep threads: 1-2 GB
          
Disque:   SSD obligatoire pour performance
          - IOPS: > 5000 4K random reads
          - Latency: < 1ms
          
RÃ©seau:   1 Gbps (10 Gbps recommandÃ©)
          - Latence < 1ms intra-DC
          - DÃ©diÃ© VLAN pour Galera recommandÃ©
```

**Calcul dimensionnement** :
```python
# Calcul RAM pour Galera
data_size_gb = 500  # Taille totale donnÃ©es

# InnoDB Buffer Pool (70-80% RAM)
buffer_pool_gb = data_size_gb * 0.8

# wsrep overhead
wsrep_slave_threads = 16  # Nombre de cores
wsrep_overhead_gb = 2

# RAM totale
total_ram_gb = buffer_pool_gb + wsrep_overhead_gb + 4 # (4GB OS)
# = 500 * 0.8 + 2 + 4 = 406 GB

â†’ Serveur avec 512 GB RAM recommandÃ©
```

### 5.2 PrÃ©requis RÃ©seau

**Ports requis** :
```bash
# Port Galera Cluster (TCP)
3306    : MySQL/MariaDB
4567    : Galera Cluster (wsrep)
4568    : IST (Incremental State Transfer)
4444    : SST (State Snapshot Transfer)

# Configuration firewall
ufw allow from 10.0.1.0/24 to any port 3306 proto tcp
ufw allow from 10.0.1.0/24 to any port 4567 proto tcp
ufw allow from 10.0.1.0/24 to any port 4568 proto tcp
ufw allow from 10.0.1.0/24 to any port 4444 proto tcp
```

**Validation rÃ©seau** :
```bash
#!/bin/bash
# check_network.sh - VÃ©rifier prÃ©requis rÃ©seau

NODES=("node1:10.0.1.10" "node2:10.0.1.11" "node3:10.0.1.12")

for node in "${NODES[@]}"; do
    name="${node%%:*}"
    ip="${node##*:}"
    
    echo "Testing $name ($ip)..."
    
    # Latency
    latency=$(ping -c 10 $ip | tail -1 | awk -F'/' '{print $5}')
    echo "  Latency: ${latency}ms"
    
    if (( $(echo "$latency > 5" | bc -l) )); then
        echo "  âš ï¸ WARNING: Latency > 5ms"
    fi
    
    # Port accessibility
    nc -zv $ip 4567 2>&1 | grep -q succeeded
    [ $? -eq 0 ] && echo "  âœ… Port 4567 accessible" || echo "  âŒ Port 4567 blocked"
    
done
```

### 5.3 PrÃ©requis Logiciels

**Stack recommandÃ©e** :
```bash
# OS
Ubuntu 24.04 LTS / Debian 12 / RHEL 9

# MariaDB
MariaDB 11.8 LTS (ou 11.4 LTS minimum)

# Galera
galera-4 (version 4.16+)

# Outils
- mariabackup (pour SST)
- socat (pour streaming SST)
- pv (pipe viewer, monitoring transferts)
```

**VÃ©rification compatibilitÃ©** :
```sql
-- VÃ©rifier support Galera
SHOW VARIABLES LIKE 'wsrep_on';
-- wsrep_on = ON âœ…

SHOW GLOBAL STATUS LIKE 'wsrep_provider_version';
-- wsrep_provider_version = 4.16 âœ…

-- VÃ©rifier InnoDB (requis)
SHOW VARIABLES LIKE 'default_storage_engine';
-- default_storage_engine = InnoDB âœ…
```

---

## 6. Architecture de DÃ©ploiement

### 6.1 Single Datacenter (3 nÅ“uds)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATACENTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  MaxScale 1  â”‚  â”‚  MaxScale 2  â”‚            â”‚
â”‚  â”‚   (Active)   â”‚  â”‚  (Standby)   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                 â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                  â”‚ Virtual IP                  â”‚
â”‚                  â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚               â”‚                â”‚            â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚            â”‚
â”‚  â–¼      â–¼                 â–¼       â–¼            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”‚
â”‚ â”‚Node1â”‚â”€â”‚Node2â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚Node3â”‚ â”‚     â”‚        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”˜ â”‚Load â”‚        â”‚
â”‚    â”‚       â”‚               â”‚    â”‚Balanâ”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚cer  â”‚        â”‚
â”‚            â”‚ Galera Cluster     â””â”€â”€â”€â”€â”€â”˜        â”‚
â”‚            â”‚ (All-to-All Mesh)                 â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaractÃ©ristiques** :
- âœ… Haute disponibilitÃ© intra-DC
- âœ… RTO < 30 secondes
- âœ… RPO = 0
- âš ï¸ VulnÃ©rable Ã  dÃ©faillance datacenter

### 6.2 Multi-Datacenter (5 nÅ“uds + Arbitre)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DC1 (Paris) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚Node1â”‚â”€â”€â”‚Node2â”‚                    â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜                    â”‚
â”‚     â”‚        â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚        â”‚
      â”‚   WAN  â”‚ (10-50ms)
      â”‚        â”‚
â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€ DC2 (London) â”€â”
â”‚     â”‚        â”‚                       â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”                    â”‚
â”‚  â”‚Node3â”‚â”€â”€â”‚Node4â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ WAN
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€ DC3 (Dublin) â”€â”€â”€â”€â”€â”
â”‚      â”Œâ”€â”€â”€â”€â”€â”                         â”‚
â”‚      â”‚Garbdâ”‚ (Arbitrator only)       â”‚
â”‚      â””â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- âœ… Protection disaster recovery
- âœ… Compliance multi-rÃ©gion
- âœ… Quorum maintenu avec garbd
- âš ï¸ Latence writes accrue (WAN)

---

## 7. Cas d'Usage RecommandÃ©s

### 7.1 Excellents Cas d'Usage

**1. Applications Transactionnelles Critiques**
- E-commerce (catalogue, commandes)
- Banking (transactions, comptes)
- SaaS B2B (donnÃ©es clients)

**2. Haute DisponibilitÃ© Stricte**
- Services 24/7 (tÃ©lÃ©communications)
- Applications mÃ©dicales
- Services publics critiques

**3. Lectures Intensives avec Writes ModÃ©rÃ©s**
- CMS (Content Management)
- Portails d'information
- Applications mobiles (backend)

### 7.2 Cas d'Usage Ã  Ã‰viter

**1. Writes TrÃ¨s Intensifs**
```
> 10 000 writes/sec sustained
â†’ ConsidÃ©rer sharding ou autre solution
```

**2. Grandes Transactions**
```
Transactions > 1 GB writesets
â†’ Risque de timeout certification
â†’ Utiliser Streaming Replication (Galera 4.x)
```

**3. SchÃ©mas avec Beaucoup de DDL**
```
FrÃ©quents ALTER TABLE
â†’ Bloquerait le cluster (TOI)
â†’ ConsidÃ©rer architecture diffÃ©rente
```

**4. Applications Incompatibles Galera**
- Utilisation extensive MyISAM
- LOCK TABLES global requis
- Applications non idempotentes (pas de retry)

---

## âœ… Points ClÃ©s Ã  Retenir

- **Galera = rÃ©plication synchrone multi-master** basÃ©e sur certification de write sets
- **RPO = 0** garanti : aucune perte de donnÃ©es si COMMIT rÃ©ussit
- **RTO < 30 sec** avec dÃ©tection automatique et failover transparent
- **Tous les nÅ“uds actifs** : pas de gaspillage de ressources comme avec standby
- **wsrep API** : intÃ©gration profonde MariaDB, pas une simple couche rÃ©plication
- **CohÃ©rence stricte** configurable via `wsrep_sync_wait`
- **Limitations rÃ©seau critiques** : latence < 10ms recommandÃ©e, < 100ms maximum
- **Minimum 3 nÅ“uds** pour quorum (5 recommandÃ© production)
- **ScalabilitÃ© reads excellente**, writes limitÃ©e par certification globale
- **InnoDB uniquement** pour tables rÃ©pliquÃ©es

---

## ğŸ”— Ressources et RÃ©fÃ©rences

### Documentation Officielle
- [ğŸ“– MariaDB Galera Cluster Documentation](https://mariadb.com/kb/en/galera-cluster/)
- [ğŸ“– Codership Galera Documentation](https://galeracluster.com/library/documentation/)
- [ğŸ“– wsrep API Specification](https://github.com/codership/wsrep-API)

### Whitepapers
- **"Understanding Galera Cluster"** - Codership AB
- **"Certification-Based Replication"** - Academic Paper
- **"Galera Performance Best Practices"** - MariaDB Corporation

### Outils
- [Galera Arbitrator (garbd)](https://galeracluster.com/library/documentation/arbitrator.html)
- [myq_gadgets](https://github.com/jayjanssen/myq_gadgets) - Monitoring Galera
- [Percona Monitoring Plugins](https://www.percona.com/software/database-tools/percona-monitoring-plugins)

---

## â¡ï¸ Sections Suivantes

Cette introduction a posÃ© les fondations conceptuelles de Galera Cluster. Les sections suivantes approfondiront :

- **14.2.1** : Architecture synchrone multi-master (dÃ©tails protocole wsrep)
- **14.2.2** : Certification-based replication (algorithmes, conflits)
- **14.2.3** : Configuration et dÃ©ploiement production
- **14.2.4** : State transfers (SST vs IST, optimisations)

Chaque sous-section construira sur ces concepts pour vous permettre de dÃ©ployer et opÃ©rer un cluster Galera production-ready.

---

**Galera Cluster reprÃ©sente un saut qualitatif dans la haute disponibilitÃ© MariaDB. MaÃ®triser ses concepts est essentiel pour tout architecte ou DBA gÃ©rant des applications critiques.**

â­ï¸ [Architecture synchrone multi-master](/14-haute-disponibilite/02.1-architecture-synchrone.md)
