ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.1 Architectures Haute DisponibilitÃ© : Concepts

> **Niveau** : Expert  
> **DurÃ©e estimÃ©e** : 2-3 heures  
> **PrÃ©requis** : MaÃ®trise de la rÃ©plication, expÃ©rience en architecture distribuÃ©e

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :

- **Comprendre** les principes fondamentaux de la haute disponibilitÃ© et le thÃ©orÃ¨me CAP
- **Ã‰valuer** les diffÃ©rents patterns d'architecture HA et leurs trade-offs
- **Calculer** et interprÃ©ter les mÃ©triques de disponibilitÃ© (RTO, RPO, MTBF, MTTR)
- **Concevoir** une architecture adaptÃ©e aux contraintes mÃ©tier et techniques
- **Anticiper** les points de dÃ©faillance (SPOF) et les mitiger
- **Ã‰tablir** un framework de dÃ©cision pour le choix d'architecture

---

## Introduction

La haute disponibilitÃ© n'est pas un produit ou une technologie unique, mais une **stratÃ©gie architecturale globale** visant Ã  minimiser l'indisponibilitÃ© des services critiques. Dans le contexte MariaDB, cela implique de comprendre les fondamentaux thÃ©oriques avant de choisir et implÃ©menter une solution technique.

> ğŸ’¡ **Citation clÃ©** : "La haute disponibilitÃ© est un voyage, pas une destination. C'est un Ã©quilibre constant entre coÃ»ts, complexitÃ© et besoins mÃ©tier." - Werner Vogels, CTO Amazon

---

## 1. Fondamentaux de la Haute DisponibilitÃ©

### 1.1 DÃ©finitions Essentielles

#### **DisponibilitÃ© (Availability)**

La disponibilitÃ© mesure le pourcentage de temps oÃ¹ un systÃ¨me est opÃ©rationnel et accessible :

```
DisponibilitÃ© = (Temps d'uptime / Temps total) Ã— 100
```

**Niveaux de disponibilitÃ© standard** :

| Niveau | DisponibilitÃ© | Downtime/an | Downtime/mois | Use Case |
|--------|---------------|-------------|---------------|----------|
| **Two Nines** | 99% | 3.65 jours | 7.2 heures | Dev/Test |
| **Three Nines** | 99.9% | 8.76 heures | 43.2 minutes | Applications standard |
| **Four Nines** | 99.99% | 52.56 minutes | 4.32 minutes | Applications critiques |
| **Five Nines** | 99.999% | 5.26 minutes | 25.9 secondes | Services financiers, santÃ© |
| **Six Nines** | 99.9999% | 31.5 secondes | 2.59 secondes | TÃ©lÃ©communications |

#### **RTO (Recovery Time Objective)**

Le **temps maximal acceptable** entre la dÃ©faillance et la restauration complÃ¨te du service :

```
RTO = Temps de dÃ©tection + Temps de dÃ©cision + Temps de rÃ©cupÃ©ration
```

**Exemples concrets** :
- **E-commerce** : RTO = 5 minutes (perte revenue estimÃ©e : 10kâ‚¬/minute)
- **Banking** : RTO = 30 secondes (exigences rÃ©glementaires)
- **SaaS B2B** : RTO = 15 minutes (SLA contractuel 99.9%)

#### **RPO (Recovery Point Objective)**

La **perte de donnÃ©es maximale acceptable** mesurÃ©e en temps :

```
RPO = DerniÃ¨re sauvegarde valide - Point de dÃ©faillance
```

**Exemples concrets** :
- **Transactions financiÃ¨res** : RPO = 0 (aucune perte acceptable)
- **Analytics** : RPO = 1 heure (donnÃ©es batch)
- **Logs applicatifs** : RPO = 24 heures (rechargeable)

#### **MTBF et MTTR**

**MTBF (Mean Time Between Failures)** : Temps moyen entre deux pannes  
**MTTR (Mean Time To Repair)** : Temps moyen de rÃ©paration

```
DisponibilitÃ© = MTBF / (MTBF + MTTR)
```

**Exemple de calcul** :
```
MTBF = 720 heures (30 jours)
MTTR = 0.5 heures (30 minutes)
DisponibilitÃ© = 720 / (720 + 0.5) = 99.93%
```

ğŸ’¡ **Insight** : Augmenter MTBF (fiabilitÃ©) est souvent plus efficace que rÃ©duire MTTR (rapiditÃ©).

---

### 1.2 Le ThÃ©orÃ¨me CAP

Le thÃ©orÃ¨me CAP (aussi appelÃ© thÃ©orÃ¨me de Brewer) stipule qu'un systÃ¨me distribuÃ© ne peut garantir simultanÃ©ment que **deux** des trois propriÃ©tÃ©s suivantes :

#### **C - Consistency (CohÃ©rence)**
Tous les nÅ“uds voient les mÃªmes donnÃ©es au mÃªme moment. Toute lecture retourne la derniÃ¨re Ã©criture.

#### **A - Availability (DisponibilitÃ©)**
Chaque requÃªte reÃ§oit une rÃ©ponse (succÃ¨s ou Ã©chec), mÃªme si certains nÅ“uds sont dÃ©faillants.

#### **P - Partition Tolerance (TolÃ©rance au partitionnement)**
Le systÃ¨me continue de fonctionner malgrÃ© la perte de messages rÃ©seau entre nÅ“uds.

```
        CAP Theorem
           /\
          /  \
         /    \
        /  CP  \
       /________\
      /\        /\
     /  \  CA  /  \
    / AP \____/ CP \
   /______\  /______\
  
  CA : CohÃ©rence + DisponibilitÃ© (impossible en cas de partition)
  CP : CohÃ©rence + Partition (sacrifice de la disponibilitÃ©)
  AP : DisponibilitÃ© + Partition (cohÃ©rence Ã©ventuelle)
```

#### **Positionnement des Technologies MariaDB**

| Technologie | Type CAP | Justification |
|-------------|----------|---------------|
| **Standalone** | CA | CohÃ©rent et disponible jusqu'Ã  panne serveur |
| **RÃ©plication Async** | AP | Disponible, cohÃ©rence Ã©ventuelle |
| **RÃ©plication Semi-sync** | CP | PrivilÃ©gie cohÃ©rence, peut bloquer si replica down |
| **Galera Cluster** | CP | CohÃ©rence stricte, indisponible si pas de quorum |
| **Multi-DC Galera** | AP/CP | Configurable selon wsrep_sync_wait |

ğŸ’¡ **En pratique** : Les partitions rÃ©seau Ã©tant inÃ©vitables dans les systÃ¨mes distribuÃ©s, le choix se rÃ©sume Ã  **CP vs AP**.

#### **Implications pour MariaDB**

**Choix CP (Galera en mode strict)** :
```sql
-- Configuration pour cohÃ©rence maximale
SET GLOBAL wsrep_sync_wait = 7; -- Attendre synchronisation complÃ¨te
SET GLOBAL wsrep_causal_reads = ON;
```
- âœ… Lectures toujours cohÃ©rentes
- âœ… Pas de divergence possible
- âŒ IndisponibilitÃ© si perte de quorum
- âŒ Latence accrue

**Choix AP (RÃ©plication async)** :
```sql
-- Configuration pour disponibilitÃ© maximale
SET GLOBAL read_only = 0 ON replicas; -- Lecture sur replicas
-- Promotion automatique en cas de panne master
```
- âœ… Toujours disponible en lecture
- âœ… Faible latence
- âŒ Possible slave lag
- âŒ Lectures potentiellement obsolÃ¨tes

---

## 2. Patterns d'Architectures Haute DisponibilitÃ©

### 2.1 Active-Passive (Primary-Standby)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     RÃ©plication      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PRIMARY    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’   â”‚   STANDBY    â”‚
â”‚  (Active)    â”‚     Asynchrone       â”‚  (Passive)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“ Heartbeat                            â†‘
     â†“                                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€ Failover (manuel/auto) â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **CaractÃ©ristiques**

**Avantages** :
- âœ… Simple Ã  comprendre et implÃ©menter
- âœ… Pas de risque de conflits d'Ã©criture
- âœ… Compatible avec rÃ©plication async standard
- âœ… CoÃ»t modÃ©rÃ© (2 serveurs minimum)

**InconvÃ©nients** :
- âŒ Standby inutilisÃ© (50% de ressources gaspillÃ©es)
- âŒ RPO > 0 (dÃ©pend du replication lag)
- âŒ RTO de minutes (dÃ©tection + bascule)
- âŒ NÃ©cessite scripts de failover

#### **Configuration de Production**

```ini
# my.cnf sur PRIMARY
[mysqld]
server-id = 1
log-bin = /var/log/mysql/mysql-bin.log
binlog_format = ROW
sync_binlog = 1
innodb_flush_log_at_trx_commit = 1

# RÃ©plication semi-synchrone pour rÃ©duire RPO
rpl_semi_sync_master_enabled = 1
rpl_semi_sync_master_timeout = 10000 # 10 secondes

# my.cnf sur STANDBY
[mysqld]
server-id = 2
relay-log = /var/log/mysql/relay-bin.log
read_only = 1
rpl_semi_sync_slave_enabled = 1

# Activation rÃ©plication
CHANGE MASTER TO
  MASTER_HOST = 'primary.example.com',
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'secure_password',
  MASTER_AUTO_POSITION = 1; -- Utilise GTID

START SLAVE;
```

#### **Failover Automatique avec Keepalived**

```bash
# /etc/keepalived/keepalived.conf
vrrp_script check_mysql {
    script "/usr/local/bin/check_mysql.sh"
    interval 2
    weight -20
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 101  # 100 sur standby
    advert_int 1
    
    virtual_ipaddress {
        10.0.1.100/24 dev eth0
    }
    
    track_script {
        check_mysql
    }
    
    notify_master "/usr/local/bin/promote_to_master.sh"
}
```

```bash
#!/bin/bash
# check_mysql.sh
mysqladmin ping -h localhost -u monitor -p${MONITOR_PASSWORD} &>/dev/null
exit $?
```

#### **MÃ©triques Typiques**

- **RTO** : 1-5 minutes (automatique), 5-30 minutes (manuel)
- **RPO** : 0-60 secondes (semi-sync), jusqu'Ã  plusieurs minutes (async)
- **DisponibilitÃ© thÃ©orique** : 99.9% - 99.95%
- **CoÃ»t** : Faible Ã  moyen

---

### 2.2 Active-Active (Multi-Master)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚        â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” RÃ©plication â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MASTER 1   â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚   MASTER 2   â”‚
â”‚  (Active)    â”‚  Synchrone  â”‚  (Active)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†•                            â†•
   RÃ©plication                 RÃ©plication
       â†•                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MASTER 3   â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚   MASTER 4   â”‚
â”‚  (Active)    â”‚             â”‚  (Active)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **ImplÃ©mentation avec Galera Cluster**

**Principe de Certification-Based Replication** :
1. Transaction exÃ©cutÃ©e localement
2. Diffusion (broadcast) aux autres nÅ“uds pour certification
3. Validation si pas de conflit
4. Application ou rollback sur tous les nÅ“uds

```sql
-- Configuration Galera optimale production
[galera]
wsrep_provider = /usr/lib/libgalera_smm.so
wsrep_cluster_address = "gcomm://node1,node2,node3,node4,node5"
wsrep_cluster_name = "production_cluster"

# Optimisations performance
wsrep_slave_threads = 16  # Nombre de CPU cores
wsrep_provider_options = "gcache.size=2G;gcs.fc_limit=128"

# SÃ©curitÃ©
wsrep_sst_method = mariabackup
wsrep_sst_auth = "sst_user:secure_password"

# CohÃ©rence
wsrep_sync_wait = 1  # Attendre sync avant SELECT
wsrep_causal_reads = ON

# Optimisation rÃ©seau
wsrep_provider_options = "gmcast.segment=0;evs.keepalive_period=PT1S"
```

#### **Avantages Active-Active**

- âœ… **RPO = 0** : Synchronisation avant commit
- âœ… **RTO < 30 secondes** : Bascule automatique
- âœ… **Utilisation 100%** : Tous les nÅ“uds actifs
- âœ… **ScalabilitÃ© reads** : LinÃ©aire avec le nombre de nÅ“uds
- âœ… **Pas de SPOF** : N'importe quel nÅ“ud peut Ãªtre primary

#### **InconvÃ©nients et DÃ©fis**

- âŒ **ScalabilitÃ© writes limitÃ©e** : Chaque write rÃ©pliquÃ© sur tous
- âŒ **Latence rÃ©seau critique** : RecommandÃ© < 10ms inter-nÅ“uds
- âŒ **ComplexitÃ© opÃ©rationnelle** : Split-brain, quorum
- âŒ **Conflits possibles** : Rollback en cas de conflit de certification
- âŒ **CoÃ»t Ã©levÃ©** : Minimum 3 nÅ“uds (5 recommandÃ©)

#### **Gestion des Conflits**

```sql
-- Exemple de conflit de certification
-- NÅ“ud 1                          NÅ“ud 2
BEGIN;                              BEGIN;
UPDATE accounts                     UPDATE accounts
SET balance = balance - 100         SET balance = balance - 50
WHERE id = 123;                     WHERE id = 123;
-- Commit envoyÃ©                   -- Commit envoyÃ©
COMMIT;                             COMMIT;
-- âœ… ValidÃ© (arrivÃ© en premier)   -- âŒ ROLLBACK (conflit dÃ©tectÃ©)
```

**StratÃ©gies d'attÃ©nuation** :
```sql
-- 1. Sharding applicatif (sticky sessions)
-- Diriger user_id impair â†’ node1, pair â†’ node2

-- 2. Optimistic locking
UPDATE accounts
SET balance = balance - 100, version = version + 1
WHERE id = 123 AND version = 5;

-- 3. Utiliser AUTO_INCREMENT avec offset
SET GLOBAL auto_increment_offset = 1;  -- Node 1
SET GLOBAL auto_increment_increment = 5; -- Nb total de nÅ“uds
```

#### **MÃ©triques Typiques**

- **RTO** : 5-30 secondes (dÃ©tection + routing)
- **RPO** : 0 (synchrone)
- **DisponibilitÃ© thÃ©orique** : 99.99% - 99.999%
- **CoÃ»t** : Ã‰levÃ©

---

### 2.3 Multi-Datacenter (Geo-Distribution)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATACENTER 1 (Paris) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Galera 1 â”‚â”€â”€â”‚ Galera 2 â”‚â”€â”€â”‚ MaxScale â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ WAN (50-100ms)
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATACENTER 2 (Londres) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Galera 3 â”‚â”€â”€â”‚ Galera 4 â”‚â”€â”€â”‚ MaxScale â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ WAN (80-120ms)
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATACENTER 3 (Dublin - Arbitre) â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ Garbd    â”‚  (Pas de donnÃ©es, uniquement quorum)          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Configuration Multi-DC Galera**

```sql
-- Segmentation rÃ©seau pour optimisation
[galera]
wsrep_provider_options = "gmcast.segment=0"  # DC1 (Paris)
wsrep_provider_options = "gmcast.segment=1"  # DC2 (Londres)
wsrep_provider_options = "gmcast.segment=2"  # DC3 (Dublin)

-- Tous les nÅ“uds dans la mÃªme grappe logique
wsrep_cluster_address = "gcomm://paris1,paris2,london1,london2,dublin-garbd"

-- Optimisation WAN
wsrep_provider_options = "
    evs.keepalive_period = PT3S;
    evs.suspect_timeout = PT30S;
    evs.inactive_timeout = PT60S;
    evs.install_timeout = PT60S
"
```

#### **Arbitre (Garagekeeper Daemon)**

```bash
# Installation garbd
apt-get install galera-arbitrator-4

# Configuration /etc/default/garbd
GALERA_GROUP="production_cluster"
GALERA_NODES="paris1:4567,paris2:4567,london1:4567,london2:4567"
LOG_FILE="/var/log/garbd.log"

# DÃ©marrage
systemctl enable garbd
systemctl start garbd
```

ğŸ’¡ **RÃ´le du Garbd** : Participe au quorum sans stocker de donnÃ©es, idÃ©al pour un 3áµ‰ DC.

#### **Trade-offs Multi-DC**

**Avantages** :
- âœ… Protection contre dÃ©faillance datacenter
- âœ… Disaster Recovery natif
- âœ… Compliance rÃ©glementaire (donnÃ©es gÃ©o-distribuÃ©es)
- âœ… Latence locale pour utilisateurs gÃ©o-distribuÃ©s

**DÃ©fis** :
- âŒ **Latence WAN** : Impact sur performance writes (50-150ms)
- âŒ **Bande passante** : CoÃ»ts rÃ©seau inter-DC
- âŒ **Split-brain complexe** : NÃ©cessite quorum strict
- âŒ **CoÃ»t infrastructure** : TrÃ¨s Ã©levÃ©

#### **StratÃ©gie de Writes Locaux**

```sql
-- MaxScale routing intelligent par gÃ©o-localisation
[router]
type = readwritesplit
master_accept_reads = false

# PrÃ©fÃ©rence locale pour writes
router_options = master_reconnect=true,delayed_retry=true

[server-paris1]
type = server
address = 10.1.1.10
port = 3306
priority = 1  # Haute prioritÃ© si client en Europe

[server-london1]
type = server
address = 10.2.1.10
port = 3306
priority = 2  # PrioritÃ© moyenne
```

#### **MÃ©triques Typiques**

- **RTO** : 10-60 secondes (selon dÃ©tection)
- **RPO** : 0 (synchrone) ou configurÃ© par segment
- **DisponibilitÃ© thÃ©orique** : 99.999% (Five Nines)
- **CoÃ»t** : TrÃ¨s Ã©levÃ©

---

## 3. MÃ©triques et Calculs de DisponibilitÃ©

### 3.1 Calcul de DisponibilitÃ© Composite

Pour une architecture avec plusieurs composants :

```
DisponibilitÃ©_Totale = âˆ DisponibilitÃ©_i
                       i=1..n
```

**Exemple : Architecture 3-tier**
- Load Balancer : 99.99%
- MaxScale : 99.95%
- Galera Cluster (3 nÅ“uds) : 99.999%

```
DisponibilitÃ© = 0.9999 Ã— 0.9995 Ã— 0.99999
              = 0.9994 (99.94%)
```

### 3.2 AmÃ©lioration par Redondance

Avec **n composants redondants** en parallÃ¨le :

```
DisponibilitÃ© = 1 - (1 - DisponibilitÃ©_individuelle)^n
```

**Exemple : 2 MaxScale en HA**
- MaxScale individuel : 99.9%
- 2 MaxScale en HA : 1 - (1 - 0.999)Â² = 1 - 0.000001 = 99.9999%

### 3.3 Calcul du RTO RÃ©el

```
RTO_rÃ©el = T_dÃ©tection + T_validation + T_bascule + T_vÃ©rification
```

**Exemple concret** :
- DÃ©tection panne (heartbeat) : 10 secondes
- Validation (Ã©viter false positive) : 5 secondes
- Bascule (failover script) : 15 secondes
- VÃ©rification santÃ© : 5 secondes
- **RTO total** : 35 secondes

âš ï¸ **Attention** : Toujours ajouter 20-30% de marge pour les imprÃ©vus.

### 3.4 Formule de CoÃ»t de l'IndisponibilitÃ©

```
CoÃ»t = (Revenue_horaire / 3600) Ã— Downtime_secondes Ã— Facteur_impact
```

**Exemple e-commerce** :
- Revenue : 1Mâ‚¬/jour = 41 667â‚¬/heure
- Downtime : 300 secondes (5 minutes)
- Impact : 1.5 (perte client + image)

```
CoÃ»t = (41 667 / 3600) Ã— 300 Ã— 1.5 = 5 208â‚¬
```

ğŸ’¡ **ROI de la HA** : Si downtime rÃ©duit de 50h Ã  5h/an, Ã©conomie = 2.08Mâ‚¬/an

---

## 4. Framework de DÃ©cision Architecturale

### 4.1 Arbre de DÃ©cision

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Budget disponible pour HA ?         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
  LimitÃ©        ConsÃ©quent
    â”‚               â”‚
    â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Active- â”‚    â”‚ RPO acceptable ? â”‚
â”‚ Passive â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
                    â”‚        â”‚
                 RPO=0    RPO>0
                    â”‚        â”‚
                    â–¼        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Galera  â”‚ â”‚ Async    â”‚
              â”‚ Cluster â”‚ â”‚ Replica  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Multi-DC requis ?   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
            â”‚        â”‚
           Oui      Non
            â”‚        â”‚
            â–¼        â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Galera   â”‚ â”‚ Galera   â”‚
      â”‚ Multi-DC â”‚ â”‚ Single   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Matrice de DÃ©cision DÃ©taillÃ©e

| CritÃ¨re | Active-Passive | Galera Single-DC | Galera Multi-DC |
|---------|----------------|------------------|-----------------|
| **CoÃ»t initial** | â‚¬ | â‚¬â‚¬ | â‚¬â‚¬â‚¬â‚¬ |
| **CoÃ»t opÃ©rationnel** | â‚¬ | â‚¬â‚¬ | â‚¬â‚¬â‚¬â‚¬ |
| **RTO** | 1-5 min | 10-30 sec | 10-60 sec |
| **RPO** | Secondes | 0 | 0 |
| **ComplexitÃ©** | â­ | â­â­â­ | â­â­â­â­â­ |
| **ScalabilitÃ© reads** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **ScalabilitÃ© writes** | â­ | â­â­â­ | â­â­ |
| **Latence writes** | Faible | Faible | Moyenne-Haute |
| **Protection DC** | âŒ | âŒ | âœ… |
| **Risque split-brain** | âŒ | âš ï¸ Faible | âš ï¸ Moyen |
| **Maintenance** | â­â­ | â­â­â­â­ | â­â­ |

### 4.3 Scoring Model

Attribuez des points selon vos prioritÃ©s :

```python
# Exemple de scoring
weights = {
    'rto': 10,          # CriticitÃ© maximale
    'rpo': 10,          # CriticitÃ© maximale
    'cost': 3,          # Moins critique
    'complexity': 5,    # Important
    'scalability': 7    # TrÃ¨s important
}

architectures = {
    'active_passive': {
        'rto': 5,       # 1-5 min
        'rpo': 7,       # Quelques secondes
        'cost': 9,      # Faible coÃ»t
        'complexity': 9,
        'scalability': 5
    },
    'galera_single': {
        'rto': 9,       # 10-30 sec
        'rpo': 10,      # ZÃ©ro
        'cost': 6,
        'complexity': 6,
        'scalability': 9
    },
    'galera_multi_dc': {
        'rto': 8,
        'rpo': 10,
        'cost': 3,
        'complexity': 3,
        'scalability': 10
    }
}

# Calcul des scores
for arch, scores in architectures.items():
    total = sum(scores[k] * weights[k] for k in scores)
    print(f"{arch}: {total}")
```

**RÃ©sultat exemple** :
- active_passive: **245**
- galera_single: **305** â† Meilleur score
- galera_multi_dc: **275**

### 4.4 Questions ClÃ©s Ã  Poser

#### **Business**
- [ ] Quel est le coÃ»t rÃ©el d'une heure d'indisponibilitÃ© ?
- [ ] Quelles sont les obligations contractuelles (SLA) ?
- [ ] Y a-t-il des exigences rÃ©glementaires (RGPD, SOC2, etc.) ?
- [ ] Quelle est la croissance prÃ©vue (3 ans) ?

#### **Technique**
- [ ] Quelle est la latence rÃ©seau entre datacenters ?
- [ ] Quel est le ratio read/write de la charge ?
- [ ] Quels sont les pics de charge prÃ©visibles ?
- [ ] Quelle expertise interne disponible ?

#### **OpÃ©rationnel**
- [ ] Existe-t-il une astreinte 24/7 ?
- [ ] Quelle est la maturitÃ© des processus (runbooks, DR drills) ?
- [ ] Quelle est la tolÃ©rance Ã  la complexitÃ© ?
- [ ] Budget annuel infrastructure ?

---

## 5. Identification et Mitigation des SPOF

### 5.1 Points de DÃ©faillance Uniques (SPOF)

**SPOF classiques dans une architecture MariaDB** :

```
Application Layer:
  â”œâ”€ SPOF: Load Balancer unique
  â””â”€ Mitigation: Keepalived + Virtual IP

Proxy Layer:
  â”œâ”€ SPOF: MaxScale unique
  â””â”€ Mitigation: Multiple MaxScale + HAProxy

Database Layer:
  â”œâ”€ SPOF: Single Master
  â””â”€ Mitigation: Galera Cluster

Network Layer:
  â”œâ”€ SPOF: Switch unique
  â””â”€ Mitigation: Redondance rÃ©seau (LACP)

Datacenter:
  â”œâ”€ SPOF: Single DC
  â””â”€ Mitigation: Multi-DC deployment

Storage:
  â”œâ”€ SPOF: Single disk
  â””â”€ Mitigation: RAID, rÃ©plication storage
```

### 5.2 Checklist SPOF

```bash
# Script d'analyse SPOF
#!/bin/bash

echo "=== SPOF Analysis ==="

# 1. Nombre de MaxScale
maxscale_count=$(systemctl list-units | grep -c maxscale)
[ $maxscale_count -lt 2 ] && echo "âš ï¸ SPOF: Only $maxscale_count MaxScale"

# 2. Nombre de nÅ“uds Galera
galera_nodes=$(mysql -e "SHOW STATUS LIKE 'wsrep_cluster_size'" -sN | awk '{print $2}')
[ $galera_nodes -lt 3 ] && echo "âš ï¸ SPOF: Only $galera_nodes Galera nodes"

# 3. Quorum
quorum=$((galera_nodes / 2 + 1))
echo "â„¹ï¸ Quorum required: $quorum / $galera_nodes"

# 4. Virtual IP configured?
ip addr show | grep -q "inet.*secondary" || echo "âš ï¸ SPOF: No Virtual IP"

# 5. Backup retention
backup_count=$(find /backup -name "*.sql.gz" -mtime -7 | wc -l)
[ $backup_count -eq 0 ] && echo "âš ï¸ SPOF: No recent backups"

echo "=== Analysis Complete ==="
```

---

## 6. StratÃ©gies de Tests

### 6.1 Chaos Engineering pour HA

**Principe** : Introduire dÃ©libÃ©rÃ©ment des pannes pour valider la rÃ©silience.

```bash
#!/bin/bash
# chaos_test.sh - Tests de rÃ©silience

function test_node_failure() {
    echo "Test: Node failure simulation"
    
    # ArrÃªt brutal d'un nÅ“ud
    ssh node2 "systemctl stop mariadb"
    
    # VÃ©rification failover
    sleep 10
    
    # Test connexion application
    mysql -h vip.example.com -e "SELECT 1" &>/dev/null
    [ $? -eq 0 ] && echo "âœ… Failover successful" || echo "âŒ Failover failed"
    
    # Restauration
    ssh node2 "systemctl start mariadb"
}

function test_network_partition() {
    echo "Test: Network partition (split-brain)"
    
    # Isolation rÃ©seau node1
    ssh node1 "iptables -A INPUT -s 10.0.1.0/24 -j DROP"
    
    # Attendre dÃ©tection
    sleep 30
    
    # VÃ©rifier quorum
    cluster_size=$(mysql -h node2 -e "SHOW STATUS LIKE 'wsrep_cluster_size'" -sN | awk '{print $2}')
    echo "Cluster size after partition: $cluster_size"
    
    # Restauration
    ssh node1 "iptables -F"
}

function test_maxscale_failure() {
    echo "Test: MaxScale proxy failure"
    
    # ArrÃªt MaxScale primary
    systemctl stop maxscale
    
    # VÃ©rification bascule VIP
    sleep 5
    ping -c 1 vip.maxscale.example.com &>/dev/null
    
    [ $? -eq 0 ] && echo "âœ… VIP migrated" || echo "âŒ VIP not migrated"
    
    # Restauration
    systemctl start maxscale
}

# ExÃ©cution sÃ©quentielle
test_node_failure
sleep 60
test_network_partition
sleep 60
test_maxscale_failure
```

### 6.2 ScÃ©narios de Tests RecommandÃ©s

| ScÃ©nario | Objectif | FrÃ©quence |
|----------|----------|-----------|
| **Node crash** | Valider dÃ©tection et failover | Mensuel |
| **Split-brain** | Valider quorum et fencing | Trimestriel |
| **Full DC outage** | Valider DR multi-DC | Semestriel |
| **Backup restore** | Valider procÃ©dure restauration | Mensuel |
| **Load spike** | Valider scalabilitÃ© | Continu (prod) |
| **Upgrade simulation** | Valider rolling upgrade | Avant chaque release |

---

## âœ… Points ClÃ©s Ã  Retenir

- **Le thÃ©orÃ¨me CAP** impose de choisir entre cohÃ©rence (CP) et disponibilitÃ© (AP) en cas de partition rÃ©seau
- **RTO et RPO** sont les mÃ©triques business fondamentales pour dimensionner une architecture HA
- **Active-Passive** convient pour des budgets limitÃ©s avec RTO de quelques minutes acceptable
- **Galera Cluster** offre un RPO de zÃ©ro et un RTO < 30 secondes, au prix d'une complexitÃ© accrue
- **Multi-DC** protÃ¨ge contre la dÃ©faillance datacenter mais introduit des dÃ©fis de latence WAN
- **Identifier et mitiger les SPOF** est crucial pour atteindre une disponibilitÃ© > 99.99%
- **Tester rÃ©guliÃ¨rement** les scÃ©narios de dÃ©faillance est non nÃ©gociable (Chaos Engineering)

---

## ğŸ”— Ressources et RÃ©fÃ©rences

### Documentation Officielle
- [ğŸ“– MariaDB High Availability Guide](https://mariadb.com/kb/en/high-availability-performance-tuning-mariadb-replication/)
- [ğŸ“– CAP Theorem Explained](https://en.wikipedia.org/wiki/CAP_theorem)
- [ğŸ“– Google SRE Book - Availability](https://sre.google/sre-book/availability/)

### Articles de RÃ©fÃ©rence
- **"Designing Data-Intensive Applications"** - Martin Kleppmann (Chapitre 5-9)
- **"The Calculus of Service Availability"** - Google SRE
- **"Chaos Engineering: Building Confidence in System Behavior"** - Netflix

### Outils d'Analyse
- [Availability Calculator](https://availability.sre.xyz/)
- [RTO/RPO Calculator](https://www.druva.com/resources/rto-rpo-calculator/)
- [Chaos Monkey](https://netflix.github.io/chaosmonkey/) - Netflix

---

## â¡ï¸ Section Suivante

**[14.2 MariaDB Galera Cluster](/14-haute-disponibilite/02-galera-cluster.md)**

Maintenant que les fondations thÃ©oriques sont posÃ©es, nous plongeons dans l'implÃ©mentation concrÃ¨te de Galera Cluster : architecture synchrone multi-master, certification-based replication, configuration de production, et opÃ©rations (SST, IST).

---

**MaÃ®triser ces concepts architecturaux est essentiel avant toute implÃ©mentation HA en production.**

â­ï¸ [MariaDB Galera Cluster](/14-haute-disponibilite/02-galera-cluster.md)
