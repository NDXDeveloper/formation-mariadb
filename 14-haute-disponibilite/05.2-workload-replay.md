ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 14.5.2 Workload Replay

> **Niveau** : Expert  
> **DurÃ©e estimÃ©e** : 4-5 heures  
> **PrÃ©requis** : Workload Capture (14.5.1), MaxScale (14.4), Benchmarking, Tests de rÃ©gression

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- Comprendre la fonctionnalitÃ© Workload Replay de MaxScale 25.01
- Configurer et exÃ©cuter des replays de workload
- Valider des upgrades MariaDB avec du trafic rÃ©el
- Comparer des rÃ©sultats entre diffÃ©rents backends
- Utiliser le Diff Router pour dÃ©tecter les incompatibilitÃ©s
- Automatiser les tests de rÃ©gression
- Analyser les diffÃ©rences de performance
- Optimiser les replays pour des tests efficaces

---

## Introduction

Le **Workload Replay** est la fonctionnalitÃ© complÃ©mentaire du Workload Capture introduite dans **MaxScale 25.01**. Elle permet de rejouer un workload capturÃ© en production contre un environnement de test, permettant de valider des changements avant leur dÃ©ploiement.

```
Workflow complet Capture â†’ Replay:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Ã‰TAPE 1: CAPTURE                           â”‚
â”‚  Production (MariaDB 11.8)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚   App    â”‚ â”€â”€â†’ MaxScale â”€â”€â†’ DB 11.8                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â†“                                     â”‚
â”‚                  workload.log                               â”‚
â”‚                  (Trafic rÃ©el 24h)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“ Copy
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Ã‰TAPE 2: REPLAY                            â”‚
â”‚  Test Environment                                           â”‚
â”‚                                                             â”‚
â”‚  maxscale-replay â”€â”€â†’ MaxScale â”€â”€â†’ DB 12.0 (candidate)       â”‚
â”‚      â†‘                   â”‚              â†“                   â”‚
â”‚  workload.log      Diff Router    RÃ©sultats                 â”‚
â”‚                         â”‚              â†“                    â”‚
â”‚                         â””â”€â†’ DB 11.8 (baseline)              â”‚
â”‚                                  â†“                          â”‚
â”‚                            Comparaison                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Ã‰TAPE 3: ANALYSE                           â”‚
â”‚  Rapport de comparaison:                                    â”‚
â”‚  âœ… 99.7% requÃªtes: rÃ©sultats identiques                    â”‚
â”‚  âš ï¸  0.3% requÃªtes: diffÃ©rences dÃ©tectÃ©es                   â”‚
â”‚  ğŸ“Š Performance: +15% plus rapide (DB 12.0)                 â”‚
â”‚                                                             â”‚
â”‚  DÃ©cision: OK pour upgrade production                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Avantages:
âœ… Tests avec trafic rÃ©el (pas synthÃ©tique)
âœ… DÃ©tection proactive d'incompatibilitÃ©s
âœ… Validation performance avant production
âœ… Confiance Ã©levÃ©e pour changements critiques
âœ… ReproductibilitÃ© (mÃªme workload, tests multiples)
```

---

## Outil maxscale-workload-replay

### Installation

**MaxScale 25.01+ requis :**

```bash
# Ubuntu/Debian
wget https://dlm.mariadb.com/3748087/MaxScale/25.01.0/ubuntu/dists/focal/main/binary-amd64/maxscale-25.01.0-1.ubuntu.focal.x86_64.deb
sudo dpkg -i maxscale-25.01.0-1.ubuntu.focal.x86_64.deb

# RHEL/Rocky Linux
sudo yum install https://dlm.mariadb.com/3748087/MaxScale/25.01.0/rhel/9/x86_64/maxscale-25.01.0-1.rhel.9.x86_64.rpm

# VÃ©rifier installation
maxscale-workload-replay --version
# Output: maxscale-workload-replay version 25.01.0
```

### Commande de base

**Syntaxe :**

```bash
maxscale-workload-replay [OPTIONS]

Options principales:
  --input FILE              Fichier workload capturÃ© (requis)
  --target HOST:PORT        Backend cible (requis)
  --user USER               Utilisateur MariaDB
  --password PASS           Mot de passe
  --database DB             Base de donnÃ©es par dÃ©faut
  
  --replay-speed FLOAT      Vitesse de replay (1.0 = temps rÃ©el)
  --concurrency INT         Nombre de threads parallÃ¨les
  --duration DURATION       Limiter durÃ©e du replay
  --loop                    Rejouer en boucle
  
  --compare-baseline FILE   Fichier baseline pour comparaison
  --diff-output FILE        Fichier de sortie diffÃ©rences
  --report FILE             Rapport HTML/JSON
  
  --verbose                 Mode verbeux
  --dry-run                 Simulation sans exÃ©cution
```

**Exemple simple :**

```bash
# Replay basique
maxscale-workload-replay \
    --input /var/lib/maxscale/workloads/prod_20241215.log \
    --target test-db:3306 \
    --user test_user \
    --password 'Test_P@ssw0rd!' \
    --database test_db \
    --replay-speed 1.0 \
    --report replay_report.html

# Output durant replay:
Replay Progress:
[====================] 100% (1,245,678 / 1,245,678 queries)
Duration: 2h 15m 34s (original: 2h 00m 00s, speed: 1.0x)
QPS: 154 (original: 173)
Errors: 12 (0.001%)
Report saved to: replay_report.html
```

---

## Validation d'upgrade MariaDB

### ScÃ©nario : Upgrade 11.8 â†’ 12.0

**Objectif :** Valider qu'un upgrade MariaDB 11.8 LTS vers 12.0 ne causera pas de rÃ©gressions.

**Ã‰tape 1 : Capturer workload production**

```bash
# Sur MaxScale production (pointant vers MariaDB 11.8)
maxctrl alter service Production-Service workload_capture true
maxctrl alter service Production-Service \
    workload_capture_file /var/lib/maxscale/workloads/prod_baseline_11.8.log
maxctrl alter service Production-Service workload_capture_duration 86400s  # 24h

# Attendre 24h (journÃ©e type)

# ArrÃªter capture
maxctrl alter service Production-Service workload_capture false

# Compresser et copier vers environnement de test
gzip /var/lib/maxscale/workloads/prod_baseline_11.8.log
scp /var/lib/maxscale/workloads/prod_baseline_11.8.log.gz test-server:/tmp/
```

**Ã‰tape 2 : PrÃ©parer environnement test**

```bash
# Sur serveur test
# DÃ©ployer 2 instances MariaDB:
# - Instance A: MariaDB 11.8 (baseline, identique prod)
# - Instance B: MariaDB 12.0 (candidate upgrade)

# Restaurer snapshot production sur les 2 instances
# (mÃªme donnÃ©es, mÃªme schÃ©ma)

# Instance A (11.8 baseline)
sudo systemctl start mariadb@11.8

# Instance B (12.0 candidate)
sudo systemctl start mariadb@12.0

# VÃ©rifier versions
mysql -h localhost -P 3308 -e "SELECT VERSION();"  # 11.8.x
mysql -h localhost -P 3309 -e "SELECT VERSION();"  # 12.0.x
```

**Ã‰tape 3 : Configurer MaxScale Diff Router**

```ini
# /etc/maxscale.cnf - Test Environment

[maxscale]
threads = auto

#
# === Servers ===
#
[server-11.8]
type = server
address = localhost
port = 3308
protocol = MariaDBBackend

[server-12.0]
type = server
address = localhost
port = 3309
protocol = MariaDBBackend

#
# === Diff Router Service ===
#
[Upgrade-Validation-Service]
type = service
router = diff

# Backend primaire (baseline)
primary_server = server-11.8

# Backend secondaire (candidate)
secondary_server = server-12.0

user = test_user
password = Test_P@ssw0rd!

# === Diff Configuration ===

# Mode de comparaison
diff_mode = both
# Options: results (rÃ©sultats), performance (temps), both

# TolÃ©rance diffÃ©rences (floats)
diff_tolerance = 0.001  # 0.1%

# Logging diffÃ©rences
diff_log_file = /var/log/maxscale/upgrade_validation_diff.log
diff_log_format = json
diff_log_threshold = 1  # Log si â‰¥1 diffÃ©rence

# Ignorer diffÃ©rences non critiques
diff_ignore_columns = created_at,updated_at,last_modified
diff_ignore_order = true
diff_ignore_auto_increment = true

# Timeout
diff_timeout = 60s

#
# === Listener ===
#
[Upgrade-Validation-Listener]
type = listener
service = Upgrade-Validation-Service
protocol = MariaDBClient
port = 3306
address = 127.0.0.1
```

**Ã‰tape 4 : ExÃ©cuter replay avec comparaison**

```bash
# DÃ©marrer MaxScale
sudo systemctl start maxscale

# DÃ©compresser workload
gunzip /tmp/prod_baseline_11.8.log.gz

# Replay avec comparaison automatique
maxscale-workload-replay \
    --input /tmp/prod_baseline_11.8.log \
    --target localhost:3306 \
    --user test_user \
    --password 'Test_P@ssw0rd!' \
    --replay-speed 10.0 \
    --concurrency 20 \
    --report upgrade_validation_report.html \
    --diff-output upgrade_differences.json \
    --verbose

# Options expliquÃ©es:
# --replay-speed 10.0: Replay 10x plus rapide (2h â†’ 12min)
# --concurrency 20: 20 threads parallÃ¨les (accÃ©lÃ¨re replay)
# --diff-output: Fichier JSON avec toutes les diffÃ©rences dÃ©tectÃ©es
```

**Ã‰tape 5 : Analyser rapport**

```html
<!-- upgrade_validation_report.html -->
<!DOCTYPE html>
<html>
<head>
    <title>Upgrade Validation Report: MariaDB 11.8 â†’ 12.0</title>
    <style>
        .success { color: green; }
        .warning { color: orange; }
        .error { color: red; }
    </style>
</head>
<body>
    <h1>Upgrade Validation Report</h1>
    
    <h2>Summary</h2>
    <table>
        <tr><td>Workload file:</td><td>prod_baseline_11.8.log</td></tr>
        <tr><td>Total queries:</td><td>1,245,678</td></tr>
        <tr><td>Duration:</td><td>12m 34s (original: 2h 00m 00s, 10.0x speed)</td></tr>
        <tr><td>Baseline:</td><td>MariaDB 11.8.12</td></tr>
        <tr><td>Candidate:</td><td>MariaDB 12.0.5</td></tr>
    </table>
    
    <h2 class="success">âœ… Results Comparison</h2>
    <table>
        <tr><td>Identical results:</td><td class="success">1,241,234 (99.64%)</td></tr>
        <tr><td>Different results:</td><td class="warning">4,444 (0.36%)</td></tr>
        <tr><td>Errors (11.8):</td><td>0</td></tr>
        <tr><td>Errors (12.0):</td><td>0</td></tr>
    </table>
    
    <h2 class="success">ğŸ“Š Performance Comparison</h2>
    <table>
        <tr><th>Metric</th><th>11.8 (baseline)</th><th>12.0 (candidate)</th><th>Delta</th></tr>
        <tr>
            <td>Avg latency</td>
            <td>15.2ms</td>
            <td>12.8ms</td>
            <td class="success">-15.8% â¬‡ï¸</td>
        </tr>
        <tr>
            <td>P95 latency</td>
            <td>45.3ms</td>
            <td>38.1ms</td>
            <td class="success">-15.9% â¬‡ï¸</td>
        </tr>
        <tr>
            <td>P99 latency</td>
            <td>120.5ms</td>
            <td>98.3ms</td>
            <td class="success">-18.4% â¬‡ï¸</td>
        </tr>
        <tr>
            <td>Max latency</td>
            <td>1,234ms</td>
            <td>890ms</td>
            <td class="success">-27.9% â¬‡ï¸</td>
        </tr>
    </table>
    
    <h2 class="warning">âš ï¸ Differences Detected (4,444 queries)</h2>
    <p>Analysis of differences:</p>
    <table>
        <tr><th>Category</th><th>Count</th><th>Impact</th></tr>
        <tr>
            <td>Float precision differences</td>
            <td>4,320 (97.2%)</td>
            <td class="success">LOW (within tolerance)</td>
        </tr>
        <tr>
            <td>Date format changes</td>
            <td>120 (2.7%)</td>
            <td class="warning">MEDIUM (investigate)</td>
        </tr>
        <tr>
            <td>Optimizer plan differences</td>
            <td>4 (0.1%)</td>
            <td class="warning">MEDIUM (review EXPLAIN)</td>
        </tr>
    </table>
    
    <h2>ğŸ” Top 10 Queries with Differences</h2>
    <table>
        <tr>
            <th>Query</th>
            <th>Difference Type</th>
            <th>Example</th>
        </tr>
        <tr>
            <td>SELECT price * tax FROM orders</td>
            <td>Float precision</td>
            <td>11.8: 99.999999 vs 12.0: 100.000000</td>
        </tr>
        <tr>
            <td>SELECT DATE_FORMAT(created, '%Y-%m-%d')</td>
            <td>Date format</td>
            <td>11.8: '2024-12-15' vs 12.0: '2024-12-15' (identical, false positive)</td>
        </tr>
        <!-- ... -->
    </table>
    
    <h2 class="success">âœ… Recommendation</h2>
    <p><strong>APPROVED FOR PRODUCTION UPGRADE</strong></p>
    <ul>
        <li>99.64% queries produce identical results</li>
        <li>Performance improved by ~16% (avg latency)</li>
        <li>Differences are non-critical (float precision within tolerance)</li>
        <li>No errors or crashes detected</li>
    </ul>
    <p>Action items before production upgrade:</p>
    <ol>
        <li>Review 120 date format differences (likely benign)</li>
        <li>Review 4 optimizer plan changes (EXPLAIN analysis)</li>
        <li>Update application to handle minor float precision differences if needed</li>
    </ol>
</body>
</html>
```

**Analyse des diffÃ©rences dÃ©taillÃ©es :**

```json
// upgrade_differences.json
{
  "summary": {
    "total_queries": 1245678,
    "identical_results": 1241234,
    "different_results": 4444,
    "percentage_identical": 99.64
  },
  "differences": [
    {
      "query_id": 12345,
      "query": "SELECT price * 1.055 AS total FROM orders WHERE id = 123",
      "difference_type": "result_value",
      "baseline_result": [
        {"total": 99.999999}
      ],
      "candidate_result": [
        {"total": 100.000000}
      ],
      "impact": "LOW",
      "notes": "Float precision difference within tolerance (0.001%)"
    },
    {
      "query_id": 67890,
      "query": "SELECT * FROM users ORDER BY created_at DESC LIMIT 10",
      "difference_type": "execution_plan",
      "baseline_explain": "Using index for ORDER BY",
      "candidate_explain": "Using filesort",
      "impact": "MEDIUM",
      "performance_delta_ms": +25.3,
      "notes": "Optimizer chose different plan, slightly slower. Investigate."
    }
    // ... autres diffÃ©rences
  ]
}
```

---

## Comparaison de configurations

### ScÃ©nario : Tester nouvelle configuration MaxScale

**Objectif :** Comparer 2 configurations MaxScale pour choisir la meilleure.

**Configuration A (actuelle) :**

```ini
# /etc/maxscale-config-a.cnf
[Read-Write-Service-A]
router = readwritesplit
max_slave_connections = 1
causal_reads = false
transaction_replay = false
```

**Configuration B (candidate) :**

```ini
# /etc/maxscale-config-b.cnf
[Read-Write-Service-B]
router = readwritesplit
max_slave_connections = 100%
causal_reads = true
transaction_replay = true
transaction_replay_max_size = 10M
```

**Tests comparatifs :**

```bash
#!/bin/bash
# compare-maxscale-configs.sh

WORKLOAD="/var/lib/maxscale/workloads/prod_workload.log"

# Test Config A
echo "Testing Config A..."
sudo cp /etc/maxscale-config-a.cnf /etc/maxscale.cnf
sudo systemctl restart maxscale
sleep 10

maxscale-workload-replay \
    --input "$WORKLOAD" \
    --target localhost:3306 \
    --user test_user \
    --password 'password' \
    --replay-speed 1.0 \
    --report config_a_results.json \
    --format json

# Test Config B
echo "Testing Config B..."
sudo cp /etc/maxscale-config-b.cnf /etc/maxscale.cnf
sudo systemctl restart maxscale
sleep 10

maxscale-workload-replay \
    --input "$WORKLOAD" \
    --target localhost:3306 \
    --user test_user \
    --password 'password' \
    --replay-speed 1.0 \
    --report config_b_results.json \
    --format json

# Comparer rÃ©sultats
maxscale-compare-results config_a_results.json config_b_results.json \
    --output comparison_report.html

echo "Comparison report: comparison_report.html"
```

**Rapport de comparaison :**

```
Configuration Comparison Report
================================

Config A (baseline):
- max_slave_connections: 1
- causal_reads: false
- transaction_replay: false

Config B (candidate):
- max_slave_connections: 100%
- causal_reads: true
- transaction_replay: true

Performance Comparison:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric           â”‚ Config A â”‚ Config B â”‚ Delta   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Avg latency      â”‚ 18.5ms   â”‚ 14.2ms   â”‚ -23.2% â†“â”‚
â”‚ P95 latency      â”‚ 55.3ms   â”‚ 42.1ms   â”‚ -23.9% â†“â”‚
â”‚ P99 latency      â”‚ 145.2ms  â”‚ 98.7ms   â”‚ -32.0% â†“â”‚
â”‚ Max latency      â”‚ 2,345ms  â”‚ 1,890ms  â”‚ -19.4% â†“â”‚
â”‚ Throughput (QPS) â”‚ 154      â”‚ 189      â”‚ +22.7% â†‘â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Read/Write Distribution:
Config A: 65% queries to master (causal_reads=false)
Config B: 28% queries to master (causal_reads=true, better balancing)

Recommendation: âœ… CONFIG B
- Significant performance improvement (+23% avg latency)
- Better load distribution (more reads on slaves)
- Transaction replay provides better resilience
- Slightly higher master load but acceptable
```

---

## Benchmarking infrastructure

### ScÃ©nario : Valider migration serveurs

**Objectif :** Justifier ROI de migration vers serveurs plus puissants.

**Infrastructure actuelle :**
- 3Ã— serveurs: Intel Xeon 16 cores, 64GB RAM, SSD SATA (500 MB/s)

**Infrastructure candidate :**
- 3Ã— serveurs: AMD EPYC 32 cores, 128GB RAM, NVMe SSD (3000 MB/s)

**MÃ©thodologie :**

```bash
#!/bin/bash
# benchmark-infrastructure.sh

WORKLOAD="/var/lib/maxscale/workloads/prod_week_sample.log"

echo "=== Benchmark Infrastructure Comparison ==="

# === Old Infrastructure ===
echo ""
echo "Phase 1: Testing OLD infrastructure..."
echo "Servers: Intel Xeon 16c/64GB/SATA SSD"

maxscale-workload-replay \
    --input "$WORKLOAD" \
    --target old-cluster:3306 \
    --user benchmark_user \
    --password 'password' \
    --replay-speed 1.0 \
    --concurrency 50 \
    --collect-system-metrics \
    --report old_infra_benchmark.json

# === New Infrastructure ===
echo ""
echo "Phase 2: Testing NEW infrastructure..."
echo "Servers: AMD EPYC 32c/128GB/NVMe SSD"

maxscale-workload-replay \
    --input "$WORKLOAD" \
    --target new-cluster:3306 \
    --user benchmark_user \
    --password 'password' \
    --replay-speed 1.0 \
    --concurrency 50 \
    --collect-system-metrics \
    --report new_infra_benchmark.json

# === Stress Test (new infra) ===
echo ""
echo "Phase 3: Stress testing NEW infrastructure..."
echo "Replay speed: 5x (simulate future growth)"

maxscale-workload-replay \
    --input "$WORKLOAD" \
    --target new-cluster:3306 \
    --user benchmark_user \
    --password 'password' \
    --replay-speed 5.0 \
    --concurrency 200 \
    --duration 1h \
    --loop \
    --report new_infra_stress_test.json

# === Generate Comparison Report ===
echo ""
echo "Generating comparison report..."

python3 << 'EOF'
import json

# Charger rÃ©sultats
with open('old_infra_benchmark.json') as f:
    old = json.load(f)
with open('new_infra_benchmark.json') as f:
    new = json.load(f)
with open('new_infra_stress_test.json') as f:
    stress = json.load(f)

# Afficher comparaison
print("\n" + "="*60)
print("INFRASTRUCTURE BENCHMARK RESULTS")
print("="*60)

print("\n1. Performance Comparison (1x speed):")
print(f"  Old Infrastructure:")
print(f"    - Avg latency: {old['metrics']['avg_latency_ms']:.1f}ms")
print(f"    - P95 latency: {old['metrics']['p95_latency_ms']:.1f}ms")
print(f"    - Max QPS: {old['metrics']['max_qps']}")
print(f"    - CPU usage: {old['system']['avg_cpu_percent']:.1f}%")
print(f"    - Disk IOPS: {old['system']['avg_disk_iops']}")

print(f"\n  New Infrastructure:")
print(f"    - Avg latency: {new['metrics']['avg_latency_ms']:.1f}ms ({(new['metrics']['avg_latency_ms']/old['metrics']['avg_latency_ms']-1)*100:+.1f}%)")
print(f"    - P95 latency: {new['metrics']['p95_latency_ms']:.1f}ms ({(new['metrics']['p95_latency_ms']/old['metrics']['p95_latency_ms']-1)*100:+.1f}%)")
print(f"    - Max QPS: {new['metrics']['max_qps']} ({(new['metrics']['max_qps']/old['metrics']['max_qps']-1)*100:+.1f}%)")
print(f"    - CPU usage: {new['system']['avg_cpu_percent']:.1f}%")
print(f"    - Disk IOPS: {new['system']['avg_disk_iops']} ({(new['system']['avg_disk_iops']/old['system']['avg_disk_iops']-1)*100:+.1f}%)")

print("\n2. Stress Test Results (5x speed, simulating 5 years growth):")
print(f"  New Infrastructure at 5x load:")
print(f"    - Avg latency: {stress['metrics']['avg_latency_ms']:.1f}ms")
print(f"    - P95 latency: {stress['metrics']['p95_latency_ms']:.1f}ms")
print(f"    - Max QPS: {stress['metrics']['max_qps']}")
print(f"    - CPU usage: {stress['system']['avg_cpu_percent']:.1f}%")
print(f"    - Headroom: {100-stress['system']['avg_cpu_percent']:.1f}% CPU available")

print("\n3. ROI Analysis:")
old_cost = 3 * 5000  # 3 serveurs Ã— $5000/an
new_cost = 3 * 12000  # 3 serveurs Ã— $12000/an
cost_increase = new_cost - old_cost
perf_improvement = (old['metrics']['avg_latency_ms'] / new['metrics']['avg_latency_ms'] - 1) * 100

print(f"  Hardware cost increase: ${cost_increase}/year (+{cost_increase/old_cost*100:.0f}%)")
print(f"  Performance improvement: {perf_improvement:.1f}%")
print(f"  Headroom for growth: 5x current load sustainable")
print(f"\n  âœ… RECOMMENDATION: Upgrade justified")
print(f"     - Significant performance gains ({perf_improvement:.0f}%)")
print(f"     - Future-proof for 5+ years growth")
print(f"     - Improved user experience (faster response times)")
EOF
```

**Output exemple :**

```
============================================================
INFRASTRUCTURE BENCHMARK RESULTS
============================================================

1. Performance Comparison (1x speed):
  Old Infrastructure:
    - Avg latency: 23.5ms
    - P95 latency: 78.3ms
    - Max QPS: 4,234
    - CPU usage: 72.3%
    - Disk IOPS: 12,500

  New Infrastructure:
    - Avg latency: 9.8ms (-58.3%)
    - P95 latency: 28.1ms (-64.1%)
    - Max QPS: 11,890 (+180.7%)
    - CPU usage: 28.5%
    - Disk IOPS: 45,200 (+261.6%)

2. Stress Test Results (5x speed, simulating 5 years growth):
  New Infrastructure at 5x load:
    - Avg latency: 18.2ms
    - P95 latency: 52.4ms
    - Max QPS: 21,234
    - CPU usage: 68.9%
    - Headroom: 31.1% CPU available

3. ROI Analysis:
  Hardware cost increase: $21,000/year (+140%)
  Performance improvement: 139.8%
  Headroom for growth: 5x current load sustainable

  âœ… RECOMMENDATION: Upgrade justified
     - Significant performance gains (140%)
     - Future-proof for 5+ years growth
     - Improved user experience (faster response times)
```

---

## Options avancÃ©es de replay

### Replay-speed : ContrÃ´le de vitesse

**Cas d'usage selon vitesse :**

```bash
# === Vitesse 0.1x (10Ã— plus lent) ===
# Use case: Debugging, inspection dÃ©taillÃ©e
maxscale-workload-replay \
    --input workload.log \
    --target debug-db:3306 \
    --replay-speed 0.1 \
    --verbose \
    --log-queries

# Permet d'observer chaque requÃªte en temps rÃ©el
# Utile pour reproduire bugs spÃ©cifiques

# === Vitesse 1.0x (temps rÃ©el) ===
# Use case: Test rÃ©aliste, validation fonctionnelle
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --replay-speed 1.0

# Reproduit exactement la charge production
# IdÃ©al pour validation comportementale

# === Vitesse 10.0x (10Ã— plus rapide) ===
# Use case: Tests rapides, CI/CD
maxscale-workload-replay \
    --input workload.log \
    --target ci-db:3306 \
    --replay-speed 10.0 \
    --concurrency 50

# Workload 2h rejouÃ© en 12min
# Parfait pour pipeline CI/CD

# === Vitesse maximale (aussi vite que possible) ===
# Use case: Stress testing, benchmarking
maxscale-workload-replay \
    --input workload.log \
    --target bench-db:3306 \
    --replay-speed 0 \
    --concurrency 500

# --replay-speed 0 = pas de throttling
# Saturer le systÃ¨me pour trouver limites
```

### Concurrency : ParallÃ©lisation

**Impact de concurrency :**

```bash
# === Low concurrency (1-10 threads) ===
# Respecte ordre sÃ©quentiel des requÃªtes
# IdÃ©al pour tests fonctionnels

maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --concurrency 1 \
    --preserve-order

# Garantit ORDER BY, transaction ordering, etc.

# === Medium concurrency (10-50 threads) ===
# Bon compromis performance/ordre

maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --concurrency 20

# === High concurrency (50-500 threads) ===
# Maximum parallÃ©lisation, stress test

maxscale-workload-replay \
    --input workload.log \
    --target stress-db:3306 \
    --concurrency 200

# Simule charge extrÃªme
# Utile pour capacity planning
```

### Filtrage pendant replay

```bash
# Rejouer seulement requÃªtes SELECT
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --filter-query-type SELECT

# Rejouer seulement requÃªtes lentes (>100ms)
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --filter-min-duration 100ms

# Rejouer seulement utilisateur spÃ©cifique
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --filter-user app_user

# Rejouer seulement database spÃ©cifique
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --filter-database production_db

# Rejouer portion temporelle
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --filter-time-start "2024-12-15 10:00:00" \
    --filter-time-end "2024-12-15 12:00:00"
```

---

## Automatisation des tests

### Pipeline CI/CD avec workload replay

**GitLab CI exemple :**

```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - deploy

variables:
  WORKLOAD_FILE: "prod_baseline.log.gz"
  TEST_DB: "test-mariadb:3306"

# Stage 1: Build MariaDB container
build_mariadb:
  stage: build
  script:
    - docker build -t mariadb-candidate:$CI_COMMIT_SHA .
    - docker push mariadb-candidate:$CI_COMMIT_SHA

# Stage 2: Workload replay test
workload_replay_test:
  stage: test
  dependencies:
    - build_mariadb
  script:
    # DÃ©marrer container MariaDB candidat
    - docker run -d --name test-db -p 3306:3306 mariadb-candidate:$CI_COMMIT_SHA
    - sleep 30  # Attendre dÃ©marrage
    
    # Restaurer snapshot donnÃ©es production
    - gunzip -c prod_snapshot.sql.gz | mysql -h localhost -u root -p$MYSQL_ROOT_PASSWORD
    
    # TÃ©lÃ©charger workload baseline
    - aws s3 cp s3://ci-artifacts/$WORKLOAD_FILE /tmp/
    - gunzip /tmp/$WORKLOAD_FILE
    
    # ExÃ©cuter replay
    - |
      maxscale-workload-replay \
        --input /tmp/${WORKLOAD_FILE%.gz} \
        --target localhost:3306 \
        --user test_user \
        --password $TEST_PASSWORD \
        --replay-speed 10.0 \
        --concurrency 20 \
        --compare-baseline s3://ci-artifacts/baseline_results.json \
        --report workload_test_report.html \
        --diff-output differences.json \
        --fail-on-differences
    
    # Uploader rapport
    - aws s3 cp workload_test_report.html s3://ci-reports/$CI_COMMIT_SHA/
    
    # Cleanup
    - docker stop test-db
    - docker rm test-db
  
  artifacts:
    paths:
      - workload_test_report.html
      - differences.json
    reports:
      junit: test-results.xml
  
  # Ã‰chouer pipeline si diffÃ©rences critiques
  allow_failure: false

# Stage 3: Deploy si tests OK
deploy_production:
  stage: deploy
  dependencies:
    - workload_replay_test
  script:
    - echo "Deploying to production..."
    # Scripts de dÃ©ploiement
  only:
    - main
  when: manual
```

### Tests de rÃ©gression automatisÃ©s

**Script de test de rÃ©gression :**

```bash
#!/bin/bash
# /usr/local/bin/regression-test.sh
# Tests de rÃ©gression automatisÃ©s avec workload replay

set -e

BASELINE_WORKLOAD="/var/lib/regression-tests/baseline_workload.log"
BASELINE_RESULTS="/var/lib/regression-tests/baseline_results.json"
TEST_DB="localhost:3306"

echo "=== Regression Test Suite ==="
echo "Date: $(date)"
echo "Baseline: $BASELINE_RESULTS"
echo ""

# DÃ©marrer base de donnÃ©es test
echo "Starting test database..."
docker-compose up -d mariadb-test
sleep 30

# Restaurer donnÃ©es baseline
echo "Restoring baseline data..."
gunzip -c /var/lib/regression-tests/baseline_data.sql.gz | \
    mysql -h localhost -u test_user -ptest_password test_db

# ExÃ©cuter replay
echo "Running workload replay..."
maxscale-workload-replay \
    --input "$BASELINE_WORKLOAD" \
    --target "$TEST_DB" \
    --user test_user \
    --password test_password \
    --database test_db \
    --replay-speed 5.0 \
    --concurrency 20 \
    --compare-baseline "$BASELINE_RESULTS" \
    --report /tmp/regression_report_$(date +%Y%m%d_%H%M%S).html \
    --diff-output /tmp/regression_diff.json \
    --diff-tolerance 0.01 \
    --fail-on-error

# VÃ©rifier rÃ©sultat
if [ $? -eq 0 ]; then
    echo ""
    echo "âœ… REGRESSION TEST PASSED"
    echo "   No significant differences detected"
    exit 0
else
    echo ""
    echo "âŒ REGRESSION TEST FAILED"
    echo "   Significant differences detected, check report"
    
    # Envoyer alerte
    /usr/local/bin/send-alert.sh "Regression Test Failed" \
        "Check report: /tmp/regression_report_*.html"
    
    exit 1
fi
```

**Crontab pour tests nocturnes :**

```cron
# /etc/cron.d/regression-tests
# Tests de rÃ©gression quotidiens
0 2 * * * jenkins /usr/local/bin/regression-test.sh >> /var/log/regression-tests.log 2>&1
```

---

## Analyse de diffÃ©rences

### Types de diffÃ©rences

**CatÃ©gories de diffÃ©rences dÃ©tectÃ©es :**

```
1. RESULT DIFFERENCES (DiffÃ©rences de rÃ©sultats)
   â”œâ”€ Row count mismatch (nombre de lignes diffÃ©rent)
   â”œâ”€ Column value mismatch (valeurs diffÃ©rentes)
   â”œâ”€ Column type mismatch (types diffÃ©rents)
   â”œâ”€ Missing/Extra columns (colonnes manquantes/surplus)
   â””â”€ Row order differences (ordre diffÃ©rent, si diff_ignore_order=false)

2. PERFORMANCE DIFFERENCES (DiffÃ©rences de performance)
   â”œâ”€ Execution time delta (temps d'exÃ©cution)
   â”œâ”€ Rows examined delta (lignes examinÃ©es)
   â”œâ”€ Temporary tables usage (tables temporaires)
   â”œâ”€ Filesort usage (utilisation filesort)
   â””â”€ Index usage changes (changement d'index)

3. ERROR DIFFERENCES (DiffÃ©rences d'erreurs)
   â”œâ”€ Baseline success, Candidate error
   â”œâ”€ Baseline error, Candidate success
   â”œâ”€ Different error codes
   â””â”€ Different error messages

4. PLAN DIFFERENCES (DiffÃ©rences de plans d'exÃ©cution)
   â”œâ”€ Index selection changes
   â”œâ”€ Join order changes
   â”œâ”€ Join type changes (NESTED LOOP vs HASH JOIN)
   â””â”€ Subquery strategy changes
```

### Analyse approfondie avec EXPLAIN

**Script d'analyse dÃ©taillÃ©e :**

```python
#!/usr/bin/env python3
# /usr/local/bin/analyze-query-differences.py
# Analyse approfondie des diffÃ©rences de requÃªtes

import json
import mysql.connector
from tabulate import tabulate

def analyze_query_difference(query, baseline_db, candidate_db):
    """
    Analyser une requÃªte avec diffÃ©rence dÃ©tectÃ©e
    """
    print(f"\n{'='*80}")
    print(f"Query: {query[:100]}...")
    print(f"{'='*80}")
    
    # Connexions
    conn_baseline = mysql.connector.connect(**baseline_db)
    conn_candidate = mysql.connector.connect(**candidate_db)
    
    cursor_baseline = conn_baseline.cursor(dictionary=True)
    cursor_candidate = conn_candidate.cursor(dictionary=True)
    
    # EXPLAIN baseline
    print("\n--- EXPLAIN (Baseline) ---")
    cursor_baseline.execute(f"EXPLAIN {query}")
    explain_baseline = cursor_baseline.fetchall()
    print(tabulate(explain_baseline, headers="keys", tablefmt="grid"))
    
    # EXPLAIN candidate
    print("\n--- EXPLAIN (Candidate) ---")
    cursor_candidate.execute(f"EXPLAIN {query}")
    explain_candidate = cursor_candidate.fetchall()
    print(tabulate(explain_candidate, headers="keys", tablefmt="grid"))
    
    # Comparer mÃ©triques
    print("\n--- Performance Comparison ---")
    
    # ExÃ©cuter et mesurer baseline
    cursor_baseline.execute(f"SELECT BENCHMARK(1, ({query})) AS baseline_time")
    
    # ExÃ©cuter et mesurer candidate
    cursor_candidate.execute(f"SELECT BENCHMARK(1, ({query})) AS candidate_time")
    
    # SHOW PROFILE (si activÃ©)
    cursor_baseline.execute("SHOW PROFILES")
    profiles_baseline = cursor_baseline.fetchall()
    
    cursor_candidate.execute("SHOW PROFILES")
    profiles_candidate = cursor_candidate.fetchall()
    
    # Analyser diffÃ©rences
    analyze_explain_differences(explain_baseline, explain_candidate)
    
    # Recommendations
    print("\n--- Recommendations ---")
    generate_recommendations(explain_baseline, explain_candidate)
    
    cursor_baseline.close()
    cursor_candidate.close()
    conn_baseline.close()
    conn_candidate.close()

def analyze_explain_differences(baseline, candidate):
    """
    Analyser diffÃ©rences dans EXPLAIN
    """
    print("\nEXPLAIN Differences:")
    
    # Comparer type
    if baseline[0]['type'] != candidate[0]['type']:
        print(f"  - Join type changed: {baseline[0]['type']} â†’ {candidate[0]['type']}")
    
    # Comparer key (index utilisÃ©)
    if baseline[0].get('key') != candidate[0].get('key'):
        print(f"  - Index changed: {baseline[0].get('key')} â†’ {candidate[0].get('key')}")
    
    # Comparer rows (lignes examinÃ©es)
    if baseline[0].get('rows') != candidate[0].get('rows'):
        delta = ((candidate[0].get('rows', 0) / baseline[0].get('rows', 1)) - 1) * 100
        print(f"  - Rows examined changed: {baseline[0].get('rows')} â†’ {candidate[0].get('rows')} ({delta:+.1f}%)")
    
    # Comparer Extra
    if baseline[0].get('Extra') != candidate[0].get('Extra'):
        print(f"  - Extra info changed:")
        print(f"    Baseline: {baseline[0].get('Extra')}")
        print(f"    Candidate: {candidate[0].get('Extra')}")

def generate_recommendations(baseline, candidate):
    """
    GÃ©nÃ©rer recommandations basÃ©es sur diffÃ©rences
    """
    # VÃ©rifier si filesort ajoutÃ©
    if 'Using filesort' in candidate[0].get('Extra', '') and \
       'Using filesort' not in baseline[0].get('Extra', ''):
        print("  âš ï¸  Filesort introduced in candidate")
        print("     â†’ Consider adding index on ORDER BY columns")
    
    # VÃ©rifier si index non utilisÃ©
    if candidate[0].get('key') is None and baseline[0].get('key') is not None:
        print("  âš ï¸  Index not used in candidate")
        print(f"     â†’ Investigate why {baseline[0].get('key')} index ignored")
        print("     â†’ Check optimizer statistics with ANALYZE TABLE")
    
    # VÃ©rifier si full table scan
    if candidate[0].get('type') == 'ALL':
        print("  âš ï¸  Full table scan detected")
        print("     â†’ Add appropriate index")
        print("     â†’ Consider partitioning if table very large")

# Utilisation
if __name__ == '__main__':
    # Charger diffÃ©rences
    with open('/tmp/regression_diff.json') as f:
        differences = json.load(f)
    
    baseline_db_config = {
        'host': 'localhost',
        'port': 3308,
        'user': 'test_user',
        'password': 'password',
        'database': 'test_db'
    }
    
    candidate_db_config = {
        'host': 'localhost',
        'port': 3309,
        'user': 'test_user',
        'password': 'password',
        'database': 'test_db'
    }
    
    # Analyser chaque requÃªte avec diffÃ©rence significative
    for diff in differences['differences']:
        if diff['impact'] in ['MEDIUM', 'HIGH']:
            analyze_query_difference(
                diff['query'],
                baseline_db_config,
                candidate_db_config
            )
```

---

## Performance et optimisation

### Monitoring du replay

**MÃ©triques en temps rÃ©el :**

```bash
# ExÃ©cuter replay avec monitoring dÃ©taillÃ©
maxscale-workload-replay \
    --input workload.log \
    --target test-db:3306 \
    --user test_user \
    --password password \
    --replay-speed 1.0 \
    --concurrency 20 \
    --monitoring-interval 1s \
    --live-stats

# Output en temps rÃ©el:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Workload Replay - Live Statistics              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Progress:     [=========>          ] 45% (560,753/1,245,678)â”‚
â”‚ Elapsed:      54m 23s                                       â”‚
â”‚ Remaining:    ~66m 12s                                      â”‚
â”‚ Current QPS:  172 (target: 173)                             â”‚
â”‚ Avg latency:  14.2ms                                        â”‚
â”‚ P95 latency:  42.8ms                                        â”‚
â”‚ Errors:       5 (0.001%)                                    â”‚
â”‚ Connections:  20/20 active                                  â”‚
â”‚                                                             â”‚
â”‚ Query Type Distribution:                                    â”‚
â”‚   SELECT:  70% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         â”‚
â”‚   INSERT:  20% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        â”‚
â”‚   UPDATE:   8% â–ˆâ–ˆ                                           â”‚
â”‚   DELETE:   2% â–Œ                                            â”‚
â”‚                                                             â”‚
â”‚ Backend Response Time:                                      â”‚
â”‚   server1: 12.5ms â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              â”‚
â”‚   server2: 14.1ms â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            â”‚
â”‚   server3: 15.8ms â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimisation mÃ©moire

**Configuration pour gros workloads :**

```bash
# Workload trÃ¨s large (>10GB)
# Utiliser mode streaming pour Ã©viter OOM

maxscale-workload-replay \
    --input huge_workload.log.gz \
    --target test-db:3306 \
    --user test_user \
    --password password \
    --streaming-mode \
    --buffer-size 100MB \
    --replay-speed 5.0 \
    --concurrency 50

# Options:
# --streaming-mode: Ne charge pas tout en mÃ©moire
# --buffer-size: Buffer de lecture (dÃ©faut: 100MB)
# Permet de rejouer workloads de plusieurs TB
```

---

## âœ… Points clÃ©s Ã  retenir

- **Workload Replay** : FonctionnalitÃ© MaxScale 25.01 pour rejouer workloads capturÃ©s, validation upgrades/configs
- **Commande** : `maxscale-workload-replay --input --target --user --password`
- **Validation upgrades** : Capturer prod â†’ Rejouer sur test â†’ Comparer rÃ©sultats (Diff Router)
- **Diff Router** : Compare automatiquement rÃ©sultats entre 2 backends (baseline vs candidate)
- **Replay speed** : 0.1x (debug), 1.0x (rÃ©aliste), 10x (rapide), 0 (stress test maximum)
- **Concurrency** : 1-10 (sÃ©quentiel), 10-50 (rÃ©aliste), 50-500 (stress test)
- **Filtrage** : Par query type, user, database, durÃ©e, pÃ©riode temporelle
- **DiffÃ©rences** : 4 catÃ©gories (rÃ©sultats, performance, erreurs, plans exÃ©cution)
- **CI/CD** : IntÃ©gration GitLab CI, tests automatisÃ©s, fail on differences
- **Analyse** : EXPLAIN comparison, performance metrics, recommandations automatiques
- **Streaming mode** : Pour workloads >10GB, Ã©vite OOM
- **Rapport HTML** : Summary, comparaison performance, diffÃ©rences dÃ©taillÃ©es, recommandations

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Documentation officielle MaxScale
- [ğŸ†• Workload Replay](https://mariadb.com/docs/server/operations/workload-testing/replay/)
- [ğŸ†• Diff Router](https://mariadb.com/docs/server/architecture/components/maxscale/diff-router/)
- [ğŸ“– MaxScale 25.01 Features](https://mariadb.com/docs/release-notes/maxscale/25-01/)

### Guides techniques
- [Testing Database Upgrades](https://mariadb.com/resources/blog/testing-database-upgrades/)
- [Continuous Integration Best Practices](https://www.percona.com/blog/database-ci-cd-best-practices/)

### Outils
- [GitLab CI/CD](https://docs.gitlab.com/ee/ci/)
- [Docker Compose](https://docs.docker.com/compose/)
- [Python mysql-connector](https://dev.mysql.com/doc/connector-python/en/)

---

## â¡ï¸ Section suivante

**14.3 Split-brain et Quorum** : Comprendre et gÃ©rer le split-brain dans Galera Cluster, mÃ©canismes de quorum, rÃ©cupÃ©ration aprÃ¨s partition rÃ©seau, et stratÃ©gies de prÃ©vention avec configurations production-ready.

---


â­ï¸ [Diff Router](/14-haute-disponibilite/05.3-diff-router.md)
