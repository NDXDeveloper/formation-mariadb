ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 7. Moteurs de Stockage

> **Niveau** : AvancÃ©
> **DurÃ©e estimÃ©e** : 8-10 heures
> **PrÃ©requis** : Chapitres 1-6, connaissances solides en SQL, administration systÃ¨me

> **Public cible** : DBA, Architectes de bases de donnÃ©es, DevOps avancÃ©s

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de ce chapitre, vous serez capable de :
- Comprendre l'architecture Pluggable Storage Engine de MariaDB
- MaÃ®triser les caractÃ©ristiques et cas d'usage de chaque moteur (InnoDB, MyISAM, Aria, ColumnStore, S3, Vector/HNSW)
- Configurer et optimiser InnoDB pour la production (Buffer Pool, logs, paramÃ¨tres avancÃ©s)
- Choisir le moteur appropriÃ© selon les besoins mÃ©tier et techniques
- Effectuer des conversions entre moteurs en toute sÃ©curitÃ©
- Exploiter le nouveau moteur Vector/HNSW pour les cas d'usage IA

---

## Introduction

Les moteurs de stockage sont au cÅ“ur de l'architecture modulaire de MariaDB. Contrairement Ã  de nombreux SGBD qui imposent un seul moteur, MariaDB offre une **architecture pluggable** permettant d'utiliser diffÃ©rents moteurs selon les besoins spÃ©cifiques de chaque table.

### Pourquoi plusieurs moteurs ?

Chaque moteur de stockage est optimisÃ© pour des cas d'usage particuliers :
- **OLTP haute performance** : InnoDB avec transactions ACID
- **Analytique et data warehouse** : ColumnStore avec compression columnar
- **Archivage Ã  froid** : S3 pour stockage objet Ã©conomique
- **Recherche vectorielle IA** : Vector/HNSW pour les embeddings
- **Tables temporaires** : Memory pour performances extrÃªmes
- **CompatibilitÃ© legacy** : MyISAM et Aria

Cette flexibilitÃ© permet d'optimiser **chaque table individuellement** selon son profil d'accÃ¨s, son volume, et ses contraintes de cohÃ©rence.

---

## Architecture Pluggable Storage Engine

### Principe de fonctionnement

MariaDB implÃ©mente une architecture en couches sÃ©parant le **moteur SQL** (parser, optimizer, query executor) des **moteurs de stockage** (gestion physique des donnÃ©es).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Couche Application/Client          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Couche SQL (Server Layer)       â”‚
â”‚  - Parser SQL                           â”‚
â”‚  - Query Optimizer                      â”‚
â”‚  - Query Executor                       â”‚
â”‚  - Cache & Buffers                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Storage Engine API (Handler API)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ InnoDB   â”‚ Aria     â”‚ColumnStoreâ”‚ Vector  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interface Handler API

Tous les moteurs implÃ©mentent une interface commune qui expose des mÃ©thodes standardisÃ©es :

```cpp
// OpÃ©rations de base (simplifiÃ©es)
handler::open()       // Ouvrir une table
handler::close()      // Fermer une table
handler::write_row()  // InsÃ©rer un enregistrement
handler::update_row() // Mettre Ã  jour un enregistrement
handler::delete_row() // Supprimer un enregistrement
handler::rnd_next()   // Lecture sÃ©quentielle
handler::index_read() // Lecture via index
handler::start_stmt() // DÃ©but de transaction
handler::commit()     // Valider transaction
```

ğŸ’¡ **Avantage** : Le moteur SQL n'a pas besoin de connaÃ®tre les dÃ©tails d'implÃ©mentation de chaque moteur. Il suffit d'appeler les mÃ©thodes de l'API Handler.

### Consultation des moteurs disponibles

```sql
-- Lister tous les moteurs disponibles
SHOW ENGINES;

-- RÃ©sultat type
+--------------------+---------+------------+----------+---------+
| Engine             | Support | Comment    | Trans... | XA      |
+--------------------+---------+------------+----------+---------+
| InnoDB             | DEFAULT | ACID...    | YES      | YES     |
| Aria               | YES     | Crash-safe | NO       | NO      |
| MyISAM             | YES     | Non-trans  | NO       | NO      |
| MEMORY             | YES     | Hash/RAM   | NO       | NO      |
| CSV                | YES     | CSV files  | NO       | NO      |
| ColumnStore        | YES     | Columnar   | YES      | NO      |
| S3                 | YES     | AWS S3     | NO       | NO      |
+--------------------+---------+------------+----------+---------+

-- DÃ©tails sur un moteur spÃ©cifique
SHOW ENGINE InnoDB STATUS\G
```

### SpÃ©cification du moteur par table

```sql
-- Lors de la crÃ©ation
CREATE TABLE users (
    id INT PRIMARY KEY,
    name VARCHAR(100)
) ENGINE=InnoDB;

-- VÃ©rifier le moteur d'une table
SHOW CREATE TABLE users;

-- Consulter les moteurs utilisÃ©s
SELECT
    TABLE_NAME,
    ENGINE,
    TABLE_ROWS,
    DATA_LENGTH,
    INDEX_LENGTH
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'mydb';
```

âš ï¸ **Important** : Le moteur par dÃ©faut depuis MariaDB 10.2 est **InnoDB**. Il est fortement recommandÃ© de l'utiliser pour les nouvelles applications.

---

## Vue d'ensemble des moteurs principaux

### Tableau comparatif

| Moteur | Transactions | Foreign Keys | MVCC | Index Type | Cas d'usage | NouveautÃ© 11.8 |
|--------|--------------|--------------|------|------------|-------------|----------------|
| **InnoDB** | âœ… ACID | âœ… | âœ… | B-Tree | **OLTP**, production | Optimisations SSD |
| **MyISAM** | âŒ | âŒ | âŒ | B-Tree | Legacy, lecture seule | ğŸ”„ DÃ©prÃ©ciÃ© |
| **Aria** | âŒ | âŒ | âŒ | B-Tree | Tables systÃ¨me, crash-safe | - |
| **ColumnStore** | âœ… | âŒ | âŒ | Bitmap | **OLAP**, analytics | - |
| **S3** | âŒ | âŒ | âŒ | Read-only | **Archivage** froid | AmÃ©liorations perf |
| **Vector/HNSW** | âœ… | âœ… | âœ… | HNSW | **IA/RAG**, embeddings | ğŸ†• Nouveau |
| **Memory** | âŒ | âŒ | âŒ | Hash/B-Tree | Tables temporaires | - |
| **Spider** | âœ… | âœ… | âŒ | - | **Sharding** distribuÃ© | - |

### CritÃ¨res de sÃ©lection

#### 1. **Besoin de transactions ACID ?**
- **OUI** â†’ InnoDB, ColumnStore, Vector/HNSW
- **NON** â†’ MyISAM, Aria, S3, Memory

#### 2. **Type de charge de travail ?**
- **OLTP** (lecture/Ã©criture Ã©quilibrÃ©e, transactions courtes) â†’ **InnoDB**
- **OLAP** (analytics, agrÃ©gations massives) â†’ **ColumnStore**
- **Recherche vectorielle** (similaritÃ©, IA) â†’ **Vector/HNSW**
- **Archivage** (lectures rares, coÃ»t minimal) â†’ **S3**

#### 3. **Volume de donnÃ©es ?**
- **< 1 TB** â†’ InnoDB (excellent pour la plupart des cas)
- **> 1 TB, lectures intensives** â†’ ColumnStore
- **> 10 TB, donnÃ©es froides** â†’ S3

#### 4. **Contraintes de cohÃ©rence ?**
- **Foreign Keys requises** â†’ InnoDB ou Vector/HNSW
- **Pas de FK** â†’ Tous les autres moteurs

---

## InnoDB : Le moteur par dÃ©faut

InnoDB est le moteur **transactionnel** par excellence de MariaDB, optimisÃ© pour les charges OLTP avec des garanties ACID complÃ¨tes.

### CaractÃ©ristiques principales

#### âœ… Transactions ACID complÃ¨tes

```sql
START TRANSACTION;

UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;

-- Garanties ACID :
-- Atomicity : Les deux UPDATE ou aucun
-- Consistency : Contraintes respectÃ©es
-- Isolation : Autres transactions ne voient pas Ã©tat intermÃ©diaire
-- Durability : Persistance garantie aprÃ¨s COMMIT

COMMIT;
```

#### âœ… Row-level locking

InnoDB utilise des verrous au niveau **ligne** (et non table comme MyISAM), permettant une concurrence maximale :

```sql
-- Session 1
BEGIN;
UPDATE orders SET status = 'shipped' WHERE id = 100;
-- Seule la ligne id=100 est verrouillÃ©e

-- Session 2 (exÃ©cution simultanÃ©e)
UPDATE orders SET status = 'shipped' WHERE id = 200;
-- SuccÃ¨s immÃ©diat : ligne diffÃ©rente
```

#### âœ… Foreign Keys et intÃ©gritÃ© rÃ©fÃ©rentielle

```sql
CREATE TABLE orders (
    id INT PRIMARY KEY,
    user_id INT NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(id)
        ON DELETE CASCADE
        ON UPDATE CASCADE
) ENGINE=InnoDB;

-- IntÃ©gritÃ© garantie par le moteur
DELETE FROM users WHERE id = 1;
-- Supprime automatiquement les orders associÃ©es
```

#### âœ… Crash Recovery automatique

En cas de crash serveur, InnoDB utilise ses logs pour :
1. **Rejouer** les transactions validÃ©es non encore Ã©crites (redo log)
2. **Annuler** les transactions non validÃ©es (undo log)

```sql
-- AprÃ¨s un crash et redÃ©marrage
-- InnoDB affiche dans l'error log :
[Note] InnoDB: Starting crash recovery.
[Note] InnoDB: Last MySQL binlog file position 0 1234567
[Note] InnoDB: Recovery completed
```

### Architecture InnoDB en dÃ©tail

#### Buffer Pool : Le cache mÃ©moire central

Le **Buffer Pool** est la zone mÃ©moire oÃ¹ InnoDB met en cache les pages de donnÃ©es et d'index.

```sql
-- Configuration Buffer Pool (my.cnf)
[mysqld]
# RÃ¨gle gÃ©nÃ©rale : 70-80% de la RAM disponible
innodb_buffer_pool_size = 16G

# Instances multiples pour rÃ©duire contention (1 par 1GB, max 64)
innodb_buffer_pool_instances = 16

# PrÃ©chargement au dÃ©marrage (aprÃ¨s crash)
innodb_buffer_pool_load_at_startup = 1
innodb_buffer_pool_dump_at_shutdown = 1
```

**Fonctionnement :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Buffer Pool (RAM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Pages de donnÃ©es (16KB chacune)        â”‚      â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”            â”‚      â”‚
â”‚  â”‚   â”‚Pg 1â”‚ â”‚Pg 2â”‚ â”‚Pg 3â”‚ â”‚Pg Nâ”‚   ...      â”‚      â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜            â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Pages d'index                          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Adaptive Hash Index (AHI)              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†• Flush/Load
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Fichiers .ibd (disque)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Algorithme LRU (Least Recently Used) :**

InnoDB utilise une variante du LRU pour gÃ©rer les pages :
- **Young sublist** (37% du pool) : Pages rÃ©cemment accÃ©dÃ©es
- **Old sublist** (63% du pool) : Pages candidates Ã  l'Ã©viction

```sql
-- Monitoring du Buffer Pool
SHOW ENGINE InnoDB STATUS\G

-- Statistiques dÃ©taillÃ©es
SELECT
    POOL_ID,
    POOL_SIZE,
    FREE_BUFFERS,
    DATABASE_PAGES,
    OLD_DATABASE_PAGES,
    MODIFIED_DATABASE_PAGES,
    PENDING_READS,
    PENDING_DECOMPRESS
FROM information_schema.INNODB_BUFFER_POOL_STATS;

-- Hit ratio (objectif > 99%)
SELECT
    (1 - (Innodb_buffer_pool_reads / Innodb_buffer_pool_read_requests)) * 100
    AS buffer_pool_hit_ratio
FROM
    (SELECT VARIABLE_VALUE AS Innodb_buffer_pool_reads
     FROM information_schema.GLOBAL_STATUS
     WHERE VARIABLE_NAME = 'Innodb_buffer_pool_reads') AS reads,
    (SELECT VARIABLE_VALUE AS Innodb_buffer_pool_read_requests
     FROM information_schema.GLOBAL_STATUS
     WHERE VARIABLE_NAME = 'Innodb_buffer_pool_read_requests') AS requests;
```

ğŸ’¡ **Conseil** : Un hit ratio < 95% indique que le Buffer Pool est sous-dimensionnÃ© ou que le workload dÃ©passe la capacitÃ© mÃ©moire.

#### Redo Log : Garantie de durabilitÃ©

Le **Redo Log** (journal de transactions) enregistre **toutes les modifications** avant leur Ã©criture sur disque.

```sql
-- Configuration Redo Log (my.cnf)
[mysqld]
# Taille totale des fichiers redo log
# Plus grand = moins de checkpoints, mais recovery plus lente
innodb_log_file_size = 512M
innodb_log_files_in_group = 2

# Flush policy (balance performance/durabilitÃ©)
innodb_flush_log_at_trx_commit = 1
# 0 = flush toutes les secondes (risque de perte)
# 1 = flush Ã  chaque commit (sÃ»r, par dÃ©faut)
# 2 = flush en cache OS Ã  chaque commit (compromis)

# Taille du buffer en mÃ©moire
innodb_log_buffer_size = 16M
```

**Cycle de vie d'une transaction :**

```
1. BEGIN
2. UPDATE table SET column = value WHERE id = 1
   â†“
   Ã‰criture dans Redo Log Buffer (RAM)
   â†“
3. COMMIT
   â†“
   Flush Redo Log sur disque (fsync)
   â†“
   Transaction durable
   â†“
4. Ã‰criture asynchrone des pages modifiÃ©es (Buffer Pool â†’ Disque)
```

**Checkpoints :**

PÃ©riodiquement, InnoDB effectue un **checkpoint** :
- Ã‰crit les pages modifiÃ©es (dirty pages) sur disque
- Permet de libÃ©rer de l'espace dans le Redo Log
- RÃ©duit le temps de recovery

```sql
-- Forcer un checkpoint (rarement nÃ©cessaire)
SET GLOBAL innodb_fast_shutdown = 0;
SHUTDOWN;
```

âš ï¸ **Attention** : Ne jamais supprimer manuellement les fichiers `ib_logfile*` lorsque le serveur est arrÃªtÃ© sans avoir fait un shutdown propre.

#### Undo Log : Support des transactions et MVCC

Le **Undo Log** permet :
1. **Rollback** des transactions
2. **MVCC** (Multi-Version Concurrency Control) pour l'isolation

```sql
-- Configuration Undo Log
[mysqld]
# Emplacement des tablespaces undo (MariaDB 10.0+)
innodb_undo_directory = /var/lib/mysql/undo
innodb_undo_tablespaces = 2

# Purge automatique des anciennes versions
innodb_purge_threads = 4
innodb_max_purge_lag = 0
```

**MVCC en action :**

```sql
-- Transaction 1 (long running read)
START TRANSACTION;
SELECT balance FROM accounts WHERE id = 1;
-- Lit 1000â‚¬

-- Transaction 2 (en parallÃ¨le)
UPDATE accounts SET balance = 2000 WHERE id = 1;
COMMIT;

-- Transaction 1 (reprend)
SELECT balance FROM accounts WHERE id = 1;
-- Lit toujours 1000â‚¬ grÃ¢ce au Undo Log
-- (Isolation REPEATABLE READ)

COMMIT;
```

Le Undo Log conserve les **anciennes versions** des lignes pour permettre aux transactions en cours de lire des donnÃ©es cohÃ©rentes.

### Configuration avancÃ©e InnoDB

#### File-per-table vs System Tablespace

```sql
-- RecommandÃ© : un fichier .ibd par table
[mysqld]
innodb_file_per_table = 1

-- Avantages :
-- - OPTIMIZE TABLE libÃ¨re vraiment l'espace disque
-- - DROP TABLE plus rapide
-- - Facilite les backups/restaurations sÃ©lectives
```

```sql
-- VÃ©rifier l'emplacement des fichiers
SELECT
    TABLE_NAME,
    ENGINE,
    CREATE_OPTIONS
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'mydb'
  AND ENGINE = 'InnoDB';

-- Les fichiers .ibd sont dans /var/lib/mysql/mydb/
```

#### I/O et performances disque

```sql
[mysqld]
# Threads I/O pour lecture/Ã©criture
innodb_read_io_threads = 8
innodb_write_io_threads = 8

# CapacitÃ© I/O (IOPS) - ajuster selon disques
# HDD : 100-200, SSD : 2000-10000, NVMe : 10000+
innodb_io_capacity = 2000
innodb_io_capacity_max = 4000

# MÃ©thode de flush (Linux)
innodb_flush_method = O_DIRECT
# O_DIRECT : bypasse le cache OS (recommandÃ© SSD)
# fsync : utilise le cache OS
# O_DSYNC : sync aprÃ¨s chaque Ã©criture
```

ğŸ†• **MariaDB 11.8** : L'optimiseur de coÃ»t prend dÃ©sormais mieux en compte les caractÃ©ristiques des SSD modernes pour ajuster les plans d'exÃ©cution.

#### Gestion de la concurrence

```sql
[mysqld]
# Nombre de threads pouvant entrer dans InnoDB simultanÃ©ment
# Formule : 2 Ã— (nb_CPU + nb_disques)
innodb_thread_concurrency = 0  # 0 = illimitÃ© (recommandÃ©)

# DurÃ©e d'attente avant de dormir si concurrency atteinte
innodb_thread_sleep_delay = 10000  # microsecondes

# Nombre de spin loops avant de bloquer un thread
innodb_sync_spin_loops = 30
```

#### Online DDL et ALTER TABLE

ğŸ†• **MariaDB 11.8** : `innodb_alter_copy_bulk` amÃ©liore les performances de reconstruction d'index.

```sql
-- Configuration
SET GLOBAL innodb_alter_copy_bulk = ON;

-- ALTER TABLE avec algorithme online
ALTER TABLE large_table
    ADD INDEX idx_email (email),
    ALGORITHM=INPLACE,  -- Sans copie de table
    LOCK=NONE;          -- Pas de lock lecture/Ã©criture

-- VÃ©rifier la progression
SELECT * FROM information_schema.INNODB_TRX;
```

#### Compression de donnÃ©es

```sql
-- Compression au niveau page (ROW_FORMAT)
CREATE TABLE compressed_data (
    id INT PRIMARY KEY,
    data TEXT
) ENGINE=InnoDB
  ROW_FORMAT=COMPRESSED
  KEY_BLOCK_SIZE=8;  -- 1, 2, 4, 8, 16 KB

-- VÃ©rifier la compression
SELECT
    TABLE_NAME,
    ROW_FORMAT,
    CREATE_OPTIONS,
    (DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 AS size_mb
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'mydb';
```

ğŸ’¡ **Conseil** : La compression rÃ©duit l'I/O mais augmente la charge CPU. Ã€ utiliser pour des donnÃ©es peu modifiÃ©es.

---

## MyISAM : Le moteur legacy

### CaractÃ©ristiques

MyISAM Ã©tait le moteur par dÃ©faut avant MariaDB 10.2. Il est dÃ©sormais **dÃ©prÃ©ciÃ©** et ne devrait Ãªtre utilisÃ© que pour :
- **CompatibilitÃ©** avec anciens systÃ¨mes
- **Tables en lecture seule** (sans Ã©criture)
- **Full-text search** legacy (InnoDB supporte FTS depuis 10.0)

#### âŒ Limitations majeures

- **Pas de transactions**
- **Pas de Foreign Keys**
- **Table-level locking** (une seule Ã©criture Ã  la fois)
- **Pas de crash recovery** automatique
- **Corruption possible** aprÃ¨s crash

```sql
-- Exemple MyISAM (Ã  Ã©viter)
CREATE TABLE legacy_data (
    id INT PRIMARY KEY,
    content TEXT,
    INDEX(content(100))
) ENGINE=MyISAM;

-- Lock complet de la table Ã  chaque Ã©criture
INSERT INTO legacy_data VALUES (1, 'data');
-- Toute la table est verrouillÃ©e !
```

### Quand utiliser MyISAM (rarement)

1. **Tables temporaires** en lecture seule
2. **Export/Import** rapide (pas de transactions = moins d'overhead)
3. **Logs** oÃ¹ l'ordre strict n'importe pas

ğŸ”„ **Recommandation** : Migrer vers InnoDB ou Aria pour les nouveaux projets.

---

## Aria : Le successeur crash-safe de MyISAM

### CaractÃ©ristiques

Aria est dÃ©veloppÃ© par MariaDB et utilisÃ© pour les **tables systÃ¨me internes**. Il offre :

- âœ… **Crash recovery** (contrairement Ã  MyISAM)
- âœ… **Checksum automatique** des donnÃ©es
- âœ… Meilleure **gestion du cache**
- âŒ Pas de transactions ACID
- âŒ Pas de Foreign Keys

```sql
-- Configuration Aria
[mysqld]
aria_pagecache_buffer_size = 128M  # Cache pour Aria
aria_log_file_size = 1G
aria_checkpoint_interval = 30      # Secondes

-- Utilisation
CREATE TABLE system_config (
    param VARCHAR(50) PRIMARY KEY,
    value TEXT
) ENGINE=Aria;
```

### Cas d'usage

- **Tables systÃ¨me** MariaDB (mysql.*)
- **Tables temporaires** (meilleures que MyISAM)
- **Charges mixtes lecture/Ã©criture** sans besoin de transactions

ğŸ’¡ **Note** : Aria est utilisÃ© automatiquement pour les tables systÃ¨me comme `mysql.user`, `mysql.db`, etc.

---

## ColumnStore : Analytics et OLAP

### Principe columnar

Contrairement aux moteurs row-based (InnoDB), ColumnStore stocke les donnÃ©es **par colonne** :

```
Row-based (InnoDB) :
[id=1, name='Alice', age=30] [id=2, name='Bob', age=25] ...

Columnar (ColumnStore) :
Column 'id':   [1, 2, 3, ...]
Column 'name': ['Alice', 'Bob', 'Charlie', ...]
Column 'age':  [30, 25, 35, ...]
```

#### âœ… Avantages pour l'analytique

1. **Compression massive** : colonnes homogÃ¨nes compressent mieux
2. **I/O rÃ©duit** : lecture uniquement des colonnes nÃ©cessaires
3. **AgrÃ©gations rapides** : CPU optimisÃ© pour opÃ©rations vectorielles

```sql
-- CrÃ©ation d'une table ColumnStore
CREATE TABLE sales_analytics (
    date DATE,
    product_id INT,
    region VARCHAR(50),
    revenue DECIMAL(10,2),
    quantity INT
) ENGINE=ColumnStore;

-- RequÃªte analytique optimale
SELECT
    region,
    SUM(revenue) AS total_revenue,
    AVG(quantity) AS avg_quantity
FROM sales_analytics
WHERE date >= '2025-01-01'
GROUP BY region;
-- ColumnStore lit uniquement region, revenue, quantity, date
-- InnoDB devrait lire toutes les colonnes
```

### Configuration et gestion

```sql
-- Installation (si non incluse)
INSTALL SONAME 'ha_columnstore';

-- Monitoring
SELECT * FROM information_schema.COLUMNSTORE_TABLES;
SELECT * FROM information_schema.COLUMNSTORE_COLUMNS;

-- Maintenance
-- ColumnStore n'a pas besoin d'OPTIMIZE TABLE
-- Compression automatique en arriÃ¨re-plan
```

âš ï¸ **Limitations** :
- Pas de Foreign Keys
- Pas d'index secondaires (scan complet optimisÃ©)
- Mises Ã  jour lentes (optimisÃ© pour lectures)

### Cas d'usage typiques

- **Data Warehouse**
- **Business Intelligence** (reporting, dashboards)
- **Log analytics** (Clickhouse-like)
- **IoT time-series data**

ğŸ’¡ **Conseil** : Utiliser ColumnStore pour tables > 10 millions de lignes avec agrÃ©gations frÃ©quentes.

---

## S3 : Stockage objet et archivage

ğŸ†• **AmÃ©liorations 11.8** : Performances accrues pour les requÃªtes sur S3.

### Principe

Le moteur S3 permet de stocker des donnÃ©es MariaDB sur **AWS S3** ou **MinIO** (S3-compatible). IdÃ©al pour :
- **Archivage de donnÃ©es froides**
- **RÃ©duction des coÃ»ts** (stockage objet < SSD)
- **Compliance** (donnÃ©es immuables)

```sql
-- Configuration S3 (my.cnf)
[mysqld]
s3_access_key = 'YOUR_ACCESS_KEY'
s3_secret_key = 'YOUR_SECRET_KEY'
s3_region = 'us-east-1'
s3_bucket = 'mariadb-archive'
s3_host_name = 's3.amazonaws.com'  -- ou MinIO endpoint

-- CrÃ©ation d'une table S3
CREATE TABLE archived_orders (
    id INT,
    order_date DATE,
    customer_id INT,
    amount DECIMAL(10,2)
) ENGINE=S3;

-- Ou migration depuis InnoDB
ALTER TABLE old_orders ENGINE=S3;
```

### CaractÃ©ristiques

- âœ… **Read-only** aprÃ¨s Ã©criture initiale
- âœ… **Compression automatique**
- âœ… **CoÃ»t stockage minimal**
- âŒ **Latence Ã©levÃ©e** (rÃ©seau S3)
- âŒ **Pas de transactions**
- âŒ **Pas de mises Ã  jour** (immutable)

```sql
-- RequÃªtes SELECT normales
SELECT * FROM archived_orders WHERE order_date = '2024-01-01';

-- Pas d'UPDATE/DELETE possible
UPDATE archived_orders SET amount = 100;
-- ERROR: Table is read-only

-- Pour modifier : recrÃ©er la table
CREATE TABLE temp_orders ENGINE=InnoDB
    SELECT * FROM archived_orders;
-- Modifier temp_orders
ALTER TABLE temp_orders ENGINE=S3;
DROP TABLE archived_orders;
RENAME TABLE temp_orders TO archived_orders;
```

### Cas d'usage

- **Logs anciens** (> 1 an)
- **DonnÃ©es de conformitÃ©** (audit trails)
- **Snapshots historiques**
- **Cold data** rarement accÃ©dÃ©

ğŸ’¡ **Conseil** : Partitionner par date et archiver les partitions anciennes en S3.

```sql
-- Exemple avec partitionnement
CREATE TABLE orders (
    id INT,
    order_date DATE,
    data TEXT
) ENGINE=InnoDB
PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2023 VALUES LESS THAN (2024) ENGINE=S3,
    PARTITION p2024 VALUES LESS THAN (2025) ENGINE=InnoDB,
    PARTITION p2025 VALUES LESS THAN (2026) ENGINE=InnoDB,
    PARTITION pmax VALUES LESS THAN MAXVALUE ENGINE=InnoDB
);
```

---

## Vector/HNSW : Recherche vectorielle pour l'IA

ğŸ†• **NouveautÃ© majeure MariaDB 11.8** : Support natif des embeddings et recherche vectorielle.

### Introduction

Avec l'essor de l'IA gÃ©nÃ©rative et des LLMs (Large Language Models), le besoin de stocker et rechercher des **vecteurs d'embeddings** est devenu crucial pour :
- **RAG (Retrieval-Augmented Generation)**
- **Recherche sÃ©mantique**
- **SystÃ¨mes de recommandation**
- **DÃ©tection d'anomalies**

MariaDB 11.8 introduit :
- Type de donnÃ©es **VECTOR**
- Index **HNSW** (Hierarchical Navigable Small Worlds)
- Fonctions de distance vectorielle
- Optimisations **SIMD** (AVX2, AVX512, ARM NEON)

### Type de donnÃ©es VECTOR

```sql
-- CrÃ©ation d'une table avec embeddings
CREATE TABLE documents (
    id INT PRIMARY KEY AUTO_INCREMENT,
    title VARCHAR(200),
    content TEXT,
    -- Embedding OpenAI text-embedding-3-small (1536 dimensions)
    embedding VECTOR(1536) NOT NULL
) ENGINE=InnoDB;

-- Insertion avec embedding
INSERT INTO documents (title, content, embedding) VALUES (
    'Guide MariaDB',
    'MariaDB est un SGBD relationnel...',
    VEC_FromText('[0.123, -0.456, 0.789, ...]')  -- 1536 valeurs
);
```

### Index HNSW pour recherche rapide

HNSW est un algorithme de **Approximate Nearest Neighbor** (ANN) qui permet des recherches vectorielles en temps logarithmique.

```sql
-- CrÃ©ation d'un index HNSW
CREATE INDEX idx_embedding ON documents(embedding)
    USING HNSW
    WITH (
        M = 16,              -- Nombre de connexions par nÅ“ud (8-48)
        ef_construction = 200 -- Effort Ã  la construction (100-500)
    );

-- Configuration runtime
SET SESSION hnsw.ef_search = 100;  -- PrÃ©cision recherche (50-200)
```

**ParamÃ¨tres clÃ©s :**
- **M** : Plus grand = meilleure prÃ©cision, index plus volumineux
- **ef_construction** : Plus grand = construction plus lente, meilleure qualitÃ©
- **ef_search** : Plus grand = recherche plus lente, meilleure prÃ©cision

### Fonctions de distance

```sql
-- Distance euclidienne (L2)
SELECT
    id,
    title,
    VEC_DISTANCE_EUCLIDEAN(embedding,
        VEC_FromText('[0.1, 0.2, ...]')) AS distance
FROM documents
ORDER BY distance
LIMIT 10;

-- Distance cosinus (similitude angulaire)
SELECT
    id,
    title,
    VEC_DISTANCE_COSINE(embedding,
        VEC_FromText('[0.1, 0.2, ...]')) AS similarity
FROM documents
ORDER BY similarity
LIMIT 10;

-- Distance Manhattan (L1)
SELECT
    id,
    title,
    VEC_DISTANCE_MANHATTAN(embedding, query_vector) AS distance
FROM documents
ORDER BY distance;
```

ğŸ’¡ **Conseil** : Utiliser la **distance cosinus** pour les embeddings normalisÃ©s (comme ceux d'OpenAI).

### Optimisations SIMD

ğŸ†• **MariaDB 11.8** inclut des optimisations SIMD pour accÃ©lÃ©rer les calculs vectoriels :

- **AVX2** : Intel/AMD moderne (jusqu'Ã  8Ã— plus rapide)
- **AVX512** : Intel Xeon rÃ©cent (jusqu'Ã  16Ã— plus rapide)
- **ARM NEON** : ARM64 (Graviton, Apple Silicon)
- **IBM Power10** : POWER10 VSX

```sql
-- VÃ©rifier le support SIMD
SHOW VARIABLES LIKE 'have_simd%';

-- RÃ©sultat type
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| have_simd_avx2   | YES   |
| have_simd_avx512 | NO    |
| have_simd_neon   | NO    |
+------------------+-------+
```

### Cas d'usage IA/RAG

#### 1. **Recherche sÃ©mantique**

```sql
-- Application : moteur de recherche documentaire
-- 1. L'utilisateur saisit une requÃªte
-- 2. On gÃ©nÃ¨re l'embedding via API (ex: OpenAI)
-- 3. On recherche les documents similaires

SELECT
    id,
    title,
    content,
    VEC_DISTANCE_COSINE(embedding, :query_embedding) AS score
FROM documents
WHERE VEC_DISTANCE_COSINE(embedding, :query_embedding) < 0.3
ORDER BY score
LIMIT 5;
```

#### 2. **RAG (Retrieval-Augmented Generation)**

```sql
-- SchÃ©ma type pour chatbot RAG
CREATE TABLE knowledge_base (
    id INT PRIMARY KEY AUTO_INCREMENT,
    source VARCHAR(200),         -- Origine du contenu
    chunk TEXT,                  -- Fragment de texte (200-500 tokens)
    embedding VECTOR(1536),      -- Embedding OpenAI
    metadata JSON,               -- MÃ©tadonnÃ©es (date, auteur, etc.)
    INDEX idx_emb(embedding) USING HNSW
) ENGINE=InnoDB;

-- Pipeline RAG :
-- 1. Recherche des chunks pertinents
-- 2. Injection dans le prompt LLM
-- 3. GÃ©nÃ©ration de la rÃ©ponse
```

#### 3. **Recherche d'images par similaritÃ©**

```sql
CREATE TABLE images (
    id INT PRIMARY KEY,
    filename VARCHAR(255),
    embedding VECTOR(512),  -- CLIP embeddings
    INDEX idx_img(embedding) USING HNSW
) ENGINE=InnoDB;

-- Recherche d'images similaires
SELECT id, filename
FROM images
ORDER BY VEC_DISTANCE_COSINE(embedding, :query_image_embedding)
LIMIT 20;
```

### IntÃ©gration avec LLMs

```python
# Exemple Python avec OpenAI
import openai
import mysql.connector

# GÃ©nÃ©rer embedding
response = openai.Embedding.create(
    input="MariaDB est un SGBD relationnel",
    model="text-embedding-3-small"
)
embedding = response['data'][0]['embedding']

# Stocker dans MariaDB
conn = mysql.connector.connect(...)
cursor = conn.cursor()
cursor.execute(
    "INSERT INTO documents (title, embedding) VALUES (%s, VEC_FromText(%s))",
    ("Title", str(embedding))
)
conn.commit()
```

ğŸ’¡ **Conseil** : Normaliser les embeddings avant stockage pour optimiser la distance cosinus.

---

## Conversion entre moteurs

### MÃ©thode ALTER TABLE

```sql
-- Conversion simple
ALTER TABLE my_table ENGINE=InnoDB;

-- Avec options
ALTER TABLE my_table
    ENGINE=InnoDB,
    ROW_FORMAT=DYNAMIC;

-- VÃ©rifier la progression (sessions parallÃ¨les)
SHOW PROCESSLIST;
SELECT * FROM information_schema.INNODB_TRX;
```

âš ï¸ **Attention** : `ALTER TABLE ENGINE` effectue une **copie complÃ¨te** de la table. Pour les grandes tables (> 100 GB), privilÃ©gier d'autres mÃ©thodes.

### Migration progressive avec partitionnement

```sql
-- 1. CrÃ©er une table partitionnÃ©e mixte
CREATE TABLE orders_new (
    id INT,
    order_date DATE,
    data TEXT
) PARTITION BY RANGE (YEAR(order_date)) (
    PARTITION p2022 VALUES LESS THAN (2023) ENGINE=S3,
    PARTITION p2023 VALUES LESS THAN (2024) ENGINE=Aria,
    PARTITION p2024 VALUES LESS THAN (2025) ENGINE=InnoDB,
    PARTITION p2025 VALUES LESS THAN (2026) ENGINE=InnoDB,
    PARTITION pmax VALUES LESS THAN MAXVALUE ENGINE=InnoDB
);

-- 2. Copier les donnÃ©es
INSERT INTO orders_new SELECT * FROM orders_old;

-- 3. Swap atomique
RENAME TABLE
    orders_old TO orders_backup,
    orders_new TO orders;
```

### Online Schema Change avec gh-ost

Pour les trÃ¨s grandes tables en production, utiliser **gh-ost** :

```bash
# Installation gh-ost
wget https://github.com/github/gh-ost/releases/download/v1.1.5/gh-ost_linux_amd64
chmod +x gh-ost_linux_amd64

# Conversion sans downtime
./gh-ost \
    --host=localhost \
    --user=admin \
    --password=secret \
    --database=mydb \
    --table=huge_table \
    --alter="ENGINE=InnoDB ROW_FORMAT=DYNAMIC" \
    --execute \
    --allow-on-master \
    --cut-over=default
```

### Migration MyISAM â†’ InnoDB : Checklist

1. **VÃ©rifier les dÃ©pendances**
```sql
-- Tables avec Foreign Keys (InnoDB uniquement)
SELECT
    TABLE_NAME,
    CONSTRAINT_NAME,
    REFERENCED_TABLE_NAME
FROM information_schema.KEY_COLUMN_USAGE
WHERE TABLE_SCHEMA = 'mydb'
  AND REFERENCED_TABLE_NAME IS NOT NULL;
```

2. **Analyser l'espace disque**
```sql
-- InnoDB utilise plus d'espace (index + undo log)
SELECT
    TABLE_NAME,
    ENGINE,
    ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS size_mb
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'mydb'
  AND ENGINE = 'MyISAM';
```

3. **Tester sur une rÃ©plique**
```sql
-- Sur une rÃ©plique secondaire
ALTER TABLE test_table ENGINE=InnoDB;
-- Valider les performances
-- Puis basculer sur le master
```

4. **Convertir par lots**
```bash
# Script de conversion progressive
for table in $(mysql -Nse "SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA='mydb' AND ENGINE='MyISAM'"); do
    echo "Converting $table..."
    mysql mydb -e "ALTER TABLE $table ENGINE=InnoDB;"
done
```

### CritÃ¨res de dÃ©cision pour la conversion

| Depuis | Vers | Quand ? | MÃ©thode |
|--------|------|---------|---------|
| MyISAM | InnoDB | **Toujours** (sauf legacy read-only) | ALTER TABLE |
| MyISAM | Aria | Tables systÃ¨me, temporaires | ALTER TABLE |
| InnoDB | ColumnStore | Analytics, agrÃ©gations (> 10M rows) | CREATE TABLE AS SELECT |
| InnoDB | S3 | Archivage donnÃ©es froides (> 1 an) | ALTER TABLE |
| InnoDB | Vector/HNSW | Ajout recherche vectorielle | ADD COLUMN + INDEX |

---

## Moteurs spÃ©cialisÃ©s

### Memory : Tables en RAM

```sql
CREATE TABLE session_data (
    session_id VARCHAR(64) PRIMARY KEY,
    user_id INT,
    data TEXT,
    expires_at TIMESTAMP
) ENGINE=Memory;

-- âŒ DonnÃ©es volatiles (perdues au restart)
-- âœ… Performance extrÃªme (RAM)
-- âœ… IdÃ©al pour caches applicatifs temporaires
```

### Archive : Compression maximale

```sql
CREATE TABLE audit_logs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    timestamp TIMESTAMP,
    action VARCHAR(100),
    details TEXT
) ENGINE=Archive;

-- âœ… Compression jusqu'Ã  75%
-- âŒ INSERT only (pas d'UPDATE/DELETE)
-- âœ… IdÃ©al pour logs append-only
```

### Spider : Sharding distribuÃ©

```sql
-- NÅ“ud Spider (proxy)
CREATE TABLE distributed_users (
    id INT PRIMARY KEY,
    name VARCHAR(100)
) ENGINE=Spider
COMMENT='wrapper "mysql",
         srv "shard1 shard2 shard3",
         table "users"'
PARTITION BY KEY(id) PARTITIONS 3;

-- âœ… Sharding transparent
-- âœ… AgrÃ©gations cross-shard
-- âŒ ComplexitÃ© opÃ©rationnelle Ã©levÃ©e
```

### CONNECT : AccÃ¨s donnÃ©es externes

```sql
-- AccÃ¨s CSV
CREATE TABLE external_csv (
    col1 INT,
    col2 VARCHAR(50)
) ENGINE=CONNECT
TABLE_TYPE=CSV
FILE_NAME='/data/file.csv'
SEP_CHAR=','
HEADER=1;

-- AccÃ¨s autre SGBD (ODBC)
CREATE TABLE external_oracle (
    id INT,
    name VARCHAR(100)
) ENGINE=CONNECT
TABLE_TYPE=ODBC
TABNAME='REMOTE_TABLE'
CONNECTION='DSN=OracleDB;UID=user;PWD=pass';
```

---

## âœ… Points clÃ©s Ã  retenir

1. **Architecture Pluggable Storage Engine** : MariaDB permet de choisir un moteur diffÃ©rent par table selon les besoins.

2. **InnoDB est le choix par dÃ©faut** pour 95% des cas d'usage (OLTP, production, transactions ACID).

3. **Buffer Pool** : Zone mÃ©moire critique d'InnoDB Ã  dimensionner Ã  70-80% de la RAM disponible.

4. **Redo/Undo Logs** : Garantissent la durabilitÃ© (redo) et l'isolation (undo) des transactions.

5. **ColumnStore** : Moteur columnar idÃ©al pour l'analytique (OLAP) et les agrÃ©gations massives sur grandes tables.

6. **S3** : Permet l'archivage Ã©conomique de donnÃ©es froides sur stockage objet (AWS S3, MinIO).

7. ğŸ†• **Vector/HNSW** : NouveautÃ© 11.8 majeure pour la recherche vectorielle et les cas d'usage IA/RAG.

8. **Conversion entre moteurs** : Possible via `ALTER TABLE ENGINE`, mais nÃ©cessite une copie complÃ¨te pour les grandes tables.

9. **MyISAM est dÃ©prÃ©ciÃ©** : Migrer vers InnoDB ou Aria pour bÃ©nÃ©ficier du crash recovery et des transactions.

10. **Choix du moteur** : BasÃ© sur les contraintes (transactions, FK, volume, type de workload, coÃ»t stockage).

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Documentation officielle MariaDB

- [ğŸ“– Storage Engines Overview](https://mariadb.com/kb/en/storage-engines/)
- [ğŸ“– InnoDB Storage Engine](https://mariadb.com/kb/en/innodb/)
- [ğŸ“– ColumnStore](https://mariadb.com/kb/en/columnstore/)
- [ğŸ“– S3 Storage Engine](https://mariadb.com/kb/en/s3-storage-engine/)
- [ğŸ“– MariaDB Vector](https://mariadb.com/kb/en/vector-overview/) ğŸ†•
- [ğŸ“– HNSW Index](https://mariadb.com/kb/en/hnsw-index/) ğŸ†•
- [ğŸ“– Storage Engine API](https://mariadb.com/kb/en/storage-engine-api/)

### Articles techniques

- [InnoDB Buffer Pool Optimization](https://www.percona.com/blog/innodb-buffer-pool-optimization/)
- [Understanding MVCC in InnoDB](https://blog.jcole.us/innodb/)
- [Vector Search with MariaDB 11.8](https://mariadb.org/vector-search-rag/) ğŸ†•
- [HNSW Algorithm Explained](https://arxiv.org/abs/1603.09320)

### Outils recommandÃ©s

- **gh-ost** : [GitHub](https://github.com/github/gh-ost) - Online schema change
- **pt-online-schema-change** : Percona Toolkit
- **mysqltuner** : Script d'audit de configuration

---

## â¡ï¸ Section suivante

**[7.1 Vue d'ensemble : Architecture Pluggable Storage Engine](/07-moteurs-de-stockage/01-vue-ensemble-architecture.md)** : DÃ©tails techniques sur l'interface Handler API, le cycle de vie d'une requÃªte Ã  travers les moteurs, et l'implÃ©mentation d'un moteur custom.

Puis nous approfondirons chaque moteur dans les sections suivantes :
- **7.2** : InnoDB en profondeur
- **7.3-7.4** : MyISAM et Aria
- **7.5** : ColumnStore et analytics
- **7.6** : S3 et archivage cloud
- **7.7** : Vector/HNSW pour l'IA ğŸ†•

---

**ğŸ“Œ MÃ©mo DBA** : Pour 95% des tables, utilisez InnoDB. Pour l'analytique, ColumnStore. Pour l'IA, Vector/HNSW. Le reste est pour des cas trÃ¨s spÃ©cifiques.

â­ï¸ [Vue d'ensemble : Architecture Pluggable Storage Engine](/07-moteurs-de-stockage/01-vue-ensemble-architecture.md)
