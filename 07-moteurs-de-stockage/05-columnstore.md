üîù Retour au [Sommaire](/SOMMAIRE.md)

# 7.5 ColumnStore : Analytique et OLAP

> **Niveau** : Avanc√©
> **Dur√©e estim√©e** : 3-4 heures
> **Pr√©requis** : Sections 7.1-7.2 (Architecture, InnoDB), concepts data warehousing et OLAP

> **Public cible** : DBA, Architectes data, Data Engineers, Analystes BI

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre l'architecture columnar et ses avantages pour l'analytique
- Ma√Ætriser le d√©ploiement et la configuration de ColumnStore
- Optimiser les requ√™tes OLAP pour tirer parti du stockage columnar
- Concevoir des sch√©mas de data warehouse avec ColumnStore
- Int√©grer ColumnStore avec InnoDB dans une architecture hybride OLTP/OLAP
- Identifier les cas d'usage appropri√©s et les limitations
- Configurer le MPP (Massively Parallel Processing) multi-n≈ìuds
- Monitorer et optimiser les performances ColumnStore

---

## Introduction

**MariaDB ColumnStore** est un moteur de stockage **columnar** (orient√© colonnes) con√ßu sp√©cifiquement pour les charges de travail **OLAP** (Online Analytical Processing) et le **data warehousing**. Il a √©t√© d√©velopp√© √† partir de la technologie InfiniDB, acquise par MariaDB en 2016.

### OLTP vs OLAP : Paradigmes oppos√©s

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OLTP (InnoDB)                           ‚îÇ
‚îÇ  ‚Ä¢ Transactions courtes                                    ‚îÇ
‚îÇ  ‚Ä¢ Lectures/√©critures de quelques lignes                   ‚îÇ
‚îÇ  ‚Ä¢ Forte concurrence                                       ‚îÇ
‚îÇ  ‚Ä¢ Latence faible (ms)                                     ‚îÇ
‚îÇ  ‚Ä¢ Exemple : SELECT * FROM users WHERE id = 42             ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Stockage ROW-BASED (orient√© lignes) :                     ‚îÇ
‚îÇ  [Row1: id=1, name='Alice', age=30, city='Paris']          ‚îÇ
‚îÇ  [Row2: id=2, name='Bob', age=25, city='Lyon']             ‚îÇ
‚îÇ  [Row3: id=3, name='Charlie', age=35, city='Paris']        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  OLAP (ColumnStore)                        ‚îÇ
‚îÇ  ‚Ä¢ Requ√™tes analytiques longues                            ‚îÇ
‚îÇ  ‚Ä¢ Scans de millions/milliards de lignes                   ‚îÇ
‚îÇ  ‚Ä¢ Agr√©gations (SUM, AVG, COUNT)                           ‚îÇ
‚îÇ  ‚Ä¢ Throughput √©lev√© (pas latence)                          ‚îÇ
‚îÇ  ‚Ä¢ Exemple : SELECT city, AVG(age)                         ‚îÇ
‚îÇ             FROM users GROUP BY city                       ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Stockage COLUMNAR (orient√© colonnes) :                    ‚îÇ
‚îÇ  Column 'id':     [1, 2, 3, ...]                           ‚îÇ
‚îÇ  Column 'name':   ['Alice', 'Bob', 'Charlie', ...]         ‚îÇ
‚îÇ  Column 'age':    [30, 25, 35, ...]                        ‚îÇ
‚îÇ  Column 'city':   ['Paris', 'Lyon', 'Paris', ...]          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pourquoi le stockage columnar pour l'analytique ?

**Probl√®me avec le stockage row-based** :

```sql
-- Requ√™te analytique typique
SELECT
    region,
    SUM(revenue) AS total_revenue,
    AVG(quantity) AS avg_quantity
FROM sales  -- 1 milliard de lignes
WHERE date >= '2024-01-01'
GROUP BY region;

-- Avec stockage row-based (InnoDB) :
-- ‚Ä¢ Lit TOUTES les colonnes de TOUTES les lignes
-- ‚Ä¢ M√™me si on n'utilise que 3 colonnes (region, revenue, quantity)
-- ‚Ä¢ Lecture de 100+ colonnes inutiles
-- ‚Ä¢ I/O massif, performances d√©grad√©es
```

**Solution avec stockage columnar** :

```sql
-- M√™me requ√™te avec ColumnStore :
-- ‚Ä¢ Lit UNIQUEMENT les colonnes n√©cessaires :
--   - date (filtrage WHERE)
--   - region (GROUP BY)
--   - revenue (SUM)
--   - quantity (AVG)
-- ‚Ä¢ Ignore les 100+ autres colonnes
-- ‚Ä¢ I/O r√©duit de 95%
-- ‚Ä¢ Compression tr√®s efficace (colonnes homog√®nes)
-- ‚Ä¢ Performance 10-100√ó sup√©rieure
```

**Comparaison visuelle** :

```
Table avec 10 colonnes, requ√™te sur 2 colonnes :

Row-based (InnoDB) :
Disque ‚Üí [Row1: C1|C2|C3|C4|C5|C6|C7|C8|C9|C10]
         [Row2: C1|C2|C3|C4|C5|C6|C7|C8|C9|C10]
         [Row3: C1|C2|C3|C4|C5|C6|C7|C8|C9|C10]
         ‚Üí Lit 100% des donn√©es pour utiliser 20%

Columnar (ColumnStore) :
Disque ‚Üí [C1: val1, val2, val3, ...]
         [C2: val1, val2, val3, ...]  ‚Üê Lit uniquement C1 et C2
         [C3: ...] ‚Üê Ignor√©
         [C4: ...] ‚Üê Ignor√©
         ...
         ‚Üí Lit 20% des donn√©es (10√ó moins d'I/O)
```

---

## Architecture de ColumnStore

### Vue d'ensemble du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   MariaDB Server (SQL Layer)                ‚îÇ
‚îÇ  ‚Ä¢ Parser, Optimizer, Executor                              ‚îÇ
‚îÇ  ‚Ä¢ InnoDB tables (OLTP)                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì Handler API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ColumnStore Storage Engine                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ         User Module (UM)                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Interface SQL                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query Parser sp√©cialis√©                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query Optimization (pushdown)                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ R√©sultats agr√©g√©s                                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ      Performance Module (PM) - Calcul parall√®le        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Scan des colonnes                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Filtrage (WHERE)                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Agr√©gations locales (SUM, COUNT, etc.)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Parall√©lisme massif                                 ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ         Extent Map & Block Manager                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ M√©tadonn√©es des extents                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Distribution des donn√©es                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Gestion des blocks (8 MB chacun)                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Stockage Physique (Disque)                  ‚îÇ
‚îÇ  ‚Ä¢ Colonnes stock√©es s√©par√©ment                             ‚îÇ
‚îÇ  ‚Ä¢ Compression avanc√©e (Snappy)                             ‚îÇ
‚îÇ  ‚Ä¢ Blocks de 8 MB                                           ‚îÇ
‚îÇ  ‚Ä¢ M√©tadonn√©es (min/max, histogrammes)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Composants principaux

#### 1. User Module (UM)

Le **User Module** est le point d'entr√©e pour les requ√™tes SQL :

```
R√¥le du UM :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Re√ßoit requ√™te SQL du MariaDB Server   ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 2. Parse et analyse la requ√™te            ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 3. Optimise pour ColumnStore              ‚îÇ
‚îÇ    ‚Ä¢ Pushdown des filtres                 ‚îÇ
‚îÇ    ‚Ä¢ Pushdown des agr√©gations             ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 4. Distribue aux Performance Modules      ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 5. Agr√®ge les r√©sultats finaux            ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 6. Retourne au MariaDB Server             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Query Pushdown** : Optimisation cl√© de ColumnStore

```sql
-- Requ√™te SQL
SELECT
    region,
    SUM(revenue) AS total
FROM sales
WHERE date >= '2024-01-01'
  AND status = 'completed'
GROUP BY region;

-- Sans pushdown (inefficace) :
-- 1. PM lit toutes les lignes
-- 2. Transfert de millions de lignes vers UM
-- 3. UM applique WHERE et GROUP BY
-- ‚Üí R√©seau satur√©, lent

-- Avec pushdown (optimal) :
-- 1. UM envoie les filtres aux PM
-- 2. PM appliquent WHERE localement
-- 3. PM calculent SUM() localement par r√©gion
-- 4. PM envoient r√©sultats agr√©g√©s √† UM (quelques lignes)
-- 5. UM fait agr√©gation finale
-- ‚Üí R√©seau minimal, rapide
```

#### 2. Performance Module (PM)

Le **Performance Module** effectue le traitement parall√®le des donn√©es :

```
Architecture MPP (Massively Parallel Processing) :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      User Module                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚Üì                ‚Üì                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PM Node 1   ‚îÇ  ‚îÇ  PM Node 2   ‚îÇ  ‚îÇ  PM Node 3   ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ
‚îÇ Scan col X   ‚îÇ  ‚îÇ Scan col X   ‚îÇ  ‚îÇ Scan col X   ‚îÇ
‚îÇ WHERE filter ‚îÇ  ‚îÇ WHERE filter ‚îÇ  ‚îÇ WHERE filter ‚îÇ
‚îÇ SUM(revenue) ‚îÇ  ‚îÇ SUM(revenue) ‚îÇ  ‚îÇ SUM(revenue) ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ
‚îÇ Partition 1  ‚îÇ  ‚îÇ Partition 2  ‚îÇ  ‚îÇ Partition 3  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚Üì                ‚Üì                ‚Üì
     [R√©sultat 1]    [R√©sultat 2]    [R√©sultat 3]
          ‚Üì                ‚Üì                ‚Üì
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì
               Agr√©gation finale (UM)
```

**Parall√©lisme multi-niveaux** :
- **Inter-n≈ìuds** : Plusieurs PM travaillent en parall√®le
- **Intra-n≈ìud** : Chaque PM utilise plusieurs threads
- **Vectorisation** : Traitement SIMD des donn√©es

#### 3. Extent Map & Metadata

ColumnStore utilise une structure hi√©rarchique pour organiser les donn√©es :

```
Hi√©rarchie ColumnStore :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Table                        ‚îÇ
‚îÇ  (ex: sales)                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Colonnes                       ‚îÇ
‚îÇ  ‚Ä¢ date                                   ‚îÇ
‚îÇ  ‚Ä¢ region                                 ‚îÇ
‚îÇ  ‚Ä¢ revenue                                ‚îÇ
‚îÇ  ‚Ä¢ quantity                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Extents (64 MB)                ‚îÇ
‚îÇ  ‚Ä¢ Unit√© de distribution                  ‚îÇ
‚îÇ  ‚Ä¢ R√©partis sur les PM                    ‚îÇ
‚îÇ  ‚Ä¢ M√©tadonn√©es : min, max, histogramme    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Blocks (8 MB)                  ‚îÇ
‚îÇ  ‚Ä¢ Unit√© de compression                   ‚îÇ
‚îÇ  ‚Ä¢ Unit√© de lecture                       ‚îÇ
‚îÇ  ‚Ä¢ ~8 millions de valeurs par block       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Exemple de m√©tadonn√©es d'Extent** :

```
Extent #42 de la colonne 'revenue' :
{
    extent_id: 42,
    column: "revenue",
    min_value: 10.00,
    max_value: 9999.99,
    num_rows: 8000000,
    compression: "Snappy",
    blocks: [
        { block_id: 1, offset: 0, size: 8388608 },
        { block_id: 2, offset: 8388608, size: 8388608 },
        ...
    ]
}
```

**Optimisation : Extent Elimination** :

```sql
SELECT SUM(revenue)
FROM sales
WHERE revenue > 10000;

-- ColumnStore lit l'Extent Map :
-- Extent #1 : min=10, max=500 ‚Üí SKIP (max < 10000)
-- Extent #2 : min=100, max=5000 ‚Üí SKIP
-- Extent #3 : min=5000, max=15000 ‚Üí SCAN (contient valeurs > 10000)
-- Extent #4 : min=12000, max=50000 ‚Üí SCAN
-- ...

-- R√©sultat : Scanne seulement 30% des extents
-- I/O r√©duit de 70%
```

### Compression

ColumnStore applique une **compression agressive** sur chaque colonne :

```
Pipeline de compression :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Donn√©es brutes (ex: colonne 'city')    ‚îÇ
‚îÇ    ['Paris', 'Lyon', 'Paris', ...]        ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 2. Encodage (Dictionary / RLE / etc.)     ‚îÇ
‚îÇ    Paris ‚Üí ID 1                           ‚îÇ
‚îÇ    Lyon ‚Üí ID 2                            ‚îÇ
‚îÇ    [1, 2, 1, 1, 2, 1, ...]                ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 3. Compression (Snappy)                   ‚îÇ
‚îÇ    Algorithme LZ77                        ‚îÇ
‚îÇ    [compressed binary data]               ‚îÇ
‚îÇ    ‚Üì                                      ‚îÇ
‚îÇ 4. Stockage (8 MB blocks)                 ‚îÇ
‚îÇ    Ratio compression : 5-20√ó              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Techniques de compression** :

| Technique | Cas d'usage | Ratio typique |
|-----------|-------------|---------------|
| **Dictionary** | Colonnes avec cardinalit√© faible (ex: pays, statuts) | 10-50√ó |
| **Run-Length Encoding (RLE)** | Colonnes tri√©es avec valeurs r√©p√©t√©es | 5-100√ó |
| **Delta Encoding** | Colonnes avec valeurs incr√©mentales (timestamps, IDs) | 3-10√ó |
| **Snappy** | Compression finale, rapide d√©compression | 2-5√ó |

**Exemple de compression** :

```sql
-- Colonne 'country' : 100 millions de lignes
-- Valeurs : 'France', 'Germany', 'Spain', 'Italy', 'UK'

-- Sans compression :
-- 100M lignes √ó 7 bytes (moyenne) = 700 MB

-- Avec Dictionary Encoding :
-- Dictionary : 5 entr√©es √ó 10 bytes = 50 bytes
-- IDs : 100M √ó 1 byte = 100 MB
-- Total : 100 MB (compression 7√ó)

-- Avec Snappy en plus :
-- 100 MB ‚Üí 25 MB (compression finale 28√ó)
```

üí° **Avantage cl√©** : Plus de donn√©es en cache = moins d'I/O = performances sup√©rieures.

---

## D√©ploiement et installation

### Architecture de d√©ploiement

ColumnStore peut √™tre d√©ploy√© en plusieurs modes :

**1. Single-node (d√©veloppement, petits volumes)** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     MariaDB Server             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  InnoDB (OLTP tables)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ColumnStore             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ UM + PM combin√©s      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ OLAP tables           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**2. Multi-node MPP (production, gros volumes)** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MariaDB UM Node (Query Coordinator)         ‚îÇ
‚îÇ  ‚Ä¢ Re√ßoit requ√™tes                                       ‚îÇ
‚îÇ  ‚Ä¢ Distribue aux PM                                      ‚îÇ
‚îÇ  ‚Ä¢ Agr√®ge r√©sultats                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì                     ‚Üì                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PM Node1‚îÇ         ‚îÇ PM Node2‚îÇ         ‚îÇ PM Node3‚îÇ
‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ         ‚îÇ
‚îÇ Disks   ‚îÇ         ‚îÇ Disks   ‚îÇ         ‚îÇ Disks   ‚îÇ
‚îÇ (RAID)  ‚îÇ         ‚îÇ (RAID)  ‚îÇ         ‚îÇ (RAID)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 Partition 1        Partition 2        Partition 3
```

### Installation

```bash
# Installation via package manager (RHEL/CentOS/Rocky)
sudo yum install MariaDB-server MariaDB-columnstore-engine

# Debian/Ubuntu
sudo apt-get install mariadb-server mariadb-plugin-columnstore

# Initialisation ColumnStore
sudo /usr/bin/columnstore-post-install

# Configuration interactive
# 1. Single-node ou Multi-node ?
# 2. R√©pertoire de stockage ?
# 3. Taille du cache ?
# etc.
```

### Configuration de base

```ini
# /etc/mysql/mariadb.conf.d/columnstore.cnf
[mysqld]
# Activer ColumnStore
plugin_load_add = ha_columnstore

# M√©moire pour ColumnStore (30-70% RAM)
columnstore_cache_size = 32G

# Nombre de threads par PM
columnstore_max_threads = 16

# Taille du buffer d'importation
columnstore_import_buffer_size = 2G

# Mode compression
columnstore_compression_type = 2  # 0=none, 1=snappy(d√©faut), 2=lz4

# Logging
columnstore_use_import_for_batchinsert = ON
```

### V√©rification

```sql
-- V√©rifier que ColumnStore est charg√©
SHOW ENGINES;
-- +--------------------+---------+-------------------------------+
-- | Engine             | Support | Comment                       |
-- +--------------------+---------+-------------------------------+
-- | ColumnStore        | YES     | ColumnStore storage engine    |
-- +--------------------+---------+-------------------------------+

-- Afficher les tables ColumnStore
SELECT
    TABLE_SCHEMA,
    TABLE_NAME,
    ENGINE
FROM information_schema.TABLES
WHERE ENGINE = 'ColumnStore';

-- V√©rifier le statut du syst√®me
SELECT calgetstats();
```

---

## Utilisation de ColumnStore

### Cr√©ation de tables

```sql
-- Cr√©er une table ColumnStore
CREATE TABLE sales_fact (
    sale_id BIGINT,
    sale_date DATE,
    customer_id INT,
    product_id INT,
    region VARCHAR(50),
    revenue DECIMAL(10,2),
    quantity INT,
    cost DECIMAL(10,2)
) ENGINE=ColumnStore;

-- Pas d'index n√©cessaire ! (scan columnar optimis√©)
-- Pas de cl√© primaire obligatoire
```

**Bonnes pratiques de design** :

```sql
-- ‚úÖ BON : Table d√©normalis√©e (star schema)
CREATE TABLE sales_analytics (
    date DATE,
    year INT,           -- D√©normalisation temporelle
    quarter INT,
    month INT,
    customer_name VARCHAR(100),
    customer_country VARCHAR(50),
    product_name VARCHAR(200),
    product_category VARCHAR(50),
    revenue DECIMAL(15,2),
    quantity INT
) ENGINE=ColumnStore;

-- ‚ùå √âVITER : Tables normalis√©es avec JOINs complexes
-- ColumnStore pr√©f√®re tables larges d√©normalis√©es
```

### Chargement de donn√©es

#### 1. LOAD DATA (recommand√© pour gros volumes)

```sql
-- Chargement depuis CSV
LOAD DATA INFILE '/data/sales.csv'
INTO TABLE sales_fact
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;

-- Performance : 500 000 - 2 000 000 lignes/seconde
-- (d√©pend du mat√©riel et taille des lignes)
```

**Optimisations pour LOAD DATA** :

```sql
-- D√©sactiver temporairement les autocommits
SET autocommit = 0;
SET unique_checks = 0;
SET foreign_key_checks = 0;

-- Charger les donn√©es
LOAD DATA INFILE '/data/huge_file.csv' INTO TABLE sales_fact;

-- R√©activer
SET autocommit = 1;
SET unique_checks = 1;
SET foreign_key_checks = 1;
```

#### 2. cpimport (outil ColumnStore natif)

```bash
# Chargement ultra-rapide via outil natif
cpimport mydb sales_fact /data/sales.csv

# Options avanc√©es
cpimport mydb sales_fact /data/sales.csv \
    -s ',' \              # S√©parateur
    -E '"' \              # Enclosure
    -c 50000 \            # Batch size
    -j 8                  # Nombre de threads parall√®les

# Performance : 5-10√ó plus rapide que LOAD DATA
# Jusqu'√† 10 millions de lignes/seconde sur mat√©riel moderne
```

#### 3. INSERT batch (pour petits volumes)

```sql
-- INSERT multiple rows (par batch de 10 000+)
INSERT INTO sales_fact VALUES
    (1, '2025-01-01', 100, 200, 'Paris', 1500.00, 10, 1000.00),
    (2, '2025-01-01', 101, 201, 'Lyon', 2500.00, 15, 1800.00),
    -- ... 9998 autres lignes ...
    (10000, '2025-01-01', 999, 299, 'Nice', 3500.00, 20, 2500.00);

-- Performance : 10 000 - 100 000 lignes/seconde
-- Acceptable pour flux continu, mais LOAD DATA/cpimport meilleurs pour bulk
```

### Requ√™tes analytiques

#### Agr√©gations simples

```sql
-- COUNT, SUM, AVG optimis√©s par ColumnStore
SELECT
    COUNT(*) AS total_sales,
    SUM(revenue) AS total_revenue,
    AVG(quantity) AS avg_quantity
FROM sales_fact
WHERE sale_date >= '2024-01-01';

-- Execution : < 1 seconde sur 100 millions de lignes
-- ColumnStore lit uniquement colonnes revenue, quantity, sale_date
```

#### GROUP BY et agr√©gations

```sql
-- Agr√©gation par r√©gion
SELECT
    region,
    COUNT(*) AS num_sales,
    SUM(revenue) AS total_revenue,
    AVG(revenue) AS avg_revenue,
    MIN(revenue) AS min_revenue,
    MAX(revenue) AS max_revenue
FROM sales_fact
WHERE sale_date BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY region
ORDER BY total_revenue DESC;

-- ColumnStore applique pushdown :
-- 1. PM filtrent par date (WHERE)
-- 2. PM calculent agr√©gations locales par r√©gion
-- 3. UM agr√®ge les r√©sultats finaux
-- ‚Üí Tr√®s rapide m√™me sur milliards de lignes
```

#### Window Functions

```sql
-- Classement des produits par revenue
SELECT
    product_id,
    product_name,
    SUM(revenue) AS total_revenue,
    RANK() OVER (ORDER BY SUM(revenue) DESC) AS revenue_rank,
    SUM(SUM(revenue)) OVER (ORDER BY SUM(revenue) DESC) AS cumulative_revenue
FROM sales_fact
WHERE sale_date >= '2024-01-01'
GROUP BY product_id, product_name;

-- Window functions b√©n√©ficient du stockage columnar
```

#### Requ√™tes complexes

```sql
-- Analyse multi-dimensionnelle
SELECT
    YEAR(sale_date) AS year,
    QUARTER(sale_date) AS quarter,
    region,
    product_category,
    COUNT(DISTINCT customer_id) AS unique_customers,
    SUM(revenue) AS total_revenue,
    SUM(quantity) AS total_quantity,
    SUM(revenue - cost) AS total_profit,
    AVG(revenue - cost) AS avg_profit_per_sale
FROM sales_fact
WHERE sale_date BETWEEN '2020-01-01' AND '2024-12-31'
GROUP BY
    YEAR(sale_date),
    QUARTER(sale_date),
    region,
    product_category
HAVING SUM(revenue) > 100000
ORDER BY year, quarter, total_revenue DESC;

-- Performance : 2-5 secondes sur 1 milliard de lignes
-- (vs plusieurs minutes avec InnoDB)
```

---

## Architecture hybride OLTP/OLAP

### Pattern ETL classique

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Application OLTP                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ          InnoDB Tables                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ orders (transactionnel)                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ customers                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ products                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Üí Optimis√© pour INSERT/UPDATE/DELETE           ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì ETL (Extract-Transform-Load)
                      ‚Üì (Batch nightly ou temps r√©el)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Data Warehouse (Analytique)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ        ColumnStore Tables                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ sales_fact (d√©normalis√©e)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ customer_dimension                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ product_dimension                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Üí Optimis√© pour SELECT/agr√©gations             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  BI Tools     ‚îÇ
              ‚îÇ  ‚Ä¢ Tableau    ‚îÇ
              ‚îÇ  ‚Ä¢ PowerBI    ‚îÇ
              ‚îÇ  ‚Ä¢ Metabase   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ETL avec MariaDB

```sql
-- Exemple : ETL quotidien OLTP ‚Üí OLAP

-- 1. Extraction depuis InnoDB
CREATE TEMPORARY TABLE daily_sales AS
SELECT
    o.order_date,
    o.order_id,
    c.customer_name,
    c.customer_country,
    p.product_name,
    p.product_category,
    o.quantity,
    o.unit_price * o.quantity AS revenue,
    o.unit_cost * o.quantity AS cost
FROM orders o  -- InnoDB
JOIN customers c ON o.customer_id = c.customer_id  -- InnoDB
JOIN products p ON o.product_id = p.product_id     -- InnoDB
WHERE o.order_date = CURDATE() - INTERVAL 1 DAY;

-- 2. Transformation (d√©j√† faite ci-dessus via JOIN)

-- 3. Chargement dans ColumnStore
INSERT INTO sales_fact_columnstore  -- ColumnStore
SELECT * FROM daily_sales;

-- Alternative : Export/Import pour meilleure performance
SELECT * FROM daily_sales
INTO OUTFILE '/tmp/daily_sales.csv'
FIELDS TERMINATED BY ','
ENCLOSED BY '"';

-- Puis cpimport :
-- shell> cpimport warehouse sales_fact /tmp/daily_sales.csv
```

### Requ√™tes hybrides (Cross-Engine JOIN)

MariaDB permet de joindre tables InnoDB et ColumnStore :

```sql
-- JOIN entre InnoDB (OLTP) et ColumnStore (OLAP)
SELECT
    c.customer_name,           -- InnoDB (actuel)
    c.email,                   -- InnoDB
    SUM(s.revenue) AS lifetime_value  -- ColumnStore (historique)
FROM customers c               -- InnoDB (10 000 lignes)
JOIN sales_fact s ON c.customer_id = s.customer_id  -- ColumnStore (1B lignes)
WHERE s.sale_date >= '2020-01-01'
GROUP BY c.customer_id, c.customer_name, c.email
ORDER BY lifetime_value DESC
LIMIT 100;

-- ‚ö†Ô∏è Performance variable selon :
-- ‚Ä¢ Taille de la table InnoDB (petite = OK)
-- ‚Ä¢ Cardinalit√© du JOIN
-- ‚Ä¢ Pr√©f√©rer mat√©rialiser les dimensions dans ColumnStore si possible
```

**Recommandation** : Dupliquer les dimensions dans ColumnStore pour √©viter cross-engine JOINs :

```sql
-- Au lieu de :
-- customers (InnoDB) JOIN sales_fact (ColumnStore)

-- Pr√©f√©rer :
-- customer_dimension (ColumnStore) JOIN sales_fact (ColumnStore)
-- Sync via ETL quotidien
```

---

## Sch√©ma en √©toile (Star Schema)

ColumnStore est id√©al pour les sch√©mas de data warehouse classiques :

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Date Dimension  ‚îÇ
                    ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
                    ‚îÇ  date_key (PK)   ‚îÇ
                    ‚îÇ  full_date       ‚îÇ
                    ‚îÇ  year            ‚îÇ
                    ‚îÇ  quarter         ‚îÇ
                    ‚îÇ  month           ‚îÇ
                    ‚îÇ  day_of_week     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üë
                             ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                   ‚îÇ                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Customer     ‚îÇ   ‚îÇ   Fact Table ‚îÇ   ‚îÇ   Product     ‚îÇ
‚îÇ   Dimension    ‚îÇ   ‚îÇ   (Sales)    ‚îÇ   ‚îÇ   Dimension   ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÇ   ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ   ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇcustomer_key(PK)‚îÇ‚Üê‚îÄ‚îÄ‚îÇdate_key (FK) ‚îÇ‚îÄ‚îÄ‚Üí‚îÇproduct_key(PK)‚îÇ
‚îÇname            ‚îÇ   ‚îÇcustomer_key  ‚îÇ   ‚îÇname           ‚îÇ
‚îÇcountry         ‚îÇ   ‚îÇproduct_key   ‚îÇ   ‚îÇcategory       ‚îÇ
‚îÇsegment         ‚îÇ   ‚îÇquantity      ‚îÇ   ‚îÇbrand          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇrevenue       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇcost          ‚îÇ
                     ‚îÇprofit        ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Region         ‚îÇ
                    ‚îÇ   Dimension      ‚îÇ
                    ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ
                    ‚îÇ   region_key(PK) ‚îÇ
                    ‚îÇ   region_name    ‚îÇ
                    ‚îÇ   country        ‚îÇ
                    ‚îÇ   continent      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Impl√©mentation en SQL** :

```sql
-- Fact Table (centre de l'√©toile)
CREATE TABLE sales_fact (
    date_key INT,
    customer_key INT,
    product_key INT,
    region_key INT,
    quantity INT,
    revenue DECIMAL(15,2),
    cost DECIMAL(15,2),
    profit DECIMAL(15,2)
) ENGINE=ColumnStore;

-- Dimensions
CREATE TABLE date_dimension (
    date_key INT PRIMARY KEY,
    full_date DATE,
    year INT,
    quarter INT,
    month INT,
    day_of_week VARCHAR(10),
    is_weekend BOOLEAN
) ENGINE=ColumnStore;

CREATE TABLE customer_dimension (
    customer_key INT PRIMARY KEY,
    customer_id VARCHAR(50),
    customer_name VARCHAR(200),
    country VARCHAR(50),
    segment VARCHAR(50)
) ENGINE=ColumnStore;

-- etc. pour product_dimension, region_dimension

-- Requ√™te analytique typique (drill-down)
SELECT
    d.year,
    d.quarter,
    c.country,
    p.category,
    SUM(f.revenue) AS total_revenue,
    SUM(f.profit) AS total_profit
FROM sales_fact f
JOIN date_dimension d ON f.date_key = d.date_key
JOIN customer_dimension c ON f.customer_key = c.customer_key
JOIN product_dimension p ON f.product_key = p.product_key
WHERE d.year = 2024
GROUP BY d.year, d.quarter, c.country, p.category
ORDER BY total_revenue DESC;
```

---

## Configuration et tuning

### Param√®tres critiques

```ini
[mysqld]
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# COLUMNSTORE PERFORMANCE TUNING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# M√©moire cache (30-70% RAM syst√®me)
# Plus = plus de donn√©es en cache = moins d'I/O
columnstore_cache_size = 64G

# Threads de traitement par PM
# Recommandation : 1-2√ó nombre de CPU cores
columnstore_max_threads = 32

# Taille buffer pour LOAD DATA / cpimport
columnstore_import_buffer_size = 4G

# Mode compression (1=Snappy recommand√©, 2=LZ4 plus rapide)
columnstore_compression_type = 1

# Utiliser cpimport pour batch inserts (plus rapide)
columnstore_use_import_for_batchinsert = ON

# Nombre de blocks √† pr√©fetch (I/O anticip√©)
columnstore_num_blocks_pct = 50

# Hash join buffer size
columnstore_hash_join_size = 100M

# Taille disk-based join (si d√©passement m√©moire)
columnstore_disk_based_join = ON
columnstore_um_mem_limit = 0  # 0 = illimit√© (utilise columnstore_cache_size)
```

### Optimisations de requ√™tes

#### 1. Pr√©f√©rer les colonnes dans ORDER BY pr√©sentes dans GROUP BY

```sql
-- ‚úÖ BON (√©vite tri final)
SELECT
    region,
    SUM(revenue) AS total
FROM sales_fact
GROUP BY region
ORDER BY region;  -- D√©j√† group√© par region

-- ‚ö†Ô∏è Moins optimal (tri suppl√©mentaire)
SELECT
    region,
    SUM(revenue) AS total
FROM sales_fact
GROUP BY region
ORDER BY total DESC;  -- Tri sur agr√©gat
```

#### 2. Utiliser WHERE plut√¥t que HAVING quand possible

```sql
-- ‚úÖ BON (filtrage pr√©coce)
SELECT
    product_category,
    SUM(revenue) AS total
FROM sales_fact
WHERE revenue > 100  -- Pushdown vers PM
GROUP BY product_category;

-- ‚ö†Ô∏è Moins optimal (filtrage tardif)
SELECT
    product_category,
    SUM(revenue) AS total
FROM sales_fact
GROUP BY product_category
HAVING SUM(revenue) > 10000;  -- Apr√®s agr√©gation
```

#### 3. Limiter les JOINs cross-engine

```sql
-- ‚ùå √Ä √âVITER
SELECT *
FROM big_innodb_table i      -- InnoDB, 10M lignes
JOIN sales_fact c ON i.id = c.customer_id  -- ColumnStore, 1B lignes

-- ‚úÖ PR√âF√âRER : Mat√©rialiser dimensions dans ColumnStore
CREATE TABLE customer_dim_cs ENGINE=ColumnStore
    SELECT * FROM big_innodb_table;

SELECT *
FROM customer_dim_cs c
JOIN sales_fact s ON c.id = s.customer_id;
```

### Partitionnement (implicite)

ColumnStore partitionne automatiquement les donn√©es par **extent** (64 MB) :

```sql
-- Pas de PARTITION BY explicite n√©cessaire
-- ColumnStore distribue automatiquement les extents sur les PM

-- Requ√™te b√©n√©ficie de l'extent elimination automatique
SELECT SUM(revenue)
FROM sales_fact
WHERE sale_date = '2024-06-15';

-- ColumnStore :
-- 1. Identifie les extents contenant des donn√©es de juin 2024
-- 2. Skip tous les autres extents (metadata min/max)
-- 3. Scan parall√®le des extents pertinents seulement
```

---

## Monitoring et diagnostics

### M√©triques syst√®me

```sql
-- Vue globale du syst√®me ColumnStore
SELECT calgetstats();
-- Retourne JSON avec :
-- ‚Ä¢ Nombre de PM actifs
-- ‚Ä¢ M√©moire utilis√©e
-- ‚Ä¢ Nombre de requ√™tes en cours
-- ‚Ä¢ Statistiques I/O

-- Version d√©taill√©e
SELECT calgetstats('verbose');

-- Statistiques par table
SELECT
    table_schema,
    table_name,
    table_rows,
    data_length / 1024 / 1024 / 1024 AS size_gb
FROM information_schema.tables
WHERE engine = 'ColumnStore';
```

### Analyse de requ√™tes

```sql
-- EXPLAIN pour ColumnStore
EXPLAIN
SELECT
    region,
    SUM(revenue)
FROM sales_fact
WHERE sale_date >= '2024-01-01'
GROUP BY region;

-- R√©sultat montre :
-- ‚Ä¢ Colonnes acc√©d√©es
-- ‚Ä¢ Filtres appliqu√©s (pushdown)
-- ‚Ä¢ Agr√©gations pushdown
```

### Logs et debug

```bash
# Logs ColumnStore
tail -f /var/log/mariadb/columnstore/debug.log

# Activer logging d√©taill√©
calsetlogconfig --debug

# Statistiques en temps r√©el
watch -n 1 'echo "SELECT calgetstats();" | mysql -u root -p'
```

---

## Limitations et cas d'usage

### ‚úÖ Id√©al pour

1. **Data Warehouse et OLAP**
   - Tables de faits avec milliards de lignes
   - Requ√™tes d'agr√©gation (SUM, AVG, COUNT)
   - Analyses multi-dimensionnelles
   - Rapports BI

2. **Analytics en temps r√©el**
   - Dashboards avec requ√™tes complexes
   - Analyses ad-hoc
   - Exploration de donn√©es

3. **IoT et time-series**
   - Logs applicatifs (millions de lignes/jour)
   - Donn√©es de capteurs
   - M√©triques syst√®me

4. **ETL et data pipelines**
   - Transformation de donn√©es massives
   - Agr√©gations interm√©diaires

### ‚ùå Ne PAS utiliser pour

1. **OLTP (transactions courtes)**
   ```sql
   -- ‚ùå Mauvais cas d'usage pour ColumnStore
   UPDATE orders SET status = 'shipped' WHERE order_id = 12345;
   -- Utilisez InnoDB !
   ```

2. **Petites tables (< 1 million de lignes)**
   - Overhead de ColumnStore non justifi√©
   - InnoDB plus rapide pour petits volumes

3. **Requ√™tes point-lookup**
   ```sql
   -- ‚ùå Inefficace avec ColumnStore
   SELECT * FROM users WHERE id = 42;
   -- InnoDB avec index primaire est 1000√ó plus rapide
   ```

4. **Forte concurrence en √©criture**
   - ColumnStore optimis√© pour lecture
   - √âcritures plus lentes qu'InnoDB
   - Batch inserts recommand√©s

5. **Tables avec modifications fr√©quentes (UPDATE/DELETE)**
   - ColumnStore n'a pas de vrai UPDATE en place
   - UPDATE = DELETE + INSERT
   - Performance d√©grad√©e

### Tableau comparatif : InnoDB vs ColumnStore

| Crit√®re | InnoDB | ColumnStore |
|---------|--------|-------------|
| **Cas d'usage** | OLTP | OLAP |
| **Taille typique** | 1 KB - 100 GB | 100 GB - 100 TB |
| **Requ√™tes** | Point-lookup, range | Agr√©gations, scans |
| **INSERT** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (rapide) | ‚≠ê‚≠ê‚≠ê (batch OK) |
| **UPDATE/DELETE** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê (lent) |
| **SELECT (row)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **SELECT (agr√©gat)** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Compression** | 2-3√ó | 10-50√ó |
| **Transactions ACID** | ‚úÖ Complet | ‚ö†Ô∏è Limit√© |
| **Index** | B-Tree, Hash, FTS | ‚ùå Pas d'index (scan optimis√©) |
| **Concurrence** | Haute (row-lock) | Moyenne (extent-lock) |
| **Parall√©lisme** | Thread-pool | MPP natif |

---

## Exemples r√©els

### Exemple 1 : E-commerce analytics

```sql
-- Sch√©ma
CREATE TABLE order_facts (
    order_date DATE,
    customer_country VARCHAR(50),
    product_category VARCHAR(100),
    product_sku VARCHAR(50),
    quantity INT,
    revenue DECIMAL(12,2),
    cost DECIMAL(12,2),
    shipping_cost DECIMAL(8,2)
) ENGINE=ColumnStore;

-- Chargement : 500 millions de commandes historiques
-- Taille : 200 GB non compress√© ‚Üí 15 GB compress√© (13√ó compression)

-- Requ√™te 1 : Top 10 produits par revenue
SELECT
    product_sku,
    SUM(revenue) AS total_revenue,
    SUM(quantity) AS total_quantity
FROM order_facts
WHERE order_date >= '2024-01-01'
GROUP BY product_sku
ORDER BY total_revenue DESC
LIMIT 10;
-- Temps : 0.8 secondes (vs 45 sec avec InnoDB)

-- Requ√™te 2 : Analyse g√©ographique mensuelle
SELECT
    DATE_FORMAT(order_date, '%Y-%m') AS month,
    customer_country,
    COUNT(DISTINCT product_sku) AS unique_products,
    SUM(revenue - cost - shipping_cost) AS net_profit
FROM order_facts
WHERE order_date BETWEEN '2023-01-01' AND '2024-12-31'
GROUP BY month, customer_country
ORDER BY month, net_profit DESC;
-- Temps : 2.3 secondes
```

### Exemple 2 : Logs applicatifs

```sql
-- Sch√©ma
CREATE TABLE application_logs (
    log_timestamp DATETIME(6),
    application VARCHAR(50),
    severity VARCHAR(10),
    message TEXT,
    user_id INT,
    request_id VARCHAR(36),
    duration_ms INT
) ENGINE=ColumnStore;

-- Volume : 10 milliards de lignes, 5 TB compress√©

-- Requ√™te : Analyse des erreurs par application
SELECT
    application,
    severity,
    COUNT(*) AS error_count,
    AVG(duration_ms) AS avg_duration
FROM application_logs
WHERE log_timestamp >= NOW() - INTERVAL 7 DAY
  AND severity IN ('ERROR', 'CRITICAL')
GROUP BY application, severity
ORDER BY error_count DESC;
-- Temps : 3.5 secondes sur 7 jours de logs
```

### Exemple 3 : IoT time-series

```sql
-- Sch√©ma
CREATE TABLE sensor_readings (
    reading_timestamp DATETIME(6),
    device_id VARCHAR(50),
    sensor_type VARCHAR(50),
    location VARCHAR(100),
    value DOUBLE,
    unit VARCHAR(20)
) ENGINE=ColumnStore;

-- Volume : 1 billion de mesures, 8 TB

-- Requ√™te : Moyenne mobile par capteur et location
SELECT
    device_id,
    location,
    DATE(reading_timestamp) AS day,
    AVG(value) AS daily_avg,
    MIN(value) AS daily_min,
    MAX(value) AS daily_max,
    STDDEV(value) AS daily_stddev
FROM sensor_readings
WHERE sensor_type = 'temperature'
  AND reading_timestamp >= '2024-01-01'
GROUP BY device_id, location, day
ORDER BY device_id, day;
-- Temps : 12 secondes sur 1 milliard de lectures
```

---

## ‚úÖ Points cl√©s √† retenir

1. **Stockage columnar** : Colonnes stock√©es s√©par√©ment, optimise les requ√™tes analytiques (lecture seulement colonnes n√©cessaires).

2. **Compression massive** : Ratio 10-50√ó gr√¢ce √† l'homog√©n√©it√© des colonnes (Dictionary, RLE, Snappy).

3. **MPP (Massively Parallel Processing)** : Architecture distribu√©e avec User Module (UM) et Performance Modules (PM).

4. **Pas d'index** : Scan columnar optimis√© avec extent elimination (m√©tadonn√©es min/max).

5. **OLAP id√©al** : Agr√©gations (SUM, AVG, COUNT), GROUP BY, analytique sur milliards de lignes.

6. **Pushdown optimization** : Filtres et agr√©gations ex√©cut√©s sur les PM (r√©duction transferts r√©seau).

7. **Architecture hybride** : Combiner InnoDB (OLTP) et ColumnStore (OLAP) dans la m√™me base.

8. **Chargement batch** : cpimport ou LOAD DATA pour insertion rapide (millions lignes/seconde).

9. **Limitations** : Pas pour OLTP, UPDATE/DELETE lents, pas d'index traditionnels.

10. **Star Schema** : Id√©al pour sch√©mas en √©toile (fact table + dimensions).

---

## üîó Ressources et r√©f√©rences

### Documentation officielle MariaDB

- [üìñ ColumnStore Overview](https://mariadb.com/kb/en/columnstore/)
- [üìñ ColumnStore Architecture](https://mariadb.com/kb/en/columnstore-architecture/)
- [üìñ ColumnStore Installation](https://mariadb.com/kb/en/installing-and-configuring-columnstore/)
- [üìñ ColumnStore Functions](https://mariadb.com/kb/en/columnstore-sql-structure-and-commands/)
- [üìñ cpimport Tool](https://mariadb.com/kb/en/columnstore-bulk-data-loading/)

### Articles techniques

- [ColumnStore Performance Tuning](https://mariadb.com/kb/en/columnstore-performance-tuning/)
- [OLAP vs OLTP: Understanding the Difference](https://mariadb.org/olap-vs-oltp/)
- [Star Schema Design for ColumnStore](https://mariadb.com/kb/en/columnstore-best-practices/)

### Outils et int√©gration

- **BI Tools** : Tableau, PowerBI, Metabase, Grafana
- **ETL** : Apache Airflow, Pentaho, Talend
- **Data Science** : Python (pandas, SQLAlchemy), R (RMariaDB)

---

## ‚û°Ô∏è Section suivante

**[7.6 Moteur S3 : Archivage donn√©es froides sur AWS S3/MinIO](/07-moteurs-de-stockage/06-moteur-s3.md)** : D√©couverte du moteur S3 pour archivage √©conomique de donn√©es froides sur stockage objet.

Puis nous continuerons avec :
- **7.7** : Vector/HNSW pour recherche vectorielle IA üÜï
- **7.8** : Comparaison et choix du moteur appropri√©
- **7.9** : Conversion entre moteurs

---

**üìå M√©mo Architecte** : "ColumnStore = OLAP, InnoDB = OLTP. Ne m√©langez pas. Utilisez ETL pour passer de l'un √† l'autre. Tables d√©normalis√©es, star schema, et batch inserts sont vos amis."

**üéØ R√®gle d'or** : Si votre requ√™te fait `SELECT COUNT(*), SUM(), AVG(), GROUP BY` sur des millions de lignes ‚Üí ColumnStore. Si c'est `SELECT * WHERE id = X` ou `UPDATE` ‚Üí InnoDB.

‚è≠Ô∏è [Moteur S3 : Archivage donn√©es froides sur AWS S3/MinIO](/07-moteurs-de-stockage/06-moteur-s3.md)
