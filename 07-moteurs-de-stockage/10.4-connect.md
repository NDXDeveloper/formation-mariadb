üîù Retour au [Sommaire](/SOMMAIRE.md)

# 7.10.4 CONNECT : Acc√®s Donn√©es Externes

> **Niveau** : Avanc√©
> **Dur√©e estim√©e** : 2.5 heures

> **Pr√©requis** :
> - Compr√©hension des moteurs de stockage MariaDB
> - Notions de bases de donn√©es f√©d√©r√©es
> - Formats de donn√©es (CSV, XML, JSON)
> - Concepts ETL et data integration

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre l'architecture et le fonctionnement du moteur CONNECT
- Acc√©der √† des sources de donn√©es h√©t√©rog√®nes (fichiers, bases externes, APIs)
- Configurer diff√©rents types de tables CONNECT (FILE, ODBC, MYSQL, MONGO, REST)
- Impl√©menter des pipelines d'int√©gration de donn√©es
- Ma√Ætriser les limitations et optimisations du moteur
- Concevoir des architectures de data federation
- Comparer CONNECT avec les alternatives (FDW PostgreSQL, Federated Engine)
- Mettre en place des processus ETL avec MariaDB

---

## Introduction

**CONNECT** est un moteur de stockage unique qui transforme MariaDB en un **hub d'int√©gration de donn√©es**. Il permet d'acc√©der √† des sources externes comme s'il s'agissait de tables natives, sans importer les donn√©es dans MariaDB.

**Caract√©ristiques principales** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MOTEUR CONNECT                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                       ‚îÇ
‚îÇ  ‚úì Acc√®s fichiers externes (CSV, JSON, XML)           ‚îÇ
‚îÇ  ‚úì Connexion bases externes (ODBC, JDBC, MySQL)       ‚îÇ
‚îÇ  ‚úì APIs REST et services web                          ‚îÇ
‚îÇ  ‚úì Bases NoSQL (MongoDB)                              ‚îÇ
‚îÇ  ‚úì Tables virtuelles (pas de stockage local)          ‚îÇ
‚îÇ  ‚úì Support INSERT/UPDATE/DELETE (selon source)        ‚îÇ
‚îÇ  ‚úó Performance variable (d√©pend de la source)         ‚îÇ
‚îÇ  ‚úó Pas de transactions distribu√©es                    ‚îÇ
‚îÇ                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

üí° **Principe fondamental** : CONNECT agit comme un **adaptateur** entre MariaDB et des sources de donn√©es externes, permettant des requ√™tes SQL standards sur donn√©es non-relationnelles ou distantes.

### Cas d'Usage

**Appropri√©s** :
- Int√©gration de fichiers CSV/JSON dans pipelines ETL
- Acc√®s √† des bases de donn√©es legacy via ODBC
- F√©d√©ration de donn√©es multi-sources
- Reporting cross-database en temps r√©el
- Migration de donn√©es depuis syst√®mes h√©t√©rog√®nes
- Acc√®s √† APIs REST pour enrichissement de donn√©es

**Inappropri√©s** :
- Tables transactionnelles haute performance
- Donn√©es n√©cessitant ACID strict
- Volumes massifs avec requ√™tes complexes
- Latence critique (<10ms)

---

## Architecture du Moteur CONNECT

### Vue d'Ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           CONNECT ENGINE ARCHITECTURE                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                        ‚îÇ
‚îÇ  APPLICATION / SQL QUERY                               ‚îÇ
‚îÇ       ‚Üì                                                ‚îÇ
‚îÇ  MariaDB Server                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  CONNECT Storage Engine                      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Query Parser & Optimizer                 ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Format Handler (CSV, JSON, XML, ...)     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Protocol Handler (ODBC, REST, ...)       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Result Aggregator                        ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ            ‚îÇ                                           ‚îÇ
‚îÇ            ‚Üì                                           ‚îÇ
‚îÇ  EXTERNAL DATA SOURCES                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   Files   ‚îÇ  Database ‚îÇ    API    ‚îÇ  NoSQL   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  (CSV,    ‚îÇ  (ODBC,   ‚îÇ  (REST)   ‚îÇ (Mongo)  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  JSON,    ‚îÇ  MySQL,   ‚îÇ           ‚îÇ          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  XML)     ‚îÇ  MSSQL)   ‚îÇ           ‚îÇ          ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pas de stockage local** : CONNECT ne stocke pas de donn√©es. Chaque requ√™te est transmise √† la source externe.

### Types de Tables CONNECT

| Type | Description | Lecture | √âcriture | Cas d'usage |
|------|-------------|---------|----------|-------------|
| **FILE** | Fichiers plats (CSV, JSON, XML) | ‚úÖ | ‚úÖ | Import/Export, ETL |
| **ODBC** | Via pilote ODBC | ‚úÖ | ‚úÖ | Bases legacy (Oracle, SQL Server) |
| **MYSQL** | Autre serveur MySQL/MariaDB | ‚úÖ | ‚úÖ | Data federation |
| **MONGO** | MongoDB | ‚úÖ | ‚úÖ | Int√©gration NoSQL |
| **REST** | APIs REST/HTTP | ‚úÖ | ‚ùå | Enrichissement donn√©es |
| **PROXY** | Table MariaDB via alias | ‚úÖ | ‚úÖ | Abstraction |
| **TBL** | Multiple sources (union) | ‚úÖ | ‚ùå | Agr√©gation |
| **PIVOT** | Transformation colonnes‚Üílignes | ‚úÖ | ‚ùå | Reporting |

---

## Tables FILE : Fichiers Externes

### CSV (Comma-Separated Values)

```sql
-- Fichier : /data/customers.csv
-- Format :
-- customer_id,name,email,country
-- 1,Alice,alice@example.com,US
-- 2,Bob,bob@example.com,UK
-- 3,Charlie,charlie@example.com,FR

-- Cr√©er table CONNECT pointant vers le fichier
CREATE TABLE customers_csv (
    customer_id INT NOT NULL,
    name VARCHAR(50),
    email VARCHAR(100),
    country CHAR(2)
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/data/customers.csv'
  HEADER=1                    -- Premi√®re ligne = header
  SEP_CHAR=','                -- S√©parateur
  QUOTED=1;                   -- Champs entre guillemets

-- Lire les donn√©es
SELECT * FROM customers_csv;
-- +-------------+---------+----------------------+---------+
-- | customer_id | name    | email                | country |
-- +-------------+---------+----------------------+---------+
-- |           1 | Alice   | alice@example.com    | US      |
-- |           2 | Bob     | bob@example.com      | UK      |
-- |           3 | Charlie | charlie@example.com  | FR      |
-- +-------------+---------+----------------------+---------+

-- Requ√™te filtr√©e
SELECT name, email
FROM customers_csv
WHERE country = 'US';

-- INSERT (ajoute au fichier)
INSERT INTO customers_csv VALUES (4, 'David', 'david@example.com', 'CA');

-- UPDATE (modifie le fichier)
UPDATE customers_csv
SET email = 'alice.new@example.com'
WHERE customer_id = 1;

-- DELETE (supprime du fichier)
DELETE FROM customers_csv WHERE customer_id = 2;
```

**Options CSV** :

```sql
CREATE TABLE data_csv (
    col1 INT,
    col2 VARCHAR(100),
    col3 DATE
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/path/to/file.csv'
  HEADER=1                    -- 1: Premi√®re ligne = noms colonnes
  SEP_CHAR=';'                -- S√©parateur (d√©faut: ',')
  QUOTED=1                    -- Champs entre guillemets
  QCHAR='"'                   -- Caract√®re quote (d√©faut: '"')
  ENDING=2                    -- Line ending: 1=\n, 2=\r\n (Windows)
  BLOCK_SIZE=8192;            -- Taille buffer lecture (bytes)
```

### JSON (JavaScript Object Notation)

```sql
-- Fichier : /data/products.json
-- Format :
-- [
--   {"product_id": 101, "name": "Laptop", "price": 999.99, "stock": 50},
--   {"product_id": 102, "name": "Mouse", "price": 29.99, "stock": 200},
--   {"product_id": 103, "name": "Keyboard", "price": 79.99, "stock": 150}
-- ]

-- Table CONNECT pour JSON array
CREATE TABLE products_json (
    product_id INT,
    name VARCHAR(100),
    price DECIMAL(10,2),
    stock INT
) ENGINE=CONNECT
  TABLE_TYPE=JSON
  FILE_NAME='/data/products.json';

-- Lecture
SELECT * FROM products_json WHERE price < 100;

-- JSON avec structure imbriqu√©e
-- Fichier : /data/orders.json
-- [
--   {
--     "order_id": 1001,
--     "customer": {"id": 1, "name": "Alice"},
--     "items": [
--       {"product_id": 101, "quantity": 2},
--       {"product_id": 102, "quantity": 1}
--     ]
--   }
-- ]

-- Table avec JPATH pour naviguer structure
CREATE TABLE orders_json (
    order_id INT FIELD_FORMAT='order_id',
    customer_id INT FIELD_FORMAT='customer.id',
    customer_name VARCHAR(50) FIELD_FORMAT='customer.name',
    item_product_id INT FIELD_FORMAT='items.0.product_id',  -- Premier item
    item_quantity INT FIELD_FORMAT='items.0.quantity'
) ENGINE=CONNECT
  TABLE_TYPE=JSON
  FILE_NAME='/data/orders.json'
  OPTION_LIST='Jmode=2';     -- Mode 2: Support structures complexes

-- Lecture
SELECT order_id, customer_name, item_product_id
FROM orders_json;
```

### XML (eXtensible Markup Language)

```sql
-- Fichier : /data/employees.xml
-- <?xml version="1.0"?>
-- <employees>
--   <employee id="1">
--     <name>John Doe</name>
--     <department>Engineering</department>
--     <salary>75000</salary>
--   </employee>
--   <employee id="2">
--     <name>Jane Smith</name>
--     <department>Marketing</department>
--     <salary>65000</salary>
--   </employee>
-- </employees>

-- Table CONNECT pour XML
CREATE TABLE employees_xml (
    id INT FIELD_FORMAT='@id',           -- Attribut XML
    name VARCHAR(100) FIELD_FORMAT='name',
    department VARCHAR(50) FIELD_FORMAT='department',
    salary DECIMAL(10,2) FIELD_FORMAT='salary'
) ENGINE=CONNECT
  TABLE_TYPE=XML
  FILE_NAME='/data/employees.xml'
  TABNAME='employee'          -- Nom de l'√©l√©ment r√©p√©titif
  OPTION_LIST='xmlsup=libxml2';  -- Parser XML

-- Lecture
SELECT name, department, salary
FROM employees_xml
WHERE salary > 70000;
```

### Fichiers Compress√©s (ZIP, GZIP)

```sql
-- Fichier compress√© : /data/logs.csv.gz

-- Lecture directe (d√©compression automatique)
CREATE TABLE logs_compressed (
    timestamp DATETIME,
    level VARCHAR(10),
    message TEXT
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/data/logs.csv.gz'
  HEADER=1
  ZIPPED=YES;                 -- Activer d√©compression

-- Lecture
SELECT * FROM logs_compressed
WHERE level = 'ERROR'
  AND timestamp > DATE_SUB(NOW(), INTERVAL 1 DAY);
```

---

## Tables ODBC : Bases de Donn√©es Externes

### Configuration ODBC

```bash
# 1. Installer pilotes ODBC (exemple : SQL Server)
sudo apt-get install unixodbc unixodbc-dev tdsodbc

# 2. Configurer DSN (Data Source Name)
sudo nano /etc/odbc.ini

# Contenu :
[MSSQL_Production]
Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so
Description = Production SQL Server
Server = sqlserver.example.com
Port = 1433
Database = ProductionDB
TDS_Version = 8.0

# 3. Tester connexion
isql -v MSSQL_Production username password
```

### Table CONNECT via ODBC

```sql
-- Acc√©der √† table SQL Server
CREATE TABLE sqlserver_customers (
    customer_id INT,
    company_name VARCHAR(100),
    contact_name VARCHAR(100),
    country VARCHAR(50)
) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  TABNAME='dbo.Customers'     -- Table sur SQL Server
  CONNECTION='DSN=MSSQL_Production;UID=dbuser;PWD=password';

-- Ou avec connection string compl√®te
CREATE TABLE oracle_employees (
    employee_id INT,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    salary DECIMAL(10,2)
) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  TABNAME='HR.EMPLOYEES'
  CONNECTION='Driver=Oracle ODBC Driver;Server=oracle.example.com;UID=hr_user;PWD=password;Database=HRDB';

-- Requ√™tes standards
SELECT * FROM sqlserver_customers WHERE country = 'Germany';

-- JOIN entre MariaDB et SQL Server
SELECT
    o.order_id,
    c.company_name,
    o.order_date,
    o.total_amount
FROM orders o                    -- Table locale MariaDB
JOIN sqlserver_customers c       -- Table distante SQL Server
  ON o.customer_id = c.customer_id
WHERE o.order_date >= '2024-01-01';
```

**Limitations ODBC** :
- Performance d√©pend du r√©seau et du serveur distant
- Pas de pushdown complexe (WHERE/JOIN trait√©s localement)
- Transactions limit√©es

---

## Tables MYSQL : F√©d√©ration MariaDB/MySQL

### Connexion √† Serveur Distant

```sql
-- Acc√©der √† table sur autre serveur MariaDB/MySQL
CREATE TABLE remote_logs (
    log_id BIGINT,
    timestamp DATETIME,
    user_id INT,
    action VARCHAR(50),
    details TEXT
) ENGINE=CONNECT
  TABLE_TYPE=MYSQL
  TABNAME='application_logs'
  OPTION_LIST='host=192.168.1.100,user=remote_user,password=secret,port=3306,database=logs_db';

-- Ou avec CONNECTION
CREATE TABLE remote_products (
    product_id INT,
    name VARCHAR(100),
    price DECIMAL(10,2)
) ENGINE=CONNECT
  TABLE_TYPE=MYSQL
  TABNAME='products'
  CONNECTION='mysql://remote_user:secret@192.168.1.100:3306/catalog_db';

-- Requ√™tes
SELECT * FROM remote_logs WHERE user_id = 12345;

-- Agr√©gation cross-server
SELECT
    DATE(timestamp) AS day,
    COUNT(*) AS log_count
FROM remote_logs
GROUP BY DATE(timestamp)
ORDER BY day DESC
LIMIT 30;
```

### Comparaison MYSQL vs Federated Engine

| Aspect | CONNECT (MYSQL) | FEDERATED Engine |
|--------|----------------|------------------|
| Configuration | OPTIONS / CONNECTION | CONNECTION string |
| Flexibilit√© | Plus d'options | Basique |
| Performance | L√©g√®rement meilleure | Standard |
| Maintenance | Actif (MariaDB 11.8) | Deprecated MySQL 8+ |
| Features | Plus riches | Minimaliste |

üí° **Recommandation** : Utiliser CONNECT TABLE_TYPE=MYSQL plut√¥t que FEDERATED.

---

## Tables MONGO : Int√©gration MongoDB

### Configuration MongoDB

```bash
# 1. Installer drivers MongoDB
# (Inclus dans MariaDB 11.x)

# 2. Configurer acc√®s MongoDB
mongo --host mongodb.example.com
```

### Table CONNECT pour MongoDB

```sql
-- Collection MongoDB : orders
-- Structure :
-- {
--   "_id": ObjectId("..."),
--   "order_id": 1001,
--   "customer_id": 123,
--   "items": [
--     {"product": "Laptop", "quantity": 1, "price": 999.99}
--   ],
--   "total": 999.99,
--   "status": "completed"
-- }

-- Table CONNECT
CREATE TABLE mongo_orders (
    order_id INT FIELD_FORMAT='order_id',
    customer_id INT FIELD_FORMAT='customer_id',
    total DECIMAL(10,2) FIELD_FORMAT='total',
    status VARCHAR(20) FIELD_FORMAT='status'
) ENGINE=CONNECT
  TABLE_TYPE=MONGO
  TABNAME='orders'
  OPTION_LIST='host=mongodb.example.com,port=27017,user=dbuser,password=secret,database=ecommerce';

-- Requ√™tes SQL sur MongoDB
SELECT order_id, customer_id, total
FROM mongo_orders
WHERE status = 'completed'
  AND total > 500;

-- Agr√©gation
SELECT
    status,
    COUNT(*) AS order_count,
    SUM(total) AS total_revenue
FROM mongo_orders
GROUP BY status;

-- JOIN MongoDB + MariaDB
SELECT
    m.order_id,
    c.name AS customer_name,
    m.total
FROM mongo_orders m
JOIN customers c ON m.customer_id = c.customer_id
WHERE m.status = 'pending';
```

---

## Tables REST : APIs HTTP

### Acc√®s API REST

```sql
-- API REST JSON : https://api.example.com/users
-- Response :
-- [
--   {"id": 1, "username": "alice", "email": "alice@example.com"},
--   {"id": 2, "username": "bob", "email": "bob@example.com"}
-- ]

-- Table CONNECT pour API
CREATE TABLE api_users (
    id INT FIELD_FORMAT='id',
    username VARCHAR(50) FIELD_FORMAT='username',
    email VARCHAR(100) FIELD_FORMAT='email'
) ENGINE=CONNECT
  TABLE_TYPE=JSON
  FILE_NAME='https://api.example.com/users'
  HTTP='YES';                 -- Activer HTTP

-- Avec authentification
CREATE TABLE api_secure (
    id INT,
    data VARCHAR(500)
) ENGINE=CONNECT
  TABLE_TYPE=JSON
  FILE_NAME='https://api.example.com/data'
  HTTP='YES'
  OPTION_LIST='http_header=Authorization: Bearer YOUR_TOKEN';

-- Lecture (appel API √† chaque requ√™te)
SELECT * FROM api_users WHERE username LIKE 'a%';

-- Cache local pour √©viter appels r√©p√©t√©s
CREATE TABLE api_users_cache ENGINE=InnoDB
SELECT * FROM api_users;

-- Rafra√Æchir cache
TRUNCATE TABLE api_users_cache;
INSERT INTO api_users_cache SELECT * FROM api_users;
```

‚ö†Ô∏è **Limitation** : Chaque requ√™te = appel API (lent). Utiliser cache local.

---

## Tables Sp√©ciales

### PROXY : Alias de Table

```sql
-- Table r√©elle (InnoDB)
CREATE TABLE products_real (
    product_id INT PRIMARY KEY,
    name VARCHAR(100),
    price DECIMAL(10,2)
) ENGINE=InnoDB;

-- Table PROXY (alias)
CREATE TABLE products (
    product_id INT,
    name VARCHAR(100),
    price DECIMAL(10,2)
) ENGINE=CONNECT
  TABLE_TYPE=PROXY
  TABNAME='products_real';

-- Requ√™tes via PROXY
SELECT * FROM products;  -- Identique √† products_real

-- Cas d'usage : abstraction, versioning, A/B testing
```

### TBL : Union de Tables

```sql
-- Combiner plusieurs sources en une vue unifi√©e

-- Tables sources
CREATE TABLE sales_2023 (
    sale_id INT,
    amount DECIMAL(10,2),
    sale_date DATE
) ENGINE=InnoDB;

CREATE TABLE sales_2024 (
    sale_id INT,
    amount DECIMAL(10,2),
    sale_date DATE
) ENGINE=InnoDB;

-- Table TBL (union)
CREATE TABLE sales_all (
    sale_id INT,
    amount DECIMAL(10,2),
    sale_date DATE
) ENGINE=CONNECT
  TABLE_TYPE=TBL
  TABNAME='sales_2023,sales_2024'
  OPTION_LIST='Ttype=MYSQL';

-- Requ√™te sur toutes les ann√©es
SELECT
    YEAR(sale_date) AS year,
    SUM(amount) AS total_sales
FROM sales_all
GROUP BY YEAR(sale_date);
```

### PIVOT : Transformation Donn√©es

```sql
-- Table source
CREATE TABLE monthly_sales (
    product VARCHAR(50),
    month INT,
    sales DECIMAL(10,2)
) ENGINE=InnoDB;

INSERT INTO monthly_sales VALUES
    ('Laptop', 1, 10000),
    ('Laptop', 2, 15000),
    ('Mouse', 1, 2000),
    ('Mouse', 2, 2500);

-- Table PIVOT (colonnes‚Üílignes)
CREATE TABLE sales_pivot (
    product VARCHAR(50),
    jan DECIMAL(10,2) FIELD_FORMAT='1',
    feb DECIMAL(10,2) FIELD_FORMAT='2'
) ENGINE=CONNECT
  TABLE_TYPE=PIVOT
  TABNAME='monthly_sales'
  OPTION_LIST='PivotCol=month,FncCol=sales';

-- R√©sultat pivoted
SELECT * FROM sales_pivot;
-- +---------+--------+--------+
-- | product | jan    | feb    |
-- +---------+--------+--------+
-- | Laptop  | 10000  | 15000  |
-- | Mouse   | 2000   | 2500   |
-- +---------+--------+--------+
```

---

## Patterns et Cas d'Usage

### 1. ETL : Extract-Transform-Load

```sql
-- Extract : Lire CSV source
CREATE TABLE staging_customers (
    id INT,
    name VARCHAR(100),
    email VARCHAR(100),
    country CHAR(2)
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/data/import/customers.csv'
  HEADER=1;

-- Transform & Load : Nettoyer et charger dans InnoDB
INSERT INTO customers (customer_id, name, email, country)
SELECT
    id,
    UPPER(TRIM(name)),                    -- Nettoyage
    LOWER(TRIM(email)),
    UPPER(country)
FROM staging_customers
WHERE email IS NOT NULL                   -- Filtrage
  AND email LIKE '%@%';

-- Rapport de chargement
SELECT
    COUNT(*) AS total_rows,
    COUNT(DISTINCT email) AS unique_emails,
    COUNT(*) - COUNT(DISTINCT email) AS duplicates
FROM staging_customers;
```

### 2. Data Federation : Requ√™tes Cross-Database

```sql
-- MariaDB local : orders, customers
-- SQL Server distant : inventory

-- Table CONNECT vers SQL Server
CREATE TABLE sqlserver_inventory (
    product_id INT,
    warehouse VARCHAR(50),
    quantity INT,
    last_updated DATETIME
) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  TABNAME='Inventory'
  CONNECTION='DSN=MSSQL_Prod;UID=user;PWD=pass';

-- Requ√™te f√©d√©r√©e
SELECT
    p.product_name,
    SUM(oi.quantity) AS ordered,
    i.quantity AS in_stock,
    i.quantity - SUM(oi.quantity) AS available
FROM orders o
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id
JOIN sqlserver_inventory i ON p.product_id = i.product_id
WHERE o.status = 'pending'
GROUP BY p.product_name, i.quantity
HAVING available < 10
ORDER BY available;
```

### 3. Log Aggregation

```sql
-- Logs sur plusieurs serveurs

-- Server 1
CREATE TABLE logs_server1 (
    timestamp DATETIME,
    level VARCHAR(10),
    message TEXT
) ENGINE=CONNECT
  TABLE_TYPE=MYSQL
  TABNAME='application_logs'
  OPTION_LIST='host=server1.example.com,user=log_reader,password=pass,database=logs';

-- Server 2
CREATE TABLE logs_server2 (
    timestamp DATETIME,
    level VARCHAR(10),
    message TEXT
) ENGINE=CONNECT
  TABLE_TYPE=MYSQL
  TABNAME='application_logs'
  OPTION_LIST='host=server2.example.com,user=log_reader,password=pass,database=logs';

-- Vue unifi√©e
CREATE VIEW logs_all AS
SELECT 'server1' AS server, timestamp, level, message FROM logs_server1
UNION ALL
SELECT 'server2' AS server, timestamp, level, message FROM logs_server2;

-- Analyse cross-server
SELECT
    server,
    level,
    COUNT(*) AS count
FROM logs_all
WHERE timestamp > DATE_SUB(NOW(), INTERVAL 1 HOUR)
GROUP BY server, level
ORDER BY count DESC;
```

### 4. Migration de Donn√©es

```sql
-- Migration depuis Oracle vers MariaDB

-- Table CONNECT vers Oracle (via ODBC)
CREATE TABLE oracle_legacy (
    id INT,
    description VARCHAR(500),
    created_date DATE,
    amount DECIMAL(15,2)
) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  TABNAME='LEGACY_DATA'
  CONNECTION='DSN=OracleProd;UID=migration_user;PWD=pass';

-- Table cible MariaDB (InnoDB)
CREATE TABLE migrated_data (
    id INT PRIMARY KEY,
    description TEXT,
    created_date DATE,
    amount DECIMAL(15,2),
    migrated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_date (created_date)
) ENGINE=InnoDB;

-- Proc√©dure de migration par lots
DELIMITER //
CREATE PROCEDURE migrate_from_oracle()
BEGIN
    DECLARE v_batch_size INT DEFAULT 10000;
    DECLARE v_offset INT DEFAULT 0;
    DECLARE v_rows INT DEFAULT 1;

    WHILE v_rows > 0 DO
        INSERT INTO migrated_data (id, description, created_date, amount)
        SELECT id, description, created_date, amount
        FROM oracle_legacy
        ORDER BY id
        LIMIT v_offset, v_batch_size;

        SET v_rows = ROW_COUNT();
        SET v_offset = v_offset + v_batch_size;

        SELECT CONCAT('Migrated: ', v_offset, ' rows') AS progress;
        DO SLEEP(1);  -- Pause entre batches
    END WHILE;
END//
DELIMITER ;

-- Ex√©cution
CALL migrate_from_oracle();
```

---

## Performance et Limitations

### Limitations CONNECT

```sql
-- ‚ùå Pas d'index sur tables CONNECT
CREATE TABLE csv_data (
    id INT,
    value VARCHAR(100),
    INDEX idx_id (id)      -- ERREUR : Index non support√©
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/data/file.csv';

-- Solution : Cr√©er table locale avec index
CREATE TABLE csv_data_indexed (
    id INT PRIMARY KEY,
    value VARCHAR(100),
    INDEX idx_value (value)
) ENGINE=InnoDB;

INSERT INTO csv_data_indexed SELECT * FROM csv_data;

-- ‚ùå Transactions limit√©es
START TRANSACTION;
UPDATE csv_file SET value = 'new' WHERE id = 1;  -- OK
UPDATE remote_odbc SET col = 'val' WHERE id = 2;  -- Pas de rollback distribu√©
ROLLBACK;  -- Seules modifications locales annul√©es

-- ‚ùå Performance variables
SELECT COUNT(*) FROM huge_csv_file;  -- Tr√®s lent (scan complet fichier)
SELECT * FROM api_rest WHERE id = 123;  -- Latence r√©seau
```

### Optimisations

#### **1. Cache Local**

```sql
-- Table CONNECT (lente)
CREATE TABLE remote_data (
    id INT,
    data VARCHAR(500)
) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  TABNAME='RemoteTable'
  CONNECTION='...';

-- Cache InnoDB (rapide)
CREATE TABLE remote_data_cache (
    id INT PRIMARY KEY,
    data VARCHAR(500),
    cached_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_cached (cached_at)
) ENGINE=InnoDB;

-- Rafra√Æchir cache p√©riodiquement
CREATE EVENT refresh_cache
ON SCHEDULE EVERY 1 HOUR
DO
BEGIN
    TRUNCATE TABLE remote_data_cache;
    INSERT INTO remote_data_cache (id, data)
    SELECT id, data FROM remote_data;
END;

-- Requ√™tes sur cache
SELECT * FROM remote_data_cache WHERE id = 123;  -- Rapide
```

#### **2. Filtrage C√¥t√© Source**

```sql
-- ‚ùå Filtrage local (transfert toutes donn√©es)
SELECT * FROM remote_large_table WHERE date_col > '2024-01-01';
-- CONNECT transf√®re TOUTES les lignes puis filtre localement

-- ‚úÖ Filtrage distant (si pushdown support√©)
-- D√©pend du type de table et driver
-- ODBC : Souvent bon pushdown
-- FILE : Pas de pushdown
```

#### **3. Limit Rows**

```sql
-- Limiter transfert de donn√©es
SELECT * FROM remote_table LIMIT 1000;

-- Pagination
SELECT * FROM remote_table
ORDER BY id
LIMIT 1000 OFFSET 0;

-- Page suivante
SELECT * FROM remote_table
ORDER BY id
LIMIT 1000 OFFSET 1000;
```

---

## Comparaison avec Alternatives

### CONNECT vs PostgreSQL FDW (Foreign Data Wrappers)

| Aspect | MariaDB CONNECT | PostgreSQL FDW |
|--------|-----------------|----------------|
| Concept | Storage Engine | Foreign tables |
| Formats fichiers | CSV, JSON, XML | CSV, JSON (extensions) |
| Bases externes | ODBC, MySQL, Mongo | postgres_fdw, oracle_fdw |
| APIs REST | Oui | N√©cessite extensions |
| Configuration | CREATE TABLE | CREATE SERVER + USER MAPPING |
| Maturit√© | Stable | Tr√®s mature |
| Performance | Variable | Optimis√©e (pushdown) |
| Communaut√© | MariaDB | PostgreSQL (large) |

### CONNECT vs Federated Engine

| Aspect | CONNECT | FEDERATED |
|--------|---------|-----------|
| Types sources | Multiple (file, ODBC, API) | MySQL/MariaDB uniquement |
| Flexibilit√© | Tr√®s √©lev√©e | Limit√©e |
| Performance | Variable | Mod√©r√©e |
| Maintenance | Actif MariaDB 11.8 | Deprecated (MySQL 8+) |
| Configuration | Riche (OPTIONS) | Simple (CONNECTION) |

üí° **Recommandation** : CONNECT remplace FEDERATED et l'√©tend consid√©rablement.

### CONNECT vs External Tables (Autre SGBD)

```sql
-- Oracle External Tables
CREATE TABLE ext_csv_oracle (
    col1 NUMBER,
    col2 VARCHAR2(100)
)
ORGANIZATION EXTERNAL (
    TYPE ORACLE_LOADER
    DEFAULT DIRECTORY ext_data_dir
    ACCESS PARAMETERS (FIELDS TERMINATED BY ',')
    LOCATION ('data.csv')
);

-- MariaDB CONNECT √©quivalent
CREATE TABLE ext_csv_mariadb (
    col1 INT,
    col2 VARCHAR(100)
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/path/data.csv'
  SEP_CHAR=',';
```

---

## Configuration et Administration

### Variables Syst√®me

```sql
-- Variables CONNECT (peu nombreuses)
SHOW VARIABLES LIKE '%connect%';

-- connect_type_conv : Conversion automatique de types
SET GLOBAL connect_type_conv = 'YES';  -- D√©faut

-- connect_work_size : Taille buffer de travail (bytes)
SET GLOBAL connect_work_size = 67108864;  -- 64 MB

-- connect_use_tempfile : Utiliser fichier temporaire pour tri
SET GLOBAL connect_use_tempfile = 'AUTO';  -- AUTO, YES, NO
```

### Monitoring

```sql
-- Statistiques tables CONNECT
SELECT
    TABLE_SCHEMA,
    TABLE_NAME,
    ENGINE,
    CREATE_OPTIONS,
    TABLE_COMMENT
FROM INFORMATION_SCHEMA.TABLES
WHERE ENGINE = 'CONNECT';

-- Aucune m√©trique sp√©cifique dans PERFORMANCE_SCHEMA
-- Monitoring via logs d'erreurs et application
```

### Troubleshooting

```sql
-- Erreurs communes

-- 1. Fichier non trouv√©
CREATE TABLE test_csv (...) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/wrong/path/file.csv';
-- ERROR: Cannot open file '/wrong/path/file.csv'

-- Solution : V√©rifier permissions et chemin
-- MariaDB doit avoir acc√®s lecture/√©criture

-- 2. Connexion ODBC √©chou√©e
CREATE TABLE test_odbc (...) ENGINE=CONNECT
  TABLE_TYPE=ODBC
  CONNECTION='DSN=InvalidDSN';
-- ERROR: ODBC connection failed

-- Solution : Tester avec isql
isql -v InvalidDSN username password

-- 3. Format JSON invalide
-- Fichier malform√©
CREATE TABLE test_json (...) ENGINE=CONNECT
  TABLE_TYPE=JSON
  FILE_NAME='/data/invalid.json';
SELECT * FROM test_json;  -- ERROR: JSON parse error

-- Solution : Valider JSON
python3 -m json.tool /data/invalid.json
```

---

## Best Practices

### ‚úÖ √Ä Faire

1. **Cache local pour donn√©es fr√©quentes** : InnoDB + refresh p√©riodique
2. **Limiter volume de donn√©es** : LIMIT, filtres, batch processing
3. **Valider sources externes** : Tester formats, permissions
4. **Documenter connexions** : Scripts de CREATE TABLE versionn√©s
5. **Monitoring des sources** : Alertes si source indisponible
6. **Utiliser vues pour abstraction** : Masquer complexit√© CONNECT
7. **Backup des fichiers externes** : Ne pas se fier uniquement √† CONNECT

```sql
-- Exemple de vue abstraite
CREATE VIEW customer_unified AS
SELECT customer_id, name, email, 'local' AS source
FROM customers_local
UNION ALL
SELECT id AS customer_id, name, email, 'remote' AS source
FROM customers_remote_odbc;

-- Application utilise la vue
SELECT * FROM customer_unified WHERE customer_id = 123;
```

### ‚ùå √Ä √âviter

1. **Tables CONNECT pour OLTP** : Performance variable
2. **Transactions distribu√©es complexes** : Pas de 2PC
3. **JOIN massifs sur sources externes** : Transfert √©norme de donn√©es
4. **D√©pendre d'APIs instables** : Caching requis
5. **Pas de validation de format** : Fichiers corrompus ‚Üí erreurs
6. **Credentials en clair** : Utiliser mysql.connect_strings
7. **Ignorer la latence r√©seau** : Sources distantes = lenteur

```sql
-- ‚ùå Anti-pattern : OLTP sur fichier CSV
CREATE TABLE orders_live (
    order_id INT,
    customer_id INT,
    amount DECIMAL(10,2)
) ENGINE=CONNECT
  TABLE_TYPE=CSV
  FILE_NAME='/data/orders.csv';

-- Application fait 10000 INSERT/s
-- ‚Üí Performance terrible, CSV corrompu

-- ‚úÖ Bon usage : ETL batch
-- Charger CSV vers InnoDB p√©riodiquement
```

---

## ‚úÖ Points cl√©s √† retenir

- **CONNECT = Hub d'int√©gration** : Acc√®s SQL √† sources h√©t√©rog√®nes (fichiers, bases, APIs)
- **8 types de tables** : FILE (CSV, JSON, XML), ODBC, MYSQL, MONGO, REST, PROXY, TBL, PIVOT
- **Pas de stockage local** : Chaque requ√™te interroge la source externe
- **Performance variable** : D√©pend de la source (fichier local rapide, API REST lente)
- **Pas d'index** : Full scan obligatoire, cache local recommand√©
- **Transactions limit√©es** : Pas de 2PC distribu√©, pas de rollback cross-source
- **Cas d'usage** : ETL, data federation, migration, int√©gration NoSQL/legacy
- **Alternatives** : PostgreSQL FDW (plus mature), Federated (deprecated)
- **Optimisations** : Cache InnoDB, filtrage source, batch processing, vues abstraites
- **Limitations** : Latence r√©seau, pushdown limit√©, pas de contraintes FK

---

## üîó Ressources et r√©f√©rences

- [üìñ CONNECT Storage Engine](https://mariadb.com/kb/en/connect-storage-engine/)
- [üìñ CONNECT Table Types](https://mariadb.com/kb/en/connect-table-types/)
- [üìñ CONNECT - CSV Files](https://mariadb.com/kb/en/connect-csv-and-fmt-table-types/)
- [üìñ CONNECT - JSON](https://mariadb.com/kb/en/connect-json-table-type/)
- [üìñ CONNECT - ODBC](https://mariadb.com/kb/en/connect-odbc-table-type/)
- [üìñ CONNECT - MONGO](https://mariadb.com/kb/en/connect-mongo-table-type/)

**Articles techniques** :
- "Data Integration with CONNECT Engine" - MariaDB Blog
- "ETL with MariaDB CONNECT" - MariaDB Corporation
- "CONNECT vs Foreign Data Wrappers" - Database Journal

**Exemples** :
- [CONNECT Examples](https://mariadb.com/kb/en/connect-table-types-overview/)
- [ETL Patterns with CONNECT](https://mariadb.com/kb/en/connect-examples/)

---

## ‚û°Ô∏è Conclusion du Chapitre 7 : Moteurs de Stockage

Vous avez maintenant explor√© l'architecture **Pluggable Storage Engine** de MariaDB et ses principaux moteurs :

- **[7.2] InnoDB** : Moteur transactionnel par d√©faut (Buffer Pool, Redo/Undo, ACID)
- **[7.3] MyISAM** : Moteur legacy (migration vers InnoDB/Aria)
- **[7.4] Aria** : Successeur de MyISAM (crash-safe, performances)
- **[7.5] ColumnStore** : Analytique OLAP (compression columnar)
- **[7.6] S3** : Archivage cloud (AWS S3, MinIO)
- **[7.7] Vector/HNSW** : Recherche vectorielle pour IA üÜï
- **[7.10] Moteurs sp√©cialis√©s** :
  - **[7.10.1] Memory** : Tables en RAM (cache haute performance)
  - **[7.10.2] Archive** : Compression maximale (archivage froid)
  - **[7.10.3] Spider** : Sharding distribu√© (scale-out horizontal)
  - **[7.10.4] CONNECT** : Acc√®s donn√©es externes (ETL, federation)


‚è≠Ô∏è [Programmation C√¥t√© Serveur](/08-programmation-cote-serveur/README.md)
