üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.9.4 Hybrid Search (Vecteurs + SQL Relationnel)

> **Niveau** : Interm√©diaire √† Avanc√©  
> **Dur√©e estim√©e** : 4-5 heures  
> **Pr√©requis** : Section 20.9.1 (Semantic Search), Chapitre 5 (Index Full-Text), SQL avanc√©

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre les forces et limites de la recherche vectorielle vs lexicale
- Impl√©menter une recherche hybride combinant `VECTOR` et `FULLTEXT` dans MariaDB 11.8
- Appliquer diff√©rentes strat√©gies de fusion des scores (RRF, weighted sum, cascade)
- Concevoir des architectures de recherche hybride pour diff√©rents cas d'usage
- Optimiser les performances des requ√™tes hybrides √† grande √©chelle

---

## Introduction

La **recherche hybride** (Hybrid Search) combine les forces de deux paradigmes de recherche compl√©mentaires :

- **Recherche lexicale (full-text)** : Correspondance exacte de mots-cl√©s, acronymes, identifiants techniques
- **Recherche s√©mantique (vectorielle)** : Compr√©hension du sens et de l'intention, synonymes, reformulations

Ni l'une ni l'autre n'est parfaite seule. La recherche hybride exploite le meilleur des deux mondes pour offrir des r√©sultats plus pertinents et robustes.

üÜï **Nouveaut√© MariaDB 11.8** : La combinaison du type `VECTOR` avec index `HNSW` et des index `FULLTEXT` existants permet d'impl√©menter nativement une recherche hybride performante, sans d√©pendre d'outils externes.

---

## Pourquoi la recherche hybride ?

### Limites de la recherche lexicale seule

| Probl√®me | Exemple |
|----------|---------|
| **Synonymes manqu√©s** | "voiture" ne trouve pas "automobile", "v√©hicule" |
| **Contexte ignor√©** | "jaguar" ‚Üí animal ou marque automobile ? |
| **Reformulations invisibles** | "comment cuisiner" vs "recette de cuisine" |
| **Fautes d'orthographe** | "MariaDB" vs "MariDB" |
| **Vocabulaire utilisateur ‚â† vocabulaire document** | Utilisateur cherche "bug", document dit "d√©faut" |

### Limites de la recherche vectorielle seule

| Probl√®me | Exemple |
|----------|---------|
| **Termes techniques dilu√©s** | Recherche "ERR_SSL_PROTOCOL_ERROR" ‚Üí embedding trop g√©n√©rique |
| **Identifiants et codes** | "SKU-12345" ou "CVE-2024-1234" perdus dans l'embedding |
| **Noms propres sp√©cifiques** | "John Smith" noy√© dans le vecteur |
| **Requ√™tes tr√®s courtes** | "MariaDB GTID" ‚Üí embedding peu informatif |
| **Matching exact requis** | Num√©ro de commande, r√©f√©rence produit |

### La compl√©mentarit√© hybride

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     COMPL√âMENTARIT√â RECHERCHE HYBRIDE                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   RECHERCHE LEXICALE (FULLTEXT)         RECHERCHE VECTORIELLE           ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ   ‚îÇ ‚úÖ Termes exacts        ‚îÇ           ‚îÇ ‚úÖ Synonymes            ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚úÖ Codes, identifiants  ‚îÇ           ‚îÇ ‚úÖ Reformulations       ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚úÖ Acronymes            ‚îÇ           ‚îÇ ‚úÖ Contexte s√©mantique  ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚úÖ Requ√™tes courtes     ‚îÇ           ‚îÇ ‚úÖ Questions naturelles ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚úÖ Pr√©cision            ‚îÇ           ‚îÇ ‚úÖ D√©couverte           ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ                         ‚îÇ           ‚îÇ                         ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚ùå Synonymes            ‚îÇ           ‚îÇ ‚ùå Termes techniques    ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚ùå Variations           ‚îÇ           ‚îÇ ‚ùå Codes exacts         ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ ‚ùå Sens implicite       ‚îÇ           ‚îÇ ‚ùå Requ√™tes tr√®s courtes‚îÇ     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ               ‚îÇ                                     ‚îÇ                   ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                              ‚îÇ                                          ‚îÇ
‚îÇ                              ‚ñº                                          ‚îÇ
‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ               ‚îÇ     RECHERCHE HYBRIDE       ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îÇ ‚úÖ Termes exacts      ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îÇ ‚úÖ Synonymes          ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îÇ ‚úÖ Codes + Contexte   ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îÇ ‚úÖ Pr√©cision + Rappel ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îÇ ‚úÖ Robustesse         ‚îÇ  ‚îÇ                           ‚îÇ
‚îÇ               ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                           ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Strat√©gies de fusion des scores

### Vue d'ensemble des approches

| Strat√©gie | Principe | Avantages | Inconv√©nients |
|-----------|----------|-----------|---------------|
| **Weighted Sum** | `Œ± √ó score_lexical + Œ≤ √ó score_semantic` | Simple, tunable | Scores non comparables directement |
| **Reciprocal Rank Fusion (RRF)** | Fusion bas√©e sur les rangs | Robuste, pas de normalisation | Perd l'information de score |
| **Cascade/Re-ranking** | Lexical ‚Üí Semantic ou inverse | Efficace, contr√¥l√© | Peut manquer des r√©sultats |
| **Intersection/Union** | R√©sultats communs ou combin√©s | Pr√©cision ou rappel | Rigide |
| **Score normalis√©** | Min-max ou z-score avant fusion | Scores comparables | Sensible aux outliers |

### Strat√©gie 1 : Weighted Sum (somme pond√©r√©e)

```sql
-- Recherche hybride avec somme pond√©r√©e
-- Poids : 60% s√©mantique, 40% lexical

SET @query_text = 'comment configurer la r√©plication MariaDB';
SET @query_embedding = VEC_FromText('[0.023, -0.156, 0.892, ...]');  -- 1536 dim
SET @weight_semantic = 0.6;
SET @weight_lexical = 0.4;

WITH 
-- Recherche s√©mantique
semantic_results AS (
    SELECT 
        dc.id,
        dc.document_id,
        dc.chunk_text,
        VEC_DISTANCE_COSINE(dc.embedding, @query_embedding) AS distance,
        -- Score s√©mantique normalis√© (0-1, plus haut = meilleur)
        (1 - VEC_DISTANCE_COSINE(dc.embedding, @query_embedding)) AS semantic_score
    FROM document_chunks dc
    ORDER BY distance ASC
    LIMIT 100
),
-- Recherche full-text
fulltext_results AS (
    SELECT 
        dc.id,
        dc.document_id,
        dc.chunk_text,
        MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) AS ft_raw_score
    FROM document_chunks dc
    WHERE MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE)
    LIMIT 100
),
-- Normaliser le score full-text (0-1)
fulltext_normalized AS (
    SELECT 
        fr.*,
        fr.ft_raw_score / (SELECT MAX(ft_raw_score) FROM fulltext_results) AS lexical_score
    FROM fulltext_results fr
)
-- Fusion avec somme pond√©r√©e
SELECT 
    COALESCE(sr.id, fn.id) AS chunk_id,
    COALESCE(sr.document_id, fn.document_id) AS document_id,
    COALESCE(sr.chunk_text, fn.chunk_text) AS chunk_text,
    COALESCE(sr.semantic_score, 0) AS semantic_score,
    COALESCE(fn.lexical_score, 0) AS lexical_score,
    -- Score hybride pond√©r√©
    (COALESCE(sr.semantic_score, 0) * @weight_semantic + 
     COALESCE(fn.lexical_score, 0) * @weight_lexical) AS hybrid_score,
    -- Indicateur de source
    CASE 
        WHEN sr.id IS NOT NULL AND fn.id IS NOT NULL THEN 'BOTH'
        WHEN sr.id IS NOT NULL THEN 'SEMANTIC_ONLY'
        ELSE 'LEXICAL_ONLY'
    END AS match_source
FROM semantic_results sr
LEFT JOIN fulltext_normalized fn ON sr.id = fn.id
UNION
SELECT 
    fn.id,
    fn.document_id,
    fn.chunk_text,
    0 AS semantic_score,
    fn.lexical_score,
    fn.lexical_score * @weight_lexical AS hybrid_score,
    'LEXICAL_ONLY' AS match_source
FROM fulltext_normalized fn
WHERE fn.id NOT IN (SELECT id FROM semantic_results)
ORDER BY hybrid_score DESC
LIMIT 20;
```

üí° **Conseil** : Les r√©sultats pr√©sents dans les DEUX listes (match_source = 'BOTH') sont g√©n√©ralement les plus pertinents. Vous pouvez ajouter un bonus pour ces r√©sultats.

### Strat√©gie 2 : Reciprocal Rank Fusion (RRF)

RRF est une m√©thode robuste qui ne n√©cessite pas de normalisation des scores. Elle fusionne les r√©sultats en fonction de leur **rang** plut√¥t que de leur score absolu.

```sql
-- Reciprocal Rank Fusion (RRF)
-- Formule : RRF_score = Œ£ 1/(k + rank_i) pour chaque liste o√π le document appara√Æt
-- k est une constante (typiquement 60)

SET @query_text = 'optimisation requ√™tes lentes MariaDB';
SET @query_embedding = VEC_FromText('[...]');
SET @k = 60;  -- Constante RRF (60 est le standard)

WITH 
-- Recherche s√©mantique avec rang
semantic_ranked AS (
    SELECT 
        dc.id,
        dc.document_id,
        dc.chunk_text,
        ROW_NUMBER() OVER (ORDER BY VEC_DISTANCE_COSINE(dc.embedding, @query_embedding) ASC) AS semantic_rank
    FROM document_chunks dc
    ORDER BY VEC_DISTANCE_COSINE(dc.embedding, @query_embedding) ASC
    LIMIT 100
),
-- Recherche full-text avec rang
fulltext_ranked AS (
    SELECT 
        dc.id,
        dc.document_id,
        dc.chunk_text,
        ROW_NUMBER() OVER (ORDER BY MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) DESC) AS lexical_rank
    FROM document_chunks dc
    WHERE MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE)
    LIMIT 100
),
-- Calculer le score RRF pour chaque document
rrf_scores AS (
    SELECT 
        COALESCE(sr.id, fr.id) AS chunk_id,
        COALESCE(sr.document_id, fr.document_id) AS document_id,
        COALESCE(sr.chunk_text, fr.chunk_text) AS chunk_text,
        sr.semantic_rank,
        fr.lexical_rank,
        -- Score RRF : somme des contributions de chaque liste
        COALESCE(1.0 / (@k + sr.semantic_rank), 0) + 
        COALESCE(1.0 / (@k + fr.lexical_rank), 0) AS rrf_score
    FROM semantic_ranked sr
    LEFT JOIN fulltext_ranked fr ON sr.id = fr.id
    
    UNION
    
    SELECT 
        fr.id,
        fr.document_id,
        fr.chunk_text,
        NULL AS semantic_rank,
        fr.lexical_rank,
        1.0 / (@k + fr.lexical_rank) AS rrf_score
    FROM fulltext_ranked fr
    WHERE fr.id NOT IN (SELECT id FROM semantic_ranked)
)
SELECT 
    chunk_id,
    document_id,
    chunk_text,
    semantic_rank,
    lexical_rank,
    ROUND(rrf_score, 6) AS rrf_score,
    -- Boost pour les r√©sultats pr√©sents dans les deux listes
    CASE 
        WHEN semantic_rank IS NOT NULL AND lexical_rank IS NOT NULL THEN 'BOTH'
        WHEN semantic_rank IS NOT NULL THEN 'SEMANTIC'
        ELSE 'LEXICAL'
    END AS source
FROM rrf_scores
ORDER BY rrf_score DESC
LIMIT 20;
```

‚ö†Ô∏è **Attention** : RRF donne le m√™me poids aux deux m√©thodes de recherche. Pour pond√©rer diff√©remment, utilisez des coefficients : `Œ± / (k + rank_semantic) + Œ≤ / (k + rank_lexical)`.

### Strat√©gie 3 : Cascade / Re-ranking

Approche en deux √©tapes : la premi√®re recherche (g√©n√©ralement lexicale) fait un premier filtrage large, puis la seconde (s√©mantique) re-classe les r√©sultats.

```sql
-- Cascade : Lexical ‚Üí Semantic re-ranking
-- √âtape 1 : R√©cup√©rer les 200 meilleurs r√©sultats full-text
-- √âtape 2 : Re-ranker par similarit√© s√©mantique

SET @query_text = 'erreur connexion base de donn√©es timeout';
SET @query_embedding = VEC_FromText('[...]');

WITH 
-- √âtape 1 : Recherche lexicale large (recall √©lev√©)
lexical_candidates AS (
    SELECT 
        dc.id,
        dc.document_id,
        dc.chunk_text,
        dc.embedding,
        MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) AS lexical_score
    FROM document_chunks dc
    WHERE MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE)
    ORDER BY lexical_score DESC
    LIMIT 200  -- Large pool de candidats
),
-- √âtape 2 : Re-ranking s√©mantique sur les candidats
semantic_reranked AS (
    SELECT 
        lc.id,
        lc.document_id,
        lc.chunk_text,
        lc.lexical_score,
        VEC_DISTANCE_COSINE(lc.embedding, @query_embedding) AS semantic_distance,
        (1 - VEC_DISTANCE_COSINE(lc.embedding, @query_embedding)) AS semantic_score
    FROM lexical_candidates lc
)
SELECT 
    id,
    document_id,
    chunk_text,
    lexical_score,
    semantic_score,
    -- Score final : priorit√© au s√©mantique avec bonus lexical
    (semantic_score * 0.7 + 
     (lexical_score / (SELECT MAX(lexical_score) FROM semantic_reranked)) * 0.3) AS final_score
FROM semantic_reranked
ORDER BY final_score DESC
LIMIT 20;
```

üí° **Conseil** : La cascade Lexical ‚Üí Semantic est plus rapide car l'index FULLTEXT est g√©n√©ralement plus efficace pour le filtrage initial. Inversement (Semantic ‚Üí Lexical) est utile quand la s√©mantique est prioritaire.

---

## Impl√©mentation compl√®te dans MariaDB 11.8

### Sch√©ma optimis√© pour la recherche hybride

```sql
-- Base de donn√©es pour recherche hybride
CREATE DATABASE IF NOT EXISTS hybrid_search
    CHARACTER SET utf8mb4
    COLLATE utf8mb4_uca1400_ai_ci;

USE hybrid_search;

-- Table des documents sources
CREATE TABLE documents (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    titre VARCHAR(500) NOT NULL,
    contenu LONGTEXT NOT NULL,
    categorie VARCHAR(100),
    tags JSON,
    auteur VARCHAR(200),
    date_publication DATE,
    langue CHAR(2) DEFAULT 'fr',
    
    -- M√©tadonn√©es de recherche
    mot_cles_extraits TEXT,  -- Mots-cl√©s extraits pour boost lexical
    
    -- Index full-text sur le document complet
    FULLTEXT INDEX idx_ft_document (titre, contenu, mot_cles_extraits),
    
    INDEX idx_categorie (categorie),
    INDEX idx_date (date_publication DESC)
) ENGINE=InnoDB;

-- Table des chunks avec double indexation
CREATE TABLE document_chunks (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    document_id BIGINT UNSIGNED NOT NULL,
    chunk_index INT UNSIGNED NOT NULL,
    chunk_text TEXT NOT NULL,
    
    -- üÜï Embedding vectoriel (MariaDB 11.8)
    embedding VECTOR(1536) NOT NULL,
    
    -- M√©tadonn√©es du chunk
    token_count INT UNSIGNED,
    section_title VARCHAR(200),
    
    -- Cl√©s √©trang√®res et index
    FOREIGN KEY (document_id) REFERENCES documents(id) ON DELETE CASCADE,
    
    -- Index full-text sur le chunk
    FULLTEXT INDEX idx_ft_chunk (chunk_text),
    
    -- üÜï Index HNSW pour recherche vectorielle
    VECTOR INDEX idx_vector_chunk (embedding)
        WITH (DISTANCE = COSINE, M = 24, EF_CONSTRUCTION = 200),
    
    INDEX idx_document_chunk (document_id, chunk_index)
) ENGINE=InnoDB;

-- Table de configuration des recherches
CREATE TABLE search_configs (
    id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    config_name VARCHAR(50) UNIQUE NOT NULL,
    
    -- Poids de fusion
    weight_semantic FLOAT DEFAULT 0.6,
    weight_lexical FLOAT DEFAULT 0.4,
    
    -- Strat√©gie de fusion
    fusion_strategy ENUM('weighted_sum', 'rrf', 'cascade_lexical_first', 'cascade_semantic_first') DEFAULT 'weighted_sum',
    
    -- Param√®tres RRF
    rrf_k INT UNSIGNED DEFAULT 60,
    
    -- Param√®tres cascade
    cascade_first_limit INT UNSIGNED DEFAULT 200,
    
    -- Filtres par d√©faut
    default_limit INT UNSIGNED DEFAULT 20,
    min_score_threshold FLOAT DEFAULT 0.1,
    
    -- Boost pour r√©sultats dans les deux listes
    both_match_boost FLOAT DEFAULT 1.2,
    
    is_active BOOLEAN DEFAULT TRUE
) ENGINE=InnoDB;

-- Configuration par d√©faut
INSERT INTO search_configs (config_name, weight_semantic, weight_lexical, fusion_strategy)
VALUES 
    ('default', 0.6, 0.4, 'weighted_sum'),
    ('precision_focus', 0.4, 0.6, 'cascade_lexical_first'),
    ('semantic_focus', 0.8, 0.2, 'cascade_semantic_first'),
    ('balanced_rrf', 0.5, 0.5, 'rrf');
```

### Proc√©dure de recherche hybride g√©n√©rique

```sql
DELIMITER //

CREATE PROCEDURE hybrid_search(
    IN p_query_text VARCHAR(1000),
    IN p_query_embedding_text TEXT,  -- Vecteur sous forme de texte '[0.1, 0.2, ...]'
    IN p_config_name VARCHAR(50),
    IN p_limit INT,
    IN p_category_filter VARCHAR(100),
    IN p_date_from DATE,
    IN p_date_to DATE
)
BEGIN
    DECLARE v_weight_semantic FLOAT;
    DECLARE v_weight_lexical FLOAT;
    DECLARE v_fusion_strategy VARCHAR(50);
    DECLARE v_rrf_k INT;
    DECLARE v_cascade_limit INT;
    DECLARE v_both_boost FLOAT;
    DECLARE v_query_embedding VECTOR(1536);
    
    -- Charger la configuration
    SELECT 
        weight_semantic, weight_lexical, fusion_strategy, 
        rrf_k, cascade_first_limit, both_match_boost
    INTO 
        v_weight_semantic, v_weight_lexical, v_fusion_strategy,
        v_rrf_k, v_cascade_limit, v_both_boost
    FROM search_configs
    WHERE config_name = COALESCE(p_config_name, 'default')
    AND is_active = TRUE
    LIMIT 1;
    
    -- Convertir l'embedding
    SET v_query_embedding = VEC_FromText(p_query_embedding_text);
    
    -- Ex√©cuter la strat√©gie appropri√©e
    IF v_fusion_strategy = 'weighted_sum' THEN
        -- Strat√©gie somme pond√©r√©e
        SELECT * FROM (
            WITH 
            semantic_results AS (
                SELECT 
                    dc.id, dc.document_id, dc.chunk_text, dc.section_title,
                    d.titre AS doc_titre, d.categorie,
                    (1 - VEC_DISTANCE_COSINE(dc.embedding, v_query_embedding)) AS semantic_score
                FROM document_chunks dc
                JOIN documents d ON dc.document_id = d.id
                WHERE (p_category_filter IS NULL OR d.categorie = p_category_filter)
                AND (p_date_from IS NULL OR d.date_publication >= p_date_from)
                AND (p_date_to IS NULL OR d.date_publication <= p_date_to)
                ORDER BY VEC_DISTANCE_COSINE(dc.embedding, v_query_embedding) ASC
                LIMIT 100
            ),
            fulltext_results AS (
                SELECT 
                    dc.id,
                    MATCH(dc.chunk_text) AGAINST(p_query_text IN NATURAL LANGUAGE MODE) AS ft_score
                FROM document_chunks dc
                JOIN documents d ON dc.document_id = d.id
                WHERE MATCH(dc.chunk_text) AGAINST(p_query_text IN NATURAL LANGUAGE MODE)
                AND (p_category_filter IS NULL OR d.categorie = p_category_filter)
                AND (p_date_from IS NULL OR d.date_publication >= p_date_from)
                AND (p_date_to IS NULL OR d.date_publication <= p_date_to)
                LIMIT 100
            ),
            fulltext_normalized AS (
                SELECT id, ft_score / (SELECT MAX(ft_score) FROM fulltext_results) AS lexical_score
                FROM fulltext_results
            )
            SELECT 
                sr.id AS chunk_id,
                sr.document_id,
                sr.doc_titre,
                sr.section_title,
                LEFT(sr.chunk_text, 300) AS chunk_preview,
                sr.categorie,
                ROUND(sr.semantic_score, 4) AS semantic_score,
                ROUND(COALESCE(fn.lexical_score, 0), 4) AS lexical_score,
                ROUND(
                    (sr.semantic_score * v_weight_semantic + 
                     COALESCE(fn.lexical_score, 0) * v_weight_lexical) *
                    CASE WHEN fn.id IS NOT NULL THEN v_both_boost ELSE 1 END,
                4) AS hybrid_score,
                CASE WHEN fn.id IS NOT NULL THEN 'BOTH' ELSE 'SEMANTIC' END AS match_type
            FROM semantic_results sr
            LEFT JOIN fulltext_normalized fn ON sr.id = fn.id
            
            UNION
            
            SELECT 
                dc.id, dc.document_id, d.titre, dc.section_title,
                LEFT(dc.chunk_text, 300), d.categorie,
                0 AS semantic_score,
                ROUND(fn.lexical_score, 4),
                ROUND(fn.lexical_score * v_weight_lexical, 4) AS hybrid_score,
                'LEXICAL' AS match_type
            FROM fulltext_normalized fn
            JOIN document_chunks dc ON fn.id = dc.id
            JOIN documents d ON dc.document_id = d.id
            WHERE fn.id NOT IN (SELECT id FROM semantic_results)
        ) combined
        ORDER BY hybrid_score DESC
        LIMIT p_limit;
        
    ELSEIF v_fusion_strategy = 'rrf' THEN
        -- Strat√©gie RRF
        SELECT * FROM (
            WITH 
            semantic_ranked AS (
                SELECT 
                    dc.id, dc.document_id, dc.chunk_text, dc.section_title,
                    d.titre AS doc_titre, d.categorie,
                    ROW_NUMBER() OVER (ORDER BY VEC_DISTANCE_COSINE(dc.embedding, v_query_embedding) ASC) AS s_rank
                FROM document_chunks dc
                JOIN documents d ON dc.document_id = d.id
                WHERE (p_category_filter IS NULL OR d.categorie = p_category_filter)
                ORDER BY VEC_DISTANCE_COSINE(dc.embedding, v_query_embedding) ASC
                LIMIT 100
            ),
            fulltext_ranked AS (
                SELECT 
                    dc.id,
                    ROW_NUMBER() OVER (ORDER BY MATCH(dc.chunk_text) AGAINST(p_query_text IN NATURAL LANGUAGE MODE) DESC) AS l_rank
                FROM document_chunks dc
                JOIN documents d ON dc.document_id = d.id
                WHERE MATCH(dc.chunk_text) AGAINST(p_query_text IN NATURAL LANGUAGE MODE)
                AND (p_category_filter IS NULL OR d.categorie = p_category_filter)
                LIMIT 100
            )
            SELECT 
                sr.id AS chunk_id,
                sr.document_id,
                sr.doc_titre,
                sr.section_title,
                LEFT(sr.chunk_text, 300) AS chunk_preview,
                sr.categorie,
                sr.s_rank AS semantic_rank,
                fr.l_rank AS lexical_rank,
                ROUND(
                    COALESCE(1.0 / (v_rrf_k + sr.s_rank), 0) + 
                    COALESCE(1.0 / (v_rrf_k + fr.l_rank), 0),
                6) AS rrf_score,
                CASE 
                    WHEN fr.l_rank IS NOT NULL THEN 'BOTH'
                    ELSE 'SEMANTIC'
                END AS match_type
            FROM semantic_ranked sr
            LEFT JOIN fulltext_ranked fr ON sr.id = fr.id
            
            UNION
            
            SELECT 
                dc.id, dc.document_id, d.titre, dc.section_title,
                LEFT(dc.chunk_text, 300), d.categorie,
                NULL, fr.l_rank,
                ROUND(1.0 / (v_rrf_k + fr.l_rank), 6),
                'LEXICAL'
            FROM fulltext_ranked fr
            JOIN document_chunks dc ON fr.id = dc.id
            JOIN documents d ON dc.document_id = d.id
            WHERE fr.id NOT IN (SELECT id FROM semantic_ranked)
        ) combined
        ORDER BY rrf_score DESC
        LIMIT p_limit;
        
    END IF;
    
END //

DELIMITER ;
```

### Utilisation de la proc√©dure

```sql
-- Recherche hybride avec configuration par d√©faut
CALL hybrid_search(
    'comment optimiser les requ√™tes lentes dans MariaDB',  -- Texte de recherche
    '[0.023, -0.156, 0.892, ...]',  -- Embedding de la requ√™te
    'default',  -- Configuration
    20,         -- Limite de r√©sultats
    NULL,       -- Pas de filtre cat√©gorie
    NULL,       -- Pas de filtre date d√©but
    NULL        -- Pas de filtre date fin
);

-- Recherche avec filtres
CALL hybrid_search(
    'backup incremental mariabackup',
    '[...]',
    'precision_focus',  -- Configuration orient√©e pr√©cision
    10,
    'administration',   -- Cat√©gorie sp√©cifique
    '2024-01-01',       -- Depuis janvier 2024
    NULL
);
```

---

## Cas d'usage d√©taill√©s

### 1. Recherche e-commerce hybride

```sql
-- Sch√©ma produits e-commerce avec recherche hybride
CREATE TABLE products_hybrid (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    sku VARCHAR(50) UNIQUE NOT NULL,
    nom VARCHAR(300) NOT NULL,
    description TEXT,
    marque VARCHAR(100),
    categorie_path VARCHAR(500),  -- "√âlectronique > T√©l√©phones > Smartphones"
    
    -- Attributs structur√©s
    prix DECIMAL(10,2),
    note_moyenne DECIMAL(3,2),
    en_stock BOOLEAN DEFAULT TRUE,
    attributs JSON,
    
    -- Champs de recherche
    keywords VARCHAR(1000),  -- Mots-cl√©s extraits/ajout√©s manuellement
    
    -- üÜï Embedding du produit
    product_embedding VECTOR(768) NOT NULL,
    
    -- Index
    FULLTEXT INDEX idx_ft_product (nom, description, marque, keywords),
    VECTOR INDEX idx_vec_product (product_embedding) WITH (DISTANCE = COSINE, M = 24),
    INDEX idx_prix (prix),
    INDEX idx_stock_note (en_stock, note_moyenne DESC)
) ENGINE=InnoDB;

-- Recherche e-commerce hybride avec filtres business
SET @search_query = 'smartphone photo haute qualit√©';
SET @query_embedding = VEC_FromText('[...]');

WITH 
-- Recherche s√©mantique (comprend "appareil photo performant", "cam√©ra", etc.)
semantic_products AS (
    SELECT 
        id, sku, nom, marque, prix, note_moyenne,
        (1 - VEC_DISTANCE_COSINE(product_embedding, @query_embedding)) AS sem_score,
        ROW_NUMBER() OVER (ORDER BY VEC_DISTANCE_COSINE(product_embedding, @query_embedding) ASC) AS sem_rank
    FROM products_hybrid
    WHERE en_stock = TRUE
    AND prix BETWEEN 200 AND 1500
    ORDER BY VEC_DISTANCE_COSINE(product_embedding, @query_embedding) ASC
    LIMIT 50
),
-- Recherche lexicale (trouve "smartphone", "photo", etc.)
lexical_products AS (
    SELECT 
        id,
        MATCH(nom, description, marque, keywords) AGAINST(@search_query IN NATURAL LANGUAGE MODE) AS lex_score,
        ROW_NUMBER() OVER (ORDER BY MATCH(nom, description, marque, keywords) AGAINST(@search_query IN NATURAL LANGUAGE MODE) DESC) AS lex_rank
    FROM products_hybrid
    WHERE MATCH(nom, description, marque, keywords) AGAINST(@search_query IN NATURAL LANGUAGE MODE)
    AND en_stock = TRUE
    AND prix BETWEEN 200 AND 1500
    LIMIT 50
)
SELECT 
    sp.id,
    sp.sku,
    sp.nom,
    sp.marque,
    sp.prix,
    sp.note_moyenne,
    sp.sem_score,
    COALESCE(lp.lex_score, 0) AS lex_score,
    -- RRF avec boost pour les deux matches
    (
        1.0 / (60 + sp.sem_rank) + 
        COALESCE(1.0 / (60 + lp.lex_rank), 0)
    ) * CASE WHEN lp.id IS NOT NULL THEN 1.3 ELSE 1.0 END AS hybrid_rrf,
    -- Boost suppl√©mentaire pour les produits bien not√©s
    (
        1.0 / (60 + sp.sem_rank) + 
        COALESCE(1.0 / (60 + lp.lex_rank), 0)
    ) * CASE WHEN lp.id IS NOT NULL THEN 1.3 ELSE 1.0 END 
    * (0.8 + sp.note_moyenne * 0.04) AS final_score
FROM semantic_products sp
LEFT JOIN lexical_products lp ON sp.id = lp.id
ORDER BY final_score DESC
LIMIT 24;
```

### 2. FAQ / Base de connaissances hybride

```sql
-- Table FAQ avec recherche hybride
CREATE TABLE faq_entries (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    question TEXT NOT NULL,
    reponse TEXT NOT NULL,
    categorie VARCHAR(100),
    tags JSON,
    
    -- Variantes de la question (pour matching lexical)
    questions_alternatives TEXT,  -- Questions similaires s√©par√©es par |
    
    -- Embedding de la question
    question_embedding VECTOR(1536) NOT NULL,
    
    -- Statistiques
    vues INT UNSIGNED DEFAULT 0,
    votes_utile INT UNSIGNED DEFAULT 0,
    
    FULLTEXT INDEX idx_ft_faq (question, questions_alternatives, reponse),
    VECTOR INDEX idx_vec_faq (question_embedding) WITH (DISTANCE = COSINE, M = 16)
) ENGINE=InnoDB;

-- Recherche FAQ hybride avec scoring de pertinence
SET @user_question = 'comment r√©initialiser mon mot de passe oubli√©';
SET @question_embedding = VEC_FromText('[...]');

SELECT 
    f.id,
    f.question,
    LEFT(f.reponse, 500) AS reponse_preview,
    f.categorie,
    
    -- Scores individuels
    (1 - VEC_DISTANCE_COSINE(f.question_embedding, @question_embedding)) AS semantic_similarity,
    MATCH(f.question, f.questions_alternatives, f.reponse) 
        AGAINST(@user_question IN NATURAL LANGUAGE MODE) AS lexical_match,
    
    -- Score hybride avec pond√©ration adaptative
    -- Plus de poids au s√©mantique pour les questions longues/naturelles
    (
        (1 - VEC_DISTANCE_COSINE(f.question_embedding, @question_embedding)) * 0.65 +
        (MATCH(f.question, f.questions_alternatives, f.reponse) 
            AGAINST(@user_question IN NATURAL LANGUAGE MODE) / 
            (SELECT MAX(MATCH(question, questions_alternatives, reponse) 
                AGAINST(@user_question IN NATURAL LANGUAGE MODE)) 
            FROM faq_entries)) * 0.35
    ) AS hybrid_score,
    
    -- Boost de popularit√© (les r√©ponses utiles remontent)
    LOG10(1 + f.votes_utile) * 0.1 AS popularity_boost

FROM faq_entries f
WHERE 
    -- Au moins un match (s√©mantique OU lexical)
    VEC_DISTANCE_COSINE(f.question_embedding, @question_embedding) < 0.5
    OR MATCH(f.question, f.questions_alternatives, f.reponse) 
        AGAINST(@user_question IN NATURAL LANGUAGE MODE) > 0
ORDER BY 
    (hybrid_score + LOG10(1 + f.votes_utile) * 0.1) DESC
LIMIT 5;
```

### 3. Recherche de documentation technique

```sql
-- Documentation technique avec codes d'erreur, commandes, etc.
CREATE TABLE tech_docs (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    titre VARCHAR(300) NOT NULL,
    contenu LONGTEXT NOT NULL,
    type_doc ENUM('guide', 'reference', 'troubleshooting', 'api', 'changelog') NOT NULL,
    version_produit VARCHAR(20),
    
    -- M√©tadonn√©es techniques (important pour matching exact)
    codes_erreur TEXT,       -- "ERR_001, ERR_002, ERR_SSL_*"
    commandes TEXT,          -- "mariadb-dump, mariabackup, ..."
    variables_config TEXT,   -- "innodb_buffer_pool_size, ..."
    
    -- Embedding du contenu
    content_embedding VECTOR(1536) NOT NULL,
    
    FULLTEXT INDEX idx_ft_tech (titre, contenu, codes_erreur, commandes, variables_config),
    VECTOR INDEX idx_vec_tech (content_embedding) WITH (DISTANCE = COSINE, M = 24)
) ENGINE=InnoDB;

-- Recherche technique hybride avec boost pour termes exacts
SET @query = 'innodb_buffer_pool_size performance m√©moire';
SET @query_embedding = VEC_FromText('[...]');

WITH 
-- Extraction des termes techniques potentiels (simplifi√©e)
query_terms AS (
    SELECT 'innodb_buffer_pool_size' AS term
    -- En production, utiliser une fonction d'extraction
),
-- Recherche s√©mantique
semantic_docs AS (
    SELECT 
        id, titre, type_doc, version_produit,
        (1 - VEC_DISTANCE_COSINE(content_embedding, @query_embedding)) AS sem_score
    FROM tech_docs
    ORDER BY VEC_DISTANCE_COSINE(content_embedding, @query_embedding) ASC
    LIMIT 50
),
-- Recherche full-text
fulltext_docs AS (
    SELECT 
        id,
        MATCH(titre, contenu, codes_erreur, commandes, variables_config) 
            AGAINST(@query IN NATURAL LANGUAGE MODE) AS ft_score,
        -- Boost pour match exact sur variables/commandes
        CASE 
            WHEN variables_config LIKE '%innodb_buffer_pool_size%' THEN 2.0
            WHEN commandes LIKE '%innodb%' THEN 1.5
            ELSE 1.0
        END AS exact_match_boost
    FROM tech_docs
    WHERE MATCH(titre, contenu, codes_erreur, commandes, variables_config) 
        AGAINST(@query IN NATURAL LANGUAGE MODE)
    LIMIT 50
)
SELECT 
    sd.id,
    sd.titre,
    sd.type_doc,
    sd.version_produit,
    sd.sem_score,
    COALESCE(fd.ft_score, 0) AS ft_score,
    COALESCE(fd.exact_match_boost, 1.0) AS exact_boost,
    -- Score hybride avec boost pour termes techniques exacts
    (
        sd.sem_score * 0.5 +
        COALESCE(fd.ft_score / (SELECT MAX(ft_score) FROM fulltext_docs), 0) * 0.5
    ) * COALESCE(fd.exact_match_boost, 1.0) AS hybrid_score
FROM semantic_docs sd
LEFT JOIN fulltext_docs fd ON sd.id = fd.id
ORDER BY hybrid_score DESC
LIMIT 15;
```

---

## Optimisation des performances

### Index et requ√™tes

```sql
-- Analyser les performances de la recherche hybride
EXPLAIN FORMAT=JSON
SELECT 
    dc.id,
    dc.chunk_text,
    VEC_DISTANCE_COSINE(dc.embedding, @query_embedding) AS vec_dist,
    MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) AS ft_score
FROM document_chunks dc
WHERE 
    VEC_DISTANCE_COSINE(dc.embedding, @query_embedding) < 0.5
    OR MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) > 0
ORDER BY 
    (1 - VEC_DISTANCE_COSINE(dc.embedding, @query_embedding)) * 0.6 +
    MATCH(dc.chunk_text) AGAINST(@query_text IN NATURAL LANGUAGE MODE) * 0.4 DESC
LIMIT 20;
```

### Strat√©gies de cache

```sql
-- Table de cache pour les recherches fr√©quentes
CREATE TABLE search_cache (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    query_hash CHAR(64) NOT NULL,  -- SHA256 du texte + embedding
    query_text VARCHAR(1000),
    
    -- R√©sultats mis en cache
    result_ids JSON NOT NULL,      -- [123, 456, 789, ...]
    result_scores JSON NOT NULL,   -- [0.95, 0.88, 0.82, ...]
    
    -- M√©tadonn√©es
    search_config VARCHAR(50),
    filters_hash CHAR(64),         -- Hash des filtres appliqu√©s
    
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    expires_at DATETIME NOT NULL,
    hit_count INT UNSIGNED DEFAULT 0,
    
    UNIQUE KEY uk_query_config (query_hash, search_config, filters_hash),
    INDEX idx_expiration (expires_at)
) ENGINE=InnoDB;

-- V√©rifier le cache avant la recherche
DELIMITER //

CREATE FUNCTION check_search_cache(
    p_query_text VARCHAR(1000),
    p_config VARCHAR(50),
    p_filters_json TEXT
) RETURNS JSON
DETERMINISTIC
BEGIN
    DECLARE v_query_hash CHAR(64);
    DECLARE v_filters_hash CHAR(64);
    DECLARE v_cached_results JSON;
    
    SET v_query_hash = SHA2(p_query_text, 256);
    SET v_filters_hash = SHA2(COALESCE(p_filters_json, ''), 256);
    
    SELECT result_ids INTO v_cached_results
    FROM search_cache
    WHERE query_hash = v_query_hash
    AND search_config = p_config
    AND filters_hash = v_filters_hash
    AND expires_at > NOW();
    
    IF v_cached_results IS NOT NULL THEN
        -- Incr√©menter le compteur de hits
        UPDATE search_cache
        SET hit_count = hit_count + 1
        WHERE query_hash = v_query_hash
        AND search_config = p_config
        AND filters_hash = v_filters_hash;
    END IF;
    
    RETURN v_cached_results;
END //

DELIMITER ;
```

### Pr√©-calcul des scores lexicaux (pour tr√®s gros volumes)

```sql
-- Table de scores full-text pr√©-calcul√©s pour les termes fr√©quents
CREATE TABLE precomputed_ft_scores (
    term_hash CHAR(64) NOT NULL,
    chunk_id BIGINT UNSIGNED NOT NULL,
    ft_score FLOAT NOT NULL,
    computed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (term_hash, chunk_id),
    INDEX idx_chunk (chunk_id),
    INDEX idx_score (term_hash, ft_score DESC)
) ENGINE=InnoDB;

-- Job de pr√©-calcul pour les termes populaires
-- (√† ex√©cuter p√©riodiquement)
INSERT INTO precomputed_ft_scores (term_hash, chunk_id, ft_score)
SELECT 
    SHA2('mariadb replication', 256) AS term_hash,
    dc.id AS chunk_id,
    MATCH(dc.chunk_text) AGAINST('mariadb replication' IN NATURAL LANGUAGE MODE) AS ft_score
FROM document_chunks dc
WHERE MATCH(dc.chunk_text) AGAINST('mariadb replication' IN NATURAL LANGUAGE MODE) > 0
ON DUPLICATE KEY UPDATE ft_score = VALUES(ft_score), computed_at = NOW();
```

---

## Architecture de production

### Pipeline de recherche hybride

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARCHITECTURE RECHERCHE HYBRIDE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                   ‚îÇ
‚îÇ   ‚îÇ   Requ√™te    ‚îÇ                                                   ‚îÇ
‚îÇ   ‚îÇ  Utilisateur ‚îÇ                                                   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                   ‚îÇ
‚îÇ          ‚îÇ                                                           ‚îÇ
‚îÇ          ‚ñº                                                           ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ                    API Search Service                        ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   Cache     ‚îÇ  ‚îÇ  Query      ‚îÇ  ‚îÇ   Embedding         ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   Check     ‚îÇ‚îÄ‚ñ∂‚îÇ  Analysis   ‚îÇ‚îÄ‚ñ∂‚îÇ   Generation        ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   (Redis)   ‚îÇ  ‚îÇ  (intent)   ‚îÇ  ‚îÇ   (OpenAI/local)    ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                   ‚îÇ                  ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ                    ‚îÇ                                          ‚îÇ      ‚îÇ
‚îÇ                    ‚ñº                                          ‚ñº      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ   Recherche Vectorielle ‚îÇ          ‚îÇ   Recherche Full-Text   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   (HNSW Index)          ‚îÇ          ‚îÇ   (FULLTEXT Index)      ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ                         ‚îÇ          ‚îÇ                         ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   VEC_DISTANCE_COSINE   ‚îÇ          ‚îÇ   MATCH...AGAINST       ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ               ‚îÇ                                    ‚îÇ                 ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                              ‚îÇ                                       ‚îÇ
‚îÇ                              ‚ñº                                       ‚îÇ
‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ               ‚îÇ      Score Fusion           ‚îÇ                        ‚îÇ
‚îÇ               ‚îÇ  (RRF / Weighted / Cascade) ‚îÇ                        ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                              ‚îÇ                                       ‚îÇ
‚îÇ                              ‚ñº                                       ‚îÇ
‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ               ‚îÇ     Post-Processing         ‚îÇ                        ‚îÇ
‚îÇ               ‚îÇ  ‚Ä¢ Deduplication            ‚îÇ                        ‚îÇ
‚îÇ               ‚îÇ  ‚Ä¢ Business Rules Boost     ‚îÇ                        ‚îÇ
‚îÇ               ‚îÇ  ‚Ä¢ Diversity Filtering      ‚îÇ                        ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                              ‚îÇ                                       ‚îÇ
‚îÇ                              ‚ñº                                       ‚îÇ
‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ               ‚îÇ       R√©sultats             ‚îÇ                        ‚îÇ
‚îÇ               ‚îÇ    (JSON Response)          ‚îÇ                        ‚îÇ
‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                     MariaDB 11.8 LTS                          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   Primary   ‚îÇ  ‚îÇ  Replica 1  ‚îÇ  ‚îÇ    Replica 2        ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   (Write)   ‚îÇ  ‚îÇ  (Read)     ‚îÇ  ‚îÇ    (Read)           ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ              MaxScale Read/Write Split                        ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Service de recherche Python

```python
# hybrid_search_service.py
import mariadb
import numpy as np
from openai import OpenAI
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import hashlib
import json
import redis

class FusionStrategy(Enum):
    WEIGHTED_SUM = "weighted_sum"
    RRF = "rrf"
    CASCADE = "cascade"

@dataclass
class SearchConfig:
    weight_semantic: float = 0.6
    weight_lexical: float = 0.4
    fusion_strategy: FusionStrategy = FusionStrategy.WEIGHTED_SUM
    rrf_k: int = 60
    both_match_boost: float = 1.2
    limit: int = 20

@dataclass
class SearchResult:
    chunk_id: int
    document_id: int
    title: str
    chunk_text: str
    semantic_score: float
    lexical_score: float
    hybrid_score: float
    match_type: str  # 'BOTH', 'SEMANTIC', 'LEXICAL'

class HybridSearchService:
    
    def __init__(
        self, 
        db_config: Dict, 
        openai_api_key: str,
        redis_config: Optional[Dict] = None
    ):
        self.conn = mariadb.connect(**db_config)
        self.openai_client = OpenAI(api_key=openai_api_key)
        self.redis_client = redis.Redis(**redis_config) if redis_config else None
        self.embedding_model = "text-embedding-3-small"
    
    def generate_embedding(self, text: str) -> np.ndarray:
        """G√©n√®re un embedding pour le texte de recherche."""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        return np.array(response.data[0].embedding)
    
    def _get_cache_key(self, query: str, config: SearchConfig, filters: Dict) -> str:
        """G√©n√®re une cl√© de cache unique."""
        cache_data = {
            'query': query,
            'config': config.__dict__,
            'filters': filters
        }
        return f"search:{hashlib.sha256(json.dumps(cache_data, sort_keys=True).encode()).hexdigest()}"
    
    def _check_cache(self, cache_key: str) -> Optional[List[SearchResult]]:
        """V√©rifie le cache Redis."""
        if not self.redis_client:
            return None
        
        cached = self.redis_client.get(cache_key)
        if cached:
            return [SearchResult(**r) for r in json.loads(cached)]
        return None
    
    def _set_cache(self, cache_key: str, results: List[SearchResult], ttl: int = 300):
        """Met en cache les r√©sultats."""
        if self.redis_client:
            self.redis_client.setex(
                cache_key,
                ttl,
                json.dumps([r.__dict__ for r in results])
            )
    
    def search(
        self,
        query: str,
        config: Optional[SearchConfig] = None,
        filters: Optional[Dict] = None
    ) -> List[SearchResult]:
        """
        Ex√©cute une recherche hybride.
        
        Args:
            query: Texte de recherche
            config: Configuration de la recherche
            filters: Filtres additionnels (category, date_from, date_to, etc.)
        
        Returns:
            Liste de SearchResult tri√©s par pertinence
        """
        config = config or SearchConfig()
        filters = filters or {}
        
        # V√©rifier le cache
        cache_key = self._get_cache_key(query, config, filters)
        cached_results = self._check_cache(cache_key)
        if cached_results:
            return cached_results
        
        # G√©n√©rer l'embedding de la requ√™te
        query_embedding = self.generate_embedding(query)
        
        # Ex√©cuter la recherche selon la strat√©gie
        if config.fusion_strategy == FusionStrategy.WEIGHTED_SUM:
            results = self._weighted_sum_search(query, query_embedding, config, filters)
        elif config.fusion_strategy == FusionStrategy.RRF:
            results = self._rrf_search(query, query_embedding, config, filters)
        else:
            results = self._cascade_search(query, query_embedding, config, filters)
        
        # Mettre en cache
        self._set_cache(cache_key, results)
        
        return results
    
    def _weighted_sum_search(
        self,
        query: str,
        query_embedding: np.ndarray,
        config: SearchConfig,
        filters: Dict
    ) -> List[SearchResult]:
        """Recherche avec fusion par somme pond√©r√©e."""
        cursor = self.conn.cursor(dictionary=True)
        
        # Construire les clauses WHERE pour les filtres
        where_clauses = ["1=1"]
        params = []
        
        if 'category' in filters:
            where_clauses.append("d.categorie = %s")
            params.append(filters['category'])
        
        if 'date_from' in filters:
            where_clauses.append("d.date_publication >= %s")
            params.append(filters['date_from'])
        
        where_clause = " AND ".join(where_clauses)
        
        # Recherche s√©mantique
        semantic_sql = f"""
            SELECT 
                dc.id, dc.document_id, dc.chunk_text, dc.section_title,
                d.titre,
                (1 - VEC_DISTANCE_COSINE(dc.embedding, VEC_FromText(%s))) AS semantic_score
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE {where_clause}
            ORDER BY VEC_DISTANCE_COSINE(dc.embedding, VEC_FromText(%s)) ASC
            LIMIT 100
        """
        
        cursor.execute(semantic_sql, [str(query_embedding.tolist())] + params + [str(query_embedding.tolist())])
        semantic_results = {row['id']: row for row in cursor.fetchall()}
        
        # Recherche full-text
        fulltext_sql = f"""
            SELECT 
                dc.id,
                MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE) AS lexical_score
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE)
            AND {where_clause}
            LIMIT 100
        """
        
        cursor.execute(fulltext_sql, [query, query] + params)
        fulltext_results = {row['id']: row['lexical_score'] for row in cursor.fetchall()}
        
        # Normaliser les scores full-text
        max_ft_score = max(fulltext_results.values()) if fulltext_results else 1
        fulltext_normalized = {k: v / max_ft_score for k, v in fulltext_results.items()}
        
        # Fusionner les r√©sultats
        results = []
        all_ids = set(semantic_results.keys()) | set(fulltext_results.keys())
        
        for chunk_id in all_ids:
            sem_data = semantic_results.get(chunk_id)
            lex_score = fulltext_normalized.get(chunk_id, 0)
            
            if sem_data:
                sem_score = sem_data['semantic_score']
                title = sem_data['titre']
                chunk_text = sem_data['chunk_text']
                doc_id = sem_data['document_id']
            else:
                sem_score = 0
                # R√©cup√©rer les infos du chunk
                cursor.execute("""
                    SELECT dc.document_id, dc.chunk_text, d.titre
                    FROM document_chunks dc
                    JOIN documents d ON dc.document_id = d.id
                    WHERE dc.id = %s
                """, [chunk_id])
                row = cursor.fetchone()
                title = row['titre']
                chunk_text = row['chunk_text']
                doc_id = row['document_id']
            
            # D√©terminer le type de match
            if sem_data and chunk_id in fulltext_results:
                match_type = 'BOTH'
                boost = config.both_match_boost
            elif sem_data:
                match_type = 'SEMANTIC'
                boost = 1.0
            else:
                match_type = 'LEXICAL'
                boost = 1.0
            
            # Calculer le score hybride
            hybrid_score = (
                sem_score * config.weight_semantic +
                lex_score * config.weight_lexical
            ) * boost
            
            results.append(SearchResult(
                chunk_id=chunk_id,
                document_id=doc_id,
                title=title,
                chunk_text=chunk_text[:500],
                semantic_score=round(sem_score, 4),
                lexical_score=round(lex_score, 4),
                hybrid_score=round(hybrid_score, 4),
                match_type=match_type
            ))
        
        # Trier par score hybride
        results.sort(key=lambda x: x.hybrid_score, reverse=True)
        
        return results[:config.limit]
    
    def _rrf_search(
        self,
        query: str,
        query_embedding: np.ndarray,
        config: SearchConfig,
        filters: Dict
    ) -> List[SearchResult]:
        """Recherche avec Reciprocal Rank Fusion."""
        cursor = self.conn.cursor(dictionary=True)
        
        # Construction des filtres (similaire √† weighted_sum)
        where_clauses = ["1=1"]
        params = []
        
        if 'category' in filters:
            where_clauses.append("d.categorie = %s")
            params.append(filters['category'])
        
        where_clause = " AND ".join(where_clauses)
        
        # Recherche s√©mantique avec rang
        semantic_sql = f"""
            SELECT 
                dc.id, dc.document_id, dc.chunk_text, d.titre,
                ROW_NUMBER() OVER (ORDER BY VEC_DISTANCE_COSINE(dc.embedding, VEC_FromText(%s)) ASC) AS s_rank
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE {where_clause}
            ORDER BY VEC_DISTANCE_COSINE(dc.embedding, VEC_FromText(%s)) ASC
            LIMIT 100
        """
        
        cursor.execute(semantic_sql, [str(query_embedding.tolist())] + params + [str(query_embedding.tolist())])
        semantic_ranked = {row['id']: row for row in cursor.fetchall()}
        
        # Recherche full-text avec rang
        fulltext_sql = f"""
            SELECT 
                dc.id,
                ROW_NUMBER() OVER (ORDER BY MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE) DESC) AS l_rank
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE)
            AND {where_clause}
            LIMIT 100
        """
        
        cursor.execute(fulltext_sql, [query, query] + params)
        fulltext_ranked = {row['id']: row['l_rank'] for row in cursor.fetchall()}
        
        # Calculer les scores RRF
        k = config.rrf_k
        results = []
        all_ids = set(semantic_ranked.keys()) | set(fulltext_ranked.keys())
        
        for chunk_id in all_ids:
            sem_data = semantic_ranked.get(chunk_id)
            lex_rank = fulltext_ranked.get(chunk_id)
            
            # Score RRF
            rrf_score = 0
            if sem_data:
                rrf_score += 1.0 / (k + sem_data['s_rank'])
            if lex_rank:
                rrf_score += 1.0 / (k + lex_rank)
            
            # D√©terminer le type de match
            if sem_data and lex_rank:
                match_type = 'BOTH'
            elif sem_data:
                match_type = 'SEMANTIC'
            else:
                match_type = 'LEXICAL'
            
            # R√©cup√©rer les donn√©es du chunk si n√©cessaire
            if sem_data:
                title = sem_data['titre']
                chunk_text = sem_data['chunk_text']
                doc_id = sem_data['document_id']
            else:
                cursor.execute("""
                    SELECT dc.document_id, dc.chunk_text, d.titre
                    FROM document_chunks dc
                    JOIN documents d ON dc.document_id = d.id
                    WHERE dc.id = %s
                """, [chunk_id])
                row = cursor.fetchone()
                title = row['titre']
                chunk_text = row['chunk_text']
                doc_id = row['document_id']
            
            results.append(SearchResult(
                chunk_id=chunk_id,
                document_id=doc_id,
                title=title,
                chunk_text=chunk_text[:500],
                semantic_score=round(1.0 / (k + sem_data['s_rank']) if sem_data else 0, 6),
                lexical_score=round(1.0 / (k + lex_rank) if lex_rank else 0, 6),
                hybrid_score=round(rrf_score, 6),
                match_type=match_type
            ))
        
        results.sort(key=lambda x: x.hybrid_score, reverse=True)
        return results[:config.limit]
    
    def _cascade_search(
        self,
        query: str,
        query_embedding: np.ndarray,
        config: SearchConfig,
        filters: Dict
    ) -> List[SearchResult]:
        """Recherche en cascade : lexical puis re-ranking s√©mantique."""
        cursor = self.conn.cursor(dictionary=True)
        
        where_clauses = ["1=1"]
        params = []
        
        if 'category' in filters:
            where_clauses.append("d.categorie = %s")
            params.append(filters['category'])
        
        where_clause = " AND ".join(where_clauses)
        
        # √âtape 1 : Recherche lexicale large
        lexical_sql = f"""
            SELECT 
                dc.id, dc.document_id, dc.chunk_text, d.titre,
                VEC_ToText(dc.embedding) AS embedding_text,
                MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE) AS lexical_score
            FROM document_chunks dc
            JOIN documents d ON dc.document_id = d.id
            WHERE MATCH(dc.chunk_text) AGAINST(%s IN NATURAL LANGUAGE MODE)
            AND {where_clause}
            ORDER BY lexical_score DESC
            LIMIT 200
        """
        
        cursor.execute(lexical_sql, [query, query] + params)
        candidates = cursor.fetchall()
        
        if not candidates:
            return []
        
        # Normaliser les scores lexicaux
        max_lex = max(c['lexical_score'] for c in candidates)
        
        # √âtape 2 : Re-ranking s√©mantique
        results = []
        for candidate in candidates:
            # Calculer la distance s√©mantique
            chunk_embedding = np.array(eval(candidate['embedding_text']))
            sem_distance = float(np.linalg.norm(query_embedding - chunk_embedding))
            sem_score = 1 / (1 + sem_distance)  # Conversion en score
            
            lex_score_norm = candidate['lexical_score'] / max_lex
            
            # Score final : priorit√© au s√©mantique
            hybrid_score = sem_score * 0.7 + lex_score_norm * 0.3
            
            results.append(SearchResult(
                chunk_id=candidate['id'],
                document_id=candidate['document_id'],
                title=candidate['titre'],
                chunk_text=candidate['chunk_text'][:500],
                semantic_score=round(sem_score, 4),
                lexical_score=round(lex_score_norm, 4),
                hybrid_score=round(hybrid_score, 4),
                match_type='BOTH'  # Tous viennent du lexical
            ))
        
        results.sort(key=lambda x: x.hybrid_score, reverse=True)
        return results[:config.limit]


# Exemple d'utilisation
if __name__ == "__main__":
    service = HybridSearchService(
        db_config={
            'host': 'localhost',
            'port': 3306,
            'user': 'search_user',
            'password': 'password',
            'database': 'hybrid_search'
        },
        openai_api_key='sk-...',
        redis_config={'host': 'localhost', 'port': 6379, 'db': 0}
    )
    
    # Recherche avec configuration personnalis√©e
    config = SearchConfig(
        weight_semantic=0.7,
        weight_lexical=0.3,
        fusion_strategy=FusionStrategy.WEIGHTED_SUM,
        limit=10
    )
    
    results = service.search(
        query="comment configurer la r√©plication MariaDB avec GTID",
        config=config,
        filters={'category': 'administration'}
    )
    
    for r in results:
        print(f"[{r.hybrid_score:.4f}] [{r.match_type}] {r.title}")
        print(f"   Semantic: {r.semantic_score:.4f}, Lexical: {r.lexical_score:.4f}")
        print(f"   {r.chunk_text[:200]}...")
        print()
```

---

## Ajustement des poids et A/B testing

### Framework d'√©valuation

```sql
-- Table de logs pour √©valuation des recherches
CREATE TABLE search_evaluation_logs (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    search_id VARCHAR(64) NOT NULL,
    query_text VARCHAR(1000),
    config_name VARCHAR(50),
    
    -- R√©sultats
    results_shown JSON,  -- [{id: 1, rank: 1, score: 0.95}, ...]
    
    -- Interactions utilisateur
    clicked_result_id BIGINT UNSIGNED,
    clicked_rank INT UNSIGNED,
    time_to_click_ms INT UNSIGNED,
    
    -- M√©triques calcul√©es
    ndcg_at_10 FLOAT,
    mrr FLOAT,  -- Mean Reciprocal Rank
    
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_config (config_name, timestamp),
    INDEX idx_query (query_text(100))
) ENGINE=InnoDB;

-- Calculer les m√©triques par configuration
SELECT 
    config_name,
    COUNT(*) AS total_searches,
    SUM(CASE WHEN clicked_result_id IS NOT NULL THEN 1 ELSE 0 END) AS searches_with_click,
    ROUND(
        SUM(CASE WHEN clicked_result_id IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*),
        2
    ) AS click_through_rate,
    ROUND(AVG(1.0 / NULLIF(clicked_rank, 0)), 4) AS mean_reciprocal_rank,
    ROUND(AVG(clicked_rank), 2) AS avg_click_position,
    ROUND(AVG(time_to_click_ms) / 1000, 2) AS avg_time_to_click_sec
FROM search_evaluation_logs
WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY config_name
ORDER BY click_through_rate DESC;
```

### Recommandations de poids par cas d'usage

| Cas d'usage | Poids s√©mantique | Poids lexical | Strat√©gie | Raison |
|-------------|------------------|---------------|-----------|--------|
| Documentation technique | 0.4 | 0.6 | Cascade | Termes techniques exacts importants |
| FAQ / Support client | 0.7 | 0.3 | Weighted Sum | Reformulations fr√©quentes |
| E-commerce | 0.5 | 0.5 | RRF | √âquilibre marque/description |
| Recherche juridique | 0.3 | 0.7 | Cascade | Pr√©cision terminologique |
| Base de connaissances | 0.65 | 0.35 | Weighted Sum | Questions naturelles |
| Logs / Monitoring | 0.2 | 0.8 | Cascade | Codes d'erreur exacts |

---

## ‚úÖ Points cl√©s √† retenir

- La **recherche hybride** combine la pr√©cision de la recherche lexicale (full-text) et la compr√©hension s√©mantique (vectorielle)
- MariaDB 11.8 permet nativement de combiner `FULLTEXT` et `VECTOR` index dans une m√™me requ√™te
- **Reciprocal Rank Fusion (RRF)** est robuste et ne n√©cessite pas de normalisation des scores
- La **somme pond√©r√©e** offre plus de contr√¥le mais requiert une normalisation des scores
- La strat√©gie **cascade** est plus performante pour les gros volumes
- Les r√©sultats pr√©sents dans **les deux listes** (match_type = 'BOTH') m√©ritent un **boost**
- **Adaptez les poids** selon votre cas d'usage : plus de lexical pour le technique, plus de s√©mantique pour les questions naturelles
- Le **cache** (Redis) est essentiel pour les performances en production

---

## üîó Ressources et r√©f√©rences

- [üìñ MariaDB Vector Documentation](https://mariadb.com/kb/en/vector/) ‚Äî Documentation officielle MariaDB Vector
- [üìñ MariaDB Full-Text Index](https://mariadb.com/kb/en/full-text-indexes/) ‚Äî Index FULLTEXT
- [üìñ Reciprocal Rank Fusion Paper](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) ‚Äî Article original RRF
- [üìñ Hybrid Search Best Practices](https://www.pinecone.io/learn/hybrid-search/) ‚Äî Guide Pinecone
- [üìñ BM25 vs Dense Retrieval](https://arxiv.org/abs/2104.08253) ‚Äî Comparaison acad√©mique

---

## ‚û°Ô∏è Section suivante

**20.10 MariaDB MCP Server pour int√©gration IA** : D√©couvrez comment utiliser le protocole Model Context Protocol (MCP) pour connecter MariaDB directement aux assistants IA comme Claude, permettant des requ√™tes en langage naturel sur vos donn√©es.

‚è≠Ô∏è [MariaDB MCP Server pour int√©gration IA](/20-cas-usage-architectures/10-mcp-server-integration-ia.md)
