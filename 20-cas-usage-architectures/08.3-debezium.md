ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 20.8.3 Debezium Connector pour MariaDB

> **Niveau** : IntermÃ©diaire Ã  AvancÃ©  
> **DurÃ©e estimÃ©e** : 3 heures  
> **PrÃ©requis** : Section 20.8.1 (CDC), Section 20.8.2 (IntÃ©gration Kafka), Chapitre 13 (RÃ©plication)

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :

- MaÃ®triser l'architecture et les composants de Debezium
- Configurer le connecteur MariaDB/MySQL avec toutes ses options
- GÃ©rer les snapshots initiaux et la reprise aprÃ¨s incident
- ImplÃ©menter des transformations (SMT) pour adapter les Ã©vÃ©nements
- GÃ©rer l'Ã©volution des schÃ©mas sans interruption
- Monitorer et opÃ©rer Debezium en production
- RÃ©soudre les problÃ¨mes courants

---

## Introduction

**Debezium** est une plateforme open-source de Change Data Capture (CDC) distribuÃ©e, dÃ©veloppÃ©e par Red Hat. Elle capture les changements de donnÃ©es en temps rÃ©el depuis diverses bases de donnÃ©es et les publie vers Apache Kafka sous forme d'Ã©vÃ©nements.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Ã‰COSYSTÃˆME DEBEZIUM                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    DEBEZIUM PLATFORM    â”‚
                        â”‚                         â”‚
                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                        â”‚  â”‚  Kafka Connect    â”‚  â”‚
                        â”‚  â”‚    Framework      â”‚  â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                        â”‚            â”‚            â”‚
                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                        â”‚  â”‚                   â”‚  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚   CONNECTEURS     â”‚  â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MariaDB  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Kafka   â”‚
â”‚ MySQL    â”‚            â”‚  â”‚   â”‚  MySQL/   â”‚   â”‚  â”‚            â”‚  Topics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚   â”‚  MariaDB  â”‚   â”‚  â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQLâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚   â”‚PostgreSQL â”‚   â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Schema  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚            â”‚ Registry â”‚
                        â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚   â”‚  MongoDB  â”‚   â”‚  â”‚
â”‚ MongoDB  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
                        â”‚  â”‚   â”‚SQL Server â”‚   â”‚  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚SQL Serverâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚   â”‚  Oracle   â”‚   â”‚  â”‚
                        â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  Oracle  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚   â”‚  DB2, ... â”‚   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
                        â”‚  â”‚                   â”‚  â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Le connecteur **MySQL/MariaDB** de Debezium lit les **binary logs** pour capturer chaque INSERT, UPDATE et DELETE, les transformant en Ã©vÃ©nements Kafka structurÃ©s.

---

## Architecture du connecteur MariaDB

### Composants internes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ARCHITECTURE INTERNE DU CONNECTEUR                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DEBEZIUM MySQL CONNECTOR                          â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    BINLOG READER                                â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚  â”‚  MySQL      â”‚   â”‚  GTID       â”‚   â”‚  Binlog     â”‚            â”‚   â”‚
â”‚  â”‚  â”‚  Client     â”‚â”€â”€â–¶â”‚  Tracker    â”‚â”€â”€â–¶â”‚  Parser     â”‚            â”‚   â”‚
â”‚  â”‚  â”‚  Protocol   â”‚   â”‚             â”‚   â”‚             â”‚            â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â”‚                                              â”‚                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    SCHEMA MANAGER                               â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚  â”‚  DDL        â”‚   â”‚  Schema     â”‚   â”‚  Schema     â”‚            â”‚   â”‚
â”‚  â”‚  â”‚  Parser     â”‚â”€â”€â–¶â”‚  History    â”‚â”€â”€â–¶â”‚  Registry   â”‚            â”‚   â”‚
â”‚  â”‚  â”‚             â”‚   â”‚  (Kafka)    â”‚   â”‚  Client     â”‚            â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â”‚                                              â”‚                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    EVENT PROCESSOR                              â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚  â”‚  Record     â”‚   â”‚    SMT      â”‚   â”‚  Kafka      â”‚            â”‚   â”‚
â”‚  â”‚  â”‚  Builder    â”‚â”€â”€â–¶â”‚  Pipeline   â”‚â”€â”€â–¶â”‚  Producer   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â–¶ Kafka
â”‚  â”‚  â”‚             â”‚   â”‚             â”‚   â”‚             â”‚            â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    OFFSET STORAGE                               â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚  Position: {file: "binlog.000042", pos: 12345, gtid: "1-1-999"} â”‚   â”‚
â”‚  â”‚  StockÃ© dans: Kafka topic "connect-offsets"                     â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de traitement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUX DE TRAITEMENT CDC                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. CONNEXION
   MariaDB â—€â”€â”€â”€â”€â”€â”€ Debezium se connecte comme replica
                   (SHOW MASTER STATUS, SHOW BINLOG EVENTS)

2. SNAPSHOT INITIAL (optionnel)
   MariaDB â—€â”€â”€â”€â”€â”€â”€ SELECT * FROM tables (avec verrous minimaux)
           â”€â”€â”€â”€â”€â”€â–¶ Kafka topics (Ã©vÃ©nements "r" = read)

3. STREAMING BINLOG
   Binlog  â”€â”€â”€â”€â”€â”€â–¶ Parse ROW events
           â”€â”€â”€â”€â”€â”€â–¶ Convertit en Ã©vÃ©nements Debezium
           â”€â”€â”€â”€â”€â”€â–¶ Publie vers Kafka topics

4. SCHEMA CHANGES
   DDL     â”€â”€â”€â”€â”€â”€â–¶ Parse ALTER/CREATE/DROP
           â”€â”€â”€â”€â”€â”€â–¶ Met Ã  jour schema history
           â”€â”€â”€â”€â”€â”€â–¶ Publie Ã©vÃ©nement DDL (optionnel)

5. OFFSET COMMIT
   Debezium â”€â”€â”€â”€â”€â–¶ Sauvegarde position binlog
                   dans Kafka topic "connect-offsets"
```

---

## Configuration complÃ¨te du connecteur

### Configuration de base

```json
{
  "name": "mariadb-production-connector",
  "config": {
    // ============================================================
    // IDENTITÃ‰ DU CONNECTEUR
    // ============================================================
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    
    // PrÃ©fixe pour tous les topics (obligatoire, unique par connecteur)
    "topic.prefix": "prod-ecommerce",
    
    // ============================================================
    // CONNEXION Ã€ MARIADB
    // ============================================================
    "database.hostname": "mariadb-primary.example.com",
    "database.port": "3306",
    "database.user": "debezium_cdc",
    "database.password": "${file:/secrets/debezium-password.txt}",
    
    // Identifiant serveur unique (doit diffÃ©rer des autres replicas)
    "database.server.id": "184054",
    
    // Connexion SSL (production)
    "database.ssl.mode": "required",
    "database.ssl.truststore": "/etc/debezium/truststore.jks",
    "database.ssl.truststore.password": "${file:/secrets/truststore-password.txt}",
    
    // ============================================================
    // SÃ‰LECTION DES DONNÃ‰ES
    // ============================================================
    
    // Bases de donnÃ©es Ã  capturer (regex supportÃ©)
    "database.include.list": "ecommerce,inventory",
    
    // Tables Ã  inclure (format: database.table, regex supportÃ©)
    "table.include.list": "ecommerce.orders,ecommerce.customers,ecommerce.products,inventory.*",
    
    // Tables Ã  exclure
    "table.exclude.list": "ecommerce.sessions,ecommerce.logs",
    
    // Colonnes Ã  masquer (donnÃ©es sensibles)
    "column.mask.with.0.bytes": "ecommerce.customers.credit_card",
    "column.mask.hash.SHA-256.with.salt.secret123": "ecommerce.customers.email",
    
    // Colonnes Ã  exclure complÃ¨tement
    "column.exclude.list": "ecommerce.customers.password_hash,ecommerce.customers.ssn",
    
    // ============================================================
    // SNAPSHOT CONFIGURATION
    // ============================================================
    
    // Mode: initial, initial_only, schema_only, schema_only_recovery, never, when_needed
    "snapshot.mode": "initial",
    
    // Verrous pendant snapshot
    "snapshot.locking.mode": "minimal",  // minimal, extended, none
    
    // Taille des lots pour le snapshot
    "snapshot.fetch.size": "10240",
    
    // DÃ©lai maximum pour le snapshot (ms)
    "snapshot.max.threads": "1",
    
    // Tables Ã  inclure dans le snapshot (subset)
    // "snapshot.include.collection.list": "ecommerce.orders,ecommerce.customers",
    
    // ============================================================
    // CONFIGURATION GTID
    // ============================================================
    
    // Utiliser GTID pour le tracking (recommandÃ©)
    "gtid.source.includes": ".*",
    
    // Filtrer certains GTID domains
    // "gtid.source.excludes": "3",
    
    // ============================================================
    // BINARY LOG PARSING
    // ============================================================
    
    // Inclure les requÃªtes SQL originales
    "include.query": "false",
    
    // Format des nombres dÃ©cimaux: precise, double, string
    "decimal.handling.mode": "string",
    
    // Format des temporels: adaptive, adaptive_time_microseconds, connect
    "time.precision.mode": "adaptive_time_microseconds",
    
    // Format des binaires: bytes, base64, base64-url-safe, hex
    "binary.handling.mode": "base64",
    
    // Intervalle de heartbeat (Ã©vite les gaps dans les binlogs inactifs)
    "heartbeat.interval.ms": "10000",
    "heartbeat.topics.prefix": "__debezium-heartbeat",
    
    // ============================================================
    // SCHEMA HISTORY
    // ============================================================
    
    "schema.history.internal.kafka.bootstrap.servers": "kafka-1:9092,kafka-2:9092,kafka-3:9092",
    "schema.history.internal.kafka.topic": "schema-changes.prod-ecommerce",
    "schema.history.internal.kafka.recovery.poll.interval.ms": "500",
    "schema.history.internal.kafka.recovery.attempts": "100",
    
    // Propager les changements DDL vers un topic dÃ©diÃ©
    "include.schema.changes": "true",
    
    // ============================================================
    // SÃ‰RIALISATION
    // ============================================================
    
    // Convertisseurs (Avro recommandÃ© pour production)
    "key.converter": "io.confluent.connect.avro.AvroConverter",
    "key.converter.schema.registry.url": "http://schema-registry:8081",
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "value.converter.schema.registry.url": "http://schema-registry:8081",
    
    // ============================================================
    // RÃ‰SILIENCE ET RETRY
    // ============================================================
    
    // Retry en cas d'erreur de connexion
    "connect.timeout.ms": "30000",
    "connect.keep.alive": "true",
    "connect.keep.alive.interval.ms": "60000",
    
    // Erreurs et retry
    "errors.max.retries": "10",
    "errors.retry.delay.initial.ms": "300",
    "errors.retry.delay.max.ms": "10000",
    
    // Dead Letter Queue
    "errors.tolerance": "all",
    "errors.deadletterqueue.topic.name": "dlq.prod-ecommerce",
    "errors.deadletterqueue.topic.replication.factor": "3",
    "errors.deadletterqueue.context.headers.enable": "true",
    
    // ============================================================
    // PERFORMANCE
    // ============================================================
    
    // Polling des binlogs
    "poll.interval.ms": "100",
    "max.batch.size": "2048",
    "max.queue.size": "8192",
    "max.queue.size.in.bytes": "67108864",
    
    // Buffers
    "binlog.buffer.size": "0"
  }
}
```

### Configuration avancÃ©e pour MariaDB

```json
{
  "name": "mariadb-advanced-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    
    // ... configuration de base ...
    
    // ============================================================
    // CONFIGURATION SPÃ‰CIFIQUE MARIADB
    // ============================================================
    
    // Type de base de donnÃ©es (auto-dÃ©tectÃ©, mais peut Ãªtre forcÃ©)
    "database.protocol": "jdbc:mariadb",
    
    // Options JDBC spÃ©cifiques MariaDB
    "database.jdbc.driver": "org.mariadb.jdbc.Driver",
    
    // PropriÃ©tÃ©s de connexion JDBC additionnelles
    "database.connectionTimeZone": "UTC",
    "database.useCursorFetch": "true",
    "database.defaultFetchSize": "10000",
    
    // ============================================================
    // GESTION DES Ã‰VÃ‰NEMENTS DDL
    // ============================================================
    
    // Parser DDL pour MariaDB
    "database.history.skip.unparseable.ddl": "true",
    
    // Stocker l'historique DDL complet
    "database.history.store.only.captured.tables.ddl": "false",
    
    // ============================================================
    // SIGNALING ET NOTIFICATIONS
    // ============================================================
    
    // Table de signaling pour opÃ©rations Ã  la demande
    "signal.enabled.channels": "source",
    "signal.data.collection": "ecommerce.debezium_signals",
    
    // Topic pour les notifications
    "notification.enabled.channels": "sink",
    "notification.sink.topic.name": "debezium-notifications",
    
    // ============================================================
    // INCREMENTAL SNAPSHOTS (Debezium 1.6+)
    // ============================================================
    
    // Activer les snapshots incrÃ©mentaux
    "read.only": "false",
    "incremental.snapshot.chunk.size": "1024",
    "incremental.snapshot.allow.schema.changes": "true",
    
    // ============================================================
    // TOPIC ROUTING AVANCÃ‰
    // ============================================================
    
    // Nom du topic par dÃ©faut
    "topic.naming.strategy": "io.debezium.schema.SchemaTopicNamingStrategy",
    
    // DÃ©limiteur entre les segments
    "topic.delimiter": ".",
    
    // PrÃ©fixe du topic de transaction
    "topic.transaction": "transaction"
  }
}
```

---

## Modes de snapshot

### Comparaison des modes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MODES DE SNAPSHOT                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODE            â”‚ COMPORTEMENT                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ initial         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ (dÃ©faut)        â”‚ â”‚ 1. Snapshot complet de toutes les tables            â”‚ â”‚
â”‚                 â”‚ â”‚ 2. Puis streaming des binlogs                       â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: Nouvelle installation                      â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ initial_only    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                 â”‚ â”‚ 1. Snapshot complet uniquement                      â”‚ â”‚
â”‚                 â”‚ â”‚ 2. ArrÃªt du connecteur aprÃ¨s snapshot               â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: Migration one-time                         â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ schema_only     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                 â”‚ â”‚ 1. Capture schÃ©ma sans donnÃ©es                      â”‚ â”‚
â”‚                 â”‚ â”‚ 2. Streaming binlogs immÃ©diat                       â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: Historique binlog disponible               â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ schema_only_    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ recovery        â”‚ â”‚ 1. Reconstruit l'historique schÃ©ma depuis binlogs   â”‚ â”‚
â”‚                 â”‚ â”‚ 2. Streaming binlogs aprÃ¨s reconstruction           â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: RÃ©cupÃ©ration aprÃ¨s corruption              â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ never           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                 â”‚ â”‚ 1. Pas de snapshot                                  â”‚ â”‚
â”‚                 â”‚ â”‚ 2. Streaming binlogs depuis position sauvegardÃ©e    â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: Reprise aprÃ¨s arrÃªt planifiÃ©               â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚                                                         â”‚
â”‚ when_needed     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                 â”‚ â”‚ 1. Snapshot si position binlog non disponible       â”‚ â”‚
â”‚                 â”‚ â”‚ 2. Sinon streaming depuis derniÃ¨re position         â”‚ â”‚
â”‚                 â”‚ â”‚ âœ… Pour: RÃ©silience automatique                     â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Snapshot incrÃ©mental (ad-hoc)

Debezium 1.6+ supporte les **snapshots incrÃ©mentaux** dÃ©clenchÃ©s Ã  la demande via une table de signaling.

```sql
-- ============================================================
-- TABLE DE SIGNALING POUR SNAPSHOTS INCRÃ‰MENTAUX
-- ============================================================

CREATE TABLE ecommerce.debezium_signals (
    id VARCHAR(64) PRIMARY KEY,
    type VARCHAR(32) NOT NULL,
    data JSON NULL
) ENGINE=InnoDB;

-- DÃ©clencher un snapshot incrÃ©mental d'une table
INSERT INTO ecommerce.debezium_signals (id, type, data)
VALUES (
    UUID(),
    'execute-snapshot',
    JSON_OBJECT(
        'data-collections', JSON_ARRAY('ecommerce.products'),
        'type', 'incremental'
    )
);

-- Snapshot de plusieurs tables
INSERT INTO ecommerce.debezium_signals (id, type, data)
VALUES (
    UUID(),
    'execute-snapshot',
    JSON_OBJECT(
        'data-collections', JSON_ARRAY(
            'ecommerce.orders',
            'ecommerce.order_items',
            'ecommerce.customers'
        ),
        'type', 'incremental',
        'additional-conditions', JSON_ARRAY(
            JSON_OBJECT(
                'data-collection', 'ecommerce.orders',
                'filter', 'created_at > "2024-01-01"'
            )
        )
    )
);

-- ArrÃªter un snapshot en cours
INSERT INTO ecommerce.debezium_signals (id, type, data)
VALUES (
    UUID(),
    'stop-snapshot',
    JSON_OBJECT(
        'data-collections', JSON_ARRAY('ecommerce.products'),
        'type', 'incremental'
    )
);
```

---

## Transformations (SMT)

Les **Single Message Transforms** (SMT) permettent de modifier les Ã©vÃ©nements avant leur publication.

### Transformations intÃ©grÃ©es Debezium

```json
{
  "name": "connector-with-transforms",
  "config": {
    // ... configuration de base ...
    
    // ============================================================
    // CHAÃNE DE TRANSFORMATIONS
    // ============================================================
    "transforms": "unwrap,route,filter,rename,insertKey,timestamp",
    
    // ============================================================
    // 1. EXTRACT NEW RECORD STATE (unwrap)
    // Simplifie la structure Debezium
    // ============================================================
    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
    
    // Garder les tombstones pour les deletes
    "transforms.unwrap.drop.tombstones": "false",
    
    // Gestion des deletes: none, drop, rewrite
    "transforms.unwrap.delete.handling.mode": "rewrite",
    
    // Ajouter des champs de mÃ©tadonnÃ©es
    "transforms.unwrap.add.fields": "op,table,source.ts_ms,transaction.id",
    "transforms.unwrap.add.headers": "db,table",
    
    // ============================================================
    // 2. TOPIC ROUTING
    // Modifier le nom du topic de destination
    // ============================================================
    "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",
    "transforms.route.regex": "prod-ecommerce\\.ecommerce\\.(.+)",
    "transforms.route.replacement": "events-$1",
    
    // ============================================================
    // 3. FILTRAGE
    // Exclure certains Ã©vÃ©nements
    // ============================================================
    "transforms.filter.type": "io.debezium.transforms.Filter",
    "transforms.filter.language": "jsr223.groovy",
    "transforms.filter.condition": "value.op == 'r' || value.after?.status == 'deleted'",
    
    // ============================================================
    // 4. RENOMMAGE DE CHAMPS
    // ============================================================
    "transforms.rename.type": "org.apache.kafka.connect.transforms.ReplaceField$Value",
    "transforms.rename.renames": "created_at:timestamp,updated_at:last_modified",
    
    // ============================================================
    // 5. EXTRACTION DE CLÃ‰
    // ============================================================
    "transforms.insertKey.type": "org.apache.kafka.connect.transforms.ValueToKey",
    "transforms.insertKey.fields": "id",
    
    // ============================================================
    // 6. CONVERSION TIMESTAMP
    // ============================================================
    "transforms.timestamp.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
    "transforms.timestamp.target.type": "Timestamp",
    "transforms.timestamp.field": "source.ts_ms",
    "transforms.timestamp.format": "yyyy-MM-dd HH:mm:ss.SSS"
  }
}
```

### Transformations personnalisÃ©es avec Groovy

```json
{
  "transforms": "customTransform",
  
  // Transformation Groovy personnalisÃ©e
  "transforms.customTransform.type": "io.debezium.transforms.ScriptingTransformation",
  "transforms.customTransform.language": "jsr223.groovy",
  "transforms.customTransform.topic.regex": ".*orders.*",
  "transforms.customTransform.null.handling.mode": "drop",
  "transforms.customTransform.script": "
    // Enrichir l'Ã©vÃ©nement avec des calculs
    if (value != null && value.after != null) {
        def order = value.after
        
        // Calculer le total TTC
        def subtotal = order.subtotal ?: 0
        def tax = order.tax_amount ?: 0
        def shipping = order.shipping_amount ?: 0
        order.total_ttc = subtotal + tax + shipping
        
        // CatÃ©goriser la commande
        order.order_size = subtotal > 500 ? 'large' : (subtotal > 100 ? 'medium' : 'small')
        
        // Anonymiser l'email si prÃ©sent
        if (order.customer_email) {
            def parts = order.customer_email.split('@')
            order.customer_email_domain = parts.length > 1 ? parts[1] : 'unknown'
            order.customer_email = null  // Supprimer l'email complet
        }
    }
    value
  "
}
```

### Transformation pour partitionnement intelligent

```json
{
  "transforms": "partition",
  
  // Partitionnement par tenant_id
  "transforms.partition.type": "io.debezium.transforms.PartitionRouting",
  "transforms.partition.partition.payload.fields": "after.tenant_id",
  "transforms.partition.partition.topic.num": "12",
  "transforms.partition.partition.hash.function": "murmur"
}
```

### Transformation Outbox Pattern

```json
{
  "transforms": "outbox",
  
  // Pattern Outbox pour Event Sourcing
  "transforms.outbox.type": "io.debezium.transforms.outbox.EventRouter",
  
  // Configuration de la table outbox
  "transforms.outbox.table.fields.additional.placement": "type:header:eventType",
  "transforms.outbox.table.field.event.id": "id",
  "transforms.outbox.table.field.event.key": "aggregate_id",
  "transforms.outbox.table.field.event.type": "type",
  "transforms.outbox.table.field.event.payload": "payload",
  "transforms.outbox.table.field.event.timestamp": "created_at",
  
  // Routing du topic basÃ© sur le type d'agrÃ©gat
  "transforms.outbox.route.by.field": "aggregate_type",
  "transforms.outbox.route.topic.replacement": "events.${routedByValue}"
}
```

**Table Outbox correspondante :**

```sql
CREATE TABLE ecommerce.outbox_events (
    id BINARY(16) PRIMARY KEY DEFAULT (UUID_TO_BIN(UUID())),
    aggregate_type VARCHAR(100) NOT NULL,
    aggregate_id VARCHAR(255) NOT NULL,
    type VARCHAR(100) NOT NULL,
    payload JSON NOT NULL,
    created_at DATETIME(6) DEFAULT CURRENT_TIMESTAMP(6),
    
    INDEX idx_aggregate (aggregate_type, aggregate_id),
    INDEX idx_created (created_at)
) ENGINE=InnoDB;

-- Exemple d'insertion d'Ã©vÃ©nement
INSERT INTO ecommerce.outbox_events (aggregate_type, aggregate_id, type, payload)
VALUES (
    'Order',
    'ORD-2024-12345',
    'OrderCreated',
    JSON_OBJECT(
        'orderId', 'ORD-2024-12345',
        'customerId', 'CUST-789',
        'items', JSON_ARRAY(
            JSON_OBJECT('sku', 'PROD-001', 'quantity', 2, 'price', 29.99)
        ),
        'total', 59.98
    )
);
```

---

## Gestion de l'Ã©volution des schÃ©mas

### Schema Registry Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Ã‰VOLUTION DES SCHÃ‰MAS                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    MariaDB                  Debezium                Schema Registry
       â”‚                        â”‚                          â”‚
       â”‚  ALTER TABLE ADD col   â”‚                          â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                          â”‚
       â”‚                        â”‚                          â”‚
       â”‚                        â”‚  Register new schema     â”‚
       â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
       â”‚                        â”‚                          â”‚
       â”‚                        â”‚  Check compatibility     â”‚
       â”‚                        â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚                        â”‚                          â”‚
       â”‚                        â”‚  Assign schema ID        â”‚
       â”‚                        â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚                        â”‚                          â”‚
       â”‚  INSERT (new format)   â”‚                          â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                          â”‚
       â”‚                        â”‚                          â”‚
       â”‚                        â”‚  Produce with schema ID  â”‚
       â”‚                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Kafka
       â”‚                        â”‚                          â”‚
```

**Configuration Schema Registry :**

```json
{
  "key.converter": "io.confluent.connect.avro.AvroConverter",
  "key.converter.schema.registry.url": "http://schema-registry:8081",
  "key.converter.enhanced.avro.schema.support": "true",
  
  "value.converter": "io.confluent.connect.avro.AvroConverter",
  "value.converter.schema.registry.url": "http://schema-registry:8081",
  "value.converter.enhanced.avro.schema.support": "true",
  
  // CompatibilitÃ© des schÃ©mas
  "value.converter.auto.register.schemas": "true",
  "value.converter.schemas.enable": "true"
}
```

### StratÃ©gies de compatibilitÃ©

```bash
# Configurer la compatibilitÃ© pour un sujet
curl -X PUT "http://schema-registry:8081/config/prod-ecommerce.ecommerce.orders-value" \
  -H "Content-Type: application/json" \
  -d '{"compatibility": "BACKWARD"}'

# Types de compatibilitÃ©:
# - BACKWARD: Nouveaux consommateurs peuvent lire anciens messages
# - FORWARD: Anciens consommateurs peuvent lire nouveaux messages
# - FULL: Les deux directions
# - NONE: Pas de vÃ©rification
```

### Gestion des changements DDL

```sql
-- ============================================================
-- CHANGEMENTS DDL SUPPORTÃ‰S
-- ============================================================

-- âœ… Ajout de colonne (BACKWARD compatible)
ALTER TABLE orders ADD COLUMN notes TEXT;

-- âœ… Suppression de colonne (nÃ©cessite configuration)
-- Configurer: "column.propagate.source.type": ".*"
ALTER TABLE orders DROP COLUMN legacy_field;

-- âœ… Renommage de colonne (avec transformation SMT)
ALTER TABLE orders CHANGE old_name new_name VARCHAR(100);

-- âœ… Modification de type compatible
ALTER TABLE orders MODIFY COLUMN quantity BIGINT;  -- INT -> BIGINT

-- âš ï¸ Modification de type incompatible (peut casser les consommateurs)
ALTER TABLE orders MODIFY COLUMN status ENUM('a','b','c');

-- âœ… Ajout de table
CREATE TABLE order_returns (...);

-- âš ï¸ Suppression de table
DROP TABLE deprecated_table;  -- Les consommateurs doivent gÃ©rer
```

---

## Monitoring et observabilitÃ©

### MÃ©triques JMX

Debezium expose des mÃ©triques dÃ©taillÃ©es via JMX :

```yaml
# docker-compose avec JMX enabled
connect:
  image: debezium/connect:2.5
  environment:
    KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote=true 
      -Dcom.sun.management.jmxremote.authenticate=false 
      -Dcom.sun.management.jmxremote.ssl=false 
      -Dcom.sun.management.jmxremote.port=9012
      -Dcom.sun.management.jmxremote.rmi.port=9012
      -Djava.rmi.server.hostname=connect"
    JMX_PORT: "9012"
  ports:
    - "9012:9012"
```

### MÃ©triques clÃ©s Ã  surveiller

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MÃ‰TRIQUES DEBEZIUM ESSENTIELLES                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STREAMING METRICS (debezium.mysql.<server>)
â”œâ”€â”€ MilliSecondsBehindSource          â†’ Lag de rÃ©plication
â”œâ”€â”€ NumberOfCommittedTransactions     â†’ Transactions traitÃ©es
â”œâ”€â”€ NumberOfEventsFiltered            â†’ Ã‰vÃ©nements filtrÃ©s
â”œâ”€â”€ TotalNumberOfEventsSeen           â†’ Total Ã©vÃ©nements lus
â”œâ”€â”€ LastEvent                         â†’ Dernier Ã©vÃ©nement traitÃ©
â”œâ”€â”€ BinlogFilename                    â†’ Fichier binlog courant
â”œâ”€â”€ BinlogPosition                    â†’ Position dans le binlog
â”œâ”€â”€ IsGtidModeEnabled                 â†’ Mode GTID actif
â””â”€â”€ GtidSet                           â†’ Set GTID courant

SNAPSHOT METRICS (debezium.mysql.<server>.snapshot)
â”œâ”€â”€ RemainingTableCount               â†’ Tables restantes
â”œâ”€â”€ TotalTableCount                   â†’ Total tables Ã  capturer
â”œâ”€â”€ SnapshotRunning                   â†’ Snapshot en cours
â”œâ”€â”€ SnapshotCompleted                 â†’ Snapshot terminÃ©
â”œâ”€â”€ SnapshotDurationInSeconds         â†’ DurÃ©e du snapshot
â””â”€â”€ RowsScanned                       â†’ Lignes scannÃ©es

SCHEMA HISTORY METRICS
â”œâ”€â”€ Status                            â†’ Ã‰tat de l'historique
â”œâ”€â”€ RecoveryStartTime                 â†’ DÃ©but de recovery
â””â”€â”€ ChangesRecovered                  â†’ Changements rÃ©cupÃ©rÃ©s
```

### Configuration Prometheus/Grafana

```yaml
# prometheus-jmx-exporter-config.yml
---
lowercaseOutputName: true
lowercaseOutputLabelNames: true
whitelistObjectNames:
  - "debezium.mysql:*"
  - "kafka.connect:*"
rules:
  - pattern: "debezium.mysql<type=connector-metrics, context=(.+), server=(.+)><>(.+)"
    name: "debezium_mysql_connector_$3"
    labels:
      context: "$1"
      server: "$2"
    type: GAUGE
    
  - pattern: "debezium.mysql<type=connector-metrics, context=streaming, server=(.+)><>MilliSecondsBehindSource"
    name: "debezium_mysql_streaming_lag_ms"
    labels:
      server: "$1"
    type: GAUGE
```

### Dashboard Grafana

```json
{
  "panels": [
    {
      "title": "Replication Lag",
      "type": "gauge",
      "targets": [{
        "expr": "debezium_mysql_streaming_lag_ms{server=\"prod-ecommerce\"}"
      }],
      "fieldConfig": {
        "defaults": {
          "thresholds": {
            "steps": [
              {"value": 0, "color": "green"},
              {"value": 5000, "color": "yellow"},
              {"value": 30000, "color": "red"}
            ]
          },
          "unit": "ms"
        }
      }
    },
    {
      "title": "Events per Second",
      "type": "graph",
      "targets": [{
        "expr": "rate(debezium_mysql_connector_TotalNumberOfEventsSeen[5m])"
      }]
    },
    {
      "title": "Snapshot Progress",
      "type": "gauge",
      "targets": [{
        "expr": "(debezium_mysql_snapshot_TotalTableCount - debezium_mysql_snapshot_RemainingTableCount) / debezium_mysql_snapshot_TotalTableCount * 100"
      }],
      "fieldConfig": {
        "defaults": {
          "max": 100,
          "unit": "percent"
        }
      }
    }
  ]
}
```

### Alerting

```yaml
# alertmanager-rules.yml
groups:
  - name: debezium
    rules:
      - alert: DebeziumHighLag
        expr: debezium_mysql_streaming_lag_ms > 60000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Debezium lag is high"
          description: "Connector {{ $labels.server }} has {{ $value }}ms lag"
      
      - alert: DebeziumConnectorDown
        expr: up{job="debezium"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Debezium connector is down"
      
      - alert: DebeziumSnapshotStuck
        expr: increase(debezium_mysql_snapshot_RowsScanned[10m]) == 0 
              and debezium_mysql_snapshot_SnapshotRunning == 1
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Debezium snapshot appears stuck"
```

---

## OpÃ©rations en production

### DÃ©marrage et arrÃªt graceful

```bash
#!/bin/bash
# manage-connector.sh

CONNECT_URL="http://connect:8083"
CONNECTOR_NAME="mariadb-production-connector"

# VÃ©rifier le statut
status() {
    curl -s "${CONNECT_URL}/connectors/${CONNECTOR_NAME}/status" | jq .
}

# Pause du connecteur (conserve la position)
pause() {
    echo "Pausing connector..."
    curl -X PUT "${CONNECT_URL}/connectors/${CONNECTOR_NAME}/pause"
    echo ""
    status
}

# Reprise du connecteur
resume() {
    echo "Resuming connector..."
    curl -X PUT "${CONNECT_URL}/connectors/${CONNECTOR_NAME}/resume"
    echo ""
    status
}

# Restart du task (en cas d'erreur)
restart_task() {
    TASK_ID=${1:-0}
    echo "Restarting task ${TASK_ID}..."
    curl -X POST "${CONNECT_URL}/connectors/${CONNECTOR_NAME}/tasks/${TASK_ID}/restart"
    echo ""
    status
}

# Suppression et recrÃ©ation
recreate() {
    echo "Deleting connector..."
    curl -X DELETE "${CONNECT_URL}/connectors/${CONNECTOR_NAME}"
    sleep 2
    echo "Creating connector..."
    curl -X POST "${CONNECT_URL}/connectors" \
        -H "Content-Type: application/json" \
        -d @connector-config.json
    echo ""
    status
}

# Mise Ã  jour de la configuration
update_config() {
    echo "Updating connector configuration..."
    curl -X PUT "${CONNECT_URL}/connectors/${CONNECTOR_NAME}/config" \
        -H "Content-Type: application/json" \
        -d @connector-config.json
    echo ""
    status
}

case "$1" in
    status) status ;;
    pause) pause ;;
    resume) resume ;;
    restart) restart_task $2 ;;
    recreate) recreate ;;
    update) update_config ;;
    *) echo "Usage: $0 {status|pause|resume|restart [task_id]|recreate|update}" ;;
esac
```

### Reprise aprÃ¨s incident

```bash
#!/bin/bash
# disaster-recovery.sh

# 1. VÃ©rifier la position binlog disponible
check_binlog_position() {
    mysql -h mariadb -u root -p -e "SHOW BINARY LOGS;" 
    mysql -h mariadb -u root -p -e "SHOW MASTER STATUS;"
}

# 2. VÃ©rifier les offsets stockÃ©s dans Kafka
check_kafka_offsets() {
    kafka-console-consumer \
        --bootstrap-server kafka:9092 \
        --topic connect-offsets \
        --from-beginning \
        --property print.key=true | grep "mariadb-production"
}

# 3. Forcer un nouveau snapshot si position perdue
force_snapshot() {
    # Supprimer les offsets existants
    kafka-delete-records --bootstrap-server kafka:9092 \
        --offset-json-file <(echo '{
            "partitions": [
                {"topic": "connect-offsets", "partition": 0, "offset": -1}
            ],
            "version": 1
        }')
    
    # RecrÃ©er le connecteur avec snapshot initial
    curl -X DELETE "http://connect:8083/connectors/mariadb-production-connector"
    sleep 5
    
    # Connecteur avec snapshot.mode=initial
    curl -X POST "http://connect:8083/connectors" \
        -H "Content-Type: application/json" \
        -d @connector-with-snapshot.json
}

# 4. Resync partiel avec snapshot incrÃ©mental
partial_resync() {
    TABLE=$1
    mysql -h mariadb -u debezium_cdc -p -e "
        INSERT INTO ecommerce.debezium_signals (id, type, data)
        VALUES (
            UUID(),
            'execute-snapshot',
            JSON_OBJECT(
                'data-collections', JSON_ARRAY('ecommerce.${TABLE}'),
                'type', 'incremental'
            )
        );
    "
}
```

### Mise Ã  jour sans interruption

```bash
#!/bin/bash
# zero-downtime-upgrade.sh

# StratÃ©gie: Blue-Green avec deux workers Kafka Connect

OLD_WORKER="connect-blue:8083"
NEW_WORKER="connect-green:8083"
CONNECTOR="mariadb-production"

echo "1. VÃ©rifier que le nouveau worker est prÃªt..."
until curl -s "http://${NEW_WORKER}/connectors" > /dev/null; do
    sleep 5
done

echo "2. Pause du connecteur sur l'ancien worker..."
curl -X PUT "http://${OLD_WORKER}/connectors/${CONNECTOR}/pause"
sleep 5

echo "3. RÃ©cupÃ©rer la derniÃ¨re configuration..."
CONFIG=$(curl -s "http://${OLD_WORKER}/connectors/${CONNECTOR}/config")

echo "4. Supprimer du vieux worker..."
curl -X DELETE "http://${OLD_WORKER}/connectors/${CONNECTOR}"
sleep 2

echo "5. CrÃ©er sur le nouveau worker..."
curl -X POST "http://${NEW_WORKER}/connectors" \
    -H "Content-Type: application/json" \
    -d "{\"name\": \"${CONNECTOR}\", \"config\": ${CONFIG}}"

echo "6. VÃ©rifier le statut..."
sleep 5
curl -s "http://${NEW_WORKER}/connectors/${CONNECTOR}/status" | jq .

echo "Migration terminÃ©e!"
```

---

## Troubleshooting

### ProblÃ¨mes courants et solutions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GUIDE DE DÃ‰PANNAGE                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: "Could not find first log file name in binary log index file"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSE: Les binlogs ont Ã©tÃ© purgÃ©s, position non disponible              â”‚
â”‚                                                                         â”‚
â”‚ SOLUTION:                                                               â”‚
â”‚ 1. VÃ©rifier la rÃ©tention: SHOW VARIABLES LIKE 'expire_logs_days';       â”‚
â”‚ 2. Augmenter la rÃ©tention: SET GLOBAL expire_logs_days = 7;             â”‚
â”‚ 3. RecrÃ©er le connecteur avec snapshot.mode=initial                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: "Access denied for user 'debezium'@'%'"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSE: PrivilÃ¨ges insuffisants                                          â”‚
â”‚                                                                         â”‚
â”‚ SOLUTION:                                                               â”‚
â”‚ GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO user;     â”‚
â”‚ GRANT BINLOG MONITOR ON *.* TO user;  -- MariaDB 11.8+                  â”‚
â”‚ FLUSH PRIVILEGES;                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: "The connector is trying to read binlog but cannot find it"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSE: server_id en conflit avec un autre replica                       â”‚
â”‚                                                                         â”‚
â”‚ SOLUTION:                                                               â”‚
â”‚ 1. VÃ©rifier: SHOW SLAVE HOSTS;                                          â”‚
â”‚ 2. Changer database.server.id dans la config Ã  une valeur unique        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: "Schema history topic is missing"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSE: Topic de schema history supprimÃ© ou non crÃ©Ã©                     â”‚
â”‚                                                                         â”‚
â”‚ SOLUTION:                                                               â”‚
â”‚ 1. Si donnÃ©es encore dans binlogs:                                      â”‚
â”‚    snapshot.mode=schema_only_recovery                                   â”‚
â”‚ 2. Sinon: snapshot.mode=initial (reprise complÃ¨te)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: "Encountered change event for table whose schema isn't known"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSE: Table crÃ©Ã©e aprÃ¨s le snapshot initial                            â”‚
â”‚                                                                         â”‚
â”‚ SOLUTION:                                                               â”‚
â”‚ 1. Snapshot incrÃ©mental de la nouvelle table                            â”‚
â”‚ 2. Ou recrÃ©er le connecteur avec snapshot complet                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PROBLÃˆME: Lag Ã©levÃ© (MilliSecondsBehindSource > 60000)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAUSES POSSIBLES:                                                       â”‚
â”‚ - Kafka trop lent (augmenter partitions)                                â”‚
â”‚ - Transformations SMT coÃ»teuses                                         â”‚
â”‚ - Schema Registry surchargÃ©                                             â”‚
â”‚ - Gros batch de donnÃ©es historiques                                     â”‚
â”‚                                                                         â”‚
â”‚ SOLUTIONS:                                                              â”‚
â”‚ 1. Augmenter max.batch.size et max.queue.size                           â”‚
â”‚ 2. Optimiser les transformations                                        â”‚
â”‚ 3. ParallÃ©liser avec plusieurs tasks (si supportÃ©)                      â”‚
â”‚ 4. Patience si rattrapage aprÃ¨s downtime                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Logs de diagnostic

```bash
# Activer les logs dÃ©taillÃ©s pour debug
docker exec connect bash -c "
cat >> /opt/kafka/config/connect-log4j.properties << EOF
log4j.logger.io.debezium=DEBUG
log4j.logger.io.debezium.connector.mysql=TRACE
log4j.logger.io.debezium.connector.mysql.BinlogReader=TRACE
EOF
"

# RedÃ©marrer le worker
docker restart connect

# Suivre les logs
docker logs -f connect 2>&1 | grep -E "(ERROR|WARN|debezium)"
```

---

## Bonnes pratiques

### Checklist de dÃ©ploiement production

| CatÃ©gorie | VÃ©rification | Status |
|-----------|--------------|--------|
| **MariaDB** | binlog_format = ROW | â˜ |
| | binlog_row_image = FULL | â˜ |
| | GTID activÃ© | â˜ |
| | RÃ©tention binlog â‰¥ 7 jours | â˜ |
| | Utilisateur CDC avec privilÃ¨ges minimaux | â˜ |
| **Kafka** | Topics avec replication â‰¥ 3 | â˜ |
| | Schema Registry configurÃ© | â˜ |
| | RÃ©tention suffisante | â˜ |
| **Debezium** | Heartbeat activÃ© | â˜ |
| | Dead Letter Queue configurÃ©e | â˜ |
| | MÃ©triques exposÃ©es | â˜ |
| | Alertes configurÃ©es | â˜ |
| **SÃ©curitÃ©** | SSL/TLS activÃ© | â˜ |
| | Mots de passe externalisÃ©s | â˜ |
| | Colonnes sensibles masquÃ©es | â˜ |
| **OpÃ©rations** | ProcÃ©dure de recovery documentÃ©e | â˜ |
| | Runbooks crÃ©Ã©s | â˜ |
| | Tests de failover effectuÃ©s | â˜ |

### Dimensionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GUIDELINES DE DIMENSIONNEMENT                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰VÃ‰NEMENTS/SEC    KAFKA CONNECT WORKERS    MÃ‰MOIRE/WORKER    CPU/WORKER
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
< 1,000           1                        2 GB              1 core
1,000 - 10,000    2-3                      4 GB              2 cores
10,000 - 50,000   3-5                      8 GB              4 cores
> 50,000          5+                       16 GB             8 cores

NOTES:
- Un connecteur MySQL = 1 task (pas de parallÃ©lisme intra-connecteur)
- Pour parallÃ©liser: plusieurs connecteurs sur diffÃ©rentes tables
- Heartbeat tous les 10s recommandÃ© pour Ã©viter les gaps
```

---

## âœ… Points clÃ©s Ã  retenir

- **Debezium** est la solution CDC de rÃ©fÃ©rence pour MariaDB, basÃ©e sur Kafka Connect
- Le connecteur MySQL fonctionne nativement avec MariaDB grÃ¢ce au protocole compatible
- Les **modes de snapshot** permettent d'adapter le dÃ©marrage selon les besoins
- Les **SMT** (transformations) permettent d'adapter les Ã©vÃ©nements sans code custom
- Le **Schema Registry** est essentiel pour gÃ©rer l'Ã©volution des schÃ©mas
- Le **monitoring JMX** avec Prometheus/Grafana est crucial en production
- Les **snapshots incrÃ©mentaux** permettent de resynchroniser des tables Ã  la demande
- Le pattern **Outbox** avec Debezium permet l'Event Sourcing transactionnel
- La **rÃ©tention des binlogs** doit Ãªtre supÃ©rieure au temps de recovery acceptable
- Les **procÃ©dures de disaster recovery** doivent Ãªtre documentÃ©es et testÃ©es

---

## ğŸ”— Ressources et rÃ©fÃ©rences

- ğŸ“– [Debezium Documentation](https://debezium.io/documentation/)
- ğŸ“– [Debezium MySQL Connector](https://debezium.io/documentation/reference/stable/connectors/mysql.html)
- ğŸ“– [Debezium MariaDB Support](https://debezium.io/documentation/reference/stable/connectors/mysql.html#mysql-mariadb-support)
- ğŸ“– [Debezium Transformations](https://debezium.io/documentation/reference/stable/transformations/index.html)
- ğŸ“– [Outbox Pattern with Debezium](https://debezium.io/documentation/reference/stable/transformations/outbox-event-router.html)
- ğŸ“– [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/index.html)
- ğŸ“– [Debezium Blog](https://debezium.io/blog/)

---


â­ï¸ [Use cases IA : RAG et recherche vectorielle](/20-cas-usage-architectures/09-use-cases-ia-rag.md)
