üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.3 Data Warehousing avec ColumnStore

> **Niveau** : Interm√©diaire √† Avanc√©  
> **Dur√©e estim√©e** : 3-4 heures  
> **Pr√©requis** : Section 20.1 (OLTP vs OLAP), Chapitre 7 (Moteurs de stockage), notions de mod√©lisation dimensionnelle

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :

- Comprendre l'architecture distribu√©e de MariaDB ColumnStore et ses composants
- Concevoir des mod√®les dimensionnels (Star Schema, Snowflake) optimis√©s pour l'analytique
- Impl√©menter des pipelines ETL/ELT performants vers ColumnStore
- Optimiser les requ√™tes analytiques pour des performances maximales
- Dimensionner et configurer un cluster ColumnStore pour des volumes de donn√©es massifs
- Int√©grer ColumnStore dans une architecture data moderne (Data Lake, Lakehouse)

---

## Introduction

Le Data Warehousing repr√©sente le c≈ìur de la Business Intelligence et de l'analytique d'entreprise. Alors que les bases transactionnelles (OLTP) g√®rent les op√©rations quotidiennes, le Data Warehouse consolid√© permet d'analyser l'historique, de d√©tecter des tendances et de prendre des d√©cisions strat√©giques bas√©es sur les donn√©es.

**MariaDB ColumnStore** est un moteur de stockage colonnaire distribu√©, con√ßu sp√©cifiquement pour les workloads analytiques (OLAP). Il permet d'ex√©cuter des requ√™tes complexes sur des t√©raoctets voire des p√©taoctets de donn√©es avec des performances exceptionnelles.

### Pourquoi ColumnStore pour le Data Warehousing ?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 POURQUOI COLUMNSTORE POUR L'ANALYTIQUE ?                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                            ‚îÇ
‚îÇ  Requ√™te analytique typique :                                              ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  SELECT region, SUM(revenue), AVG(profit_margin)                           ‚îÇ
‚îÇ  FROM sales                           -- 500 millions de lignes            ‚îÇ
‚îÇ  WHERE year = 2024                    -- Filtre sur 1 colonne              ‚îÇ
‚îÇ  GROUP BY region;                     -- Agr√©gation sur 3 colonnes         ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ROW STORE (InnoDB)                                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Lit TOUTES les colonnes de chaque ligne                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ I/O : 100% des donn√©es (50 colonnes √ó 500M lignes)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Pas de compression efficace (donn√©es h√©t√©rog√®nes par ligne)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Temps : minutes √† heures                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  COLUMN STORE (ColumnStore)                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Lit SEULEMENT les colonnes n√©cessaires (4 sur 50)                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ I/O : 8% des donn√©es                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Compression 5-15x (valeurs similaires par colonne)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Ex√©cution vectoris√©e (SIMD)                                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Temps : secondes                                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  Gain typique : 10x √† 100x sur les requ√™tes analytiques                    ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Architecture de MariaDB ColumnStore

### Composants du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARCHITECTURE COLUMNSTORE DISTRIBU√âE                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                            ‚îÇ
‚îÇ                              Clients                                       ‚îÇ
‚îÇ                                 ‚îÇ                                          ‚îÇ
‚îÇ                                 ‚ñº                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                      User Module (UM)                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  MariaDB Server                                             ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Parser SQL                                               ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Query Optimizer                                          ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Result Aggregation                                       ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Client Protocol                                          ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ExeMgr (Execution Manager)                                 ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Query Decomposition                                      ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Work Distribution                                        ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Result Merge                                             ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                    ‚îÇ                                       ‚îÇ
‚îÇ                    Distribution du travail                                 ‚îÇ
‚îÇ                                    ‚îÇ                                       ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ          ‚îÇ                         ‚îÇ                         ‚îÇ             ‚îÇ
‚îÇ          ‚ñº                         ‚ñº                         ‚ñº             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Performance   ‚îÇ        ‚îÇ Performance   ‚îÇ        ‚îÇ Performance   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Module (PM1)  ‚îÇ        ‚îÇ Module (PM2)  ‚îÇ        ‚îÇ Module (PM3)  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ PrimProc  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ PrimProc  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ PrimProc  ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢ Scan    ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Scan    ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Scan    ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢ Filter  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Filter  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Filter  ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢ Project ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Project ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Project ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ WriteEngn ‚îÇ ‚îÇ        ‚îÇ ‚îÇ WriteEngn ‚îÇ ‚îÇ        ‚îÇ ‚îÇ WriteEngn ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢ Insert  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Insert  ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Insert  ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢ Bulk    ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Bulk    ‚îÇ ‚îÇ        ‚îÇ ‚îÇ ‚Ä¢ Bulk    ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ        ‚îÇ               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Storage   ‚îÇ ‚îÇ        ‚îÇ ‚îÇ Storage   ‚îÇ ‚îÇ        ‚îÇ ‚îÇ Storage   ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Extents   ‚îÇ ‚îÇ        ‚îÇ ‚îÇ Extents   ‚îÇ ‚îÇ        ‚îÇ ‚îÇ Extents   ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÇ (8M rows) ‚îÇ ‚îÇ        ‚îÇ ‚îÇ (8M rows) ‚îÇ ‚îÇ        ‚îÇ ‚îÇ (8M rows) ‚îÇ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  Stockage partag√© (optionnel) : S3, GlusterFS, ou local                    ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Organisation des donn√©es

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ORGANISATION DU STOCKAGE COLUMNSTORE                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  Table                                                                      ‚îÇ
‚îÇ    ‚îÇ                                                                        ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ Colonne 1 (ex: customer_id)                                          ‚îÇ
‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ Extent 1 (8M valeurs, compress√©)                               ‚îÇ
‚îÇ    ‚îÇ     ‚îÇ     ‚îú‚îÄ‚îÄ Block 1 (8K valeurs)                                     ‚îÇ
‚îÇ    ‚îÇ     ‚îÇ     ‚îú‚îÄ‚îÄ Block 2                                                  ‚îÇ
‚îÇ    ‚îÇ     ‚îÇ     ‚îî‚îÄ‚îÄ ...                                                      ‚îÇ
‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ Extent 2                                                       ‚îÇ
‚îÇ    ‚îÇ     ‚îî‚îÄ‚îÄ ...                                                            ‚îÇ
‚îÇ    ‚îÇ                                                                        ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ Colonne 2 (ex: order_date)                                           ‚îÇ
‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ Extent 1                                                       ‚îÇ
‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ Extent 2                                                       ‚îÇ
‚îÇ    ‚îÇ     ‚îî‚îÄ‚îÄ ...                                                            ‚îÇ
‚îÇ    ‚îÇ                                                                        ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ Colonne N                                                            ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ ...                                                            ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  M√©tadonn√©es par Extent :                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Min/Max values (Extent Map)  ‚Üí √âlimination d'extents              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Compression type             ‚Üí Snappy, LZ4, ou None               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Row count                    ‚Üí Jusqu'√† 8 millions                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Dictionary (si applicable)   ‚Üí Pour cha√Ænes r√©p√©titives           ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  Extent Elimination :                                                       ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                         ‚îÇ
‚îÇ  WHERE order_date = '2025-01-15'                                            ‚îÇ
‚îÇ  ‚Üí ColumnStore v√©rifie le min/max de chaque extent                          ‚îÇ
‚îÇ  ‚Üí Skip les extents o√π min > '2025-01-15' OR max < '2025-01-15'             ‚îÇ
‚îÇ  ‚Üí Peut √©liminer 90%+ des donn√©es sans les lire                             ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Mod√©lisation dimensionnelle

### Star Schema

Le Star Schema est le mod√®le de r√©f√©rence pour le Data Warehousing :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           STAR SCHEMA                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                            ‚îÇ
‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ                          ‚îÇ   dim_date      ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ date_key (PK)   ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ full_date       ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ day_name        ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ month           ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ quarter         ‚îÇ                               ‚îÇ
‚îÇ                          ‚îÇ year            ‚îÇ                               ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                   ‚îÇ                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  dim_product    ‚îÇ              ‚îÇ              ‚îÇ  dim_customer   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ              ‚îÇ              ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ product_key(PK) ‚îÇ              ‚îÇ              ‚îÇ customer_key(PK)‚îÇ       ‚îÇ
‚îÇ  ‚îÇ sku             ‚îÇ              ‚îÇ              ‚îÇ customer_id     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ name            ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ name            ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ category        ‚îÇ    ‚îÇ                   ‚îÇ    ‚îÇ segment         ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ brand           ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    fact_sales     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ region          ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ price           ‚îÇ    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ    ‚îÇ country         ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ date_key (FK)     ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                         ‚îÇ product_key (FK)  ‚îÇ                              ‚îÇ
‚îÇ                         ‚îÇ customer_key (FK) ‚îÇ                              ‚îÇ
‚îÇ                         ‚îÇ store_key (FK)    ‚îÇ                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ   dim_store     ‚îÇ    ‚îÇ quantity          ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ unit_price        ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ store_key (PK)  ‚îÇ    ‚îÇ revenue           ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ store_name      ‚îÇ    ‚îÇ cost              ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ city            ‚îÇ    ‚îÇ profit            ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ region          ‚îÇ    ‚îÇ discount          ‚îÇ                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îÇ  Caract√©ristiques :                                                        ‚îÇ
‚îÇ  ‚Ä¢ Une table de faits centrale avec les mesures                            ‚îÇ
‚îÇ  ‚Ä¢ Tables de dimensions autour (d√©normalis√©es)                             ‚îÇ
‚îÇ  ‚Ä¢ Jointures simples (1 niveau)                                            ‚îÇ
‚îÇ  ‚Ä¢ Optimal pour les requ√™tes analytiques                                   ‚îÇ
‚îÇ                                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Impl√©mentation compl√®te

```sql
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DATA WAREHOUSE E-COMMERCE - STAR SCHEMA AVEC COLUMNSTORE
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Cr√©ation de la base de donn√©es
CREATE DATABASE IF NOT EXISTS ecommerce_dw 
    CHARACTER SET utf8mb4 
    COLLATE utf8mb4_unicode_ci;
USE ecommerce_dw;

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DIMENSION : DATE (g√©n√©r√©e pour 20 ans)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TABLE dim_date (
    date_key INT NOT NULL COMMENT 'Format YYYYMMDD, ex: 20250115',
    full_date DATE NOT NULL,
    
    -- Attributs jour
    day_of_week TINYINT NOT NULL COMMENT '1=Lundi, 7=Dimanche',
    day_of_week_name VARCHAR(10) NOT NULL,
    day_of_month TINYINT NOT NULL,
    day_of_year SMALLINT NOT NULL,
    
    -- Attributs semaine
    week_of_year TINYINT NOT NULL,
    week_start_date DATE NOT NULL,
    
    -- Attributs mois
    month_number TINYINT NOT NULL,
    month_name VARCHAR(15) NOT NULL,
    month_short VARCHAR(3) NOT NULL,
    
    -- Attributs trimestre
    quarter_number TINYINT NOT NULL,
    quarter_name CHAR(2) NOT NULL COMMENT 'Q1, Q2, Q3, Q4',
    
    -- Attributs ann√©e
    year_number SMALLINT NOT NULL,
    
    -- Combinaisons utiles
    year_month CHAR(7) NOT NULL COMMENT 'YYYY-MM',
    year_quarter CHAR(7) NOT NULL COMMENT 'YYYY-Q1',
    year_week CHAR(8) NOT NULL COMMENT 'YYYY-W01',
    
    -- Flags
    is_weekend BOOLEAN NOT NULL,
    is_holiday BOOLEAN NOT NULL DEFAULT FALSE,
    holiday_name VARCHAR(50),
    is_last_day_of_month BOOLEAN NOT NULL,
    
    -- Fiscal (personnalisable selon l'entreprise)
    fiscal_year SMALLINT,
    fiscal_quarter TINYINT,
    fiscal_month TINYINT,
    
    PRIMARY KEY (date_key)
) ENGINE=Columnstore
  COMMENT='Dimension temporelle - g√©n√©ration: 2015-01-01 √† 2035-12-31';

-- Proc√©dure de g√©n√©ration de la dimension date
DELIMITER //

CREATE PROCEDURE generate_dim_date(
    IN start_date DATE,
    IN end_date DATE
)
BEGIN
    DECLARE current_date_val DATE;
    
    SET current_date_val = start_date;
    
    -- D√©sactiver temporairement pour insertion bulk
    SET SESSION sql_mode = '';
    
    WHILE current_date_val <= end_date DO
        INSERT INTO dim_date (
            date_key, full_date,
            day_of_week, day_of_week_name, day_of_month, day_of_year,
            week_of_year, week_start_date,
            month_number, month_name, month_short,
            quarter_number, quarter_name,
            year_number,
            year_month, year_quarter, year_week,
            is_weekend, is_last_day_of_month,
            fiscal_year, fiscal_quarter, fiscal_month
        )
        VALUES (
            CAST(DATE_FORMAT(current_date_val, '%Y%m%d') AS UNSIGNED),
            current_date_val,
            DAYOFWEEK(current_date_val),
            DAYNAME(current_date_val),
            DAYOFMONTH(current_date_val),
            DAYOFYEAR(current_date_val),
            WEEKOFYEAR(current_date_val),
            DATE_SUB(current_date_val, INTERVAL (DAYOFWEEK(current_date_val) - 2) DAY),
            MONTH(current_date_val),
            MONTHNAME(current_date_val),
            DATE_FORMAT(current_date_val, '%b'),
            QUARTER(current_date_val),
            CONCAT('Q', QUARTER(current_date_val)),
            YEAR(current_date_val),
            DATE_FORMAT(current_date_val, '%Y-%m'),
            CONCAT(YEAR(current_date_val), '-Q', QUARTER(current_date_val)),
            CONCAT(YEAR(current_date_val), '-W', LPAD(WEEKOFYEAR(current_date_val), 2, '0')),
            DAYOFWEEK(current_date_val) IN (1, 7),
            current_date_val = LAST_DAY(current_date_val),
            -- Fiscal year (exemple: commence en Avril)
            IF(MONTH(current_date_val) >= 4, 
               YEAR(current_date_val), 
               YEAR(current_date_val) - 1),
            CEIL((MONTH(current_date_val) - 3) / 3),
            MOD(MONTH(current_date_val) + 8, 12) + 1
        );
        
        SET current_date_val = DATE_ADD(current_date_val, INTERVAL 1 DAY);
    END WHILE;
END //

DELIMITER ;

-- G√©n√©rer 20 ans de dates
CALL generate_dim_date('2015-01-01', '2035-12-31');

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DIMENSION : PRODUIT (avec hi√©rarchie d√©normalis√©e)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TABLE dim_product (
    product_key INT NOT NULL AUTO_INCREMENT,
    
    -- Cl√© m√©tier
    product_id VARCHAR(50) NOT NULL COMMENT 'ID source OLTP',
    sku VARCHAR(50) NOT NULL,
    
    -- Attributs produit
    product_name VARCHAR(255) NOT NULL,
    product_description TEXT,
    
    -- Hi√©rarchie de cat√©gories (d√©normalis√©e pour performances)
    category_id INT,
    category_name VARCHAR(100),
    subcategory_id INT,
    subcategory_name VARCHAR(100),
    department_id INT,
    department_name VARCHAR(100),
    
    -- Marque et fournisseur
    brand_id INT,
    brand_name VARCHAR(100),
    supplier_id INT,
    supplier_name VARCHAR(200),
    supplier_country VARCHAR(100),
    
    -- Attributs commerciaux
    unit_cost DECIMAL(10,2) COMMENT 'Co√ªt d''achat',
    list_price DECIMAL(10,2) COMMENT 'Prix catalogue',
    weight_kg DECIMAL(8,3),
    
    -- Statut
    status VARCHAR(20) DEFAULT 'Active' COMMENT 'Active, Discontinued, Seasonal',
    introduction_date DATE,
    discontinuation_date DATE,
    
    -- SCD Type 2 : Gestion des changements
    effective_start_date DATETIME NOT NULL,
    effective_end_date DATETIME DEFAULT '9999-12-31 23:59:59',
    is_current BOOLEAN DEFAULT TRUE,
    version_number INT DEFAULT 1,
    
    PRIMARY KEY (product_key)
) ENGINE=Columnstore;

-- Index sur la cl√© m√©tier pour les lookups ETL
-- Note: ColumnStore g√®re les index diff√©remment, on utilise extent elimination

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DIMENSION : CLIENT (avec segmentation)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TABLE dim_customer (
    customer_key INT NOT NULL AUTO_INCREMENT,
    
    -- Cl√© m√©tier
    customer_id VARCHAR(50) NOT NULL,
    
    -- Identit√©
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    full_name VARCHAR(200),
    email VARCHAR(255),
    phone VARCHAR(50),
    
    -- Type de client
    customer_type VARCHAR(20) COMMENT 'B2C, B2B, Wholesale, Partner',
    
    -- G√©ographie (d√©normalis√©e)
    address_line1 VARCHAR(255),
    address_line2 VARCHAR(255),
    city VARCHAR(100),
    state_province VARCHAR(100),
    postal_code VARCHAR(20),
    country VARCHAR(100),
    country_code CHAR(2),
    region VARCHAR(50) COMMENT 'EMEA, APAC, Americas, etc.',
    
    -- Segmentation analytique
    segment VARCHAR(50) COMMENT 'Premium, Standard, Basic, Churned',
    acquisition_channel VARCHAR(50) COMMENT 'Organic, Paid, Referral, Partner',
    acquisition_campaign VARCHAR(100),
    acquisition_date DATE,
    
    -- M√©triques pr√©-calcul√©es (mises √† jour p√©riodiquement)
    lifetime_value DECIMAL(12,2),
    total_orders INT,
    avg_order_value DECIMAL(10,2),
    first_order_date DATE,
    last_order_date DATE,
    days_since_last_order INT,
    
    -- RFM Score (calcul√©)
    rfm_recency_score TINYINT,
    rfm_frequency_score TINYINT,
    rfm_monetary_score TINYINT,
    rfm_segment VARCHAR(50),
    
    -- SCD Type 2
    effective_start_date DATETIME NOT NULL,
    effective_end_date DATETIME DEFAULT '9999-12-31 23:59:59',
    is_current BOOLEAN DEFAULT TRUE,
    
    PRIMARY KEY (customer_key)
) ENGINE=Columnstore;

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- DIMENSION : MAGASIN / CANAL
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TABLE dim_store (
    store_key INT NOT NULL AUTO_INCREMENT,
    
    store_id VARCHAR(20) NOT NULL,
    store_name VARCHAR(100) NOT NULL,
    store_type VARCHAR(30) COMMENT 'Physical, Online, Marketplace, Franchise',
    
    -- Localisation physique (si applicable)
    address VARCHAR(255),
    city VARCHAR(100),
    state_province VARCHAR(100),
    country VARCHAR(100),
    region VARCHAR(50),
    latitude DECIMAL(9,6),
    longitude DECIMAL(9,6),
    timezone VARCHAR(50),
    
    -- Caract√©ristiques
    size_sqm INT COMMENT 'Surface en m¬≤',
    employee_count INT,
    parking_spaces INT,
    
    -- Dates cl√©s
    opening_date DATE,
    renovation_date DATE,
    closing_date DATE,
    
    -- Gestion
    district_manager VARCHAR(100),
    regional_manager VARCHAR(100),
    
    -- Statut
    status VARCHAR(20) DEFAULT 'Open' COMMENT 'Open, Closed, Renovating',
    is_flagship BOOLEAN DEFAULT FALSE,
    
    PRIMARY KEY (store_key)
) ENGINE=Columnstore;

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- TABLE DE FAITS : VENTES (grain = ligne de commande)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TABLE fact_sales (
    -- Cl√©s de dimension
    date_key INT NOT NULL,
    product_key INT NOT NULL,
    customer_key INT NOT NULL,
    store_key INT NOT NULL,
    
    -- Cl√©s d√©g√©n√©r√©es (info sans dimension d√©di√©e)
    order_id BIGINT NOT NULL,
    order_line_id BIGINT NOT NULL,
    
    -- Attributs de la transaction
    order_datetime DATETIME NOT NULL,
    order_status VARCHAR(20),
    payment_method VARCHAR(30),
    shipping_method VARCHAR(30),
    
    -- Mesures additives
    quantity INT NOT NULL,
    unit_price DECIMAL(10,2) NOT NULL,
    unit_cost DECIMAL(10,2),
    
    -- Montants
    gross_amount DECIMAL(12,2) NOT NULL COMMENT 'quantity * unit_price',
    discount_amount DECIMAL(10,2) DEFAULT 0,
    tax_amount DECIMAL(10,2) DEFAULT 0,
    shipping_amount DECIMAL(10,2) DEFAULT 0,
    net_amount DECIMAL(12,2) NOT NULL COMMENT 'gross - discount + tax + shipping',
    
    -- Co√ªts et profits
    cost_amount DECIMAL(12,2) COMMENT 'quantity * unit_cost',
    profit_amount DECIMAL(12,2) COMMENT 'net_amount - cost_amount',
    profit_margin_pct DECIMAL(5,2) COMMENT 'profit / net_amount * 100',
    
    -- Flags analytiques
    is_return BOOLEAN DEFAULT FALSE,
    is_promotion BOOLEAN DEFAULT FALSE,
    promotion_id INT,
    
    -- Timestamps ETL
    etl_loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    
    -- Note: Pas de PRIMARY KEY composite en ColumnStore
    -- L'unicit√© est garantie par order_line_id
) ENGINE=Columnstore
  COMMENT='Table de faits des ventes - grain: ligne de commande';

-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- TABLES DE FAITS AGR√âG√âES (pour performances dashboard)
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Agr√©gation quotidienne par magasin et cat√©gorie
CREATE TABLE fact_daily_sales (
    date_key INT NOT NULL,
    store_key INT NOT NULL,
    category_id INT NOT NULL,
    
    -- Comptages
    order_count INT NOT NULL,
    line_count INT NOT NULL,
    customer_count INT NOT NULL,
    
    -- Mesures agr√©g√©es
    total_quantity INT NOT NULL,
    gross_revenue DECIMAL(14,2) NOT NULL,
    discount_total DECIMAL(12,2) NOT NULL,
    tax_total DECIMAL(12,2) NOT NULL,
    net_revenue DECIMAL(14,2) NOT NULL,
    cost_total DECIMAL(14,2),
    profit_total DECIMAL(14,2),
    
    -- M√©triques calcul√©es
    avg_order_value DECIMAL(10,2),
    avg_items_per_order DECIMAL(6,2),
    avg_selling_price DECIMAL(10,2),
    
    -- ETL
    etl_loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=Columnstore;

-- Agr√©gation mensuelle (pour trends long terme)
CREATE TABLE fact_monthly_sales (
    year_month CHAR(7) NOT NULL COMMENT 'YYYY-MM',
    year_number SMALLINT NOT NULL,
    month_number TINYINT NOT NULL,
    store_key INT NOT NULL,
    category_id INT NOT NULL,
    customer_segment VARCHAR(50),
    
    -- M√™mes mesures que daily mais agr√©g√©es
    order_count INT NOT NULL,
    unique_customers INT NOT NULL,
    new_customers INT NOT NULL,
    returning_customers INT NOT NULL,
    
    gross_revenue DECIMAL(16,2) NOT NULL,
    net_revenue DECIMAL(16,2) NOT NULL,
    profit_total DECIMAL(16,2),
    
    -- Comparaisons
    revenue_vs_prev_month DECIMAL(16,2),
    revenue_vs_prev_year DECIMAL(16,2),
    yoy_growth_pct DECIMAL(6,2),
    mom_growth_pct DECIMAL(6,2)
) ENGINE=Columnstore;
```

---

## Pipelines ETL/ELT

### Architecture ETL moderne

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE ETL VERS COLUMNSTORE                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  Sources OLTP                   Transformation              Data Warehouse  ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê              ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  MariaDB    ‚îÇ‚îÄ‚îÄ‚îê                                        ‚îÇ ColumnStore ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Orders)   ‚îÇ  ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ                     ‚îÇ           ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ                   ‚îÇ      ‚îÇ    ETL Engine       ‚îÇ           ‚îÇ ‚îÇdim_date ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ                     ‚îÇ           ‚îÇ ‚îÇdim_prod ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  MariaDB    ‚îÇ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚Ä¢ Extract (CDC)    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇdim_cust ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Products) ‚îÇ  ‚îÇ      ‚îÇ  ‚Ä¢ Transform        ‚îÇ           ‚îÇ ‚îÇ         ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚Ä¢ Load (cpimport)  ‚îÇ           ‚îÇ ‚îÇfact_    ‚îÇ ‚îÇ  ‚îÇ
‚îÇ                   ‚îÇ      ‚îÇ                     ‚îÇ           ‚îÇ ‚îÇsales    ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  Outils:            ‚îÇ           ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL ‚îÇ‚îÄ‚îÄ‚î§      ‚îÇ  ‚Ä¢ Debezium/Kafka   ‚îÇ           ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Legacy)   ‚îÇ  ‚îÇ      ‚îÇ  ‚Ä¢ Apache Airflow   ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚Ä¢ dbt              ‚îÇ                            ‚îÇ
‚îÇ                   ‚îÇ      ‚îÇ  ‚Ä¢ Custom Python    ‚îÇ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ                     ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ  APIs       ‚îÇ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ  ‚îÇ  (External) ‚îÇ                                                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                            ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  Patterns de chargement :                                                   ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                    ‚îÇ
‚îÇ  ‚Ä¢ Full Load     : Rechargement complet (dimensions petites)                ‚îÇ
‚îÇ  ‚Ä¢ Incremental   : Delta via timestamp/CDC (faits)                          ‚îÇ
‚îÇ  ‚Ä¢ Merge (SCD)   : Update + Insert pour dimensions                          ‚îÇ
‚îÇ  ‚Ä¢ Bulk (cpimport): Chargement optimis√© pour gros volumes                   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Chargement bulk avec cpimport

```bash
#!/bin/bash
# etl-load-sales.sh
# Chargement optimis√© des ventes via cpimport

# Configuration
DW_HOST="columnstore-um"
DW_DB="ecommerce_dw"
DATA_DIR="/data/staging"
LOG_DIR="/var/log/etl"
DATE=$(date +%Y%m%d)

# Cr√©er le r√©pertoire de logs
mkdir -p "$LOG_DIR"

# Fonction de chargement bulk
load_table() {
    local table=$1
    local file=$2
    local delimiter=${3:-','}
    
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Loading $table from $file..."
    
    cpimport \
        -h "$DW_HOST" \
        -u etl_user \
        -p "$ETL_PASSWORD" \
        -s "$delimiter" \
        -E '"' \
        -C 'YYYY-MM-DD HH:MI:SS' \
        -n 1 \
        "$DW_DB" \
        "$table" \
        "$file" \
        >> "$LOG_DIR/cpimport_${DATE}.log" 2>&1
    
    local status=$?
    if [ $status -eq 0 ]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] $table loaded successfully"
    else
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR loading $table (exit code: $status)"
        exit 1
    fi
}

# Chargement des dimensions (full refresh pour les petites tables)
echo "=== Loading dimensions ==="
load_table "dim_store" "$DATA_DIR/dim_store_${DATE}.csv"
load_table "dim_product" "$DATA_DIR/dim_product_${DATE}.csv"
load_table "dim_customer" "$DATA_DIR/dim_customer_${DATE}.csv"

# Chargement des faits (incr√©mental)
echo "=== Loading fact tables ==="
load_table "fact_sales" "$DATA_DIR/fact_sales_delta_${DATE}.csv"

# Mise √† jour des agr√©gats
echo "=== Refreshing aggregates ==="
mariadb -h "$DW_HOST" -u etl_user -p"$ETL_PASSWORD" "$DW_DB" << 'EOF'
-- Recalculer les agr√©gations quotidiennes pour les donn√©es charg√©es
INSERT INTO fact_daily_sales
SELECT 
    date_key,
    store_key,
    p.category_id,
    COUNT(DISTINCT f.order_id),
    COUNT(*),
    COUNT(DISTINCT f.customer_key),
    SUM(quantity),
    SUM(gross_amount),
    SUM(discount_amount),
    SUM(tax_amount),
    SUM(net_amount),
    SUM(cost_amount),
    SUM(profit_amount),
    SUM(net_amount) / NULLIF(COUNT(DISTINCT f.order_id), 0),
    SUM(quantity) / NULLIF(COUNT(DISTINCT f.order_id), 0),
    SUM(net_amount) / NULLIF(SUM(quantity), 0),
    NOW()
FROM fact_sales f
JOIN dim_product p ON f.product_key = p.product_key AND p.is_current = TRUE
WHERE f.etl_loaded_at >= CURDATE()
GROUP BY date_key, store_key, p.category_id
ON DUPLICATE KEY UPDATE
    order_count = VALUES(order_count),
    line_count = VALUES(line_count),
    customer_count = VALUES(customer_count),
    total_quantity = VALUES(total_quantity),
    gross_revenue = VALUES(gross_revenue),
    net_revenue = VALUES(net_revenue),
    etl_loaded_at = NOW();
EOF

echo "=== ETL completed successfully ==="
```

### ETL avec Python et pandas

```python
#!/usr/bin/env python3
"""
etl_pipeline.py
Pipeline ETL pour charger les donn√©es OLTP vers ColumnStore
"""

import pandas as pd
import mariadb
from datetime import datetime, timedelta
import logging
from typing import Optional
import os

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ColumnStoreETL:
    """Pipeline ETL vers MariaDB ColumnStore"""
    
    def __init__(self, source_config: dict, target_config: dict):
        self.source_config = source_config
        self.target_config = target_config
        self.source_conn = None
        self.target_conn = None
    
    def connect(self):
        """√âtablir les connexions source et cible"""
        logger.info("Connecting to databases...")
        
        self.source_conn = mariadb.connect(**self.source_config)
        self.target_conn = mariadb.connect(**self.target_config)
        
        logger.info("Connections established")
    
    def close(self):
        """Fermer les connexions"""
        if self.source_conn:
            self.source_conn.close()
        if self.target_conn:
            self.target_conn.close()
    
    def extract_incremental(
        self, 
        table: str, 
        timestamp_col: str,
        last_load: datetime
    ) -> pd.DataFrame:
        """Extraction incr√©mentale depuis la source"""
        
        query = f"""
        SELECT * FROM {table}
        WHERE {timestamp_col} > %s
        ORDER BY {timestamp_col}
        """
        
        logger.info(f"Extracting from {table} since {last_load}")
        
        df = pd.read_sql(query, self.source_conn, params=[last_load])
        logger.info(f"Extracted {len(df)} rows from {table}")
        
        return df
    
    def transform_sales(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transformation des donn√©es de ventes"""
        
        logger.info("Transforming sales data...")
        
        # Calcul des m√©triques
        df['gross_amount'] = df['quantity'] * df['unit_price']
        df['net_amount'] = df['gross_amount'] - df['discount_amount'] + df['tax_amount']
        df['cost_amount'] = df['quantity'] * df['unit_cost']
        df['profit_amount'] = df['net_amount'] - df['cost_amount']
        df['profit_margin_pct'] = (
            df['profit_amount'] / df['net_amount'].replace(0, float('nan')) * 100
        ).fillna(0)
        
        # Cl√© de date (YYYYMMDD)
        df['date_key'] = pd.to_datetime(df['order_datetime']).dt.strftime('%Y%m%d').astype(int)
        
        # Colonnes finales
        columns = [
            'date_key', 'product_key', 'customer_key', 'store_key',
            'order_id', 'order_line_id', 'order_datetime', 'order_status',
            'payment_method', 'shipping_method',
            'quantity', 'unit_price', 'unit_cost',
            'gross_amount', 'discount_amount', 'tax_amount', 'shipping_amount',
            'net_amount', 'cost_amount', 'profit_amount', 'profit_margin_pct',
            'is_return', 'is_promotion', 'promotion_id'
        ]
        
        return df[columns]
    
    def lookup_dimension_keys(
        self, 
        df: pd.DataFrame,
        dim_table: str,
        business_key_col: str,
        surrogate_key_col: str
    ) -> pd.DataFrame:
        """Lookup des cl√©s de dimension (surrogate keys)"""
        
        # R√©cup√©rer le mapping depuis la dimension
        lookup_query = f"""
        SELECT {business_key_col}, {surrogate_key_col}
        FROM {dim_table}
        WHERE is_current = TRUE
        """
        
        lookup_df = pd.read_sql(lookup_query, self.target_conn)
        lookup_dict = dict(zip(
            lookup_df[business_key_col], 
            lookup_df[surrogate_key_col]
        ))
        
        # Appliquer le mapping
        source_col = business_key_col.replace('_id', '_key').replace('_key_key', '_key')
        df[f'{source_col}'] = df[business_key_col].map(lookup_dict)
        
        # V√©rifier les cl√©s manquantes
        missing = df[df[f'{source_col}'].isna()][business_key_col].unique()
        if len(missing) > 0:
            logger.warning(f"Missing dimension keys for {dim_table}: {missing[:10]}...")
        
        return df
    
    def load_to_columnstore(
        self, 
        df: pd.DataFrame, 
        table: str,
        batch_size: int = 10000
    ):
        """Chargement vers ColumnStore par batch"""
        
        logger.info(f"Loading {len(df)} rows to {table}...")
        
        cursor = self.target_conn.cursor()
        
        # Pr√©parer la requ√™te INSERT
        columns = ', '.join(df.columns)
        placeholders = ', '.join(['%s'] * len(df.columns))
        insert_query = f"INSERT INTO {table} ({columns}) VALUES ({placeholders})"
        
        # Insertion par batch
        total_loaded = 0
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            values = [tuple(row) for row in batch.values]
            
            cursor.executemany(insert_query, values)
            self.target_conn.commit()
            
            total_loaded += len(batch)
            logger.info(f"Loaded {total_loaded}/{len(df)} rows")
        
        cursor.close()
        logger.info(f"Successfully loaded {total_loaded} rows to {table}")
    
    def run_full_pipeline(self, last_load: datetime):
        """Ex√©cuter le pipeline complet"""
        
        try:
            self.connect()
            
            # 1. Extract
            orders_df = self.extract_incremental(
                'order_items', 
                'updated_at',
                last_load
            )
            
            if orders_df.empty:
                logger.info("No new data to process")
                return
            
            # 2. Transform
            sales_df = self.transform_sales(orders_df)
            
            # 3. Dimension lookups
            sales_df = self.lookup_dimension_keys(
                sales_df, 'dim_product', 'product_id', 'product_key'
            )
            sales_df = self.lookup_dimension_keys(
                sales_df, 'dim_customer', 'customer_id', 'customer_key'
            )
            
            # 4. Load
            self.load_to_columnstore(sales_df, 'fact_sales')
            
            logger.info("Pipeline completed successfully")
            
        finally:
            self.close()


# Point d'entr√©e
if __name__ == '__main__':
    source_config = {
        'host': os.environ.get('SOURCE_HOST', 'oltp-db'),
        'port': 3306,
        'user': 'etl_reader',
        'password': os.environ['SOURCE_PASSWORD'],
        'database': 'ecommerce'
    }
    
    target_config = {
        'host': os.environ.get('TARGET_HOST', 'columnstore-um'),
        'port': 3306,
        'user': 'etl_writer',
        'password': os.environ['TARGET_PASSWORD'],
        'database': 'ecommerce_dw'
    }
    
    # Derni√®re ex√©cution (√† stocker en base ou fichier)
    last_load = datetime.now() - timedelta(hours=1)
    
    etl = ColumnStoreETL(source_config, target_config)
    etl.run_full_pipeline(last_load)
```

---

## Optimisation des requ√™tes analytiques

### Bonnes pratiques

```sql
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- OPTIMISATION DES REQU√äTES COLUMNSTORE
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- ‚úÖ BON : Filtrer sur les colonnes pour extent elimination
-- Le filtre sur date_key permet d'√©liminer les extents non pertinents
SELECT 
    d.month_name,
    p.category_name,
    SUM(f.net_amount) AS revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
JOIN dim_product p ON f.product_key = p.product_key
WHERE d.year_number = 2025           -- Extent elimination efficace
  AND d.quarter_number = 1
GROUP BY d.month_name, p.category_name
ORDER BY revenue DESC;

-- ‚ùå MAUVAIS : Fonction sur la colonne filtr√©e (pas d'extent elimination)
SELECT 
    d.month_name,
    SUM(f.net_amount) AS revenue
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
WHERE YEAR(d.full_date) = 2025      -- Fonction emp√™che l'optimisation
GROUP BY d.month_name;

-- ‚úÖ BON : Pr√©-agr√©ger pour les dashboards fr√©quents
-- Utiliser les tables agr√©g√©es pour les requ√™tes r√©p√©titives
SELECT 
    year_month,
    SUM(net_revenue) AS revenue,
    SUM(profit_total) AS profit
FROM fact_monthly_sales
WHERE year_number = 2025
GROUP BY year_month
ORDER BY year_month;

-- ‚úÖ BON : Limiter les colonnes s√©lectionn√©es
-- ColumnStore lit seulement les colonnes demand√©es
SELECT 
    date_key,
    SUM(quantity),
    SUM(net_amount)
FROM fact_sales
WHERE date_key BETWEEN 20250101 AND 20250131
GROUP BY date_key;

-- ‚ùå MAUVAIS : SELECT * (lit toutes les colonnes)
SELECT *
FROM fact_sales
WHERE date_key BETWEEN 20250101 AND 20250131;

-- ‚úÖ BON : ORDER BY apr√®s les agr√©gations
SELECT 
    p.category_name,
    SUM(f.net_amount) AS revenue
FROM fact_sales f
JOIN dim_product p ON f.product_key = p.product_key
WHERE f.date_key >= 20250101
GROUP BY p.category_name
ORDER BY revenue DESC              -- Tri sur r√©sultat agr√©g√© (petit volume)
LIMIT 10;

-- ‚úÖ BON : Utiliser des CTE pour la lisibilit√© et l'optimisation
WITH monthly_sales AS (
    SELECT 
        d.year_month,
        d.year_number,
        d.month_number,
        SUM(f.net_amount) AS revenue
    FROM fact_sales f
    JOIN dim_date d ON f.date_key = d.date_key
    WHERE d.year_number IN (2024, 2025)
    GROUP BY d.year_month, d.year_number, d.month_number
),
with_comparison AS (
    SELECT 
        year_month,
        revenue,
        LAG(revenue, 12) OVER (ORDER BY year_month) AS revenue_prev_year
    FROM monthly_sales
)
SELECT 
    year_month,
    revenue,
    revenue_prev_year,
    (revenue - revenue_prev_year) / NULLIF(revenue_prev_year, 0) * 100 AS yoy_growth
FROM with_comparison
WHERE year_month >= '2025-01'
ORDER BY year_month;
```

### Analyser les performances

```sql
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- ANALYSE DES PERFORMANCES COLUMNSTORE
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- V√©rifier les statistiques de la requ√™te
SET infinidb_vtable_mode = 1;  -- Mode verbose

EXPLAIN SELECT 
    d.year_month,
    SUM(f.net_amount)
FROM fact_sales f
JOIN dim_date d ON f.date_key = d.date_key
WHERE d.year_number = 2025
GROUP BY d.year_month;

-- Statistiques d'extent elimination
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME,
    COLUMN_NAME,
    OBJECT_ID,
    EXTENT_COUNT,
    EXTENT_ROWS
FROM information_schema.COLUMNSTORE_EXTENTS
WHERE TABLE_SCHEMA = 'ecommerce_dw'
  AND TABLE_NAME = 'fact_sales';

-- Requ√™tes en cours d'ex√©cution
SELECT 
    ID,
    USER,
    HOST,
    DB,
    TIME,
    STATE,
    SUBSTRING(INFO, 1, 200) AS query_preview
FROM information_schema.PROCESSLIST
WHERE COMMAND != 'Sleep'
  AND TIME > 5
ORDER BY TIME DESC;

-- Utilisation m√©moire
SHOW STATUS LIKE 'columnstore%';
```

---

## D√©ploiement et dimensionnement

### Configuration cluster multi-n≈ìuds

```yaml
# docker-compose-columnstore-cluster.yml
version: '3.8'

services:
  # User Module (point d'entr√©e SQL)
  columnstore-um:
    image: mariadb/columnstore:latest
    hostname: um1
    container_name: columnstore-um
    environment:
      - MARIADB_ROOT_PASSWORD=${ROOT_PASSWORD}
      - MARIADB_USER=dw_user
      - MARIADB_PASSWORD=${DW_PASSWORD}
      - MARIADB_DATABASE=ecommerce_dw
      - COLUMNSTORE_MODULE_TYPE=um
      - COLUMNSTORE_UM_COUNT=1
      - COLUMNSTORE_PM_COUNT=3
    ports:
      - "3306:3306"
    volumes:
      - um-data:/var/lib/columnstore
      - ./config/Columnstore.xml:/etc/columnstore/Columnstore.xml
    networks:
      - columnstore-net
    depends_on:
      - columnstore-pm1
      - columnstore-pm2
      - columnstore-pm3

  # Performance Module 1
  columnstore-pm1:
    image: mariadb/columnstore:latest
    hostname: pm1
    container_name: columnstore-pm1
    environment:
      - COLUMNSTORE_MODULE_TYPE=pm
      - COLUMNSTORE_PM_ID=1
    volumes:
      - pm1-data:/var/lib/columnstore
      - ./data/pm1:/data/columnstore
    networks:
      - columnstore-net

  # Performance Module 2
  columnstore-pm2:
    image: mariadb/columnstore:latest
    hostname: pm2
    container_name: columnstore-pm2
    environment:
      - COLUMNSTORE_MODULE_TYPE=pm
      - COLUMNSTORE_PM_ID=2
    volumes:
      - pm2-data:/var/lib/columnstore
      - ./data/pm2:/data/columnstore
    networks:
      - columnstore-net

  # Performance Module 3
  columnstore-pm3:
    image: mariadb/columnstore:latest
    hostname: pm3
    container_name: columnstore-pm3
    environment:
      - COLUMNSTORE_MODULE_TYPE=pm
      - COLUMNSTORE_PM_ID=3
    volumes:
      - pm3-data:/var/lib/columnstore
      - ./data/pm3:/data/columnstore
    networks:
      - columnstore-net

volumes:
  um-data:
  pm1-data:
  pm2-data:
  pm3-data:

networks:
  columnstore-net:
    driver: bridge
```

### Dimensionnement

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GUIDE DE DIMENSIONNEMENT COLUMNSTORE                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  Volume donn√©es    ‚îÇ  Config recommand√©e                                    ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚îÇ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                    ‚îÇ
‚îÇ  < 100 GB          ‚îÇ  Single node (UM+PM combin√©)                           ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ 16 GB RAM, 4 cores                                  ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ SSD 500 GB                                          ‚îÇ
‚îÇ                    ‚îÇ                                                        ‚îÇ
‚îÇ  100 GB - 1 TB     ‚îÇ  1 UM + 2-3 PM                                         ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ UM: 16 GB RAM, 4 cores                              ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ PM: 32 GB RAM, 8 cores chacun                       ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ SSD 1-2 TB par PM                                   ‚îÇ
‚îÇ                    ‚îÇ                                                        ‚îÇ
‚îÇ  1 TB - 10 TB      ‚îÇ  1-2 UM + 5-10 PM                                      ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ UM: 32 GB RAM, 8 cores                              ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ PM: 64 GB RAM, 16 cores chacun                      ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ SSD NVMe 2-4 TB par PM                              ‚îÇ
‚îÇ                    ‚îÇ                                                        ‚îÇ
‚îÇ  > 10 TB           ‚îÇ  2+ UM (HA) + 10+ PM                                   ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ UM: 64 GB RAM, 16 cores                             ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ PM: 128 GB RAM, 32 cores chacun                     ‚îÇ
‚îÇ                    ‚îÇ  ‚Ä¢ Storage distribu√© (S3, GlusterFS)                   ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  R√®gles g√©n√©rales :                                                         ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                                                           ‚îÇ
‚îÇ  ‚Ä¢ RAM PM : 2-4 GB par TB de donn√©es compress√©es                            ‚îÇ
‚îÇ  ‚Ä¢ Compression typique : 5-10x (10 TB raw ‚Üí 1-2 TB stock√©)                  ‚îÇ
‚îÇ  ‚Ä¢ CPU : Plus de cores = meilleur parall√©lisme sur grosses requ√™tes         ‚îÇ
‚îÇ  ‚Ä¢ R√©seau : 10 Gbps minimum entre UM et PM pour gros volumes                ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Int√©gration dans une architecture data moderne

### Data Lakehouse avec ColumnStore

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARCHITECTURE DATA LAKEHOUSE                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  Sources                  Data Lake              Data Warehouse             ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê              ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê             ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                                ‚îÇ
‚îÇ  ‚îÇ OLTP    ‚îÇ‚îÄ‚îÄ‚îê                                                             ‚îÇ
‚îÇ  ‚îÇ Systems ‚îÇ  ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ          ‚îÇ                 ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ               ‚îÇ          ‚îÇ   S3 / MinIO    ‚îÇ    ‚îÇ   ColumnStore   ‚îÇ         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ          ‚îÇ   (Raw Zone)    ‚îÇ    ‚îÇ   (Gold Zone)   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ APIs    ‚îÇ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ                 ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  Ingest  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇETL ‚îÇ   Star Schema   ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ          ‚îÇ   ‚îÇ Parquet  ‚îÇ  ‚îÇ    ‚îÇ   Optimis√©      ‚îÇ         ‚îÇ
‚îÇ               ‚îÇ          ‚îÇ   ‚îÇ CSV      ‚îÇ  ‚îÇ    ‚îÇ                 ‚îÇ         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ          ‚îÇ   ‚îÇ JSON     ‚îÇ  ‚îÇ    ‚îÇ   fact_sales    ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ Streams ‚îÇ‚îÄ‚îÄ‚î§          ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ   dim_*         ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ (Kafka) ‚îÇ  ‚îÇ          ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ               ‚îÇ                   ‚îÇ                      ‚îÇ                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ Files   ‚îÇ‚îÄ‚îÄ‚îò          ‚îÇ   Spark/dbt     ‚îÇ    ‚îÇ   BI Tools      ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ (S3)    ‚îÇ             ‚îÇ   Processing    ‚îÇ    ‚îÇ   (Tableau,     ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ                 ‚îÇ    ‚îÇ    Metabase,    ‚îÇ         ‚îÇ
‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    Superset)    ‚îÇ         ‚îÇ
‚îÇ                                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  Avantages de cette architecture :                                          ‚îÇ
‚îÇ  ‚Ä¢ Donn√©es brutes pr√©serv√©es dans le Data Lake (S3)                         ‚îÇ
‚îÇ  ‚Ä¢ Traitement flexible avec Spark/dbt                                       ‚îÇ
‚îÇ  ‚Ä¢ ColumnStore pour les requ√™tes SQL haute performance                      ‚îÇ
‚îÇ  ‚Ä¢ S√©paration stockage (S3) et compute (ColumnStore)                        ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Requ√™tes analytiques avanc√©es

```sql
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
-- REQU√äTES ANALYTIQUES COMPLEXES
-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Analyse de cohortes (r√©tention client)
WITH first_purchase AS (
    SELECT 
        customer_key,
        MIN(date_key) AS cohort_date_key
    FROM fact_sales
    GROUP BY customer_key
),
cohort_data AS (
    SELECT 
        fp.cohort_date_key,
        d_cohort.year_month AS cohort_month,
        d_order.year_month AS order_month,
        PERIOD_DIFF(
            EXTRACT(YEAR_MONTH FROM d_order.full_date),
            EXTRACT(YEAR_MONTH FROM d_cohort.full_date)
        ) AS months_since_first,
        f.customer_key
    FROM fact_sales f
    JOIN first_purchase fp ON f.customer_key = fp.customer_key
    JOIN dim_date d_cohort ON fp.cohort_date_key = d_cohort.date_key
    JOIN dim_date d_order ON f.date_key = d_order.date_key
)
SELECT 
    cohort_month,
    months_since_first,
    COUNT(DISTINCT customer_key) AS customers,
    FIRST_VALUE(COUNT(DISTINCT customer_key)) OVER (
        PARTITION BY cohort_month ORDER BY months_since_first
    ) AS cohort_size,
    COUNT(DISTINCT customer_key) * 100.0 / 
        FIRST_VALUE(COUNT(DISTINCT customer_key)) OVER (
            PARTITION BY cohort_month ORDER BY months_since_first
        ) AS retention_pct
FROM cohort_data
WHERE cohort_month >= '2024-01'
  AND months_since_first <= 12
GROUP BY cohort_month, months_since_first
ORDER BY cohort_month, months_since_first;

-- Analyse RFM (Recency, Frequency, Monetary)
WITH customer_rfm AS (
    SELECT 
        c.customer_key,
        c.customer_id,
        c.full_name,
        DATEDIFF(CURRENT_DATE, MAX(d.full_date)) AS recency_days,
        COUNT(DISTINCT f.order_id) AS frequency,
        SUM(f.net_amount) AS monetary
    FROM fact_sales f
    JOIN dim_customer c ON f.customer_key = c.customer_key
    JOIN dim_date d ON f.date_key = d.date_key
    WHERE d.full_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)
      AND c.is_current = TRUE
    GROUP BY c.customer_key, c.customer_id, c.full_name
),
rfm_scores AS (
    SELECT 
        *,
        NTILE(5) OVER (ORDER BY recency_days DESC) AS r_score,  -- Lower is better
        NTILE(5) OVER (ORDER BY frequency) AS f_score,
        NTILE(5) OVER (ORDER BY monetary) AS m_score
    FROM customer_rfm
)
SELECT 
    customer_key,
    customer_id,
    full_name,
    recency_days,
    frequency,
    monetary,
    r_score,
    f_score,
    m_score,
    CONCAT(r_score, f_score, m_score) AS rfm_cell,
    CASE 
        WHEN r_score >= 4 AND f_score >= 4 AND m_score >= 4 THEN 'Champions'
        WHEN r_score >= 4 AND f_score >= 3 THEN 'Loyal Customers'
        WHEN r_score >= 4 AND f_score <= 2 THEN 'Recent Customers'
        WHEN r_score >= 3 AND f_score >= 3 THEN 'Promising'
        WHEN r_score <= 2 AND f_score >= 4 THEN 'At Risk'
        WHEN r_score <= 2 AND f_score <= 2 AND m_score >= 3 THEN 'Cant Lose Them'
        WHEN r_score <= 2 AND f_score <= 2 THEN 'Lost'
        ELSE 'Others'
    END AS rfm_segment
FROM rfm_scores
ORDER BY monetary DESC;

-- Analyse panier (Market Basket Analysis - Produits fr√©quemment achet√©s ensemble)
WITH order_products AS (
    SELECT 
        order_id,
        product_key
    FROM fact_sales
    WHERE date_key >= 20240101
),
product_pairs AS (
    SELECT 
        a.product_key AS product_a,
        b.product_key AS product_b,
        COUNT(DISTINCT a.order_id) AS pair_count
    FROM order_products a
    JOIN order_products b ON a.order_id = b.order_id AND a.product_key < b.product_key
    GROUP BY a.product_key, b.product_key
    HAVING pair_count >= 100
),
product_stats AS (
    SELECT 
        product_key,
        COUNT(DISTINCT order_id) AS product_orders
    FROM order_products
    GROUP BY product_key
)
SELECT 
    pa.product_name AS product_a_name,
    pb.product_name AS product_b_name,
    pp.pair_count,
    ps_a.product_orders AS orders_with_a,
    ps_b.product_orders AS orders_with_b,
    pp.pair_count * 1.0 / ps_a.product_orders AS support_a,
    pp.pair_count * 1.0 / ps_b.product_orders AS support_b,
    (pp.pair_count * 1.0 / ps_a.product_orders) / 
        (ps_b.product_orders * 1.0 / (SELECT COUNT(DISTINCT order_id) FROM order_products)) AS lift
FROM product_pairs pp
JOIN dim_product pa ON pp.product_a = pa.product_key AND pa.is_current = TRUE
JOIN dim_product pb ON pp.product_b = pb.product_key AND pb.is_current = TRUE
JOIN product_stats ps_a ON pp.product_a = ps_a.product_key
JOIN product_stats ps_b ON pp.product_b = ps_b.product_key
WHERE lift > 1.5
ORDER BY lift DESC
LIMIT 50;
```

---

## ‚úÖ Points cl√©s √† retenir

- **ColumnStore** est optimis√© pour les requ√™tes analytiques lisant peu de colonnes mais beaucoup de lignes ‚Äî gains de 10x √† 100x vs InnoDB
- **Le Star Schema** est le mod√®le de r√©f√©rence : une table de faits centrale entour√©e de dimensions d√©normalis√©es
- **L'Extent Elimination** est la cl√© de performance ‚Äî filtrer sur des colonnes avec bonne distribution min/max
- **cpimport** est l'outil de chargement bulk optimal ‚Äî bien plus rapide que INSERT
- **Les tables agr√©g√©es** (daily, monthly) acc√©l√®rent drastiquement les dashboards fr√©quents
- **Dimensionnement** : 2-4 GB RAM par TB de donn√©es compress√©es sur les Performance Modules
- **SCD Type 2** permet de tracer l'historique des dimensions (effective_start_date, effective_end_date, is_current)
- **L'architecture Lakehouse** combine le meilleur du Data Lake (S3, flexibilit√©) et du Data Warehouse (ColumnStore, SQL)

---

## üîó Ressources et r√©f√©rences

- [üìñ MariaDB ColumnStore Documentation](https://mariadb.com/kb/en/mariadb-columnstore/)
- [üìñ The Data Warehouse Toolkit - Ralph Kimball](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/)
- [üìñ cpimport User Guide](https://mariadb.com/kb/en/columnstore-bulk-data-loading/)
- [üìñ ColumnStore System Variables](https://mariadb.com/kb/en/columnstore-system-variables/)
- [üìñ Star Schema Best Practices](https://mariadb.com/kb/en/columnstore-star-schema/)

---

## ‚û°Ô∏è Section suivante

[20.4 Architecture Multi-Tenant](./04-architecture-multi-tenant.md) : D√©couvrez les strat√©gies d'isolation des donn√©es pour les applications SaaS avec MariaDB.

‚è≠Ô∏è[Architecture multi-tenant](/20-cas-usage-architectures/04-architecture-multi-tenant.md)
