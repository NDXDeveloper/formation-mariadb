ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13.4.2 Avantages pour Failover

> **Niveau** : AvancÃ©  
> **DurÃ©e estimÃ©e** : 3 heures  
> **PrÃ©requis** : 
> - Section 13.4.1 (Configuration GTID)
> - Section 13.1 (Concepts de rÃ©plication)
> - ComprÃ©hension des architectures haute disponibilitÃ©
> - ExpÃ©rience en gestion d'incidents production

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de cette section, vous serez capable de :
- Comprendre comment GTID simplifie drastiquement les opÃ©rations de failover
- Comparer les procÃ©dures de failover avec et sans GTID
- ImplÃ©menter un failover automatique avec GTID
- GÃ©rer des scÃ©narios de failover complexes (multi-tier, multi-source)
- Utiliser les outils d'automatisation de failover (MaxScale, Orchestrator)
- RÃ©duire le RTO (Recovery Time Objective) grÃ¢ce Ã  GTID
- PrÃ©venir les split-brain et divergences de donnÃ©es
- Optimiser les failovers avec les nouveautÃ©s MariaDB 11.8

---

## Introduction

Le **failover** est l'opÃ©ration critique de bascule du trafic d'un Primary dÃ©faillant vers un Replica fonctionnel. C'est un moment **Ã  haut risque** oÃ¹ chaque seconde compte et oÃ¹ une erreur peut causer :

- **Perte de donnÃ©es** (transactions non rÃ©pliquÃ©es)
- **IncohÃ©rence** (divergence entre serveurs)
- **IndisponibilitÃ© prolongÃ©e** (calculs de position erronÃ©s)
- **Split-brain** (plusieurs Primary actifs simultanÃ©ment)

Le **GTID (Global Transaction Identifier)** transforme radicalement cette opÃ©ration en automatisant ce qui Ã©tait auparavant **manuel, complexe et risquÃ©**.

### Contexte : Le problÃ¨me du failover sans GTID

**ScÃ©nario traditionnel (positions binlog)** :

```
Primary crash Ã  : mariadb-bin.000015, position 67890
Question critique : Quelle position utiliser sur le nouveau Primary ?

ProblÃ¨mes :
1. Le Replica A est Ã  : mariadb-bin.000015, position 67850 (40 octets de retard)
2. Le Replica B est Ã  : mariadb-bin.000015, position 67890 (Ã  jour)
3. Le Replica C est Ã  : mariadb-bin.000014, position 99999 (trÃ¨s en retard)

DÃ©cisions complexes :
- Quel Replica promouvoir ? (B est le meilleur candidat)
- Comment configurer A pour se connecter Ã  B ?
- Quelle position binlog A doit-il utiliser pour se synchroniser Ã  B ?
- Comment garantir qu'aucune transaction n'est perdue ?

DurÃ©e du failover : 10-30 minutes (selon expertise)
Risque d'erreur : Ã‰LEVÃ‰
```

**Avec GTID** :

```
Primary crash
GTID Position : 0-1-5000

Replica A : 0-1-4998 (2 transactions de retard)
Replica B : 0-1-5000 (Ã  jour)  âœ… Meilleur candidat
Replica C : 0-1-4500 (500 transactions de retard)

DÃ©cision automatisÃ©e :
1. Promouvoir B (plus Ã  jour)
2. Pointer A vers B avec SOURCE_USE_GTID = slave_pos
3. A rattrape automatiquement (de 0-1-4998 Ã  0-1-5000)
4. C rattrape automatiquement (de 0-1-4500 Ã  0-1-5000+)

DurÃ©e du failover : 30 secondes - 2 minutes
Risque d'erreur : FAIBLE
Automatisable : OUI
```

ğŸ’¡ **Gain clÃ©** : GTID rÃ©duit le **RTO (Recovery Time Objective)** de 90% et le **risque d'erreur humaine** de 95%.

---

## Comparaison DÃ©taillÃ©e : Failover Sans vs Avec GTID

### Failover Sans GTID (Positions Binlog)

**Ã‰tape 1 : Identifier le Replica le plus Ã  jour**

```bash
# Sur chaque Replica, exÃ©cuter :
mariadb -e "SHOW SLAVE STATUS\G" | grep -E "Master_Log_File|Read_Master_Log_Pos|Exec_Master_Log_Pos"

# Replica A :
Master_Log_File: mariadb-bin.000015
Read_Master_Log_Pos: 67890
Exec_Master_Log_Pos: 67850

# Replica B :
Master_Log_File: mariadb-bin.000015
Read_Master_Log_Pos: 67890
Exec_Master_Log_Pos: 67890  âœ… Plus Ã  jour

# Replica C :
Master_Log_File: mariadb-bin.000014
Read_Master_Log_Pos: 99999
Exec_Master_Log_Pos: 99999
```

**ComplexitÃ©** : Il faut **comparer manuellement** les fichiers ET les positions.

**Ã‰tape 2 : Promouvoir le Replica B**

```sql
-- Sur Replica B
STOP SLAVE;
RESET SLAVE ALL;
SET GLOBAL read_only = OFF;
```

**Ã‰tape 3 : Calculer la position pour Replica A** âš ï¸ **Point critique**

```
ProblÃ¨me : Replica A doit se connecter Ã  Replica B (nouveau Primary)
Question : Quelle position binlog utiliser ?

Replica A Ã©tait Ã  : mariadb-bin.000015, position 67850 (old Primary)
Replica B (nouveau Primary) a un binlog diffÃ©rent : mariadb-bin.000001, position XXX

IMPOSSIBLE de convertir directement !
```

**Solution traditionnelle** (complexe et risquÃ©e) :

```sql
-- Option 1 : Utiliser mysqlbinlog pour extraire les positions
-- TrÃ¨s technique, risque d'erreur Ã©levÃ©

-- Option 2 : Recommencer from scratch (perte de temps)
-- Sur Replica A : Dump complet de B, puis restaurer
-- DurÃ©e : 1-4 heures selon taille de la base
```

âš ï¸ **ProblÃ¨me majeur** : Pas de correspondance automatique entre les binlogs de diffÃ©rents serveurs.

**DurÃ©e totale** : 15-60 minutes (voire plusieurs heures)  
**Risque** : Perte de donnÃ©es, configurations incorrectes  
**ComplexitÃ©** : Requiert expertise DBA senior

---

### Failover Avec GTID (AutomatisÃ©)

**Ã‰tape 1 : Identifier le Replica le plus Ã  jour**

```sql
-- Sur chaque Replica, exÃ©cuter :
SELECT @@gtid_slave_pos;

-- Replica A : 0-1-4998
-- Replica B : 0-1-5000  âœ… Plus Ã  jour
-- Replica C : 0-1-4500
```

**SimplicitÃ©** : Une seule requÃªte, comparaison triviale des numÃ©ros de sÃ©quence.

**Ã‰tape 2 : Promouvoir Replica B**

```sql
-- Sur Replica B
STOP REPLICA;
RESET REPLICA ALL;
SET GLOBAL read_only = OFF;
SET GLOBAL super_read_only = OFF;

-- C'est fini ! Replica B est le nouveau Primary
```

**Ã‰tape 3 : Reconfigurer Replica A** ğŸš€ **Automatique**

```sql
-- Sur Replica A
STOP REPLICA;

CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '192.168.1.102',  -- IP de Replica B (nouveau Primary)
  SOURCE_USE_GTID = slave_pos;    -- MAGIE : Trouve automatiquement la position

START REPLICA;

-- GTID compare automatiquement :
-- Position Replica A : 0-1-4998
-- Position Replica B : 0-1-5000
-- RÃ©sultat : A rattrape les transactions 4999 et 5000 automatiquement
```

**Ã‰tape 4 : Reconfigurer Replica C** (identique)

```sql
-- Sur Replica C
STOP REPLICA;
CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '192.168.1.102',
  SOURCE_USE_GTID = slave_pos;
START REPLICA;

-- Rattrape automatiquement de 0-1-4500 Ã  0-1-5000+
```

**DurÃ©e totale** : 30 secondes - 2 minutes  
**Risque** : Minimal (synchronisation automatique)  
**ComplexitÃ©** : DBA junior peut l'exÃ©cuter  
**Automatisable** : OUI (scripts, outils)

---

## Tableau Comparatif Complet

| Aspect | Sans GTID (Binlog Positions) | Avec GTID | Gain |
|--------|------------------------------|-----------|------|
| **Identification Replica Ã  jour** | Comparaison manuelle fichier+position | Une requÃªte : `SELECT @@gtid_slave_pos` | -90% temps |
| **Promotion nouveau Primary** | Identique | Identique | - |
| **Reconfiguration autres Replicas** | Calcul complexe de positions | `SOURCE_USE_GTID = slave_pos` | -95% complexitÃ© |
| **Synchronisation automatique** | âŒ Manuelle | âœ… Automatique | Critique |
| **Risque d'erreur** | â˜…â˜…â˜…â˜…â˜… (trÃ¨s Ã©levÃ©) | â˜…â˜†â˜†â˜†â˜† (minimal) | -95% |
| **DurÃ©e RTO** | 15-60 minutes | 30s - 2 min | -90% |
| **Automatisable** | âŒ Difficile | âœ… Facile | Oui |
| **Expertise requise** | DBA Senior | DBA Junior | Accessible |
| **Perte de donnÃ©es** | Risque Ã©levÃ© | Risque faible | -80% |
| **Split-brain** | Risque moyen | DÃ©tectable | +50% sÃ©curitÃ© |

---

## ScÃ©narios de Failover Avec GTID

### ScÃ©nario 1 : Failover Simple (Primary â†’ Replica)

**Architecture initiale** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRIMARY A   â”‚  GTID: 0-1-5000
â”‚ 192.168.1.100â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚
       â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPLICA B   â”‚  â”‚  REPLICA C   â”‚
â”‚ 192.168.1.101â”‚  â”‚ 192.168.1.102â”‚
â”‚ 0-1-5000     â”‚  â”‚ 0-1-4998     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Incident** : Primary A tombe (hardware failure).

**ProcÃ©dure de failover** :

```bash
#!/bin/bash
# failover_simple.sh

# 1. VÃ©rifier les positions GTID
echo "=== VÃ©rification positions GTID ==="
REPLICA_B_POS=$(mariadb -h 192.168.1.101 -N -e "SELECT @@gtid_slave_pos")
REPLICA_C_POS=$(mariadb -h 192.168.1.102 -N -e "SELECT @@gtid_slave_pos")

echo "Replica B: $REPLICA_B_POS"
echo "Replica C: $REPLICA_C_POS"

# 2. Identifier le meilleur candidat (simplifiÃ©)
# Dans un script rÃ©el, parser et comparer les sequence numbers
echo "Replica B est le plus Ã  jour, promotion..."

# 3. Promouvoir Replica B
mariadb -h 192.168.1.101 <<EOF
STOP REPLICA;
RESET REPLICA ALL;
SET GLOBAL read_only = OFF;
SET GLOBAL super_read_only = OFF;
EOF

echo "Replica B promoted to Primary"

# 4. Reconfigurer Replica C vers nouveau Primary (Replica B)
mariadb -h 192.168.1.102 <<EOF
STOP REPLICA;
CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '192.168.1.101',
  SOURCE_USER = 'repl_user',
  SOURCE_PASSWORD = 'SecurePassword123!',
  SOURCE_USE_GTID = slave_pos;
START REPLICA;
EOF

echo "Replica C reconfigured to replicate from new Primary (Replica B)"

# 5. VÃ©rifier la rÃ©plication
mariadb -h 192.168.1.102 -e "SHOW REPLICA STATUS\G" | grep -E "Slave_IO_Running|Slave_SQL_Running|Gtid_Slave_Pos"

echo "=== Failover completed ==="
```

**Architecture finale** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRIMARY B   â”‚  (anciennement Replica B)
â”‚ 192.168.1.101â”‚  GTID: 0-1-5000+
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPLICA C   â”‚
â”‚ 192.168.1.102â”‚
â”‚ 0-1-5000     â”‚  (rattrape automatiquement)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DurÃ©e** : ~1 minute  
**Impact** : IndisponibilitÃ© minimale

---

### ScÃ©nario 2 : Failover Multi-Tier (Cascade)

**Architecture initiale** :

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PRIMARY A   â”‚  GTID: 0-1-10000
        â”‚ 192.168.1.100â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚
        â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPLICA B   â”‚  â”‚  REPLICA C   â”‚
â”‚ 192.168.1.101â”‚  â”‚ 192.168.1.102â”‚
â”‚ 0-1-10000    â”‚  â”‚ 0-1-10000    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPLICA D   â”‚  (cascade depuis B)
â”‚ 192.168.1.103â”‚
â”‚ 0-1-9998     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Incident** : Primary A tombe.

**ProblÃ¨me spÃ©cifique** : Replica D est en cascade via Replica B. Si on promeut C, D doit Ãªtre reconfigurÃ©.

**Solution avec GTID** :

```sql
-- 1. Promouvoir Replica C (le plus Ã  jour, tier 1)
-- Sur Replica C
STOP REPLICA;
RESET REPLICA ALL;
SET GLOBAL read_only = OFF;

-- 2. Reconfigurer Replica B vers nouveau Primary C
-- Sur Replica B
STOP REPLICA;
CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '192.168.1.102',  -- Nouveau Primary C
  SOURCE_USE_GTID = slave_pos;
START REPLICA;

-- 3. Replica D continue automatiquement !
-- D rÃ©plique depuis B, qui lui-mÃªme rÃ©plique depuis C
-- GTID garantit la cohÃ©rence : 0-1-9998 â†’ 0-1-10000 â†’ 0-1-10000+
-- Pas de reconfiguration nÃ©cessaire sur D !
```

**Architecture finale** :

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PRIMARY C   â”‚  (anciennement Replica C)
        â”‚ 192.168.1.102â”‚  GTID: 0-1-10000+
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  REPLICA B   â”‚
        â”‚ 192.168.1.101â”‚
        â”‚ 0-1-10000    â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  REPLICA D   â”‚
        â”‚ 192.168.1.103â”‚
        â”‚ 0-1-10000    â”‚  (rattrape automatiquement via B)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ **Avantage GTID** : Les replicas en cascade **n'ont pas besoin d'Ãªtre reconfigurÃ©s** si leur parent intermÃ©diaire reste actif. GTID traverse toute la hiÃ©rarchie.

---

### ScÃ©nario 3 : Failover Multi-Source

**Architecture initiale** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRIMARY A   â”‚         â”‚  PRIMARY B   â”‚
â”‚ (ecommerce)  â”‚         â”‚ (CRM)        â”‚
â”‚ Domain 0     â”‚         â”‚ Domain 1     â”‚
â”‚ 0-100-5000   â”‚         â”‚ 1-200-3000   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚      â”‚
                â–¼      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  REPLICA C       â”‚
         â”‚  Multi-Source    â”‚
         â”‚  0-100-5000,     â”‚
         â”‚  1-200-3000      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Incident** : Primary A (ecommerce, domain 0) tombe.

**ProblÃ¨me** : Replica C rÃ©plique depuis deux sources. On ne peut pas le promouvoir directement.

**Solution : Promotion sÃ©lective avec GTID** :

```sql
-- Option 1 : CrÃ©er un nouveau Primary pour domain 0
-- Restaurer Primary A ou crÃ©er un nouveau serveur

-- Option 2 : Promouvoir Replica C en Primary pour domain 0 uniquement
-- Sur Replica C : Stopper seulement la connexion 'ecommerce'
STOP REPLICA 'ecommerce';

-- Extraire la position domain 0 uniquement
SELECT @@gtid_slave_pos;
-- RÃ©sultat : 0-100-5000,1-200-3000

-- CrÃ©er un nouveau Replica D dÃ©diÃ© au domaine 0
-- Sur nouveau serveur D :
SET GLOBAL gtid_slave_pos = '0-100-5000';

CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '192.168.1.103',  -- Replica C devient Primary pour domain 0
  SOURCE_USER = 'repl_user',
  SOURCE_PASSWORD = 'SecurePass',
  SOURCE_USE_GTID = slave_pos,
  DO_DOMAIN_IDS = (0);  -- RÃ©pliquer seulement domain 0

START REPLICA;
```

**Architecture finale** :

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  PRIMARY B   â”‚
                        â”‚ (CRM)        â”‚
                        â”‚ Domain 1     â”‚
                        â”‚ 1-200-3000+  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚                 â”‚
         â–¼                     â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REPLICA C       â”‚  â”‚  REPLICA D       â”‚  â”‚  REPLICA E   â”‚
â”‚  Multi-Source    â”‚  â”‚  (Domain 0 only) â”‚  â”‚  (Domain 1)  â”‚
â”‚  (Primary D0)    â”‚  â”‚  0-100-5000      â”‚  â”‚  1-200-3000  â”‚
â”‚  0-100-5000+,    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  1-200-3000+     â”‚           â–²
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                               â”‚
                    RÃ©plique domain 0 depuis C
```

ğŸ’¡ **Avantage GTID** : Les **domain IDs** permettent une gestion granulaire en cas de failover multi-source. Chaque domaine peut avoir son propre Primary de failover.

---

## Outils d'Automatisation de Failover avec GTID

### MaxScale : Automatic Failover

**MaxScale** est le proxy intelligent de MariaDB qui supporte le failover automatique avec GTID.

**Configuration MaxScale** :

```ini
# /etc/maxscale.cnf

[maxscale]
threads = auto

# Serveurs MariaDB
[Primary-Server]
type = server
address = 192.168.1.100
port = 3306
protocol = MariaDBBackend

[Replica-1]
type = server
address = 192.168.1.101
port = 3306
protocol = MariaDBBackend

[Replica-2]
type = server
address = 192.168.1.102
port = 3306
protocol = MariaDBBackend

# Monitor avec auto-failover
[MariaDB-Monitor]
type = monitor
module = mariadbmon
servers = Primary-Server, Replica-1, Replica-2
user = maxscale_monitor
password = MonitorPassword123!

# ParamÃ¨tres de monitoring
monitor_interval = 2000  # 2 secondes

# Failover automatique avec GTID
auto_failover = true
auto_rejoin = true

# Utiliser GTID pour la promotion
enforce_read_only_slaves = true
switchover_on_low_disk_space = true

# DurÃ©e de vÃ©rification avant failover (Ã©viter split-brain)
failcount = 3
verify_master_failure = true
master_failure_timeout = 10s

# Service ReadWriteSplit
[Read-Write-Service]
type = service
router = readwritesplit
servers = Primary-Server, Replica-1, Replica-2
user = maxscale_user
password = ServicePassword123!

# Options de routing
master_failure_mode = error_on_write
master_accept_reads = true

# Listener
[Read-Write-Listener]
type = listener
service = Read-Write-Service
protocol = MariaDBClient
port = 3306
address = 0.0.0.0
```

**Fonctionnement du failover automatique** :

```
1. MaxScale dÃ©tecte que Primary est down (3 Ã©checs consÃ©cutifs)
2. MaxScale identifie le Replica avec le GTID le plus Ã©levÃ© (Replica-1 : 0-1-5000)
3. MaxScale promeut Replica-1 :
   - STOP REPLICA
   - SET GLOBAL read_only = OFF
4. MaxScale reconfigure Replica-2 :
   - CHANGE REPLICATION SOURCE TO SOURCE_HOST='Replica-1', SOURCE_USE_GTID=slave_pos
5. MaxScale redirige le trafic vers le nouveau Primary (Replica-1)

DurÃ©e totale : 6-10 secondes (detection + promotion)
```

ğŸ†• **MaxScale 25.01 (MariaDB 11.8)** : 
- **Workload Capture** : Enregistre le trafic pour replay post-failover
- **Diff Router** : Compare les rÃ©sultats entre Primary et Replica
- **Optimistic ALTER** : RÃ©duit le lag pendant DDL lourds

ğŸ’¡ **Avantage** : Failover **100% automatique**, aucune intervention humaine nÃ©cessaire.

---

### Orchestrator : Topology Management

**Orchestrator** est un outil open-source de gestion de topologie de rÃ©plication avec support GTID.

**Installation et configuration** :

```bash
# Installation
wget https://github.com/openark/orchestrator/releases/download/v3.2.6/orchestrator-3.2.6-1.x86_64.rpm
sudo rpm -i orchestrator-3.2.6-1.x86_64.rpm

# Configuration : /etc/orchestrator.conf.json
```

**Configuration JSON** :

```json
{
  "Debug": false,
  "MySQLTopologyUser": "orchestrator",
  "MySQLTopologyPassword": "OrchestratorPass123!",
  "MySQLTopologyMaxPoolConnections": 3,
  "DatabaselessMode__experimental": false,
  
  "MySQLOrchestratorHost": "127.0.0.1",
  "MySQLOrchestratorPort": 3306,
  "MySQLOrchestratorDatabase": "orchestrator",
  "MySQLOrchestratorUser": "orchestrator",
  "MySQLOrchestratorPassword": "OrchestratorPass123!",
  
  "DetectClusterAliasQuery": "SELECT 'main_cluster'",
  "DetectInstanceAliasQuery": "SELECT @@hostname",
  
  "RecoveryPeriodBlockSeconds": 3600,
  "RecoveryIgnoreHostnameFilters": [],
  "RecoverMasterClusterFilters": ["*"],
  "RecoverIntermediateMasterClusterFilters": ["*"],
  
  "AutomaticFailover": true,
  "FailoverPeriodSeconds": 300,
  
  "ApplyMySQLPromotionAfterMasterFailover": true,
  "MasterFailoverLostInstancesDowntimeMinutes": 10,
  "DetachLostReplicasAfterMasterFailover": true,
  
  "EnableGTIDMode": true,
  "GTIDStrictMode": true
}
```

**Utilisation** :

```bash
# DÃ©marrer Orchestrator
sudo systemctl start orchestrator

# Interface Web : http://localhost:3000

# CLI : DÃ©couvrir un cluster
orchestrator-client -c discover -i 192.168.1.100:3306

# Forcer un failover manuel
orchestrator-client -c graceful-master-takeover -alias main_cluster -d 192.168.1.101:3306

# Lister la topologie
orchestrator-client -c topology -alias main_cluster
```

**Failover automatique avec Orchestrator** :

```
1. Orchestrator dÃ©tecte Primary down (heartbeat manquant)
2. Identifie le meilleur candidat via GTID (@@gtid_slave_pos)
3. Promeut le candidat
4. Reconfigure tous les autres Replicas
5. Envoie des notifications (email, Slack, PagerDuty)
6. Log tous les Ã©vÃ©nements

DurÃ©e : 10-30 secondes
```

ğŸ’¡ **Avantage** : Interface graphique, historique des failovers, support multi-cluster.

---

## RÃ©duction du RTO avec GTID

Le **RTO (Recovery Time Objective)** est le temps maximum acceptable d'indisponibilitÃ©. GTID rÃ©duit drastiquement le RTO.

### Mesure du RTO Sans GTID

```
Incident : Primary crash Ã  10:00:00

10:00:00 - Detection (monitoring)
10:00:30 - Alerte envoyÃ©e aux DBA
10:01:00 - DBA connectÃ©, diagnostic
10:03:00 - DÃ©cision de failover
10:05:00 - Identification du Replica le plus Ã  jour (SHOW SLAVE STATUS Ã— N)
10:10:00 - Calcul des positions binlog (complexe)
10:20:00 - Promotion du nouveau Primary
10:25:00 - Reconfiguration des autres Replicas (calculs de positions)
10:35:00 - Tests de validation
10:40:00 - Redirection du trafic applicatif

RTO total : 40 minutes
IndisponibilitÃ© : 40 minutes
```

### Mesure du RTO Avec GTID (Automatique)

```
Incident : Primary crash Ã  10:00:00

10:00:00 - Detection (monitoring)
10:00:06 - MaxScale dÃ©tecte (3 Ã— 2 secondes)
10:00:08 - Identification Replica le plus Ã  jour (SELECT @@gtid_slave_pos)
10:00:10 - Promotion automatique (STOP REPLICA; SET read_only=OFF)
10:00:12 - Reconfiguration automatique (CHANGE MASTER ... SOURCE_USE_GTID)
10:00:15 - Redirection trafic (MaxScale)
10:00:20 - Validation automatique

RTO total : 20 secondes
IndisponibilitÃ© : 20 secondes
RÃ©duction : 99% du RTO
```

### Impact Business

| MÃ©trique | Sans GTID | Avec GTID | Gain |
|----------|-----------|-----------|------|
| **RTO** | 30-60 min | 20s - 2 min | -95% |
| **Perte transactions** | 100-1000+ | 0-10 | -99% |
| **CoÃ»t indisponibilitÃ©** | 50Kâ‚¬/h Ã— 0.5h = 25Kâ‚¬ | 50Kâ‚¬/h Ã— 0.01h = 500â‚¬ | -98% |
| **Risque erreur** | 20-30% | 1-2% | -90% |
| **Stress Ã©quipe** | â˜…â˜…â˜…â˜…â˜… | â˜…â˜†â˜†â˜†â˜† | -80% |

ğŸ’¡ **ROI** : Pour une entreprise avec 50Kâ‚¬/h de coÃ»t d'indisponibilitÃ©, GTID peut Ã©conomiser **24,500â‚¬ par incident**.

---

## PrÃ©vention du Split-Brain avec GTID

Le **split-brain** est un scÃ©nario catastrophique oÃ¹ **deux serveurs agissent comme Primary simultanÃ©ment**, causant des divergences de donnÃ©es impossibles Ã  rÃ©concilier.

### ScÃ©nario Split-Brain Sans Protection

```
1. Primary A et Replica B perdent la connectivitÃ© rÃ©seau (partition rÃ©seau)
2. Primary A continue Ã  accepter les Ã©critures : GTID 0-1-5000 â†’ 0-1-5100
3. Replica B est promu en Primary (failover automatique) : GTID 0-1-5000 â†’ 0-1-5050
4. RÃ©seau restaurÃ© : CONFLIT !
   - Primary A : 0-1-5100
   - Primary B : 0-1-5050
   MÃªmes GTIDs (0-1-5001 Ã  0-1-5050) avec transactions DIFFÃ‰RENTES
```

### Protection Split-Brain Avec GTID Strict Mode

```sql
-- Configuration sur TOUS les serveurs
SET GLOBAL gtid_strict_mode = ON;
```

**Comportement** :

```
1. Partition rÃ©seau : A et B isolÃ©s
2. A continue : 0-1-5000 â†’ 0-1-5100
3. B promu : 0-1-5000 â†’ tente d'Ã©crire 0-1-5001
4. GTID Strict Mode dÃ©tecte : "Je ne suis pas le serveur 1 (server_id original)"
5. B refuse l'Ã©criture directe avec server_id=1
6. B doit utiliser un nouveau domain_id ou server_id
```

**Solution recommandÃ©e** :

```sql
-- Lors du failover, changer le domain_id
-- Sur Replica B promu :
SET GLOBAL gtid_domain_id = 1;  -- Nouveau domain (Ã©tait 0)

-- Les nouvelles transactions utilisent :
-- Format : 1-2-1, 1-2-2, etc.
-- Pas de conflit avec les GTID de A (0-1-XXXX)
```

### DÃ©tection Split-Brain Avec GTID

```sql
-- Script de monitoring pour dÃ©tecter split-brain
SELECT 
  @@hostname AS server,
  @@server_id AS server_id,
  @@gtid_domain_id AS domain_id,
  @@gtid_binlog_pos AS position,
  @@read_only AS read_only,
  @@super_read_only AS super_read_only;

-- Sur chaque serveur du cluster
-- Alerter si :
-- 1. Plusieurs serveurs avec read_only = OFF (plusieurs Primary)
-- 2. Overlap dans les GTID sequences avec server_id diffÃ©rents
```

ğŸ’¡ **Best Practice** : Utiliser **GTID strict mode** + **VIP (Virtual IP)** + **fencing** (STONITH) pour garantir un seul Primary actif.

---

## Impact de MariaDB 11.8 sur le Failover

### Optimistic ALTER TABLE et RÃ©duction du Lag

**ProblÃ¨me traditionnel** :

```sql
-- Sur Primary : ALTER TABLE de 4 heures
ALTER TABLE huge_orders ADD INDEX idx_created_at(created_at);

-- Impact sur Replicas :
-- Seconds_Behind_Master = 14400 (4 heures)
-- Toute la rÃ©plication est bloquÃ©e

-- Pendant un failover :
-- Replica avec lag de 4h ne peut PAS Ãªtre promu
-- On doit attendre la fin de l'ALTER (4h supplÃ©mentaires !)
-- RTO dÃ©gradÃ© : 4 heures au lieu de 2 minutes
```

ğŸ†• **MariaDB 11.8 : Optimistic ALTER TABLE**

```sql
-- MÃªme ALTER de 4 heures
ALTER TABLE huge_orders ADD INDEX idx_created_at(created_at);

-- Impact avec Optimistic ALTER :
-- Seconds_Behind_Master pour AUTRES tables : < 60 secondes
-- Seule la table huge_orders est en attente

-- Pendant un failover :
-- Replica peut Ãªtre promu IMMÃ‰DIATEMENT
-- L'ALTER en cours est gÃ©rÃ© intelligemment :
--   Option 1 : Continuer l'ALTER sur le nouveau Primary
--   Option 2 : Rollback et relancer plus tard
-- RTO prÃ©servÃ© : 2 minutes au lieu de 4 heures
```

**Configuration** :

```ini
[mariadb]
# ActivÃ© automatiquement avec GTID en 11.8
replication_optimize_for_static_plugin_config = ON
```

**Impact sur failover** :

| ScÃ©nario | Sans Optimistic ALTER | Avec Optimistic ALTER (11.8) |
|----------|----------------------|------------------------------|
| ALTER 1h en cours | RTO = 1 heure (attente) | RTO = 2 minutes âœ… |
| ALTER 4h en cours | RTO = 4 heures | RTO = 2 minutes âœ… |
| Lag durant ALTER | 3600+ secondes | < 60 secondes âœ… |
| Candidate pool | 1 Replica (sans ALTER) | Tous les Replicas âœ… |

ğŸ’¡ **Gain critique** : Les opÃ©rations DDL lourdes ne **bloquent plus le failover**. C'est une rÃ©volution pour la haute disponibilitÃ©.

---

## ProcÃ©dure de Failover ComplÃ¨te (Production)

Voici une procÃ©dure complÃ¨te et sÃ©curisÃ©e de failover avec GTID pour la production.

### PrÃ©-requis

```bash
# VÃ©rifier que GTID est activÃ© partout
for host in primary replica1 replica2; do
  echo "=== $host ==="
  mariadb -h $host -e "SELECT @@gtid_strict_mode, @@gtid_domain_id, @@server_id"
done

# VÃ©rifier la rÃ©plication
for host in replica1 replica2; do
  echo "=== $host ==="
  mariadb -h $host -e "SHOW REPLICA STATUS\G" | grep -E "Slave_IO_Running|Slave_SQL_Running|Gtid_Slave_Pos"
done
```

### Phase 1 : DÃ©tection et Validation

```bash
#!/bin/bash
# failover_production.sh - Phase 1

PRIMARY_HOST="192.168.1.100"
REPLICA1_HOST="192.168.1.101"
REPLICA2_HOST="192.168.1.102"

# 1. VÃ©rifier que Primary est vraiment down
echo "=== VÃ©rification Primary down ==="
if mariadb -h $PRIMARY_HOST -e "SELECT 1" 2>/dev/null; then
  echo "ERROR: Primary is still responding. Aborting failover."
  exit 1
fi
echo "Primary confirmed down"

# 2. Identifier le Replica le plus Ã  jour
echo "=== Identification meilleur candidat ==="
REPLICA1_POS=$(mariadb -h $REPLICA1_HOST -N -e "SELECT @@gtid_slave_pos")
REPLICA2_POS=$(mariadb -h $REPLICA2_HOST -N -e "SELECT @@gtid_slave_pos")

echo "Replica1 GTID: $REPLICA1_POS"
echo "Replica2 GTID: $REPLICA2_POS"

# Parser et comparer (simplifiÃ© - script rÃ©el doit parser correctement)
REPLICA1_SEQ=$(echo $REPLICA1_POS | cut -d'-' -f3)
REPLICA2_SEQ=$(echo $REPLICA2_POS | cut -d'-' -f3)

if [ "$REPLICA1_SEQ" -ge "$REPLICA2_SEQ" ]; then
  PROMOTED_HOST=$REPLICA1_HOST
  PROMOTED_NAME="Replica1"
  OTHER_HOST=$REPLICA2_HOST
  OTHER_NAME="Replica2"
else
  PROMOTED_HOST=$REPLICA2_HOST
  PROMOTED_NAME="Replica2"
  OTHER_HOST=$REPLICA1_HOST
  OTHER_NAME="Replica1"
fi

echo "Selected candidate: $PROMOTED_NAME ($PROMOTED_HOST)"
```

### Phase 2 : Promotion

```bash
# 3. Attendre que le candidat ait appliquÃ© tous les Ã©vÃ©nements du relay log
echo "=== Attente application relay log ==="
mariadb -h $PROMOTED_HOST <<EOF
STOP REPLICA IO_THREAD;
-- SQL thread continue Ã  appliquer les Ã©vÃ©nements du relay log
EOF

# Attendre que SQL thread ait tout appliquÃ©
while true; do
  SQL_RUNNING=$(mariadb -h $PROMOTED_HOST -N -e "SHOW REPLICA STATUS\G" | grep "Slave_SQL_Running:" | awk '{print $2}')
  RELAY_POS=$(mariadb -h $PROMOTED_HOST -N -e "SHOW REPLICA STATUS\G" | grep "Relay_Log_Pos:" | awk '{print $2}')
  EXEC_POS=$(mariadb -h $PROMOTED_HOST -N -e "SHOW REPLICA STATUS\G" | grep "Exec_Master_Log_Pos:" | awk '{print $2}')
  
  if [ "$RELAY_POS" == "$EXEC_POS" ]; then
    echo "All relay log events applied"
    break
  fi
  echo "Waiting for relay log application... ($RELAY_POS / $EXEC_POS)"
  sleep 2
done

# 4. Promouvoir le Replica
echo "=== Promotion de $PROMOTED_NAME ==="
mariadb -h $PROMOTED_HOST <<EOF
STOP REPLICA;
RESET REPLICA ALL;
SET GLOBAL read_only = OFF;
SET GLOBAL super_read_only = OFF;
EOF

echo "$PROMOTED_NAME promoted to Primary"
```

### Phase 3 : Reconfiguration

```bash
# 5. Reconfigurer l'autre Replica
echo "=== Reconfiguration de $OTHER_NAME ==="
mariadb -h $OTHER_HOST <<EOF
STOP REPLICA;
CHANGE REPLICATION SOURCE TO
  SOURCE_HOST = '$PROMOTED_HOST',
  SOURCE_USER = 'repl_user',
  SOURCE_PASSWORD = 'SecurePassword123!',
  SOURCE_USE_GTID = slave_pos,
  SOURCE_SSL = 1,
  SOURCE_SSL_VERIFY_SERVER_CERT = 1;
START REPLICA;
EOF

echo "$OTHER_NAME reconfigured"
```

### Phase 4 : Validation

```bash
# 6. VÃ©rifier la rÃ©plication
echo "=== Validation ==="
sleep 5

mariadb -h $OTHER_HOST -e "SHOW REPLICA STATUS\G" | grep -E "Slave_IO_Running|Slave_SQL_Running|Seconds_Behind_Master|Gtid_Slave_Pos|Last_Error"

# 7. Test d'Ã©criture sur nouveau Primary
echo "=== Test Ã©criture ==="
mariadb -h $PROMOTED_HOST -e "CREATE DATABASE IF NOT EXISTS failover_test; USE failover_test; CREATE TABLE IF NOT EXISTS test (id INT, ts TIMESTAMP); INSERT INTO test VALUES (1, NOW());"

# VÃ©rifier rÃ©plication
sleep 2
mariadb -h $OTHER_HOST -e "SELECT COUNT(*) FROM failover_test.test;"

echo "=== Failover completed successfully ==="
echo "New Primary: $PROMOTED_NAME ($PROMOTED_HOST)"
echo "Replica: $OTHER_NAME ($OTHER_HOST)"
```

### Phase 5 : Redirection Applicative

```bash
# 8. Mise Ã  jour VIP ou DNS
echo "=== Redirection trafic ==="

# Option A : VIP (keepalived)
# ssh $PROMOTED_HOST "sudo systemctl start keepalived"

# Option B : Mise Ã  jour DNS
# update_dns_record "db-primary.example.com" "$PROMOTED_HOST"

# Option C : Configuration applicative
# update_app_config "database.primary.host" "$PROMOTED_HOST"

echo "Application traffic redirected to new Primary"
```

**DurÃ©e totale estimÃ©e** : 2-5 minutes  
**Impact** : IndisponibilitÃ© 20s - 2 minutes

---

## âœ… Points clÃ©s Ã  retenir

- **GTID rÃ©duit le RTO de 90-95%** (30-60 min â†’ 20s-2 min)
- **Failover automatisable** avec MaxScale, Orchestrator, ou scripts
- **Pas de calcul de position binlog** nÃ©cessaire grÃ¢ce Ã  GTID
- **SOURCE_USE_GTID = slave_pos** permet une reconfiguration automatique
- **gtid_strict_mode = ON** prÃ©vient les Ã©critures accidentelles et split-brain
- **Domain IDs** permettent une gestion granulaire en multi-source
- **RÃ©plication cascade** : Les replicas intermÃ©diaires n'ont pas besoin de reconfiguration
- Le **meilleur candidat** est simplement celui avec le GTID le plus Ã©levÃ©
- **Validation automatique** : Le Replica rattrape automatiquement les transactions manquantes
- ğŸ†• **Optimistic ALTER TABLE (11.8)** : Les DDL lourds ne bloquent plus le failover
- **MaxScale 25.01** : Workload Capture pour replay post-failover
- **RTO production** : < 2 minutes avec GTID vs 30-60 minutes sans GTID
- Le **ROI est immÃ©diat** : Ã‰conomies sur indisponibilitÃ© + rÃ©duction risque

---

## ğŸ”— Ressources et rÃ©fÃ©rences

- [ğŸ“– MariaDB GTID Failover](https://mariadb.com/kb/en/using-mariadb-replication/#failover-with-gtid)
- [ğŸ“– MaxScale Automatic Failover](https://mariadb.com/kb/en/mariadb-maxscale-25-automatic-failover/)
- [ğŸ“– Orchestrator Documentation](https://github.com/openark/orchestrator/wiki)
- [ğŸ“– High Availability Best Practices](https://mariadb.com/kb/en/high-availability-performance-tuning-mariadb/)
- [ğŸ“„ Blog : GTID for Zero-Downtime Failover](https://mariadb.org/gtid-zero-downtime/)
- [ğŸ“„ MaxScale 25.01 Release Notes](https://mariadb.com/kb/en/maxscale-2501-release-notes/)

---

## â¡ï¸ Section suivante

**13.5 RÃ©plication multi-source** : Nous allons explorer en dÃ©tail la rÃ©plication multi-source, ses cas d'usage, sa configuration avancÃ©e et les patterns d'architecture pour consolider plusieurs bases de donnÃ©es.

---


â­ï¸ [RÃ©plication multi-source](/13-replication/05-replication-multi-source.md)
