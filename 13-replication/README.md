ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 13. RÃ©plication MariaDB

> **Niveau** : AvancÃ©  
> **DurÃ©e estimÃ©e** : 8-10 heures  
> **PrÃ©requis** : 
> - MaÃ®trise des concepts de transactions et ACID (Chapitre 6)
> - ComprÃ©hension des binary logs (Section 11.5)
> - Connaissance des architectures distribuÃ©es
> - ExpÃ©rience en administration systÃ¨me Linux

## ğŸ¯ Objectifs d'apprentissage

Ã€ l'issue de ce chapitre, vous serez capable de :

- Comprendre les diffÃ©rents modes de rÃ©plication (asynchrone, semi-synchrone) et leurs implications
- Configurer une topologie de rÃ©plication Master-Slave (Source-Replica) en production
- Mettre en Å“uvre la rÃ©plication basÃ©e sur les positions binlog et GTID
- DÃ©ployer des architectures avancÃ©es (multi-source, cascade)
- Monitorer efficacement la rÃ©plication et diagnostiquer les problÃ¨mes de lag
- Utiliser les optimisations MariaDB 11.8 pour minimiser le retard de rÃ©plication
- GÃ©rer les opÃ©rations de failover et switchover en toute sÃ©curitÃ©

---

## Introduction

La **rÃ©plication** est l'un des mÃ©canismes fondamentaux permettant d'assurer la **haute disponibilitÃ©**, la **scalabilitÃ© en lecture** et la **redondance des donnÃ©es** dans MariaDB. Elle consiste Ã  copier automatiquement les modifications de donnÃ©es depuis un serveur source (Primary/Master) vers un ou plusieurs serveurs de destination (Replica/Slave).

### Pourquoi la rÃ©plication ?

Dans un environnement de production moderne, la rÃ©plication rÃ©pond Ã  plusieurs besoins critiques :

**ğŸ“ˆ ScalabilitÃ© horizontale**
- Distribution de la charge de lecture sur plusieurs rÃ©plicas
- CapacitÃ© Ã  servir des milliers de requÃªtes SELECT simultanÃ©es
- SÃ©paration des charges OLTP et analytiques

**ğŸ›¡ï¸ Haute disponibilitÃ©**
- ContinuitÃ© de service en cas de panne du serveur primary
- Basculement automatique ou manuel vers un replica
- Temps de rÃ©cupÃ©ration rÃ©duit (RTO/RPO optimisÃ©s)

**ğŸ”„ Redondance des donnÃ©es**
- Protection contre la perte de donnÃ©es
- Copies multiples pour la sÃ©curitÃ©
- PossibilitÃ© de restauration Ã  partir d'un replica

**ğŸŒ GÃ©o-distribution**
- RÃ©plication entre datacenters pour la latence
- ConformitÃ© rÃ©glementaire (donnÃ©es localisÃ©es)
- Disaster Recovery cross-rÃ©gion

**âš™ï¸ Maintenance sans interruption**
- Upgrades progressifs (upgrade replica puis basculement)
- Tests de nouvelles versions en parallÃ¨le
- Backups depuis un replica sans impact sur le primary

### Architecture de base

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PRIMARY       â”‚
â”‚  (Master)       â”‚
â”‚                 â”‚
â”‚  Writes + Reads â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Binary Log
         â”‚ Replication
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REPLICA       â”‚
â”‚  (Slave)        â”‚
â”‚                 â”‚
â”‚  Reads Only     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Le serveur **Primary** :
- Accepte les Ã©critures (INSERT, UPDATE, DELETE)
- Enregistre toutes les modifications dans le **binary log**
- RÃ©pond aux requÃªtes de lecture

Le serveur **Replica** :
- Se connecte au Primary via un thread I/O
- RÃ©cupÃ¨re les Ã©vÃ©nements du binary log
- Les applique via un thread SQL
- RÃ©pond aux requÃªtes de lecture (read-only par dÃ©faut)

---

## Vue d'ensemble du chapitre

Ce chapitre explore la rÃ©plication MariaDB dans tous ses aspects, de la configuration de base aux architectures avancÃ©es.

### 13.1 Concepts de rÃ©plication : Asynchrone vs Semi-synchrone

Nous commenÃ§ons par comprendre les **modes de rÃ©plication** :

**RÃ©plication asynchrone** (par dÃ©faut)
- Le Primary n'attend pas la confirmation du Replica
- Performance maximale mais risque de perte de donnÃ©es
- AppropriÃ©e pour la scalabilitÃ© en lecture

**RÃ©plication semi-synchrone**
- Le Primary attend qu'au moins un Replica ait reÃ§u les Ã©vÃ©nements
- Garantie de durabilitÃ© renforcÃ©e
- LÃ©ger impact sur les performances d'Ã©criture

ğŸ’¡ **Cas d'usage** : La rÃ©plication asynchrone convient aux applications tolÃ©rantes Ã  une perte de donnÃ©es minimale, tandis que la semi-synchrone est recommandÃ©e pour les donnÃ©es critiques.

### 13.2 RÃ©plication Master-Slave (Source-Replica)

Configuration Ã©tape par Ã©tape d'une topologie classique :

- **Configuration du Primary** : activation du binary log, crÃ©ation d'un utilisateur de rÃ©plication
- **Configuration du Replica** : paramÃ©trage du serveur, options de sÃ©curitÃ©
- **Commande CHANGE MASTER TO** : Ã©tablissement de la connexion

```sql
-- Sur le Primary
CREATE USER 'repl_user'@'%' IDENTIFIED BY 'StrongPassword123!';
GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'%';

-- Sur le Replica
CHANGE MASTER TO
  MASTER_HOST='primary.example.com',
  MASTER_USER='repl_user',
  MASTER_PASSWORD='StrongPassword123!',
  MASTER_LOG_FILE='mariadb-bin.000042',
  MASTER_LOG_POS=1234;

START SLAVE;
```

### 13.3 RÃ©plication basÃ©e sur les positions binlog

La mÃ©thode traditionnelle utilise les **coordonnÃ©es binlog** :
- Nom du fichier binlog (`mariadb-bin.000042`)
- Position dans le fichier (`1234`)

âš ï¸ **Limitation** : ComplexitÃ© lors des failovers (nÃ©cessite de calculer la position exacte sur le nouveau Primary)

### 13.4 GTID (Global Transaction Identifier)

Le **GTID** est une rÃ©volution dans la rÃ©plication MariaDB :

```
0-1-1000
â”‚ â”‚  â””â”€â”€â”€ Sequence number
â”‚ â””â”€â”€â”€â”€â”€â”€ Server ID
â””â”€â”€â”€â”€â”€â”€â”€â”€ Domain ID
```

**Avantages dÃ©cisifs** :
- Identification unique de chaque transaction
- Failover automatisÃ© simplifiÃ©
- RÃ©plication multi-source facilitÃ©e
- RÃ©solution automatique des conflits

```sql
-- Activation GTID
SET GLOBAL gtid_strict_mode=ON;
SET GLOBAL gtid_domain_id=0;

-- RÃ©plication avec GTID
CHANGE MASTER TO
  MASTER_HOST='primary.example.com',
  MASTER_USER='repl_user',
  MASTER_PASSWORD='StrongPassword123!',
  MASTER_USE_GTID=slave_pos;
```

ğŸ†• **MariaDB 11.8** : AmÃ©liorations de la gestion GTID pour les topologies complexes et meilleure compatibilitÃ© avec MySQL GTID.

### 13.5 RÃ©plication multi-source

Permet Ã  un Replica de rÃ©pliquer depuis **plusieurs Primary** simultanÃ©ment :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary1 â”‚     â”‚ Primary2 â”‚
â”‚ (Sales)  â”‚     â”‚ (HR)     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Replica   â”‚
        â”‚(Reporting)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cas d'usage** :
- Consolidation de donnÃ©es pour le reporting
- AgrÃ©gation de bases sÃ©parÃ©es
- Migration progressive

### 13.6 RÃ©plication en cascade

Permet de **chaÃ®ner les serveurs** pour rÃ©duire la charge sur le Primary :

```
Primary â†’ Replica1 â†’ Replica2 â†’ Replica3
          (Relay)
```

**Configuration** :
```sql
-- Sur Replica1 (intermÃ©diaire)
SET GLOBAL log_slave_updates=ON;
```

âš ï¸ **Attention** : Augmente la latence de rÃ©plication proportionnellement au nombre de niveaux.

### 13.7 Monitoring et troubleshooting

**Commandes essentielles** :

```sql
-- Ã‰tat dÃ©taillÃ© de la rÃ©plication
SHOW REPLICA STATUS\G

-- ou (ancien nom)
SHOW SLAVE STATUS\G
```

**MÃ©triques critiques** :
- `Slave_IO_Running` : Thread I/O actif ?
- `Slave_SQL_Running` : Thread SQL actif ?
- `Seconds_Behind_Master` : Retard en secondes
- `Last_Error` : DerniÃ¨re erreur rencontrÃ©e

**Diagnostic du lag** :

```sql
-- VÃ©rifier le lag actuel
SELECT 
  TIMESTAMPDIFF(SECOND, 
    ts, 
    NOW()
  ) AS replication_lag_seconds
FROM mysql.heartbeat
WHERE server_id = @@server_id;
```

**Erreurs courantes** :
- **1062 (Duplicate entry)** : Insertion d'une clÃ© dÃ©jÃ  existante
- **1032 (Can't find record)** : Ligne Ã  modifier/supprimer introuvable
- **2003 (Can't connect)** : ProblÃ¨me rÃ©seau avec le Primary

**RÃ©solution** :
```sql
-- Ignorer une erreur ponctuelle (avec prÃ©caution !)
SET GLOBAL sql_slave_skip_counter = 1;
START SLAVE;

-- Ou dÃ©finir des erreurs Ã  ignorer
SET GLOBAL slave_skip_errors = 1062,1032;
```

### 13.8 Failover et switchover

**Failover** (panne du Primary) :
1. Identifier le Replica le plus Ã  jour
2. Promouvoir ce Replica en Primary
3. Reconfigurer les autres Replicas

**Switchover** (maintenance planifiÃ©e) :
1. ArrÃªter les Ã©critures sur le Primary
2. Attendre que tous les Replicas soient synchronisÃ©s
3. Promouvoir le Replica cible
4. Basculer le trafic applicatif

ğŸ’¡ **Outils** : Orchestrator, MHA (Master High Availability), MaxScale Auto-Failover

### 13.9 RÃ©plication semi-synchrone

Garantit qu'au moins un Replica a reÃ§u la transaction avant que le Primary ne confirme le COMMIT :

```sql
-- Sur le Primary
INSTALL SONAME 'semisync_master';
SET GLOBAL rpl_semi_sync_master_enabled=ON;
SET GLOBAL rpl_semi_sync_master_timeout=1000; -- 1 seconde

-- Sur le Replica
INSTALL SONAME 'semisync_slave';
SET GLOBAL rpl_semi_sync_slave_enabled=ON;
```

**Trade-off** :
- âœ… DurabilitÃ© accrue (pas de perte de donnÃ©es en cas de crash)
- âš ï¸ Latence d'Ã©criture lÃ©gÃ¨rement augmentÃ©e

### ğŸ†• 13.10 Optimistic ALTER TABLE pour rÃ©duction du lag

**NouveautÃ© MariaDB 11.8** : Une innovation majeure pour minimiser l'impact des DDL sur la rÃ©plication.

**ProblÃ¨me traditionnel** :
```
Primary executes ALTER TABLE â†’ Blocks writes for 30 minutes
                              â†“
Replica receives binlog event â†’ Blocks replication for 30 minutes
                              â†“
Replication lag: 30+ minutes âŒ
```

**Solution Optimistic ALTER** :
```sql
-- Sur le Primary
SET SESSION alter_algorithm='INSTANT', lock='NONE';
ALTER TABLE large_table ADD COLUMN new_col INT;
```

Le Replica peut appliquer l'ALTER de maniÃ¨re **non-bloquante** :
- Utilise un algorithme optimiste
- Permet aux autres transactions de continuer
- RÃ©duit drastiquement le lag

**Configuration** :
```sql
-- Sur le Replica
SET GLOBAL slave_parallel_threads=4;
SET GLOBAL slave_parallel_mode='optimistic';
SET GLOBAL slave_run_triggers_for_rbr='YES';
```

**RÃ©sultats** :
- Lag rÃ©duit de **80-95%** pour les grosses tables
- ContinuitÃ© de service amÃ©liorÃ©e
- Maintenance moins disruptive

âš ï¸ **PrÃ©requis** : Compatible avec `ALTER ALGORITHM=INSTANT` ou `COPY` selon le cas.

---

## Architecture de rÃ©plication avancÃ©e

### Topologie complÃ¨te

```
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   PRIMARY    â”‚
                  â”‚  (Master)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚             â”‚             â”‚
            â–¼             â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Replica 1 â”‚  â”‚ Replica 2 â”‚  â”‚ Replica 3 â”‚
    â”‚ (Reads)   â”‚  â”‚ (Reporting)â”‚ â”‚ (Backup)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Replica 4 â”‚
                  â”‚ (Cascade) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Bonnes pratiques de production

**1. SÃ©curitÃ©**
```ini
[mysqld]
# Replica en read-only
read_only=1
super_read_only=1

# Utiliser SSL pour la rÃ©plication
ssl-ca=/etc/mysql/ssl/ca-cert.pem
ssl-cert=/etc/mysql/ssl/server-cert.pem
ssl-key=/etc/mysql/ssl/server-key.pem
```

**2. Performance**
```ini
# ParallÃ©lisation de la rÃ©plication
slave_parallel_threads=4
slave_parallel_mode=optimistic

# Optimisation checksum binlog
binlog_checksum=CRC32
master_verify_checksum=ON
slave_sql_verify_checksum=ON
```

**3. FiabilitÃ©**
```ini
# DurabilitÃ© des relay logs
sync_relay_log=1
relay_log_recovery=ON

# Position de rÃ©plication persistÃ©e
relay_log_info_repository=TABLE
master_info_repository=TABLE
```

**4. Monitoring**
```sql
-- Script de monitoring quotidien
SELECT 
  @@hostname AS replica_host,
  CASE 
    WHEN Slave_IO_Running='Yes' AND Slave_SQL_Running='Yes' THEN 'OK'
    ELSE 'ERROR'
  END AS replication_status,
  Seconds_Behind_Master AS lag_seconds,
  Master_Host AS primary_host,
  Master_Log_File AS current_binlog,
  Read_Master_Log_Pos AS binlog_position
FROM information_schema.REPLICA_STATUS;
```

---

## Cas d'usage rÃ©els

### Exemple 1 : E-commerce avec rÃ©plication gÃ©ographique

```
Europe DC              â†â†’              US DC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary  â”‚                      â”‚ Replica  â”‚
â”‚ (Writes) â”‚  â”€ RÃ©plication  â”€â†’   â”‚ (Reads)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      asynchrone      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration** :
- Primary en Europe pour les Ã©critures
- Replica aux US pour les lectures locales
- Latence de rÃ©plication : 100-200ms acceptable
- RÃ©duction de la latence utilisateur : 80%

### Exemple 2 : Reporting sans impact sur la production

```
Production DB          Reporting DB
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary  â”‚          â”‚ Replica  â”‚
â”‚ OLTP     â”‚  â”€â”€â”€â”€â”€â†’  â”‚ OLAP     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      ColumnStore
```

**Avantages** :
- RequÃªtes analytiques lourdes sur le Replica
- Zero impact sur le Primary
- PossibilitÃ© d'utiliser ColumnStore sur le Replica

---

## âœ… Points clÃ©s Ã  retenir

1. **Modes de rÃ©plication** : Asynchrone (par dÃ©faut, performant) vs Semi-synchrone (durable, lÃ©gÃ¨re latence)

2. **GTID** : Remplace avantageusement les positions binlog pour une gestion simplifiÃ©e et un failover automatisÃ©

3. **Monitoring essentiel** : Surveiller `Slave_IO_Running`, `Slave_SQL_Running` et `Seconds_Behind_Master` en permanence

4. **RÃ©plication multi-source** : Permet de consolider plusieurs bases pour le reporting et l'analytique

5. **Semi-synchrone** : Obligatoire pour les donnÃ©es critiques nÃ©cessitant une garantie de durabilitÃ©

6. **Optimistic ALTER TABLE (11.8)** : RÃ©duit drastiquement le lag lors des opÃ©rations DDL sur de grosses tables

7. **ParallÃ©lisation** : Utiliser `slave_parallel_threads` pour accÃ©lÃ©rer l'application des Ã©vÃ©nements

8. **SÃ©curitÃ©** : Toujours configurer `read_only=1` sur les Replicas et utiliser SSL

9. **Failover** : GTID simplifie grandement les opÃ©rations de basculement et de reconfiguration

10. **Testing** : Tester rÃ©guliÃ¨rement les procÃ©dures de failover et de switchover

---

## ğŸ”— Ressources et rÃ©fÃ©rences

### Documentation officielle MariaDB

- [ğŸ“– Replication Overview](https://mariadb.com/kb/en/replication-overview/)
- [ğŸ“– Setting Up Replication](https://mariadb.com/kb/en/setting-up-replication/)
- [ğŸ“– Global Transaction ID (GTID)](https://mariadb.com/kb/en/gtid/)
- [ğŸ“– Semi-synchronous Replication](https://mariadb.com/kb/en/semisynchronous-replication/)
- [ğŸ“– Multi-Source Replication](https://mariadb.com/kb/en/multi-source-replication/)
- [ğŸ“– Parallel Replication](https://mariadb.com/kb/en/parallel-replication/)

### Articles et guides

- [ğŸ”— MariaDB Replication Best Practices (2025)](https://mariadb.com/resources/blog/mariadb-replication-best-practices/)
- [ğŸ”— GTID Migration Guide](https://mariadb.com/kb/en/migrating-to-gtid-based-replication/)
- [ğŸ”— Troubleshooting Replication](https://mariadb.com/kb/en/troubleshooting-replication/)

### Outils

- **Orchestrator** : Gestion automatisÃ©e de topologies de rÃ©plication
- **MHA (Master High Availability)** : Failover automatique
- **MaxScale** : Proxy avec gestion de rÃ©plication intÃ©grÃ©e
- **pt-heartbeat** (Percona Toolkit) : Mesure prÃ©cise du lag

---

## ğŸ“ Prochaines Ã©tapes

AprÃ¨s avoir maÃ®trisÃ© la rÃ©plication, vous Ãªtes prÃªt Ã  aborder :

### â¡ï¸ Chapitre 14 : Haute DisponibilitÃ©

DÃ©couvrez comment construire des architectures **hautement disponibles** avec :
- **Galera Cluster** : RÃ©plication synchrone multi-master
- **MaxScale** : Load balancing et query routing
- **Failover automatique** : Solutions de basculement intelligent
- Architectures de **disaster recovery**

La rÃ©plication est la fondation ; la haute disponibilitÃ© est l'Ã©difice que vous allez construire dessus !

---


â­ï¸ [Concepts de rÃ©plication : Asynchrone vs Semi-synchrone](/13-replication/01-concepts-replication.md)
