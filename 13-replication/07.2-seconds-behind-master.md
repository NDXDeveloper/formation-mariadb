üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.7.2 Seconds_Behind_Master et lag

> **Niveau** : Avanc√©  
> **Dur√©e estim√©e** : 2-3 heures  
> **Pr√©requis** : 
> - Section 13.7.1 (SHOW REPLICA STATUS)
> - Section 13.4 (GTID)
> - Compr√©hension des architectures de r√©plication
> - Notions de performance et tuning

## üéØ Objectifs d'apprentissage

√Ä l'issue de cette section, vous serez capable de :
- Comprendre pr√©cis√©ment comment Seconds_Behind_Master est calcul√©
- Identifier les causes du lag de r√©plication et leurs impacts
- Diagnostiquer et r√©soudre les probl√®mes de lag
- Utiliser des m√©triques alternatives et compl√©mentaires
- Optimiser la r√©plication pour minimiser le lag
- Mettre en place un monitoring avanc√© du lag
- Exploiter les nouveaut√©s MariaDB 11.8 pour r√©duire le lag
- Comprendre les limitations de Seconds_Behind_Master

---

## Introduction

Le **lag de r√©plication** (ou **replication lag**) est le **retard temporel** entre le moment o√π une transaction est valid√©e sur le Primary et le moment o√π elle est appliqu√©e sur le Replica. C'est une m√©trique **critique** pour :

- **Coh√©rence des donn√©es** : Un Replica en lag affiche des donn√©es obsol√®tes
- **Haute disponibilit√©** : Un Replica avec lag important ne peut pas √™tre promu rapidement
- **Performance applicative** : Les lectures sur Replica peuvent retourner des donn√©es p√©rim√©es
- **Monitoring** : D√©tection pr√©coce de probl√®mes de r√©plication

La m√©trique **Seconds_Behind_Master** est l'indicateur principal pour mesurer ce lag, mais elle a des **limitations importantes** qu'il faut comprendre pour l'interpr√©ter correctement.

### Contexte : Pourquoi le lag existe-t-il ?

```
Primary                          Replica
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Transaction ‚îÇ                 ‚îÇ I/O Thread  ‚îÇ
‚îÇ   T1        ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ‚îÇ  (lit)      ‚îÇ
‚îÇ  commit@    ‚îÇ                 ‚îÇ             ‚îÇ
‚îÇ  10:00:00   ‚îÇ                 ‚îÇ Relay Log   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ             ‚îÇ
                                ‚îÇ SQL Thread  ‚îÇ
                                ‚îÇ (applique)  ‚îÇ
                                ‚îÇ   T1        ‚îÇ
                                ‚îÇ commit@     ‚îÇ
                                ‚îÇ 10:00:05    ‚îÇ
                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Lag = 10:00:05 - 10:00:00 = 5 secondes
```

Le lag existe car :
1. **Transfert r√©seau** : Temps pour envoyer les √©v√©nements binlog
2. **√âcriture relay log** : Temps pour √©crire dans le relay log
3. **Application SQL** : Temps pour ex√©cuter les transactions sur le Replica
4. **Saturation ressources** : CPU, RAM, I/O limit√©s sur le Replica

---

## Calcul de Seconds_Behind_Master

### Algorithme de calcul

```
Seconds_Behind_Master = Horloge_actuelle_Replica - Timestamp_derni√®re_transaction_ex√©cut√©e
```

**D√©tail du processus** :

```sql
-- 1. Chaque √©v√©nement dans le binlog a un timestamp
-- Exemple d'√©v√©nement binlog :
#201213 10:00:00 server id 1  end_log_pos 12345
BEGIN
/*!*/;
# at 12345
#201213 10:00:00 server id 1  end_log_pos 12450
INSERT INTO orders VALUES (1, 'item', NOW());
COMMIT
/*!*/;

-- 2. Le SQL thread ex√©cute cet √©v√©nement
-- Il note le timestamp : 10:00:00

-- 3. √Ä l'instant t (disons 10:00:05), MariaDB calcule :
Seconds_Behind_Master = 10:00:05 (maintenant) - 10:00:00 (timestamp √©v√©nement)
                      = 5 secondes
```

### Code source MariaDB (simplifi√©)

```c
// Pseudo-code bas√© sur le code source MariaDB

time_t current_time = time(NULL);
time_t event_timestamp = rli->last_master_timestamp;

if (event_timestamp == 0) {
  // Pas encore d'√©v√©nements ex√©cut√©s
  seconds_behind_master = NULL;
} else {
  seconds_behind_master = current_time - event_timestamp;
  
  // Ne jamais retourner de valeur n√©gative
  if (seconds_behind_master < 0) {
    seconds_behind_master = 0;
  }
}
```

üí° **Point cl√©** : Seconds_Behind_Master mesure le **temps √©coul√© depuis l'√©v√©nement**, pas le **temps de traitement**.

---

## Interpr√©tation de Seconds_Behind_Master

### Valeurs et signification

```sql
SELECT Seconds_Behind_Master FROM information_schema.SLAVE_STATUS;
```

| Valeur | Signification | Action | Criticit√© |
|--------|---------------|--------|-----------|
| `0` | ‚úÖ Parfait : Replica √† jour | Aucune | ‚úÖ OK |
| `1-30` | ‚úÖ Excellent : Lag n√©gligeable | Surveiller | ‚úÖ OK |
| `30-60` | ‚ö†Ô∏è Acceptable : Lag faible | Surveiller | ‚ö†Ô∏è Warning |
| `60-300` | ‚ö†Ô∏è Pr√©occupant : Lag mod√©r√© (1-5 min) | Investiguer | ‚ö†Ô∏è Warning |
| `300-3600` | ‚ùå Probl√©matique : Lag √©lev√© (5-60 min) | Action urgente | ‚ùå Critical |
| `> 3600` | ‚ùå Critique : Lag tr√®s √©lev√© (> 1h) | Action imm√©diate | ‚ùå Emergency |
| `NULL` | ‚ö†Ô∏è Ind√©fini : R√©plication arr√™t√©e | V√©rifier √©tat | ‚ö†Ô∏è Alert |

### Seuils recommand√©s par cas d'usage

```sql
-- E-commerce temps r√©el
Acceptable : 0-5 secondes
Warning    : 5-30 secondes
Critical   : > 30 secondes

-- Reporting / Analytics
Acceptable : 0-300 secondes (5 min)
Warning    : 300-1800 secondes (30 min)
Critical   : > 1800 secondes

-- Disaster Recovery (DR)
Acceptable : 0-3600 secondes (1h)
Warning    : 3600-7200 secondes (2h)
Critical   : > 7200 secondes
```

### Cas sp√©ciaux

**1. Seconds_Behind_Master = NULL**

```sql
Seconds_Behind_Master: NULL
```

**Causes possibles** :
- R√©plication **arr√™t√©e** (STOP REPLICA)
- R√©plication **en d√©marrage** (juste apr√®s START REPLICA)
- Aucun √©v√©nement ex√©cut√© encore
- Erreur grave de r√©plication

**V√©rification** :

```sql
-- V√©rifier l'√©tat des threads
SELECT 
  Slave_IO_Running,
  Slave_SQL_Running,
  Seconds_Behind_Master,
  Last_Error
FROM information_schema.SLAVE_STATUS;

-- Si threads = No et SBM = NULL ‚Üí R√©plication arr√™t√©e
-- Si threads = Yes et SBM = NULL ‚Üí D√©marrage en cours, attendre
```

**2. Seconds_Behind_Master avec delayed replication**

```sql
-- Configuration delayed replica (1 heure)
CHANGE REPLICATION SOURCE TO SOURCE_DELAY = 3600;

-- Observation
Seconds_Behind_Master: 3610
SQL_Delay: 3600
SQL_Remaining_Delay: 2400

-- Lag R√âEL = Seconds_Behind_Master - SQL_Delay
Lag r√©el = 3610 - 3600 = 10 secondes  ‚úÖ OK
```

üí° **Important** : Toujours soustraire `SQL_Delay` du `Seconds_Behind_Master` pour obtenir le lag r√©el.

---

## Limitations de Seconds_Behind_Master

### Limitation 1 : Bas√© sur les timestamps d'√©v√©nements

**Probl√®me** : Ne refl√®te pas le **temps de traitement r√©el**.

**Exemple** :

```
Sc√©nario :
- Primary : Transaction T1 commit √† 10:00:00 (1 ms d'ex√©cution)
- Replica : Transaction T1 commence √† 10:00:05, se termine √† 10:00:35 (30s d'ex√©cution)

Seconds_Behind_Master √† 10:00:10 (pendant l'ex√©cution) :
= 10:00:10 - 10:00:00 = 10 secondes

Seconds_Behind_Master √† 10:00:35 (apr√®s ex√©cution) :
= 10:00:35 - 10:00:00 = 35 secondes

Mais le Replica a rattrap√© ! Il n'y a plus de lag.
```

‚ö†Ô∏è **Impact** : Une transaction longue peut **gonfler artificiellement** le `Seconds_Behind_Master` m√™me si le Replica rattrape ensuite.

### Limitation 2 : Sensible aux horloges d√©synchronis√©es

**Probl√®me** : D√©pend de la **synchronisation horaire** entre Primary et Replica.

**Exemple** :

```
Primary : Horloge √† 10:00:00
Replica : Horloge √† 10:00:30 (30s d'avance, NTP mal configur√©)

Transaction commit sur Primary √† 10:00:00
Appliqu√©e sur Replica √† 10:00:02 (r√©el)

Seconds_Behind_Master = 10:00:02 (horloge Replica) - 10:00:00 (timestamp √©v√©nement)
                      = 2 secondes  ‚úÖ Semble OK

Mais si Replica avait horloge synchronis√©e :
Seconds_Behind_Master = 10:00:32 (horloge r√©elle Replica) - 10:00:00
                      = 32 secondes  ‚ùå Lag r√©el
```

üí° **Solution** : Toujours utiliser **NTP** (Network Time Protocol) pour synchroniser les horloges.

### Limitation 3 : Ne d√©tecte pas l'inactivit√© du Primary

**Probl√®me** : Si le Primary est **inactif**, le lag peut sembler faible.

**Exemple** :

```
10:00:00 - Derni√®re transaction sur Primary
10:05:00 - Maintenant, pas de nouvelles transactions

Seconds_Behind_Master = 10:05:00 - 10:00:00 = 300 secondes

Mais le Replica est √† jour ! Il n'y a juste pas de nouvelles donn√©es.
```

‚ö†Ô∏è **Impact** : `Seconds_Behind_Master` peut √™tre **√©lev√©** m√™me si le Replica a appliqu√© **toutes** les transactions disponibles.

üí° **Solution** : Utiliser les **heartbeats** pour envoyer des √©v√©nements r√©guliers m√™me sans activit√©.

### Limitation 4 : Granularit√© de la transaction

**Probl√®me** : Le lag est mis √† jour **seulement apr√®s un COMMIT**.

**Exemple** :

```sql
-- Sur Primary : Transaction longue (30 minutes)
BEGIN;
-- 30 minutes d'INSERT/UPDATE
COMMIT;  -- commit √† 10:30:00

-- Sur Replica : Pendant les 30 minutes
Seconds_Behind_Master = 0  -- Pas encore de nouveau commit ex√©cut√©

-- Apr√®s le COMMIT (√† 10:30:00)
Seconds_Behind_Master = (maintenant) - 10:30:00
```

‚ö†Ô∏è **Impact** : Le lag **saute brusquement** apr√®s les grosses transactions.

### Limitation 5 : Format binlog STATEMENT vs ROW

**Avec STATEMENT** :

```sql
-- Sur Primary √† 10:00:00
UPDATE orders SET status = 'shipped' WHERE created_at < NOW() - INTERVAL 1 DAY;
-- Affecte 10,000 lignes, ex√©cution : 2 secondes

-- Sur Replica (d√©marre √† 10:00:05)
-- Ex√©cute le m√™me UPDATE : 30 secondes (index diff√©rent)
-- Termine √† 10:00:35

Seconds_Behind_Master = 10:00:35 - 10:00:00 = 35 secondes
```

**Avec ROW** :

```sql
-- Sur Primary √† 10:00:00
-- Binlog contient 10,000 √©v√©nements ROW

-- Sur Replica
-- Applique les 10,000 ROW updates : 20 secondes
-- Termine √† 10:00:25

Seconds_Behind_Master = 10:00:25 - 10:00:00 = 25 secondes
```

üí° **ROW format** donne une **meilleure consistance** du lag (recommand√©).

---

## Causes du Lag de R√©plication

### 1. Charge √©lev√©e sur le Primary

```
Primary g√©n√®re plus d'√©v√©nements que le Replica ne peut en traiter.

Exemple :
- Primary : 10,000 transactions/seconde
- Replica : Capacit√© de 5,000 transactions/seconde
‚Üí Lag cro√Æt de 5,000 transactions/seconde
```

**Diagnostic** :

```sql
-- Sur Primary : TPS (Transactions Per Second)
SHOW STATUS LIKE 'Com_commit';
-- Noter la valeur, attendre 1 seconde
SHOW STATUS LIKE 'Com_commit';
-- TPS = (Valeur_2 - Valeur_1) / 1

-- Sur Replica : V√©rifier throughput SQL thread
SELECT 
  Slave_Transactional_Groups,
  Executed_log_entries
FROM information_schema.SLAVE_STATUS;
-- R√©p√©ter apr√®s 1 seconde pour calculer TPS
```

**Solution** :

```sql
-- Activer la r√©plication parall√®le
SET GLOBAL slave_parallel_threads = 8;
SET GLOBAL slave_parallel_mode = 'optimistic';

-- Ou scale horizontalement (plus de Replicas)
```

### 2. I/O satur√© sur le Replica

```
Disque du Replica trop lent pour suivre le rythme.

Sympt√¥mes :
- Relay_Log_Space croissant
- iowait% √©lev√© (>20%)
- Slow queries sur le Replica
```

**Diagnostic** :

```bash
# V√©rifier I/O wait
iostat -x 1

# V√©rifier taille relay log
mariadb -e "SELECT Relay_Log_Space / 1024 / 1024 AS relay_log_mb FROM information_schema.SLAVE_STATUS"

# V√©rifier slow queries
mariadb -e "SELECT * FROM mysql.slow_log ORDER BY query_time DESC LIMIT 5"
```

**Solution** :

```sql
-- Optimiser InnoDB pour SSD
SET GLOBAL innodb_flush_method = 'O_DIRECT';
SET GLOBAL innodb_io_capacity = 4000;
SET GLOBAL innodb_io_capacity_max = 8000;

-- Augmenter buffer pool
SET GLOBAL innodb_buffer_pool_size = 32G;

-- Ou migrer vers SSD NVMe
```

### 3. Index manquants sur le Replica

```
Requ√™tes qui utilisent des index sur Primary, mais pas sur Replica.

Exemple :
- Primary : UPDATE orders WHERE user_id = 123 (0.01s, utilise index)
- Replica : M√™me UPDATE sans index user_id (5s, full table scan)
```

**Diagnostic** :

```sql
-- Comparer les index entre Primary et Replica
-- Sur Primary
SELECT TABLE_NAME, INDEX_NAME, COLUMN_NAME 
FROM information_schema.STATISTICS 
WHERE TABLE_SCHEMA = 'production'
ORDER BY TABLE_NAME, INDEX_NAME;

-- Sur Replica
-- M√™me requ√™te, comparer les r√©sultats

-- Identifier les requ√™tes lentes sur Replica
SELECT * FROM mysql.slow_log 
WHERE db = 'production' 
ORDER BY query_time DESC 
LIMIT 10;
```

**Solution** :

```sql
-- Ajouter les index manquants sur le Replica
ALTER TABLE orders ADD INDEX idx_user_id(user_id);
```

### 4. Transactions longues

```
Une transaction de 30 minutes bloque toute la r√©plication (si mono-thread).

Exemple :
- Primary : ALTER TABLE huge_table ADD COLUMN status VARCHAR(20);
- Replica : Doit ex√©cuter le m√™me ALTER (30 minutes)
‚Üí Lag = 30 minutes pendant toute la dur√©e
```

**Diagnostic** :

```sql
-- Identifier les transactions longues en cours
SHOW PROCESSLIST;

-- V√©rifier l'√©tat SQL thread
SELECT Slave_SQL_Running_State 
FROM information_schema.SLAVE_STATUS;
-- Ex: "Altering table..."
```

**Solution** :

üÜï **MariaDB 11.8 : Optimistic ALTER TABLE**

```sql
-- Avec Optimistic ALTER, les autres transactions continuent !
-- Configuration (activ√© par d√©faut avec GTID en 11.8)
SET GLOBAL replication_optimize_for_static_plugin_config = ON;

-- Impact :
-- Avant 11.8 : Lag = 30 min pour TOUTES les tables
-- Avec 11.8  : Lag = 30 min pour huge_table seulement
--               Lag < 60s pour toutes les autres tables
```

### 5. R√©seau lent ou satur√©

```
Transfert binlog ralenti par un r√©seau lent ou satur√©.

Sympt√¥mes :
- Read_Master_Log_Pos augmente lentement
- Latence r√©seau √©lev√©e
```

**Diagnostic** :

```bash
# Tester latence r√©seau
ping -c 100 192.168.1.100  # Primary IP
# RTT moyen devrait √™tre < 1ms (LAN) ou < 50ms (WAN)

# Tester bande passante
iperf3 -c 192.168.1.100 -t 30
```

**Solution** :

```sql
-- Activer la compression de r√©plication
CHANGE REPLICATION SOURCE TO SOURCE_COMPRESSION = 1;

-- Optimiser le r√©seau (c√¥t√© infrastructure)
-- Utiliser un r√©seau d√©di√© pour la r√©plication
```

### 6. R√©plication mono-thread

```
Par d√©faut, le SQL thread est mono-threaded.
‚Üí Une seule transaction √† la fois, m√™me si le Primary en ex√©cute 100.

Limitation :
- Primary : 100 threads parall√®les
- Replica : 1 thread SQL
‚Üí Lag inevitable si charge √©lev√©e
```

**Solution** :

```sql
-- Activer la r√©plication parall√®le
SET GLOBAL slave_parallel_threads = 8;  -- 8 threads
SET GLOBAL slave_parallel_mode = 'optimistic';

-- V√©rifier l'activation
SHOW VARIABLES LIKE 'slave_parallel%';

-- Monitorer les threads parall√®les
SELECT 
  COUNT(*) AS active_workers
FROM information_schema.PROCESSLIST
WHERE User = 'system user' 
  AND State LIKE '%Waiting for prior transaction%';
```

---

## M√©triques Compl√©mentaires et Alternatives

### 1. GTID Lag (Nombre de transactions)

Plus pr√©cis que `Seconds_Behind_Master` avec GTID.

```sql
-- Sur Primary
SELECT @@gtid_binlog_pos;
-- R√©sultat : 0-1-10000

-- Sur Replica
SELECT @@gtid_slave_pos;
-- R√©sultat : 0-1-9950

-- Lag GTID = 10000 - 9950 = 50 transactions
```

**Avantage** : Mesure **exacte** du nombre de transactions en retard, ind√©pendant du temps.

**Script de monitoring** :

```sql
-- Cr√©er une vue pour faciliter le monitoring
CREATE OR REPLACE VIEW v_gtid_lag AS
SELECT 
  @@gtid_slave_pos AS slave_pos,
  CAST(SUBSTRING_INDEX(@@gtid_slave_pos, '-', -1) AS UNSIGNED) AS slave_seq,
  -- Stocker la position Primary (n√©cessite heartbeat ou connexion Primary)
  NULL AS master_seq,
  NULL AS gtid_lag
;

-- Requ√™te avec connexion au Primary (via federated ou script externe)
SELECT 
  (SELECT CAST(SUBSTRING_INDEX(@@gtid_binlog_pos, '-', -1) AS UNSIGNED) 
   FROM PRIMARY_CONNECTION) -
  CAST(SUBSTRING_INDEX(@@gtid_slave_pos, '-', -1) AS UNSIGNED) AS gtid_lag;
```

### 2. Relay Log Size Growth Rate

Mesure la **vitesse d'accumulation** du relay log.

```sql
-- Mesure 1
SELECT Relay_Log_Space FROM information_schema.SLAVE_STATUS;
-- R√©sultat : 100000000 (100 MB)

-- Attendre 60 secondes

-- Mesure 2
SELECT Relay_Log_Space FROM information_schema.SLAVE_STATUS;
-- R√©sultat : 110000000 (110 MB)

-- Taux de croissance = (110 - 100) MB / 60s = 170 KB/s
```

**Interpr√©tation** :
- **Taux n√©gatif** : Replica rattrape (bon)
- **Taux nul** : Replica suit le rythme (OK)
- **Taux positif croissant** : Lag augmente (probl√®me)

### 3. Event Throughput (Events/second)

Mesure le **d√©bit d'√©v√©nements** appliqu√©s.

```sql
-- Mesure 1
SELECT Executed_log_entries FROM information_schema.SLAVE_STATUS;
-- R√©sultat : 5000

-- Attendre 10 secondes

-- Mesure 2
SELECT Executed_log_entries FROM information_schema.SLAVE_STATUS;
-- R√©sultat : 5500

-- Throughput = (5500 - 5000) / 10 = 50 √©v√©nements/seconde
```

### 4. Heartbeat Lag

Utilise les **heartbeats** pour mesurer le lag r√©el.

**Configuration** :

```sql
-- Sur Replica : Configurer heartbeat
CHANGE REPLICATION SOURCE TO SOURCE_HEARTBEAT_PERIOD = 10;  -- 10 secondes
```

**Monitoring** :

```sql
SELECT 
  Slave_received_heartbeats,
  Slave_heartbeat_period,
  UNIX_TIMESTAMP() - Slave_last_heartbeat AS seconds_since_last_heartbeat
FROM information_schema.SLAVE_STATUS;

-- Si seconds_since_last_heartbeat > 2 √ó Slave_heartbeat_period
-- ‚Üí Probl√®me de connexion I/O
```

üí° **Avantage** : D√©tecte les probl√®mes m√™me sans transactions sur le Primary.

### 5. Custom Heartbeat Table

M√©thode la plus pr√©cise pour mesurer le lag **end-to-end**.

**Setup** :

```sql
-- Sur Primary : Cr√©er une table de heartbeat
CREATE TABLE heartbeat (
  id INT PRIMARY KEY AUTO_INCREMENT,
  ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  server_id INT
) ENGINE=InnoDB;

-- Cr√©er un √©v√©nement pour ins√©rer p√©riodiquement
CREATE EVENT heartbeat_event
ON SCHEDULE EVERY 5 SECOND
DO INSERT INTO heartbeat (server_id) VALUES (@@server_id);

SET GLOBAL event_scheduler = ON;
```

**Monitoring sur Replica** :

```sql
-- Lag = Diff√©rence entre maintenant et le dernier heartbeat
SELECT 
  TIMESTAMPDIFF(SECOND, MAX(ts), NOW()) AS heartbeat_lag_seconds
FROM heartbeat
WHERE server_id = 1;  -- server_id du Primary

-- R√©sultat : 3 (le Replica a 3 secondes de retard)
```

**Avantages** :
- ‚úÖ Mesure **r√©elle** et **pr√©cise**
- ‚úÖ Ind√©pendant de la charge applicative
- ‚úÖ D√©tecte les probl√®mes de timestamp d'horloge
- ‚úÖ Fonctionne m√™me si Primary inactif

**Script d'automatisation** :

```bash
#!/bin/bash
# check_heartbeat_lag.sh

THRESHOLD=30  # Seuil en secondes

LAG=$(mariadb -N -e "
  SELECT COALESCE(TIMESTAMPDIFF(SECOND, MAX(ts), NOW()), -1)
  FROM heartbeat 
  WHERE server_id = 1
")

if [ "$LAG" -eq -1 ]; then
  echo "CRITICAL: No heartbeat found"
  exit 2
elif [ "$LAG" -gt "$THRESHOLD" ]; then
  echo "CRITICAL: Heartbeat lag is $LAG seconds (threshold: $THRESHOLD)"
  exit 2
else
  echo "OK: Heartbeat lag is $LAG seconds"
  exit 0
fi
```

---

## Optimisation du Lag de R√©plication

### Strat√©gie 1 : R√©plication Parall√®le

**Configuration optimale** :

```sql
-- Nombre de threads = Nombre de CPU cores / 2
SET GLOBAL slave_parallel_threads = 8;

-- Mode optimistic (recommand√© pour MariaDB 11.8)
SET GLOBAL slave_parallel_mode = 'optimistic';

-- Taille de la queue
SET GLOBAL slave_parallel_max_queued = 131072;

-- V√©rifier l'effet
SHOW STATUS LIKE 'Slave_parallel_workers';
SHOW STATUS LIKE 'Slave_parallel_batches';
```

**Impact** :

```
Avant (mono-thread) :
- TPS Replica : 2,000
- Lag avec charge 10,000 TPS : Cro√Æt continuellement

Apr√®s (8 threads parall√®les) :
- TPS Replica : 12,000
- Lag avec charge 10,000 TPS : Stable √† 0-5 secondes
```

### Strat√©gie 2 : Optimisation I/O

```sql
-- Configuration InnoDB optimis√©e SSD
SET GLOBAL innodb_flush_method = 'O_DIRECT';
SET GLOBAL innodb_io_capacity = 4000;
SET GLOBAL innodb_io_capacity_max = 8000;
SET GLOBAL innodb_flush_log_at_trx_commit = 2;  -- Moins durable, plus rapide
SET GLOBAL sync_relay_log = 0;  -- Ne pas fsync relay log

-- Buffer pool maximum
SET GLOBAL innodb_buffer_pool_size = 48G;  -- 70-80% RAM
```

‚ö†Ô∏è **Trade-off** : Ces param√®tres am√©liorent les performances mais **r√©duisent la durabilit√©**. Acceptable sur un Replica (donn√©es r√©cup√©rables depuis Primary).

### Strat√©gie 3 : Filtrage S√©lectif

```sql
-- Ne r√©pliquer que certaines bases critiques
CHANGE REPLICATION SOURCE TO
  REPLICATE_DO_DB = 'production',
  REPLICATE_DO_DB = 'analytics';

-- Ignorer les tables temporaires
CHANGE REPLICATION SOURCE TO
  REPLICATE_WILD_IGNORE_TABLE = '%.tmp_%',
  REPLICATE_WILD_IGNORE_TABLE = '%.temp_%';
```

**Impact** : R√©duit le volume de donn√©es √† r√©pliquer ‚Üí Moins de lag.

### Strat√©gie 4 : Compression de R√©plication

```sql
-- Activer la compression (r√©duction bande passante 50-70%)
CHANGE REPLICATION SOURCE TO 
  SOURCE_COMPRESSION = 1,
  SOURCE_COMPRESSION_LEVEL = 6;
```

**Quand utiliser** :
- ‚úÖ R√©seau WAN lent
- ‚úÖ Bande passante limit√©e
- ‚ùå CPU limit√© (compression co√ªteuse en CPU)

### Strat√©gie 5 : Hardware Scaling

**Recommandations** :

| Composant | Minimum | Recommand√© | Optimal |
|-----------|---------|------------|---------|
| **CPU** | 4 cores | 8 cores | 16+ cores |
| **RAM** | 8 GB | 32 GB | 64+ GB |
| **Disque** | SATA SSD | NVMe SSD | NVMe RAID 10 |
| **R√©seau** | 1 Gbps | 10 Gbps | 25+ Gbps |

### Strat√©gie 6 : Optimistic ALTER TABLE (MariaDB 11.8)

üÜï **Nouveaut√© 11.8** : R√©volutionne le lag durant les DDL.

**Avant 11.8** :

```sql
-- Sur Primary : ALTER de 2 heures
ALTER TABLE huge_orders ADD COLUMN status VARCHAR(20);

-- Sur Replica : Tout est bloqu√© pendant 2 heures
Seconds_Behind_Master: 7200  -- 2 heures
-- TOUTES les transactions sont en attente
```

**Avec 11.8 (Optimistic ALTER)** :

```sql
-- M√™me ALTER de 2 heures
ALTER TABLE huge_orders ADD COLUMN status VARCHAR(20);

-- Sur Replica :
-- Table huge_orders : En cours d'ALTER (2h)
-- TOUTES les autres tables : Lag < 60 secondes
Seconds_Behind_Master (global): 7200
Seconds_Behind_Master (autres tables): < 60  -- Via monitoring custom
```

**Configuration** :

```sql
-- Activ√© automatiquement avec GTID en 11.8
SET GLOBAL replication_optimize_for_static_plugin_config = ON;

-- V√©rifier
SHOW VARIABLES LIKE 'replication_optimize%';
```

**Impact concret** :

```
Sc√©nario : E-commerce avec ALTER TABLE de 4 heures

Sans Optimistic ALTER :
- Lag global : 4 heures
- Impact : Toute l'application affiche donn√©es p√©rim√©es de 4h
- Failover impossible pendant 4h

Avec Optimistic ALTER (11.8) :
- Lag table en ALTER : 4 heures (normal)
- Lag autres tables : < 60 secondes
- Impact : Application reste quasi temps-r√©el
- Failover possible √† tout moment (avec gestion de l'ALTER en cours)

ROI : Disponibilit√© applicative pr√©serv√©e pendant les maintenances
```

---

## Monitoring Avanc√© du Lag

### Dashboard Grafana

**Requ√™tes Prometheus** :

```promql
# Lag en secondes
mysql_slave_status_seconds_behind_master

# Alertes
- alert: ReplicationLagHigh
  expr: mysql_slave_status_seconds_behind_master > 60
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Replication lag is {{ $value }}s on {{ $labels.instance }}"

- alert: ReplicationLagCritical
  expr: mysql_slave_status_seconds_behind_master > 300
  for: 2m
  labels:
    severity: critical
  annotations:
    summary: "CRITICAL: Replication lag is {{ $value }}s"
```

**Panels Grafana** :

```
1. Lag temporel (gauge)
   - Vert : 0-30s
   - Orange : 30-300s
   - Rouge : > 300s

2. Lag GTID (graph)
   - Transactions en retard au fil du temps

3. Relay log size (graph)
   - D√©tection accumulation

4. Event throughput (graph)
   - Events/second appliqu√©s

5. Parallel workers (stat)
   - Nombre de threads actifs
```

### Script Python de monitoring complet

```python
#!/usr/bin/env python3
# replication_monitor.py

import mysql.connector
import time
import json
from datetime import datetime

class ReplicationMonitor:
    def __init__(self, host, user, password):
        self.conn = mysql.connector.connect(
            host=host,
            user=user,
            password=password
        )
        self.cursor = self.conn.cursor(dictionary=True)
    
    def get_replication_status(self):
        self.cursor.execute("SHOW REPLICA STATUS")
        status = self.cursor.fetchone()
        
        if not status:
            return {"error": "Not a replica or replication not configured"}
        
        # Calculer le lag GTID
        gtid_lag = None
        if status['Using_Gtid'] != 'No':
            io_pos = status['Gtid_IO_Pos']
            slave_pos = status['Gtid_Slave_Pos']
            if io_pos and slave_pos:
                io_seq = int(io_pos.split('-')[-1])
                slave_seq = int(slave_pos.split('-')[-1])
                gtid_lag = io_seq - slave_seq
        
        return {
            "timestamp": datetime.now().isoformat(),
            "io_running": status['Slave_IO_Running'] == 'Yes',
            "sql_running": status['Slave_SQL_Running'] == 'Yes',
            "seconds_behind_master": status['Seconds_Behind_Master'],
            "gtid_lag": gtid_lag,
            "relay_log_space_mb": status['Relay_Log_Space'] / 1024 / 1024,
            "last_error": status['Last_Error'],
            "parallel_mode": status.get('Parallel_Mode'),
            "executed_entries": status['Executed_log_entries']
        }
    
    def check_health(self):
        status = self.get_replication_status()
        
        if "error" in status:
            return {"status": "ERROR", "message": status["error"]}
        
        # V√©rifications
        if not status["io_running"] or not status["sql_running"]:
            return {"status": "CRITICAL", "message": "Replication stopped", "details": status}
        
        lag = status["seconds_behind_master"]
        if lag is None:
            return {"status": "WARNING", "message": "Lag is NULL", "details": status}
        
        if lag > 300:
            return {"status": "CRITICAL", "message": f"Lag is {lag}s", "details": status}
        elif lag > 60:
            return {"status": "WARNING", "message": f"Lag is {lag}s", "details": status}
        else:
            return {"status": "OK", "message": f"Healthy (lag: {lag}s)", "details": status}
    
    def close(self):
        self.cursor.close()
        self.conn.close()

# Usage
if __name__ == "__main__":
    monitor = ReplicationMonitor(
        host="localhost",
        user="monitor",
        password="MonitorPass123!"
    )
    
    health = monitor.check_health()
    print(json.dumps(health, indent=2))
    
    monitor.close()
```

---

## ‚úÖ Points cl√©s √† retenir

- **Seconds_Behind_Master** = Temps √©coul√© depuis le timestamp de la derni√®re transaction ex√©cut√©e
- **Valeur cible** : 0-30 secondes pour production temps r√©el, 0-300s pour analytics
- **NULL** signifie r√©plication arr√™t√©e ou en d√©marrage, pas "lag nul"
- **Limitations** : Sensible aux horloges, transactions longues, inactivit√© Primary
- **Soustrayez SQL_Delay** pour obtenir le lag r√©el avec delayed replication
- **GTID lag** (nombre de transactions) est plus pr√©cis que le lag temporel
- **Heartbeat table** personnalis√©e offre la mesure la plus fiable
- **R√©plication parall√®le** (8+ threads) r√©duit drastiquement le lag sous charge
- **Optimistic ALTER TABLE (11.8)** r√©volutionne le lag durant DDL lourds
- **NTP** est obligatoire pour des mesures de lag fiables
- **Monitoring multi-m√©triques** : Combiner SBM + GTID lag + relay log size + heartbeat
- Toujours **monitorer le taux de croissance** du lag, pas seulement la valeur absolue

---

## üîó Ressources et r√©f√©rences

- [üìñ Replication Lag Documentation](https://mariadb.com/kb/en/replication-lag/)
- [üìñ SHOW REPLICA STATUS](https://mariadb.com/kb/en/show-replica-status/)
- [üìñ Parallel Replication](https://mariadb.com/kb/en/parallel-replication/)
- [üìñ Optimistic Parallel Replication](https://mariadb.com/kb/en/parallel-replication/#optimistic-mode)
- [üìÑ Blog : Understanding Seconds_Behind_Master](https://mariadb.com/resources/blog/understanding-seconds-behind-master/)
- [üìÑ MariaDB 11.8 : Optimistic ALTER TABLE](https://mariadb.org/optimistic-alter-table/)

---

## ‚û°Ô∏è Section suivante

**13.7.3 Erreurs courantes et r√©solution** : Nous allons explorer les erreurs de r√©plication les plus fr√©quentes, leurs causes et les proc√©dures de r√©solution step-by-step.

---


‚è≠Ô∏è [Erreurs courantes et r√©solution](/13-replication/07.3-erreurs-courantes.md)
